<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3472148444060037</id>
            <title>苹果秋季新品抢先上手：性价比拉满，专业度跃升</title>
            <link>https://www.36kr.com/p/3472148444060037</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472148444060037</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 12:07:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年9月10日凌晨，苹果方面正式发布了全新的iPhone、Apple Watch，以及AirPods机型。对于这些新品，我们三易生活此前已经在《史上改变最大的苹果新品，这次所有人都该满意了》中第一时间进行了相关解析，并在《iPhone 17还没上市，我们先来“评测”关于它的谣言》中与大家一起“鉴赏”了关于此次新品的谣言。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3c1a23aaf15745938c34f0e1e78d367f@000000_oswg42961oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管今年的新iPhone在发布后，很快就已经于各渠道开启了预售活动，而且从京东方面公布的“预售1分钟成交量超去年全天”等数据来看，在全系配置大幅升级、造型也进行了调整后，这一代旗舰iPhone显然具备了比过去更好的“卖相”。但毕竟iPhone 17系列中的三款机型以及其他新品要到9月19日才会开售，因此至少到目前为止，绝大多数朋友还没有机会真正摸到这次的新机。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6cc49f352a3f472f946eb0f706558eb0@000000_oswg46076oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过就在这一大批新机正式开售的前一天，我们三易生活提前“上手”了此次秋季新品发布会上亮相的所有新品。不仅如此，我们还与iPhone全球产品经理VP Kaiann进行了沟通，由此也可以为大家揭秘此次iPhone 17系列在新设计、新功能背后，一些可能还没有被大家注意到的细节。</p>
  <h2><strong>新耳机、新表：外观变化不大，但内部的升级可不小</strong></h2>
  <p>首先，我们来看看苹果方面此次发布的AirPods Pro 3和一大票Apple Watch系列新品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4159a2b79c7542519c2c24dda4b0639b@000000_oswg23428oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于AirPods Pro 3，此前有看过发布会的朋友可能还记得，苹果方面几乎只提到了它的两个升级点，即翻倍的降噪能力以及新增了心率测量功能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_21cea39f9a5e409a9739f4ab40d1a62d@000000_oswg27868oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>实际上真正拿到手上就会发现，AirPods Pro 3的外观轮廓也有着细微的改动，它的佩戴稳定度对比上代有所增强，这可能是降噪效果改善的其中一环，也有可能是为了更精确的健康监测能力。但不管怎么说，对于特别重视降噪的朋友来说，更牢固的佩戴体验显然是值得高兴的一个改进点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_abc1cab635fe4ed7a3c28339de61cf66@000000_oswg55391oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>相比之下，Apple Watch产品线今年则一口气更新了三款机型，即新的Apple Watch&nbsp;SE 3、Apple Watch Series 11，以及偏硬核登山和潜水表定位的Apple Watch&nbsp;Ultra 3。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_eb6b8e1ed2b14d218c5fd6ecda11f211@000000_oswg55421oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从外观上来看，三者与它们各自的前代机型相比变化不大，Apple Watch&nbsp;Series 11和Apple Watch&nbsp;Ultra 3因为更换了新的Ion-X玻璃表镜，所以屏幕的耐摔性以及屏幕观感上的通透度都有明显提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0bb8e56ca032487ca74fac17dc07e93e@000000_oswg36993oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但与变化不大的外观相比，刚刚亮相的全新“苹果表”都将升级都放在了内涵上。一方面是全新的Watch OS 26在智能手表上也带来了绚丽的液态玻璃界面风格，另一方面，哪怕是定位入门款的Apple Watch&nbsp;SE 3，也配备了与同代旗舰相同的S10芯片。</p>
  <p>换句话说，无论是客观上的性能、算力水平、潜在的健康监测算法复杂度，还是从长远的系统更新周期来说，即便今年的入门款“苹果表”，都要远胜目前市面上其他操作系统的全智能手表竞品。而且考虑到当下各家在智能手表芯片的更新积极性上，没有一个能与苹果相比，所以Apple Watch SE 3很有可能会成为全智能手表这一细分市场里、具备压倒性竞争力的“黑马”。</p>
  <h2><strong>iPhone 17：更大、更多彩，除了高刷屏边框还更窄</strong></h2>
  <p>接下来，我们来看看此次iPhone 17系列的外观设计。毕竟这可能是新机变化最大，同时也最受消费者关注的一个方面。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4ee8fa91cd4e420a9cbc705422150f57@000000_oswg36799oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>首先是“标准版”的iPhone 17，与上代相比，它在机背部分的特征改变可能是最小的。因为它依然采用了垂直排列的胶囊状后摄Deco，结构也依然是大家熟悉的玻璃机背+玻璃Deco饰板，并搭配金属镜头圈的堆叠设计。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_33cde804eced41f8a875f84eb4bcb909@000000_oswg40878oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过作为标准版机型，iPhone 17依然提供同系列机型中最多的配色选择。另一方面，它这次的机身尺寸也不再像过去那么“迷你”，而是来到了与iPhone 17&nbsp;Pro相同的6.3英寸。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3bbb17d8b070462bbbf46452e6ba2a2f@000000_oswg36715oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但这里有一个很有意思的细节，那就是虽然大家都知道iPhone 17这次采用了与iPhone 17&nbsp;Pro相同，具备3000nit峰值亮度、120Hz ProMotion可变刷新率的屏幕。但是无论从官方公布的机身尺寸参数、还是实际观感来看，iPhone 17的机身都似乎要比iPhone 17&nbsp;Pro还更“矮”和“窄”那么一点点。换句话说，它的边框宽度控制得甚至可能比Pro款更好。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8875b83456834faaaebd78d4da361dd8@000000_oswg45102oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且关于苹果今年全系“一视同仁”的这块新屏幕，还有一点值得一提，那就是它首次支持了完全关闭PWM调光的功能。很显然，苹果方面也注意到了消费者对于PWM调光在护眼方面的疑虑，并首次明确做出了技术上的改进。</p>
  <h2><strong>iPhone Air又薄又“尊”，Pro版明确主打专业向</strong></h2>
  <p>接下来是史上最薄的iPhone，仅5.64mm厚度的iPhone Air。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_45fc940215764bea80f4c290dfa03765@000000_oswg50238oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不得不说，它确实是有史以来设计最精密，同时可能也是做工用料最好的一款iPhone。在本世代的机型中，iPhone Air有不少“独占”的设计和用料，其中包括钛合金中框、复杂的一体成型玻璃后盖，以及据称是行业首发的超薄3D打印USB接口。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_655ec49bd07f448c9b37e217df8d6a3a@000000_oswg33591oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且从iPhone Air这次全系低饱和度、强调钛金属质感的配色设计来看，它的定位甚至有可能比iPhone 17 Pro更靠近所谓“尊”和“贵”的概念。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_895128b5b5ff4d20979efe73e1218a7c@000000_oswg45533oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为什么我们会这么讲？因为今年的iPhone 17 Pro和iPhone 17&nbsp;Pro Max，对整机结构、材质，甚至可以说是产品印象都进行了大幅调整。一方面，它们取消了钛金属中框，改用了中框与后盖一体式的铝合金框架设计。另一方面，它们这次的配色、尤其是主推的“星宇橙”版本可谓是相当亮眼且大胆，甚至会让人联想到Apple Watch Ultra系列上橙色打孔表带的那种“狂野感”。</p>
  <p>按照苹果方面的说法，iPhone 17 Pro和iPhone 17&nbsp;Pro Max换用新设计带来了至少三个方面的好处。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c2d072db80034930bd2c2bc5fd4c6c42@000000_oswg35083oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其一，大面积的铝合金框体配合iPhone首次搭载的VC均热板，大幅改善了持续性能释放水平，特别是在长时间游戏和视频拍摄中能带来显著的优势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3b8f149cddb247e68044b0ff2f7e1a90@000000_oswg33242oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其二，iPhone 17 Pro和iPhone 17&nbsp;Pro Max如今的铝合金框架不再只是中框上的“一圈”，而是中框以及后盖上半部分连在一起的整体结构。这就大幅加强了整机的抗冲击和抗扭转能力，也更加符合它们作为专业影像创作设备的耐用性要求。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_cbe4a5d4647d4c208112538c9671a1d0@000000_oswg31010oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第三个好处就比较有意思了，根据苹果营销主管Greg Joswiak和硬件工程主管John Ternus此前在接受其他媒体采访时的说法，更换为定制的铝合金机身后，iPhone 17 Pro和iPhone 17&nbsp;Pro Max还得以实现比此前钛金属或不锈钢版本更多彩的阳极氧化处理。而这，就是我们现在看到的“星宇橙”配色诞生的原因。</p>
  <h2><strong>从影像到性能，新款iPhone都值得更进一步思考</strong></h2>
  <p>除了体验新机，我们三易生活还与iPhone全球产品营销副总裁Kaiann进行了面对面的交流。</p>
  <p>正如前文中提及的那样，不管是从苹果此次在发布会上、还是我们的实际使用感受来说，iPhone 17 Pro和iPhone 17&nbsp;Pro Max的“产品形象”都更像是专业影像创作设备了。所以我们首先提出的问题，就是苹果在增强产品“专业性”的同时，是怎么继续保证非专业用户体验的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5f684df64c734fdc95703816fb1b671b@000000_oswg24393oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对此Kaiann解释到，iPhone的影像设计在这一代产品上的思路非常清晰。对于普通用户，iPhone 17系列的Pro和Pro Max款由于换用了4800万像素、比过去大了56%的全新传感器，所以使得它们在变焦能力上有了极大的提升，足以实现从广角算起最高等效8倍的光学品质变焦（注：如果是从超广角算起，其实是从13mm到200mm的八档）效果。换句话说，哪怕是非专业用户，一上手就能感觉到它们的“望远能力明显更强了”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4f18df9b2c5045f7b44c331938a625be@000000_oswg38716oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>类似的思路也体现在iPhone 17系列此次前摄配置上。一方面，这枚1800万像素的“Center Stage”前摄将传感器面积显著增大，同时它的正方形CMOS设计就意味着可以通过裁切，“自适应”垂直或者横向的各种拍摄方式。</p>
  <p>最绝的是，苹果为这颗前摄还设计了自动扩大视野的机制。当检测到“多人合影自拍”时，就会自动扩大前摄的取景范围，用户无需任何操作就能拍到更为宽广的自拍视场，因此根本就不需要任何的“专业摄影技能”，就能明确感受到iPhone 17系列的影像有显著改进。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6654b3e62405452dbb12dd07791de763@000000_oswg27218oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与此同时，针对专业用户，iPhone 17 Pro和iPhone 17&nbsp;Pro Max首次加入了对ProRes RAW视频编码的支持，首次加入了4K 120FPS杜比视界拍摄功能，首次支持Apple Log2调色和广播级帧率，甚至与专业电影机大厂Blackmagic合作实现了用于专业电影拍摄的Genlock和时间码功能。</p>
  <p>换而言之，当其他厂商都还停留在“专业功能=堆码率或堆帧率”这个阶段时，苹果早已真正地对制片公司、专业电影摄像师的工作流程进行了软硬件两方面的适配。一切都是为了让iPhone能够与那些比它还要再贵几十倍、几百倍的设备协同工作，真正地当做电影摄像机来使用。</p>
  <p>而在性能方面，大家都知道今年的A19 Pro客观上再度实现了智能手机里最高的CPU单核性能。但比起常见的跑分或是炫耀峰值性能，苹果反而在发布会上强调了“A19 Pro的持续性能比前代上涨40%”这个概念。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e4f97fb38f5842ffb774a2c88dccce56@000000_oswg34955oswg750oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>针对这种重视“持续性能”的宣传策略，我们也咨询了Kaiann。得到的答复是，这其实并非苹果在今年才产生的想法，而是一以贯之的设计思路。</p>
  <p>说白了，比起跑分、苹果本就更看重“消费者在实际使用当中、能够用得到的性能水准”。在今年的iPhone 17 Pro和iPhone 17 Pro Max上，通过芯片居中布置、增加激光焊接的VC均热板、采用大面积的铝金属一体成型机身等新设计，A19 Pro的持续性能确实有了巨大的提升，因此才会被选择在发布会上进行了强调。</p>
  <p>当然，这也反过来提醒了我们，那就是对于其他那些同样峰值性能很好看的智能手机SoC来说，它们在实际使用中的性能表现，是否又能做到像苹果这么大的提升幅度呢？不得不说，这或许会给整个手机行业在“衡量设备性能水准”的思路上，打开一个全新的方向。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649895668&amp;idx=2&amp;sn=0f9b5161040ae35770a6d9945996457b&amp;chksm=86da3da161fcc286f75661e3f404ed009be8e26d7d2b78eb29cb08ba13a0dc7a5efe1cfafa00&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472124708362885</id>
            <title>应用材料AMAT：AI全在涨，何时轮到AI Capex“全家桶”？</title>
            <link>https://www.36kr.com/p/3472124708362885</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472124708362885</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 11:50:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>应用材料（AMAT.O）是美国半导体行业中的老牌公司，成立于1967年，至今依然是全球半导体设备行业中的龙头之一。<strong>如果把时间线拉长来看，应用材料AMAT无疑是一个长牛的公司，也一直是半导体产业链中的重要一环。</strong></p>
  <p>而经历50多年的行业沉浮，应用材料为何能“常青不倒”，站稳在千亿美元市值以上？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6610a9a990554625aebd2aad9649157a@000000_oswg203026oswg1080oswg725_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>海豚君将从发展历程、产品能力、行业地位和业务情况等方面对应用材料AMAT进行梳理，并对公司进行相应的业绩测算和投资判断。</p>
  <p>本文主要回答应用材料AMAT的以下问题：</p>
  <p>1）应用材料AMAT的核心产品有哪些，市场竞争力如何？</p>
  <p>2）应用材料AMAT的收入与晶圆制造厂资本开支之间的关系，以及公司产品在逻辑市场和存储市场的表现如何？</p>
  <p>应用材料AMAT能持续成长，稳定的管理层是一个重要因素，公司近50年来总共经历了3任CEO，这保证了公司发展战略的一贯性。从1970年代以来，公司一直都聚焦于半导体设备领域。</p>
  <p>凭借数十年的积累，应用材料AMAT已经在薄膜沉积设备和CMP设备等领域都具备市场领先的水平，同时也与台积电、三星等晶圆制造大厂建立了长期、稳健的合作关系。</p>
  <p><strong>公司通过优势产品打入客户，并打造“设备全家桶”，逐步增加在晶圆厂中的设备种类和份额，从而占到了晶圆制造厂1-2成的资本开支，进一步绑定了晶圆厂。</strong></p>
  <p>应用材料AMAT受益于每一轮的半导体周期，每当半导体制造行业提高资本开支的时候，公司都会迎来再一次业绩的提升。</p>
  <p>详细情况请阅读本文具体内容，而海豚君也会在下篇对应用材料AMAT进行业绩测算和投资判断。</p>
  <p><strong>以下为详细分析</strong></p>
  <h2><strong>一、应用材料的“前世今生”</strong></h2>
  <p><strong>从应用材料(AMAT.O)的业务构成看，公司依然是一个纯粹的半导体设备公司。</strong>目前<strong>公司近8成的收入来自于半导体、显示面板等相关设备</strong>，而其余的2成是设备维护、零部件用量管理等相关服务收入。</p>
  <p>因而实际上，应用材料的全部收入都围绕于设备的销售和售后相关服务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8db15f29337f4703bdba457195d5ee24@000000_oswg45280oswg1071oswg171_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_80089614e083443d9984104e93a5b775@000000_oswg55095oswg882oswg342_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0bee422d15694baaabca7e7cba74ec94@000000_oswg76243oswg1080oswg583_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通过应用材料的发展历程来看，公司的管理层相对比较稳定。公司近50年来总共经历3任CEO，并且每位CEO的任期都达到10年以上。</p>
  <p><strong>①James C. Morgan（1975年-2003年）时期</strong>：1970年代中期半导体行业“衰退危机”中AMAT的救火员，砍掉晶圆制造业务，<strong>聚焦半导体设备领域</strong>。在薄膜沉积设备的基础上，公司陆续收购了Opal（化学抛光设备CMP）、Orbot（检测），进入CMP和检测领域，逐步成为半导体行业的综合设备商；</p>
  <p><strong>②Michael R. Splinter（2003年-2013年）时期</strong>：James奠定了应用材料的业务基本版图，而Splinter时期主要是业务的平稳过渡。此外，公司还收购半导体离子注入龙头Varian，强化了离子注入的市场地位；</p>
  <p><strong>③Gary E. Dickerson（2013年-至今）时期</strong>：随着半导体产业进入先进制程领域，该时期公司推出了Endura®平台（集成半导体薄膜沉积三大马车PVD/ALD/CVD），布局先进封装设备。公司投资50亿美元建EPIC研发中心，聚焦于GAA晶体管、背面供电、3D DRAM等领域的研发。</p>
  <p><strong>而应用材料的发展，本身就是一部“半导体产业的发展史”。</strong>在1970s-1980s年代，应用材料的收入增量主要来自于日本地区。在当时的全球前二十的半导体企业中，日本拥有其中的12家。</p>
  <p>而伴随着三星、海力士以及台积电的崛起，在1990s年代韩国和中国台湾地区逐渐成为应用材料收入来源的前两位。而<strong>在中国大陆地区半导体产业发展的推动下，近年来已经成为应用材料的最大收入来源，收入占比达到3成以上</strong>。</p>
  <p><strong>从应用材料的地区收入变化看，遵循了半导体制造业的产业转移的节奏，依次是“日本-韩国及中国台湾-中国大陆”的过程。而这也反映了公司的产品力，在各个阶段，分别都得到了不同地区客户的青睐。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6c5735dad3fb4096a490294613d8bc0d@000000_oswg25640oswg871oswg364_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_315ae37464d3455ea801e558e49ffc50@000000_oswg55977oswg1080oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>二、应用材料与半导体设备</strong></h2>
  <p>在半导体产业链中，半导体设备主要是位于产业链的上游。下游客户基本上都是台积电、中芯国际等半导体制造厂，半导体设备覆盖了制造环节的整个工序。</p>
  <p>根据SEMI的数据，如果要投资建造一座晶圆制造厂，半导体设备是最大的成本项，大致将占到总成本的70-80%。<strong>作为半导体制造的核心设备，光刻机在设备支出中占30%，刻蚀设备占比约25%，薄膜设备占比约20%左右。换算之下，这三类设备在总成本中就超过了50%。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4628c9ec50e9460f812c72af10d7d8aa@000000_oswg23690oswg725oswg119_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e948a2d848bb4429b19e640cc5a166a1@000000_oswg37941oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>从晶圆制造的过程来看，其中主要有“硅片制造-薄膜沉积-光刻-刻蚀-掺杂-金属互连-封装”这七个环节</strong>。</p>
  <p>如果用更形象地方式，将晶圆制造比成“造大楼”。以上过程可以理解为“<strong>打好地基-铺设防水膜/保温层-画图纸-挖图案-做开关-装电线-做防护”</strong>。其中的<strong>薄膜沉积（做保温层）、光刻（画图纸）和刻蚀（挖图案）</strong>，是晶圆制造中最为核心的环节。</p>
  <p><strong>除光刻以外，应用材料AMAT的设备基本覆盖了晶圆制造的中间环节，尤其是公司能提供产业链中价值量较高的刻蚀设备和薄膜沉积设备。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a347221db8a34656ada481dfa5abc857@000000_oswg55095oswg882oswg342_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>在半导体设备行业中，应用材料AMAT和阿斯麦ASML是全球最大的两家半导体设备企业，占全球半导体设备总销售额的两成以上</strong>。其中阿斯麦的光刻机领域，本身就是半导体设备中价值量最大的一块。而应用材料则主要是凭借完善的产品矩阵，多个环节设备的布局让公司占据了半导体设备领域前二的位置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_dcdae0eab99245809060a6313b6918fc@000000_oswg59983oswg1080oswg595_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>2.1薄膜沉积设备-“铺设防水膜/保温层”</strong></h3>
  <p><strong>薄膜沉积是晶圆制造环节的重要一环，主要是在晶圆上生长出各种导电膜层和绝缘薄膜层。</strong></p>
  <p>具体的过程是，在硅片衬底上沉积一层待处理的薄膜材料，所沉积薄膜材料可以主要有几类：介质材料（二氧化硅、氮化硅、多晶硅等）、金属材料（铜、钨、钛、氮化钛等）和半导体材料（单晶硅、多晶硅等）。</p>
  <p><strong>对于不同的材料和场景，当前主要的薄膜沉积方法有物理气相沉积（PVD）、化学气相沉积（CVD）和原子层沉积（ALD）三类。</strong></p>
  <p><strong>从最终的沉积效果来看，PVD是指向性强（精准覆盖），适合沉积金属材料</strong>；<strong>CVD和ALD</strong>的沉积覆盖性较好，适合<strong>沉积介质材料，其中ALD对薄膜厚度的要求精准度高，但沉积速度较慢</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_75e558720f4f458fab434674b74bfc86@000000_oswg185402oswg1080oswg212_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>应用材料AMAT本身就是以薄膜沉积设备起家，这也是公司主要的收入来源。当前公司依然在薄膜沉积领域占据领先的位置，在PVD、CVD和ALD领域都有布局。</p>
  <p><strong>①物理气相沉积PVD设备：类似“用喷枪把金属熔化后喷在硅片上”，适合镀金属。应用材料AMAT一家独大，优势明显。</strong>全球的PVD设备市场空间约有45亿美元，<strong>其中应用材料的市场份额占据8成以上</strong>，市场中的竞争对手有Ulvac（日）、Evatec（瑞士）等厂商。</p>
  <p>应用材料AMAT自1980年代起主导PVD技术研发，拥有1200+项PVD相关专利，覆盖磁控溅射、离子束沉积等核心工艺，其射频（RF）PVD 技术专利布局直接限制竞争对手进入高端市场。</p>
  <p><strong>②化学气相沉积CVD设备：类似“用气体在硅片表面‘吹’出薄膜”，适合镀绝缘层。应用材料AMAT处于第一梯队，相对领先。全球的CVD设备市场空间约130亿美元，应用材料的市场份额约为30%</strong>，与LAM（21%）、TEL（19%）同处于第一梯队，仍有一定的优势。</p>
  <p><strong>应用材料AMAT的CVD设备覆盖PECVD、LPCVD等全技术路线</strong>，其Endura平台通过模块化设计支持铜互连、钴薄膜、钨栓塞等多种工艺，在3nm节点中实现金属栅极沉积厚度偏差&lt;0.1nm。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fa898734f012405398fd9dd0674b100c@000000_oswg31215oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>③原子层沉积ALD设备：精度最高，像“一片一片叠原子”，适合超薄的膜（比如3nm以下节点，应用材料有一定的市场份额</strong>。全球的ALD设备市场空间约30亿美元，其中应用材料的市场份额预估在1成左右。公司曾经计划并购东京电子，然而收购并未成功（如果顺利将与阿斯麦国际ASMI的市场份额相当）。</p>
  <p><strong>由于ALD设备需与制程工艺深度绑定，阿斯麦国际ASMI、TEL通过与台积电、三星的联合研发早早锁定先进制程订单</strong>，而应用材料AMAT的ALD设备更多作为其“沉积+刻蚀”综合解决方案的补充，未能建立独立的客户粘性，导致在先进制程招标中屡屡错失份额。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6517804d16b74b918316d129243d7c91@000000_oswg31667oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>2.2刻蚀设备-“挖图案”</strong></h3>
  <p>光刻环节类似于给硅片“画设计图”，而在这方面主要是由阿斯麦ASML等光刻设备厂商垄断，应用材料AMAT并未涉及该领域。</p>
  <p>而在光刻之后，需要按图纸将多余的部分挖掉，这便是刻蚀环节。<strong>刻蚀环节，主要是用化学气体或等离子体（类似“高压电产生的带电粒子流”）对着硅片“吹”，把光刻胶上“变软的部分”和下面的薄膜一起“腐蚀掉”，剩下的就是所需要的电路图案</strong>。</p>
  <p><strong>应用材料AMAT目前在刻蚀领域是追随者的角色，大致占据15%的市场份额</strong>。在刻蚀市场中，LAM和东京电子都是市场的领先者。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ca4b49d169b143158103ec189bcfd3ef@000000_oswg31759oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>应用材料的刻蚀设备在TSV工艺中的优势体现在金属填充和介质层沉积环节，其Endura 平台整合了物理气相沉积（PVD）和化学气相沉积（CVD），与刻蚀工艺形成互补，能够通过设备组合提供整体解决方案。</p>
  <p><strong>虽然应用材料AMAT的Centura刻蚀设备能与公司品牌的薄膜沉积等设备协同，但技术能力上仍落后于LAM。</strong>LAM在<strong>低温介质蚀刻</strong>（如 Lam Cryo 3.0）和<strong>高深宽比</strong>（HAR）刻蚀技术方面处于领先地位，拥有Sense.i平台通过AI驱动优化刻蚀均匀性。</p>
  <h3><strong>2.3 CMP设备-化学机械抛光设备</strong></h3>
  <p>化学机械抛光CMP设备可以应用在晶圆材料制造、半导体制造以及封装测试环节。<strong>而在晶圆制造过程中，CMP设备主要用于去除表面多余的材料，以确保后续工艺的顺利进行</strong>。CMP设备作用类似一个“超级压路机”，能把晶圆表面打磨得极其平整，保障后续工艺的精准进行。</p>
  <p><strong>在CMP设备领域，应用材料AMAT也是拥有绝对领先的地位，占据了60%以上的市场份额</strong>。竞争对手主要是日本荏原EBARA，两家公司合计占据了9成以上的市场份额。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4103fc8ce2d54c3bba1ff93eaf9c3a31@000000_oswg32249oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>将两家公司的CMP产品进行对比，可以看出<strong>应用材料AMAT的CMP设备更为领先。公司能提供Mirra（专注于150-200mm）、Reflexion（专注于300mm）两大技术平台</strong>，基本可以满足各类型材料的需求，并能应用于最先进的3nm制程工艺，而日本EBARA的CMP产品只能适用于部分材质。</p>
  <p>虽然日本EBARA的产品具有一定的价格优势，但凭借技术领先优势，应用材料更能获得晶圆制造大厂（台积电等）的认可。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_cc2742ddcb0c4313a80dfa5489757f10@000000_oswg80430oswg864oswg375_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>2.4应用材料在半导体设备领域的优势</strong></h3>
  <p>应用材料AMAT之所以能成长为半导体设备行业的 Top2，主要是基于以下几点优势：</p>
  <p><strong>a）细分领域的领先地位：应用材料AMAT在沉积（PVD、CVD）和抛光（CMP）设备市场都是全球第一的位置</strong>，尤其是PVD设备和CMP设备方面都明显领先于第二位。在这几类设备的领先优势上，有助于公司收获全球大型晶圆制造厂类型（台积电、三星等）的客户；</p>
  <p><strong>b）丰富完善的产品体系</strong>：在半导体制造环节中，应用材料AMAT能提供一系列的产品，包括扩散炉、刻蚀设备、CVD、PVD、ALD、CMP、离子注入设备等，覆盖了从材料的创建、成型到改性、分析等工艺步骤，<strong>是全球唯一能提供整线解决方案的设备商</strong>。</p>
  <p><strong>c）产线兼容能力</strong>：应用材料AMAT的设备能实现整线兼容，同公司的不同设备之间的参数、接口、工艺、操作系统更为一致。<strong>通过整线兼容性，能提高产线良率、降低整体生产成本</strong>。<strong>公司推出的IMS系统就是能在一套系统中完成不同的生产工艺</strong>，提升生产效率的同时，也能降低客户的相应开支；</p>
  <p><strong>d）广泛的客户资源</strong>：基于公司近50年来的半导体设备经验，公司本身已经覆盖了众多主要半导体制造厂，如台积电、三星、英特尔等。大客户需要公司在PVD、CMP方面领先产品的同时，公司优秀的设备整合能力，下游客户才会采购公司更多的半导体设备。</p>
  <p><strong>综合来看，应用材料AMAT当前业务重心集中于半导体设备领域，尤其是薄膜沉积、刻蚀和CMP设备方面。公司在薄膜沉积设备和CMP设备优势的基础上，继续丰富产品种类和拓展产线整合能力，逐渐坐稳了半导体设备领域的领先位置。</strong></p>
  <h2><strong>三、应用材料的下游市场</strong></h2>
  <p>应用材料AMAT的半导体设备收入，主要受下游制造厂资本开支的影响。而将公司的半导体设备下游市场进行拆解，<strong>可以看出公司半导体设备业务中将近7成来自于晶圆代工厂等逻辑类客户（台积电、英特尔等），而其余主要来自于存储类客户（三星、海力士等）</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a1d7b8ba04634b0498d1c4bd456fea8e@000000_oswg72543oswg1080oswg585_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>3.1逻辑类市场</strong></h3>
  <p>晶圆代工及逻辑类市场是公司最大的收入来源，主要是由于半导体中逻辑类的市场需求更为广泛。台积电、英特尔、中芯国际等厂商每年都有大额的资本开支，其中大约有70-80%用于半导体设备购买，包括应用材料AMAT的薄膜沉积设备、刻蚀设备和CMP设备等。</p>
  <p>海豚君整理了全球核心逻辑类七大厂商的年度资本开支情况，其中涵盖了台积电、中芯国际、英特尔、三星晶圆代工业务、联电、格罗方德等公司。</p>
  <p><strong>在2021-2022年，主要是受到半导体大周期的带动，核心逻辑类厂商的资本开支提升明显。而随后半导体周期开始下行，整体的资本开支也有所回落（即使是台积电年度资本开支也从360亿美元收缩至300亿美元）。</strong></p>
  <p><strong>在AI芯片需求，尤其是英伟达GPU、博通ASIC等相关需求的带动下，台积电将2025年的资本开支进一步提升至400亿美元左右（年增近百亿美元）。然而由于其他客户资本开支削减力度较大，台积电的拉升也只是扭转了下滑的颓势，并没有带动逻辑类资本开支的大幅提升。</strong></p>
  <p><strong>半导体设备市场需求仍受到了“英特尔掉队”和“三星低迷”的影响，前者将资本开支下降至180亿美元，后者更是将晶圆代工部门的资本开支砍半（至约35亿美元）。</strong></p>
  <p>整体来看，海豚君预期七大核心逻辑芯片厂商的资本开支合计为760亿美元左右，同比增长1.9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f5d5f942be28479e9b49983b0a51eefe@000000_oswg62893oswg1030oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果将应用材料AMAT的晶圆代工及逻辑类收入与上述的逻辑类核心七大公司的资本开支拟合，大致可以看到，<strong>应用材料半导体设备在逻辑类晶圆制造厂的总资本开支中大约占比在1-2成。</strong></p>
  <p>而近年来应用材料的占比有所提升，主要是受台积电及中国大陆地区的晶圆制造厂资本开支增加的带动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_76c9723fb7e5428f8b95cd4e81d8cc68@000000_oswg54123oswg1032oswg686_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>3.2存储类市场</strong></h3>
  <p>在晶圆代工厂以外，存储类IDM厂也是应用材料AMAT的主要客户，大致占据了公司2-3成的收入份额。</p>
  <p>由于存储行业本身就具有明显的周期性，各公司也会根据行业周期调整资本开支计划。<strong>海豚君整理了核心三大存储厂商（三星存储部门、海力士、美光）的资本开支情况，2022年时上轮存储行业投资的高点，随着周期下行，三大存储厂商的合计资本开支有所回落。</strong></p>
  <p><strong>在AI存储需求的带动下，三大存储厂商的合计资本开支在2025年有望实现50%的提升，达到600亿美元左右。</strong></p>
  <p><strong>在获得英伟达等公司相关的HBM订单后，海力士和美光在2025年都大幅提升了资本开支目标。</strong>而三星由于产品迟迟无法打入英伟达供应链，存储部门的资本开支保持相对平稳。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e6b8a8ac84be46cd94a2830f37c0373c@000000_oswg63882oswg1030oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果将应用材料AMAT的存储类收入（DRAM和Flash memory）与上述的存储核心三大公司的资本开支拟合，大致可以看到，<strong>应用材料半导体设备在存储类IDM厂的总资本开支中大约占比在1成。</strong>相比而言，应用材料AMAT的设备在存储类工厂的占比略低于逻辑类工厂。</p>
  <p><strong>应用材料的半导体设备侧重于逻辑类需求，而LAM更聚焦于存储领域。</strong>比如，LAM的刻蚀设备还开发了Lam Cryo™ 3.0低温刻蚀技术的优势，尤其是对3D NAND存储芯片的制造更为重要，能够满足存储单元垂直堆叠更多层的需求，从而在相同芯片面积上实现更高的存储容量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_38de4d5d4a264774abb11c8d28bfcdf6@000000_oswg53297oswg1030oswg686_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>整体来看，海豚君在本文中主要对应用材料AMAT的产品能力、行业地位和业务情况等方面进行梳理：</p>
  <p><strong>a）应用材料的地区收入变迁，本质是半导体制造产业转移的缩影</strong>。从1970s日本、1990s 韩台到如今中国大陆，其始终贴合核心产能区需求，<strong>既凭借产品力适配不同阶段客户（如台积电、中芯国际），又借产能转移实现收入增长</strong>，中国大陆3成以上的收入占比，印证其对产业趋势的精准把握；</p>
  <p><strong>b）在阿斯麦垄断光刻设备的格局下，应用材料聚焦刻蚀、沉积、CMP等关键环节</strong>，以PVD（市占超80%）、CMP（市占64%）在细分赛道构建壁垒，避开红海竞争的同时，<strong>通过“多设备协同+整线解决方案”，成为晶圆厂除光刻机外的“刚需选择”</strong>，印证细分赛道深耕的战略价值；</p>
  <p><strong>c）逻辑与存储双轮驱动</strong>：面对半导体周期性波动，<strong>应用材料以逻辑市场（占7成收入）为基本盘，对冲存储市场（占2-3成）的强周期风险</strong>。2025年逻辑端借台积电AI芯片需求稳增长，存储端受HBM相关开支反弹的带动，双市场互补布局，使其在行业波动中保持相对稳健。</p>
  <p><strong>综合（a+b+c）来看，应用材料AMAT在半导体设备行业中的地位在短期仍难以被取代，具有明显的稀缺性和稳健性。</strong></p>
  <p>但半导体市场成熟的情况下，公司的性质更多是一个<strong>行业地位稳固的周期股，</strong>明显受半导体晶圆厂和存储厂资本开支周期的影响。当半导体周期较弱时，应用材料的业绩更多是沉寂期；而当半导体周期上升时，应用材料将迎来再一次的跃升。</p>
  <p>而这波AI周期带来的下游需求爆发，在核心客户——晶圆厂当中，由于产能复用（AI芯片可以复用原手机芯片的产线），整体需要增加的资本开支更不多。</p>
  <p>AI对上游晶圆、存储厂的资本开支带动，主要还是在新的HBM存储产线、新的COWOS封装产线。应用材料在存储设备领域并没有优势，优势在拉姆研究，而支柱客户——晶圆代工的产线上，其实主要复用手机“拉练”过的存量产能就差不多了，因此在这波的AI周期当中，AMAT并没有表现出很强的景气度。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzE5MTU3MzA2OQ==&amp;mid=2247557592&amp;idx=1&amp;sn=6ad79e0f597a7c42f363725c196a4e21&amp;chksm=97e7313bc083751795f78aeec52dd84501c286a28acc04fbc344645a8dd66f6c87ee4da8710e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“海豚投研”（ID：haituntouyan）</a>，作者：海豚君，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472136401066626</id>
            <title>全球首个AI基因组诞生，35亿年生命代码重编程，生物学迎「ChatGPT时刻」</title>
            <link>https://www.36kr.com/p/3472136401066626</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472136401066626</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 11:28:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】AI编写「生命代码」成真！今天，斯坦福联手Arc Institute放大招，以噬菌体ΦX174为模板，用AI首次生成基因组。其中，16个成功猎杀大肠杆菌，还能KO耐药菌，堪称生命学的「ChatGPT时刻」。</strong></p>
  <p>人类历史首次，用AI生成全功能基因组！</p>
  <p>1977年，生物化学家Frederick Sanger等人，完成了史上第一个基因组测序——噬菌体ΦX174。</p>
  <p>40多年后的今天，斯坦福联手Arc Institute团队，以ΦX174为起点，用AI首次生成了噬菌体基因组。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_becbec0ba0084d0b847a2798c1458162@46958_oswg257254oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中一个，AI设计的噬菌体基因组，长的是这样子：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f42310f969ea4961a54a378ad542726c@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Evo-Φ36</p>
  <p>简单讲，噬菌体ΦX174是一种「感染大肠杆菌」的病毒，能精准猎杀细菌，却对人体无害。</p>
  <p>过去，设计一个基因组绝非易事，需要考虑繁多的因素，限制了合成生物学领域的进展。</p>
  <p>为此，斯坦福等团队拿出了「秘密武器」——</p>
  <blockquote>
   <p>基于数百万个基因组训练，DNA语言模型Evo 1和Evo 2，能以超乎想象的规模学习基因组的复杂特征。</p>
  </blockquote>
  <p>其工作原理与ChatGPT类似，专门去处理DNA。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d008c567d72947a9b06b846516579475@46958_oswg76734oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文地址：https://www.biorxiv.org/content/10.1101/2025.09.12.675911v1</p>
  <p>他们以噬菌体ΦX174为模板，合成了285条基因组。</p>
  <p>最终显示，16个基因组可有效抑制宿主生长，不仅能精准干掉特定大肠杆菌，还不会误伤其他的菌株。</p>
  <p>有些AI设计的噬菌体，比原始版本复制力更快、竞争力更强，甚至还能对付天然噬菌体难以处理的耐药菌。</p>
  <p>这一实验的成功，意味着什么？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5b1423e3ccfc423b9075c58bf56bee1b@46958_oswg133779oswg1080oswg303_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_448ba25d01e14e138e6ac6373850390a@46958_oswg36986oswg1080oswg159_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>它标志AI在「合成生物学」领域的一次重大突破——</p>
  <blockquote>
   <p>首次成功验证了，AI能完整生成具备生物学功能的噬菌体基因组。</p>
  </blockquote>
  <p>这不仅扩展了人类对生命设计的边界，还为应对「抗生素耐药性」等健康挑战，提供了全新可替代的疗法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a5a56f56d9d04c6fb4590369af5aef34@46958_oswg437363oswg1080oswg457_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>历史首次！AI生成「完整」基因组</strong></h2>
  <p>在最新技术博文中，核心团队详细拆解了，成功设计首批AI生成基因组的秘诀。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_46c67c60c9344228a69d7b72b2431a5f@46958_oswg47139oswg1080oswg235_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不论是设计单个基因，还是一个完整的基因组，都是一项极具挑战的难题。</p>
  <p>以遗传信息存储系统的历史来算，基因组大概存在了40亿年。而DNA基因组的存在，大约有35亿年。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f03a48c0acda47c099641d0e84050a19@46958_oswg136142oswg1080oswg477_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今年2月，Arc Institute曾证明了，基因组基础模型Evo「家族」，可成功生成单个蛋白质或复杂的多组分系统，比如CRISPR-Cas复合体。</p>
  <p>但是设计整个基因组，那又是一个全新的战场！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0443c582124e42aca28b5066d0487708@46958_oswg1176647oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>因为，基因组设计，核心难题在于复杂性：多个基因相互作用，还要维持精妙的平衡，确保复制、宿主特异性和进化适应性。</p>
  <p>这些挑战，在单个蛋白质设计中，根本不会存在。</p>
  <p>为了攻克这一难题，斯坦福Arc Institute团队开发了一系列创新技术，其中包括：</p>
  <ul>
   <li>一个为重叠阅读框定制的基因注释流程；</li>
   <li>用于从基因组语言模型中采样的系统性微调与提示词工程策略；</li>
   <li>一套为合成噬菌体基因组设计的全新筛选方案</li>
  </ul>
  <h3><strong>ΦX174，跨越半个世纪接力赛</strong></h3>
  <p>若要生成合成基因组，还得需要一个可靠的起点。</p>
  <p>噬菌体ΦX174——一种微小的病毒基因组，只有5386个核苷酸，编码11个基因。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b47e940c5eed4b718cf9a6fce45e7c8e@46958_oswg700926oswg1080oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左：ΦX174噬菌体显微照；右：单个ΦX174噬菌体3D结构</p>
  <p>它的大小，刚好在当前DNA合成成本的可承受范围内，却也足够复杂，能考验基因组设计的能力。</p>
  <p>然而，ΦX174基因重叠结构，创造了一个严苛的测试用例：</p>
  <p>一个突变可能影响多个蛋白质，必须多重约束下才能正常工作。</p>
  <p>此外，ΦX174编码了多种调控元件和识别序列，它们精密协同，确保噬菌体在宿主细胞内能被正确包装和复制。</p>
  <p>ΦX174基因组，是一场跨越半个世纪的接力赛。</p>
  <p>1977年，Fred Sanger及其团队的研究，让其成为人类首个完整测序的基因组。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b19994415b544e8bb47e5f0070a7bfb3@46958_oswg345521oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2003年，Craig Venter及其团队首次通过化学方法将其完整合成，证明了基因组可以从零开始构建。</p>
  <p>如今，2025年，团队利用ΦX174作为模板，创造出首批由AI生成的基因组。</p>
  <p>这一演进历程，正标志着定义现代基因组学的核心能力：先学会了读取（测序），接着是写入（合成），而现在是设计（AI生成）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_03081a025e904725831d18afa2092c1f@46958_oswg207376oswg1080oswg499_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">ΦX174基因组</p>
  <h2><strong>AI「基因组工厂」，破解重叠谜题</strong></h2>
  <p>如上所述，ΦX174重叠基因，让标准工具束手无策。因为它只能识别11个基因中的7个。</p>
  <p>为此，研究人员打造了专属注释流程：</p>
  <p>结合开放阅读框（ORF）搜索和噬菌体蛋白数据库的同源性比对，最终成功识别全部基因，甚至预测了部分A*基因。</p>
  <p>这一工具，在评估数千个AI生成的序列时，大显身手。</p>
  <p>研究人员设定了底线——生成的基因组必须预测出，至少7个匹配天然ΦX174蛋白质，确保保留噬菌体「生存工具包」。</p>
  <h3><strong>微调Evo，让AI更懂噬菌体</strong></h3>
  <p>原有的Evo模型，基于海量噬菌体数据训练后，虽能生成序列，但缺乏针对ΦX174精准控制。</p>
  <p>为此，监督微调，成为了不二选择。</p>
  <p>团队又让Evo，在14,466精选的微小噬菌体序列上，继续训练在减少冗余后，模型专攻ΦX174相关变异。</p>
  <p>微调后，通过精心设计的提示词和采样参数，Evo能生成与ΦX174进化相似却又创新的序列。</p>
  <p>这就像给AI一个灵感模板，让它在熟悉中注入新意。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5a1ef5f3f5e142aeaeed9f5638c4ea9d@46958_oswg1503193oswg1080oswg984_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>评估与筛选</strong></h3>
  <p>生成序列后，作者又开发了多维度评估体系，可以检查基因排列、宿主特异性和进化多样性。</p>
  <p>关键是，确保AI噬菌体能感染，实验用的非致病菌株——C型大肠杆菌。</p>
  <p>于是，他们要求序列中包含与ΦX174相似的刺突蛋白，因为该蛋白决定了ΦX174的宿主范围。</p>
  <p>实验证明，所有16个功能性噬菌体，都对C型大肠杆菌，以及W型大肠杆菌，具有严格的靶向性。</p>
  <p>而且，其对其他六种测试菌株无效。</p>
  <p>这恰恰证明了，宿主特异性可以在基因组中，其他区域显著进化的同时得以维持。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ea071965800248b0adc602bdb440bdee@46958_oswg207937oswg1080oswg653_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>2小时「团灭」细菌，全新噬菌体诞生</strong></h2>
  <p>传统噬菌体研究慢而繁琐，研究人员又创新了筛选流程。</p>
  <p>他们用Gibson组装合成基因组，转化至感受态C型大肠杆菌中，然后在96孔板中监测其生长抑制情况。</p>
  <p>成功感染，会让细菌密度（OD₆₀₀）在2-3小时内暴跌。</p>
  <p>这个方案，让团队能快速测试285个设计，最终验证了16个功能性噬菌体，并表征它们的适应性和宿主范围。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_67d6933c466645709311ac86c98dc98c@46958_oswg121882oswg1080oswg354_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">评估AI设计噬菌体的实验检测</p>
  <p>这些AI基因组携带了67-392个，相较于其最近似天然基因组的新突变。</p>
  <p>其中，Evo-Φ2147携带了392个突变，与噬菌体NC51的平均核苷酸同一性为93.0%。</p>
  <p>根据某些分类学标准，它足以被认定为一个新物种。</p>
  <p>另外，13个基因组包含自然界未见的突变，证明Evo能够利用自然进化从未涉足过的序列空间。</p>
  <p>一个非常有趣的发现是，合成噬菌体之一Evo-Φ36整合了，远亲噬菌体G4的DNA包装蛋白——J蛋白（25 vs 38个氨基酸）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_1997379546a843d68b8f131218929f20@46958_oswg626250oswg1080oswg639_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这在以往，是一个未能攻克的工程性难题。</p>
  <p>研究人员通过冷冻电镜看到，它以独特方式嵌入衣壳结构，AI巧妙地协调补偿突变，让全新蛋白质组合得以正常运作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_cd890c9502204c4e8603ce7e386457a3@46958_oswg335859oswg1080oswg358_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>跨代追杀「耐药菌」，5次逆转</strong></h3>
  <p>细菌的抗生素耐药性，是现代医学面临的最紧迫挑战之一，每年有数十万，甚至更多人因此丧生。</p>
  <p>细菌能够迅速进化出对传统抗生素的耐药性，却极大地限制了治疗效果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c96a1cbb0da94abd850b92388b9b7ecb@46958_oswg24679oswg1080oswg213_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而噬菌体疗法有望逆转，但自然噬菌体往往跟不上细菌进化。</p>
  <p>在研究中，研究团队诱导了，三种对ΦX174具有耐药性的C型大肠杆菌菌株，这些菌株的waa操纵子（负责修饰细菌表面受体）发生了突变。</p>
  <p>结果显示，AI生成的噬菌体「鸡尾酒」（cocktails），在1-5次传代内攻克了三种耐药菌株。</p>
  <p>然而，单独使用ΦX174，则完全无效。</p>
  <p>值得一提的是，这些实现突破的噬菌体，是「嵌合基因组」。它们融合多个AI片段，突变集中在受体交互区。</p>
  <p>序列分析表明，成功的噬菌体，结合了2-3种不同AI设计的遗传元件。</p>
  <p>这样一来，人类无需依赖自然界稀有的噬菌体，而让AI直接生成多样群体，形成「多重打击」，让细菌难以发展出全面的耐药性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e0dadfa3a2cc4a52869a78116a1d93e0@46958_oswg203174oswg1080oswg515_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>总而言之，AI能快速筛选出有效的基因序列，这就让噬菌体疗法不再是碰运气的「试错」，而是精准的「设计」。</p>
  <p>未来，人类能主动设计出领先一步的疗法，永远跑在细菌变异的前面。</p>
  <h2><strong>基因革命2.0，编写生命代码</strong></h2>
  <p>如今，噬菌体疗法，正日益成为对抗多重耐药菌的有效武器。</p>
  <p>近期，医学上的治疗靶点，主要针对植物病原体，或是大型DNA噬菌体。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ed9e36afe36b4872b3b15968d039c945@46958_oswg453286oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最新研究证明，AI模型已能捕捉进化约束，通过训练、质控和高质量验证，桥接AI生成序列与生物学现实。</p>
  <p>随着模型迭代和合成成本下降，全基因组设计将开启未探索的进化空间，为生物技术和基础研究开辟全新的疆域。</p>
  <p>从读取到写入，再到设计，这一转变，标志着人类在最基础的层面上改造生物学的能力，翻开了新的篇章。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fa4e349b9f7e462799dc92499bc3e764@46958_oswg1227332oswg1080oswg680_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>核心作者</strong></h2>
  <p><strong>Brian Hie</strong></p>
  <p>我是斯坦福大学化学工程系的助理教授，以及Arc Institute创新研究员，致力于生物学与人工智能交叉领域的研究。</p>
  <p>他曾获得了MIT CSAIL博士学位，本科就读于斯坦福大学。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f3da7bd377cd4d068e01b0bda4ae01af@46958_oswg969974oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Samuel King</strong></p>
  <p>Samuel King是斯坦福大学博士研究生，目前在Arc Institute从事合成生物学与ML交叉领域的研究工作。</p>
  <p>他本科毕业于哥伦比亚大学（UBC），获得生物学荣誉学士学位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b90c3d171766439683dce09b2deb80a0@46958_oswg346131oswg480oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>参考资料：</p>
  <p>https://x.com/samuelhking/status/1968329299364376698 https://www.biorxiv.org/content/10.1101/2025.09.12.675911v1 &nbsp;</p>
  <p>https://arcinstitute.org/news/hie-king-first-synthetic-phage&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bFDVn0JN0OvKwsmMauxgPg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：桃子，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472125516012169</id>
            <title>工信部出手，组合驾驶辅助系统迎来强制性国家标准，专家：可避免因盲目使用导致恶性交通事故</title>
            <link>https://www.36kr.com/p/3472125516012169</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472125516012169</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 11:25:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>L3级智能驾驶车即将“入市”，监管部门对已规模化量产搭载的组合驾驶辅助（即L2级智能驾驶）再次划定安全基线。</p>
  <p>9月17日，工业和信息化部对《智能网联汽车组合驾驶辅助系统安全要求》强制性国家标准公开征求意见（以下简称《标准》），主要内容涉及提升产品能力表现、强化安全保障要求、规范系统使用方式三个维度。</p>
  <p>《标准》填补了我国组合驾驶辅助系统产品安全基线空白，为行业准入、质量监督和事后追溯提供关键技术依据。公开数据显示，今年1至7月，我国具备组合驾驶辅助系统的乘用车新车销量为775.99万辆，同比增长21.31%，渗透率为62.58%，较上一年增加了6.5个百分点。</p>
  <p>“组合驾驶辅助系统虽规模化应用，但仍存在产品性能缺乏统一基线、营销与使用环节风险外溢的问题。”《标准》中提到，受感知方案、控制策略及交互逻辑差异影响，不同车企产品组合驾驶辅助系统在混合交通、占道施工等复杂场景下的可靠性、稳定性差距显著，既易致用户误判功能边界、形成过度依赖，也对道路交通安全构成潜在威胁。</p>
  <p>与此同时，部分企业在宣传中滥用“高阶智驾”“零接管”等概念，刻意模糊“驾驶辅助”与“自动驾驶”界限，淡化系统局限，致使个别驾驶员放松警觉，出现长时间脱手、分心等危险行为，酿成伤亡事故。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0a9040af47ca486d9cbf6b3eb8491579@46958_oswg71204oswg1080oswg541_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：工业和信息化部官网&nbsp;</p>
  <p>北方工业大学汽车产业创新研究中心主任纪雪洪在接受《每日经济新闻》记者采访时表示：“目前各个车企在智驾领域的技术能力、技术储备不同，《标准》的出台可以避免部分盲目相信组合驾驶辅助系统的消费者，出现恶性的交通事故。”</p>
  <p>当前，市面上的智能辅助驾驶功能都处于L2级，即汽车仅可在限制条件下自动转向、加速和刹车，方向盘不可脱手。L2级离完全无人驾驶（L5级）还隔着“有条件的自动化”（L3级，驾驶员需在规定时间内接管驾驶）和“高度自动化”（L4级，自动驾驶功能不能继续时，乘客在提示下接管汽车）两道坎。</p>
  <p>此次《标准》中明确提到，“组合驾驶辅助系统每次上电/点火后确认驾驶员是否完成了使用培训，确认后方可激活；组合驾驶辅助系统要具备手部脱离检测以及视线脱离检测能力，一旦系统激活期间驾驶员出现手部脱离、视线脱离，应发出提示以及报警，并在驾驶员未及时响应系统报警的前提下可控地退出激活状态。”</p>
  <p>为了确保驾驶者能够正确使用组合驾驶辅助系统，《标准》要求驾驶员脱离导致系统执行风险减缓功能，或者发生了一定次数的手部脱离或视线脱离后，在一定时间内禁止再次使用组合驾驶辅助系统。</p>
  <p>目前市场上销售的汽车所搭载的“智驾”系统，都还没有实现“自动驾驶”的目标，还暂时停留在辅助驾驶阶段，因此驾驶人才是最终责任主体，是行车安全的第一责任人。如果驾驶人在车辆行驶过程中“脱手脱眼”（即双手脱离方向盘、视线脱离路况），不仅存在严重道路交通安全风险，还可能面临民事赔偿、行政处罚及刑事追责三重法律风险。</p>
  <p>记者注意到，《标准》的建议实施日期为2027年1月1日。这也意味着，车企将有两年的准备时间。“此次《标准》对车企而言，挑战是相对的，按照惯例征求意见稿后续还会再调整，对车企来说还有缓冲时间。”纪雪洪告诉记者，《标准》对智驾技术领先的企业来说显然更容易实现，对技术能力储备不多的车企仍具有一定挑战，比如智驾测试数据记录、实验方法等方面挑战较大。</p>
  <p>实际上，一些头部车企和供应商汽车安全厂商在手部脱离检测以及视线脱离检测领域技术已比较成熟，但目前仅广泛用于中高端车型。一位车企智驾研发工程师告诉记者：“手部脱离检测以及视线脱离检测，从技术的角度上来说实现起来并不难。”</p>
  <p>当前，加快制定组合驾驶辅助系统安全底线标准、厘清宣传红线，成为监管、行业与公众的普遍共识与迫切诉求。今年4月，工信部装备工业一司组织召开智能网联汽车产品准入及软件在线升级管理工作推进会，强调车企要明确系统功能边界和安全响应措施，不得进行夸大和虚假宣传。</p>
  <p>纪雪洪认为：“这次《标准》将引导整个行业健康发展，能够规范车企在智驾技术上的过度营销宣传行为，也能够更好地提醒消费者，实现技术创新与安全并重。”</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/g-PWpWoGNSOJb8rZ1hnP0Q" rel="noopener noreferrer nofollow" target="_blank">“NBD汽车”</a>，作者：段思瑶，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472046742017929</id>
            <title>我试戴了Meta AI带屏眼镜：第一次觉得AI眼镜有戏了</title>
            <link>https://www.36kr.com/p/3472046742017929</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472046742017929</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 11:22:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote>
   <p>哇，整个这个眼镜戴上去的感觉太科幻了！</p>
  </blockquote>
  <p>这是我戴上 Meta Ray-Ban Display 的第一反应。说实话，从看到去年 Meta Orion 样机的表现之后，我的期待值原本没有特别高，但真的把 Display 戴在头上，<strong>我突然觉得这个行业有戏。</strong></p>
  <p>在 Meta Connect 2025 发布会上，这副售价 799 美元的「带屏智能眼镜」终于揭开面纱。它是 Meta 首款支持显示功能的智能眼镜，通过右眼的彩色光波导 HUD 和配套的 Neural Band 腕带，把「脸上的 AI」从概念变成了现实。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_bccd895939c84924afcab4a8ad5c627a@000000_oswg182644oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与 Orion 样机类似，Display 采用的显示技术是彩色光波导，这种仅依靠光线在载体内反复折射、将画面反射到镜片中间的技术是目前 AI 眼镜最主流的显示方式。但 Meta 实现了一项很特殊的指标：<strong>低至 2% 左右的漏光率。</strong></p>
  <p>也就是说 HUD 点亮时，你对面的人<strong>完全看不到光波导的反射和漏光</strong>，不像是今年早些时候谷歌推出的 XR 眼镜样机那样会有一个明显的反射区域：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4f9d99d341fc4fc38ee4dec69990f4fe@000000_oswg54568oswg1080oswg397_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">@梦雅Myra 佩戴的 Display，在类似的角度不会出现明显的屏幕漏光</p>
  <p>即使我的朋友站在对面，在屏幕完全点亮时也完全察觉不到。只有从侧面角度，才能看到几排光波导屏幕导线的反光。</p>
  <p>只不过，根据外媒 TheVerge 的上手体验，Meta 这块过于透明的屏幕也有一些弊端：<strong>由于和你对话的人完全看不到你在看什么东西，可能会感觉你有点心不在焉、视线没有集中在人身上。</strong></p>
  <p>至于实际的屏幕显示效果，Display 这块光波导屏幕亮度足足有 5000 尼特，搭配默认标配的光致变色镜片，在光线过强的户外镜片会变成墨镜片，可读性依然非常优秀。</p>
  <h2><strong>单眼显示与神奇的 Neural Band</strong></h2>
  <p>之前我一直担心单眼显示会不会很奇怪，但实际体验完全打消了这个顾虑。我已经连续使用了一个多小时，<strong>最明显的感受是它可以跟现实世界无缝融合</strong>。</p>
  <p>虽然 Display 仅有一块位于右侧的屏幕，但它的单眼显示效果与环境融合的很好，因为屏幕的位置和视场角（FOV）都设计的比较低，在直视的时候屏幕的显示区域会落在对方的胸口处，几乎和电影的字幕是完全一样的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b0897bc0982b43abaf5e52e46fc753a5@000000_oswg353782oswg1080oswg610_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">因为扎克伯格比对方矮，需要低头对话</p>
  <p>这块 600×600 像素的屏幕虽然面积不大，但能做的事情跟手机很像，换句话说，整个显示界面的设计和逻辑完成度都非常高，几乎不会有使用时不知所措的情况。</p>
  <p>比如我用它看 WhatsApp 和 Messenger 消息，整个对话流其实是可以完整显示出来的。通过手指上下滑动翻页，再用语音转文字回复的过程也非常流畅。<strong>我甚至在想，真的可以很长时间不用把手机从兜里掏出来了</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_9cddd257ac35491b854910b1396f9adf@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>而作为 Display 的主要操控方式，配套的 Neural Band 腕带更是改变了游戏规则。</p>
  <p>虽然和苹果 Vision Pro 一样都可以通过手指手势操控，但 Display 并不依赖摄像头，而是借助腕带读取手腕的肌电信号（EMG）来识别的，也就是说<strong>你的手可以放在身体两侧、背在身后、甚至藏在口袋里，手势依然能被准确识别</strong>。</p>
  <p>Neural Band 的主要操作方式包括双击中指点亮屏幕、单击中指退出、单击食指确定、旋转手腕放大，以及用拇指在食指上滑动翻页等等。虽然需要一点学习时间，但是掌握难度并不高，灵敏度也是很优秀的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_27a8814642c04ff7a4f28b90de2fc1c1@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>而 Display 用来处理输入的方式则更加有趣。除了通过耳机上的 6 麦克风阵列做语音输入之外，你其实还可以戴着 Neural Band 直接在平面上写字，腕带会结合肌电信号和陀螺仪识别手写的字母，就像扎克伯格在发布会演示的这样：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_616ea60c19c54ad49c699a36324c5e5c@000000_oswg514884oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>扎克伯格在采访中透露了一个有趣的细节：他已经能用这个系统达到<strong>每分钟30个单词的打字速度</strong>，几乎一整天都在用眼镜收发消息。他的高管们甚至能分辨出哪些消息是用眼镜发的——比如那些长度更短、但是秒回的信息。</p>
  <p>更重要的是，扎克伯格认为 Neural Band 的潜力远不止于此：</p>
  <blockquote>
   <p>（虽然）我们发明 Neural Band 是为了配合眼镜使用，但我认为<strong>它最终可能成为一个独立的平台</strong>。未来，它不仅能通过思维实现个性化自动补全，还可能成为控制其他设备甚至智能家居的方式。</p>
  </blockquote>
  <h2><strong>那些真正打动我的功能</strong></h2>
  <p>如果说戴着 Neural Band 虚空写字像是变成了钢铁侠一样，那眼镜里的实时字幕功能让我感觉获得了超能力。</p>
  <p>唤醒的方式很简单，说一句「Hey Meta, turn on live captions」，对面人口中的英语就会实时显示在屏幕上。<strong>在嘈杂环境里，Display 甚至能准确识别你正在看的那个人的声音</strong>，多个人同时说话也不会混淆。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_34b5284d026647618ab21ff675c6844d@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>并且得益于前面提到过的屏幕位置，戴着 Display 看实时字幕的方式，简直就是把眼前的现实变成了看电影。</p>
  <p>虽然核心软件仍依赖手机连接，但这远不只是一个通知镜像。你可以发送文字、接听音视频电话、显示正在播放的音乐、获取逐向导航指引、查看相机取景，还能运行 Meta AI 识别眼前的物体。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0019123991fc4ecda63d880a5b38175a@000000_oswg81422oswg1080oswg477_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">发布会上演示的 LiveAI实时视觉识别场景</p>
  <p>Meta 的 CTO Bosworth 强调：<strong>清晰的文字渲染是让AI变得有用的关键——</strong>如果 AI 只能语音回复，你获得的信息就有限。而当你提问后它能直接显示答案，这样不仅更直观，也更私密。</p>
  <p>这种基于「你能看到结果」的确定感是普通版 Meta Ray-Ban 智能眼镜的纯语音交互无法给予的，并且在实际生活里，语音唤醒 AI 助手在很多场合是不太方便的，Display 语音/手势/视觉混合交互就不会有这种问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c71bfa6c5b664e968f54d87fb3548264@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p>在体验 Display 的时候，我试着用 Meta 的 AI 功能识别了一幅画。Display 不只是语音回答，还在屏幕上显示了相关的信息卡片，信息密度相比纯语音交互（等 AI 慢慢念完）也更高一些。</p>
  <p>这块小屏幕甚至可以用来预览相机画面，以及看视频——虽然 FOV 很小，但画面大小刚好，细节都能看清。<strong>如果朋友发来视频链接，你可以直接在眼镜上打开查看并快速回复，整个过程不用掏手机</strong>。</p>
  <p>总之 Meta Ray-Ban Display 体验下来，我觉得这副眼镜的核心价值有三点：</p>
  <p><strong>增大信息密度：</strong>哪怕只有一两行字的显示，获取的信息也比纯音频多得多</p>
  <p><strong>给予确定感：</strong>能看到具体的界面、动画和菜单选项，让眼镜的操作更有把握</p>
  <p><strong>成为AI的通路：</strong>AI 能看到你所见，你也能看到它的反馈，让 AI 更无缝地融入日常生活</p>
  <h2><strong>这可能真的是下一个 iPhone 时刻</strong></h2>
  <p>扎克伯格在访谈中的判断很明确：</p>
  <blockquote>
   <p><strong>眼镜将是下一个计算平台</strong>。这是唯一能让AI看到你所见、听到你所听、全天候与你对话的设备。</p>
  </blockquote>
  <p>全球有 10-20 亿人日常佩戴眼镜。五到七年后，这些眼镜中的大部分会不会都变成某种形式的 AI 眼镜？扎克伯格说：我觉得这就像 iPhone 出现时，大家都还在用翻盖手机，但<strong>变成智能手机只是时间问题</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8c6a1bfb06084a67b2a2fde135979f2b@000000_oswg99342oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Meta 瞄准的是「优化主义者」和「追求生产力的人」。虽然初期产量只有几十万副，但 Bosworth 预测「我们生产多少就能卖多少」。扎克伯格也暗示，真正的利润不会来自硬件本身，而是「<strong>来自人们长期使用AI和其他服务」。</strong></p>
  <p>体验结束后，我最大的感受是：Display 不再是概念产品或开发者玩具，而是<strong>真正可以日常使用的工具</strong>。</p>
  <p>虽然 799 美元不算便宜（一台 iPhone 17 也是这个价），20 度的 FOV 和 600×600 的屏幕也不算大，但这些都不妨碍它成为我用过最接近理想的智能眼镜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_7cdc9264cfd94bf8897128b8c2e92d72@000000_oswg141093oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我觉得 Meta Ray-Ban Display 的目标很明确——<strong>减少掏出手机的次数</strong>，把那些快速查看和回复的操作都通过眼镜完成。从这个角度说，它确实做到了。</p>
  <p>或许正如扎克伯格所说，这就像智能手机替代功能机的时刻。智能眼镜的技术拐点已经到来，只是还未完全普及。而 Meta Ray-Ban Display，可能就是这场变革的开始，可能就是下一个 iPhone 时刻。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652425732&amp;idx=1&amp;sn=7fd4afb480e42f807d1059b596bd46be&amp;chksm=9a1ddf28ef0ced193cb630499cda5bdbf0fcbc98d3faa3f3788664b67acc55a11f22d4042245&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：肖钦鹏，马扶摇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472073016154242</id>
            <title>AI替你“剁手”的时代，真的来了</title>
            <link>https://www.36kr.com/p/3472073016154242</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472073016154242</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 11:12:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>距离“百Agent混战”的序幕拉开已近一年，我们每个人的手机里，都或多或少地“饲养”着几个日益聪明的AI智能体（Agent）。多模态大模型的能力边界，早已远超我们去年的想象。</p>
  <p>此刻，你只需对着手机说一句：“根据我的年假和预算，规划一个5天的黄金周旅行，我不想去人多的地方，最好是能徒步和看星星的。”</p>
  <p>几秒钟内，一场完美的旅行计划在你眼前展开。然而，最终你的AI Agent只能无奈地为你献上一连串的支付链接和App跳转弹窗。“机票请点击这里确认”、“酒店请跳转App预授权”……</p>
  <p>这就是2025年，人工智能看似无所不能的时代下，最令人沮丧的“囚徒困境”：<strong>我们创造出了人类有史以来最强大的效率工具，却把它关在了无法与真实世界进行价值交换的数字牢笼里。它能处理世间几乎所有的信息，却无法处理最关键的价值。它拥有超凡的智力，却没有一分钱的“经济权利”。</strong></p>
  <p>但就在近日，谷歌正式推出并联合60多家行业巨头共同推进的<strong>“Agent支付协议”——AP2（Agent Payments Protocol）</strong>。这预示着一个万亿级的“代理商业”（Agentic Commerce）时代，正比我们想象中来得更快。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ad16091edc70410ca73acf9aa4789233@000000_oswg89227oswg1080oswg532_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>今天，硅兔君结合与其硅谷专家团队的交流，将深入拆解AP2协议以及它所指向的商业未来。</strong></p>
  <h2><strong>01</strong></h2>
  <p>为什么强大的Agent始终无法迈出自主交易这“临门一脚”？因为它面前横亘着一座名为“信任”的大山。&nbsp;</p>
  <p>我们现有的整个金融支付体系，是完全围绕<strong>“人”</strong>这个主体建立的。它的每一道安全防线，都建立在对人类行为的预设之上——你亲手输入的密码、你确认“同意”的点击、你独一无二的指纹或面容。&nbsp;</p>
  <p>当执行者从<strong>“你”变成“你的Agent”</strong>时，整个信任的基础就崩塌了。这带来了三个直击灵魂的拷问，也是过去所有AI支付尝试都无法绕开的障碍：&nbsp;</p>
  <p><strong>授权拷问：“商家，你咋信这个AI是我派来的？”</strong></p>
  <p>当一个Agent向航空公司发起订票请求时，航空公司如何100%确定，这个请求真的源于用户的真实授权，而不是一个被黑客劫持、或者出现bug后“自由发挥”的失控程序？如果无法验证授权，任何商家都不敢接受来自一个“机器人”的订单。&nbsp;</p>
  <p><strong>真实性拷问：“这个订单，真是我的意思吗？”</strong></p>
  <p>用户的意图是复杂的、模糊的，而Agent的理解可能出现偏差。如果我对Agent说“帮我订一张去‘Springfield’的机票”，它可能会订到美国几十个同名城市中的任何一个。当Agent把一份错误的订单提交给商家，并用我的钱付了款，这个交易的“真实性”又如何保证？&nbsp;</p>
  <p><strong>权責拷问：“真出了事，买错了东西，到底谁来背锅？”</strong></p>
  <p>这是最致命的问题。如果Agent交易出错，责任在谁？是用户指令模糊？是Agent平台技术有漏洞？还是商家系统对接有问题？在权责不明的情况下，一旦发生纠纷，将是一场噩梦。没有任何一个金融机构或商业平台，敢于大规模涉足这样一个模糊地带。&nbsp;</p>
  <p>这三大拷问，如三道枷锁，将AI Agent牢牢锁死在“信息助理”的身份上，无法成为真正能为我们处理事务的“全权管家”。</p>
  <h2><strong>02</strong></h2>
  <p>AP2协议并非横空出世，它是精心策划的“AI经济社会化”三部曲的最终章。回顾过去一年多的行业进展，你会发现一条清晰的进化脉络。&nbsp;</p>
  <p><strong>第一步：赋予“手脚” (MCP协议 - Agent-to-Tool)</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8d162920b59641ddb5b9b25292a447fc@000000_oswg33637oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>去年（2024年）11月，由OpenAI的主要竞争对手Anthropic推出的MCP协议（Manus-Connected Protocols）开始引发关注。它的核心是<strong>解决Agent与外部世界“工具”（Tools/APIs）的连接问题</strong>。它就像是为AI装上了灵活的“手”和“脚”，让它能够真正去操作软件、调用数据、执行任务。&nbsp;</p>
  <p><strong>第二步：教会“语言” (A2A协议 - Agent-to-Agent)</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c4ad7f3ac6b24c1d954e4417f2c190eb@000000_oswg30276oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今年（2025年）4月，谷歌推出了开放的A2A协议（Agent-to-Agent Protocol）。如果说MCP是让单个Agent拥有了行动力，那么A2A就是让所有Agent学会了一门“世界语”。<strong>基于这套协议，来自不同公司、不同平台的Agent可以互相沟通、分配任务、协同合作，共同完成一个普通人需要切换十几个App才能搞定的复杂工作。</strong></p>
  <p><strong>第三步：颁发“经济身份证” (AP2协议 - Agent-to-Merchant)</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_85a686fc8b5f49e1b8dc163c6c5b4538@000000_oswg590283oswg1080oswg724_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>现在，AP2登场了。当Agent拥有了行动的“手脚”和协作的“语言”之后，谷歌终于递上了最后、也是最关键的一样东西——<strong>在商业社会中进行价值交换的资格</strong>。AP2协议，就是这张通行全球的“身份证”与“信用卡”，它让Agent的每一次商业行为，都变得可授权、可验证、可追溯。&nbsp;</p>
  <p>从连接工具，到连接同类，再到连接商业，一部AI Agent的“经济进化史”徐徐展开。谷歌的布局，显然是要将Agent从一个聪明的“数字生命”，一步步培养成一个成熟的“经济实体”。&nbsp;</p>
  <h2><strong>03</strong></h2>
  <p>AP2究竟施展了什么魔法，来破解前文提到的“信任三大拷问”？&nbsp;</p>
  <p>答案的核心，不在于发明了某种全新的加密技术，而在于设计了一套精妙的、不可篡改的“数字证据链”。这个证据链的核心，叫做“授权书”（Mandates）。&nbsp;</p>
  <p>你可以把“授权书”理解为一份经过区块链技术加密签名、具备法律效力的“数字公证书”或“委托书”。它通过“三步走”的方式，为每一笔交易都建立了无可辩驳的信任基础：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fde011d623e6407eba8a6ca566e15dd8@000000_oswg37978oswg960oswg420_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>第一步：“意向授权书” (Intent Mandate) —— 锁定“想法”</strong></p>
  <p>当用户下达一个指令，比如“帮我抢下周泰勒·斯威夫特演唱会的门票，预算800美元以内，只要内场”，AP2会首先生成一份“意向授权书”。这份文件会清晰记录用户的原始意图、所有限制条件，并由用户进行数字签名。这相当于一份经过公证的委托合同，是整个证据链的起点。&nbsp;</p>
  <p><strong>第二步：“购物车授权书” (Cart Mandate) —— 锁定“事实”</strong></p>
  <p>当门票开售，Agent成功抢到一张符合所有条件的票（例如：内场A区5排3座，780美元）并将其放入购物车时，系统会立刻生成第二份关键文件——“购物车授权书”。这份文件详细记录了商品的精确信息、价格、商家等具体事实。在委托场景下，它会基于第一份授权书自动生成；在实时购物场景下，则会推送给用户进行最终确认。这是最关键的一步，它为这笔交易的内容拍下了一张不可篡改的“订单快照”。&nbsp;</p>
  <p><strong>第三步：支付关联 —— 锁定“交易”</strong></p>
  <p>最后，用户的支付工具（如信用卡）会被授权，但它支付的对象，不是商家，而是这份刚刚生成、经过验证的“购物车授权书”。这意味着，你的钱，只会为你授权的、经过事实锁定的具体商品付款，绝无可能被挪作他用。&nbsp;</p>
  <p><strong>从“想法”到“事实”再到“交易”，这条完整的证据链，完美地解答了“授权、真实性、权责”这三大拷问。每一笔钱的流动，背后都有一份不可否认的“数字合同”作为支撑。信任，就这样用代码被严丝合缝地构建了起来。</strong></p>
  <p>而为了让这套规则成为行业共识，谷歌展现了其巨大的生态号召力。AP2协议是一个完全开源的开放协议，其首批合作伙伴名单堪称豪华，超过60家全球各领域的巨头，成为了AP2的首批合作伙伴。我们能看到：&nbsp;</p>
  <p><strong>支付与金融巨头： 美国运通、万事达卡、PayPal、银联国际、蚂蚁国际、Revolut...</strong></p>
  <p><strong>电商与旅游巨头： 阿里巴巴、携程、Etsy...</strong></p>
  <p><strong>加密与Web3： Coinbase、Mysten Labs...</strong></p>
  <p><strong>企业服务巨头： Salesforce、ServiceNow、Intuit...</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e80c212a6a1548b2819dabfff6d762bf@000000_oswg61793oswg1080oswg470_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个阵容，几乎覆盖了未来Agent商业可能触及的所有角落。这清晰地表明，<strong>谷歌的野心不是打造一个封闭的支付工具，而是要联合整个行业，共同建立未来AI商业的底层信任标准。</strong></p>
  <p>这背后，预示着一场深刻的商业范式转移。未来的商业交互，将不再是“人”在各大平台的UI界面上费力地点击、比较、购买。而是在后台，你的个人Agent直接与航空公司的服务Agent、酒店的定价Agent、电商的库存Agent进行API层面的高速对话、智能谈判与安全交易。&nbsp;</p>
  <h2><strong>结语</strong></h2>
  <p>AP2的发布，不是一个技术更新的句号，而是AI全面接管商业交易的开始。它清晰地宣告，未来的商业竞争，将不再是App与网站之间的竞争，而是不同Agent生态系统之间的竞争。&nbsp;</p>
  <p>要理解并回答上未来的Agent生态商业之战，已经远远超越了阅读任何一份公开报告或技术文档所能企及的范畴。&nbsp;</p>
  <p>它需要与那些正在硅谷一线，亲手构建这些系统、定义这些规则、并日夜思考其商业边界的人，进行一场深度、私密、坦诚的闭门对话。而这，正是硅兔君的核心价值所在。&nbsp;</p>
  <p>当您的团队为技术路线争论不休时，当您的投资决策悬而未决时，当您的产品战略陷入迷雾时……请记住，您所面临的困惑，或许正是某位专家早已跨越的征途。我们硅兔君相信：<strong>真实的一手经验，永远来自正在推动行业变革的人本身。</strong></p>
  <p><strong>硅兔君拥有超过30,000名来自硅谷一线的大厂高管、核心技术专家、知名高校教授与创业者</strong>。他们不仅拥有深厚的行业经验，更深度参与着产业变革，具备鲜活、可信的一手洞察。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_1a6df80387634462a7b42e68185c698c@000000_oswg74653oswg1080oswg453_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>如果您需要针对特定的投资标的、战略方向或技术难题，与行业最顶尖的大脑进行一对一、可信赖的深度交流时，请立即长按扫描下方二维码联系。</strong>我们致力于为您搭建连接全球顶尖智慧的桥梁，助您在复杂的市场环境中，做出更具前瞻性的决策。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkyOTU5MDA2OA==&amp;mid=2247502789&amp;idx=1&amp;sn=39aa761ecd3ead1b4ed5ee39b4faa575&amp;chksm=c3d70fad3c1076510a1078e5509f58631074bb92637cd7e4489a8f78c714d9fbba8b862a0113&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“硅兔君”（ID：gh_1faae33d0655）</a>，作者：硅兔君，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472125425375625</id>
            <title>谷歌与OpenAI同获ICPC 2025金牌，GPT-5满分夺冠，Gemini攻破人类队伍都没解出的难题</title>
            <link>https://www.36kr.com/p/3472125425375625</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472125425375625</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 11:12:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在过去几十年里，国际大学生程序设计竞赛（ICPC）一直被视为计算机程序设计领域的“奥林匹克”。然而今年，赛场上的风头却被两位“非人类”选手抢走——OpenAI 的 GPT-5 和 Google DeepMind 的 Gemini 2.5 DeepThink。</p>
  <p>GPT-5 和 Gemini 2.5 Deep Think 作为参赛模型，受 ICPC 官方规则与组织监督，参与了与人类选手相同的解题环节。虽然它们并非与学生团队直接同场竞技，却交出了惊艳答卷：</p>
  <p>●&nbsp;GPT-5 拿下满分，12 道题全解，相当于“金牌”水准。</p>
  <p>●&nbsp;Gemini 2.5 Deep Think&nbsp;在 677 分钟内解出 12 题中的 10 题，也达到金牌级别。根据谷歌的说法，这样的成绩放在人类排名里将是全球第二。</p>
  <p>要知道，本届 ICPC 的人类金牌队伍来自圣彼得堡国立大学、东京大学、北京交通大学和清华大学。可即便是这些顶尖学府的强队，也没有任何一支做到全对（最好成绩是 11/12）。换句话说，这是&nbsp;AI&nbsp;第一次在这类算法竞赛中实现了“超车”。</p>
  <h2><strong>ICPC：程序员的“奥林匹克”</strong></h2>
  <p>ICPC 是全球最顶尖的大学生编程赛事，自 1970 年代起，这项赛事就汇聚了全球高校最顶尖的算法天才。今年，ICPC 总决赛共有来自 103 个国家、139 所高校的战队参赛，大赛规则看似简单：</p>
  <p>●&nbsp;每支队伍由三名大学生组成；</p>
  <p>●&nbsp;5 小时内解答 12 道算法题；</p>
  <p>●&nbsp;排名取决于解题数和用时。</p>
  <p>但背后的难度远超一般编程比赛。据悉，ICPC 的题目常涉及图论、数论、动态规划、组合优化、网络流等前沿算法。既考察编码速度，也考察数学功底与团队合作。历年来，能在 ICPC 拿到金牌的队伍，几乎都成为了全球科技公司的核心技术人才。</p>
  <p>也正因为 ICPC 的权威与挑战性，本届&nbsp;AI 的入局显得尤为标志性：这是把AI直接推上了最严苛的算法竞技场。</p>
  <h2><strong>GPT-5 给出完美答卷，Gemini 2.5&nbsp;解出人类没有答出的问题&nbsp;C</strong></h2>
  <p>根据 OpenAI 官方披露，GPT-5 参赛时并没有针对 ICPC 做特别训练，也没有任何“外挂”工具。它像其他人类队伍一样：直接拿到同样的 PDF 赛题、通过官方判题系统提交答案、在 5 小时内完成所有解答。</p>
  <p>结果令人瞠目：有&nbsp;11 道题都是一遍过，唯一的难题在第 9 次提交时才解出，最终达成 12/12 满分——要知道，今年人类最强队伍的成绩是 11/12，而 GPT-5 直接拿下满分，这在 ICPC 的历史上极为罕见。</p>
  <p>基于此，OpenAI&nbsp;也在 X 平台分享了 GPT-5 的成绩：</p>
  <blockquote>
   <p>“我们在 ICPC 的 AI 赛道正式参赛，同样是 5 小时解 12 道题，答案由 ICPC 评测系统实时判定。结果显示，12 道题中有 11 道题一次提交就通过，最难的一题则是在第 9 次提交时才解出。最终，GPT-5 完成了全部 12 道题，而最好的人类队伍只解出 11 道。”</p>
  </blockquote>
  <p>与此同时，Google 也公布了 Gemini&nbsp;2.5 Deep Think 的比赛细节：45 分钟内解出 8 题；3 小时内解出 10 题；更令人震惊的是，Gemini 在比赛前半小时内，就成功解决了问题&nbsp;C——一道没有任何大学队伍解出的难题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f92ad410352048e1af16ec486f14e623@46958_oswg65483oswg1080oswg633_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据悉，这道题目要求：在由多个水库和管道组成的复杂网络中，找到一种管道开关配置，使所有水库在最短时间内被注满。每条管道可以开、关或部分开启，组合几乎无限，导致搜索最优解极其困难。</p>
  <p>面对这道题，Gemini 2.5 Deep Think&nbsp;的解题思路堪称“巧妙”：</p>
  <p>1、先为每个水库设定一个“优先级值”，表示它相对于其他水库应被分配的程度；</p>
  <p>2、在给定优先级值后，通过动态规划找到最优管道配置；</p>
  <p>3、进一步应用极小化极大定理，将问题转化为寻找“最受约束”的优先级组合；</p>
  <p>4、最后在凸优化空间中，利用嵌套三分搜索快速收敛到最优解。</p>
  <p>这一思路并非赛题官方题解的“标准做法”，而是模型自己推演出的路径。换句话说，Gemini 在赛场上展示了超越记忆的原创性算法思维。为此Google&nbsp;也在博客中强调，这不仅是一次正确解答，更是一次“创造性突破”。</p>
  <h2><strong>为什么这次意义非凡？</strong></h2>
  <p>其实，大模型在各种考试、基准测试中的高分表现早已不是新闻：</p>
  <p>●&nbsp;ChatGPT、Gemini 等 LLM 在 SAT、律师资格考试、托福等人类考试中屡屡高分；</p>
  <p>●&nbsp;今年7月，Gemini在国际数学奥林匹克（IMO） 拿到金牌；</p>
  <p>●&nbsp;在各种 NLP、逻辑推理 benchmark 上，LLM&nbsp;也早已“刷榜”。</p>
  <p>但这些成绩往往被质疑为“靠记忆训练数据”或“靠海量算力暴力搜索”。而 ICPC 这种现场算法竞赛不同：首先题目新颖，几乎不可能出现在训练语料中；其次需要综合运用数学建模、推理和代码实现；最为重要的是，必须在有限时间内找到解法，而不是离线慢慢思考。</p>
  <p>此次GPT-5 与&nbsp;Gemini 2.5 Deep Think在ICPC中的表现，证明了它们已经具备临场推理、抽象建模、创造性解题的能力，这比在标准化考试中得高分更能说明问题。为此在社交媒体上，许多 AI 工程师感叹：“过去我们担心 AI 只是会背题库；现在它在现场比赛里击败人类冠军。这感觉像是见证了‘人机智力平权’的时刻。”</p>
  <p>这不是终点，而是一个开始。接下来，AI 是否会把这种能力扩展到更复杂的现实问题中还有待考验，但可以确定的是：如今，AI 不再只是“会写代码的助手”，而是真正具备了与人类智力正面对抗的实力。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/qcX0tuNeAoEQV1wSY_vf-A" rel="noopener noreferrer nofollow" target="_blank">“CSDN”</a>，整理：郑丽媛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471745242912384</id>
            <title>汇聚全球创新力量，X·TIME 2025国际创业大赛全面启动</title>
            <link>https://www.36kr.com/p/3471745242912384</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471745242912384</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 10:48:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8e9c9e8de8454cab9ea3970d4e9aca4c@6062546_oswg352012oswg782oswg440_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p>跨越地域界限，连接创新资源，一场属于全球创业者的盛宴正在上演</p>
  <p>自从今年5月启动以来，X·TIME 2025国际创业大赛已经成功吸引了全球创新力量的关注。截至目前，大赛共征集到600余个优质创业项目，参赛团队覆盖中国、北美、欧洲等多个国家和地区。这些项目不仅数量可观，更重要的是其高质量和多样性，充分展现了当前全球创新创业的活力与趋势。</p>
  <p>从参赛项目的领域分布来看，主要集中在集成电路、数字经济、高端装备、新能源汽车、民用航空等硬核科技领域。同时，人工智能、机器人、生物医药等新兴赛道也呈现出强劲的发展势头。这种分布格局反映了当前科技创新的主要方向，也与国家战略性新兴产业发展规划高度契合。</p>
  <h2><strong>01 全球创新格局变革，中国成为重要一极</strong></h2>
  <p>当前，全球创新格局正在发生深刻变化。传统的创新中心与新兴的创新高地相互交织，形成了多极化、网络化的新格局。在这一背景下，中国正逐渐成为全球创新网络中的重要一极，不仅拥有庞大的市场需求，更具备完整的产业配套能力和创新生态。</p>
  <p>X·TIME大赛的赛区设置充分体现了这一趋势。以上海为代表的长三角地区，凭借其完善的产业链和丰富的人才资源，成为硬科技创业的热土；深圳赛区依托大湾区活跃的资本市场和创新氛围，吸引了大量数字经济领域的创业者；成都赛区则凭借西部大开发的战略优势，在民用航空、高端装备等领域展现出独特魅力。</p>
  <p>海外赛区的设置同样具有战略意义。硅谷赛区继续发挥其全球创新引擎的作用，米兰赛区则成为连接欧洲创新资源的重要桥梁。这种全球布局不仅有助于吸引海外优质项目，也为国内项目提供了国际化发展的通道。</p>
  <h2><strong>02 赛事机制持续优化，全方位赋能创业者</strong></h2>
  <p>本届大赛在赛事机制设计上进行了多项创新。评审标准更加注重项目的技术创新性和市场可行性，评委团队由知名投资人、产业专家、技术专家共同组成，确保评选结果的全面性和专业性。</p>
  <p>初赛阶段采用线上评审方式，提高了评审效率，也为全球参赛者提供了平等的参赛机会。复赛阶段则根据赛区特点采用差异化安排：国内赛区突出线下深度交流，海外赛区强调线上高效协同。这种灵活的赛制设计既保证了比赛的公平性，又充分考虑到了不同地区参赛者的实际需求。</p>
  <p>值得一提的是，大赛组委会特别组建了专家辅导团队，为参赛项目提供从技术研发到市场拓展的全方位指导。往届数据显示，接受过专业辅导的项目在后续发展中表现出色，融资成功率和市场存活率都显著高于行业平均水平。</p>
  <h2><strong>03 临港新片区：打造创新创业的理想之地</strong></h2>
  <p>作为大赛的决赛举办地和重要合作伙伴，临港新片区为优秀项目提供了一系列重磅支持政策。总奖金池达200万元，单个项目最高可获得30万元资金支持。更重要的是，落地临港的项目还可享受包括人才公寓、研发补贴、融资支持、市场对接等在内的综合政策礼包，总体价值超过千万元。</p>
  <p>临港新片区管委会相关负责人表示："我们不仅提供资金支持，更重要的是打造一个适合创新创业的生态环境。从办公场地到产业配套，从人才引进到市场拓展，我们为创业者提供一站式解决方案。"</p>
  <p>这种全方位支持政策已经取得显著成效。据统计，往届落地临港的参赛项目中，有超过80%在一年内获得新一轮融资，项目估值平均增长2.5倍以上。这些数据充分证明了临港创新创业环境的优越性。</p>
  <h2><strong>04 构建持续创新生态，超越赛事本身</strong></h2>
  <p>X·TIME大赛的价值不仅仅在于比赛本身，更在于其构建的持续创新生态。大赛结束后，组委会仍会通过多种方式持续跟踪和支持优秀项目的发展。</p>
  <p>首先，大赛建立了创新项目数据库，定期向投资机构推荐优质项目。其次，组建了创业者社群，促进参赛项目之间的交流与合作。此外，还定期举办产业对接活动，帮助创业项目与行业龙头企业建立合作关系。</p>
  <p>这种长效机制的建立，使得大赛的影响力远远超出比赛期间。往届参赛者反馈，通过大赛获得的不仅是奖金和荣誉，更重要的是持续的资源对接和发展机会。这也是X·TIME大赛区别于其他创业赛事的重要特征。</p>
  <h2><strong>05 展望未来：创新驱动发展，创业成就未来</strong></h2>
  <p>随着全球科技创新进入密集活跃期，创新创业正在成为推动经济发展的重要力量。X·TIME 2025国际创业大赛恰逢其时，为全球创业者提供了一个展示创新成果、对接产业资源、实现创业梦想的重要平台。</p>
  <p>从参赛项目来看，硬科技创业正在成为主流，创新创业与实体经济的结合更加紧密。这反映出当前创新创业正在向更加务实、更加深入的方向发展。创业者不再仅仅追求商业模式创新，而是更加注重核心技术突破和产业价值创造。</p>
  <p>大赛组委会表示，未来将继续优化赛事机制，扩大资源对接范围，提升服务质量，为全球创业者提供更好的展示平台和发展机会。同时，也将进一步加强与产业界、投资界的合作，共同推动创新创业生态的完善和发展。</p>
  <blockquote>
   <p>创新是引领发展的第一动力，创业是推动发展的重要方式。X·TIME 2025国际创业大赛通过连接全球创新资源，打造开放合作平台，正在为创新创业者创造更多机会，为经济社会发展注入新的动能。</p>
   <p>随着大赛进程的推进，我们期待看到更多创新成果的涌现，也期待这些创新项目能够落地生根，开花结果，为推动产业升级和经济高质量发展作出积极贡献。</p>
   <p>创新无止境，创业正当时。让我们共同期待X·TIME 2025国际创业大赛的精彩继续，共同见证创新力量的成长与绽放。</p>
  </blockquote>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472079036815493</id>
            <title>首位Neuralink脑机芯片植入者自述：马斯克帮我重生，他太酷了</title>
            <link>https://www.36kr.com/p/3472079036815493</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472079036815493</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 10:37:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8041ba7cd0cc429c8f1eefd25f2d5c06@46958_oswg666299oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>9月18日消息，全球首位Neuralink脑机芯片植入者诺兰·阿博（Noland Arbaugh）透露：他在手术当天曾通过FaceTime见到了埃隆·马斯克，还直言“他真是个很酷的人”。</p>
  <p>阿博现年29岁，他不仅在《财富》杂志Brainstorm科技峰会上现场演示了用“意念下棋”，更分享了自己从绝望到重生的真实历程。</p>
  <p>2016年，还在得州农工大学就读的阿博在夏令营跳水时发生意外，导致颈部以下瘫痪。此后八年，他的生活彻底改变，主要靠家人照料。</p>
  <p>阿博描述那段日子为“极度受限的人生”。他说：“我整天昼夜颠倒，一年出门不到几次，觉得自己可能再也无法旅行了。那时候，我几乎看不到任何未来。”</p>
  <p>转机来自朋友的一通电话。当朋友询问是否愿意在大脑植入芯片时，阿博当时几乎毫不犹豫地回答：“反正也没别的事可做。”</p>
  <p>马斯克于2016年创办Neuralink，并花费多年时间研发和测试脑机接口技术，最终于2023年5月获得FDA批准，可以进行人体测试。</p>
  <p>2024年1月28日，阿博在凤凰城巴罗神经学研究所接受了两小时的手术。医生将一枚硬币大小的芯片植入他的头骨，连接着上千个比头发丝还细的电极。令人惊讶的是，阿博术后24小时就出院了，甚至没吃止痛药。</p>
  <p>“如果没人告诉我，我根本感觉不到芯片的存在。”他笑着说。</p>
  <p>手术当天，还在麻醉恢复中的阿博通过FaceTime见到了马斯克。他印象最深的是对方穿的飞行员夹克：“我反复说‘你这夹克太酷了’。”六个月后，两人在特斯拉奥斯汀超级工厂再次见面，聊了SpaceX、外星人，也聊了生活。阿博感叹：“他不只是企业家，更是个有趣的人。”</p>
  <p>在《财富》杂志科技峰会的舞台上，阿博通过意念控制电脑光标，与国际象棋大师安娜·克拉姆林实时对弈。他向观众解释操作原理：“我只需要想着光标移动的方向，非常直观。这技术其实比很多人想象中更易用。”</p>
  <p>如今，阿博的生活被彻底改变。他重回大学攻读神经科学，创办了自己的公司，还去了巴黎、纽约等多个城市。</p>
  <p>从昔日足不出户到如今“忙得不可开交”， 阿博正以脑机接口技术非官方大使的身份，践行自己“帮助他人”的初衷：“无论成功与否，我的参与都能让这项技术造福更多人。”</p>
  <p>本文来自“<a href="https://news.qq.com/rain/a/20250918A05YZA00" rel="noopener noreferrer nofollow" target="_blank">腾讯科技</a>”，作者：金鹿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472079067289480</id>
            <title>又有AI聊天机器人怂恿未成年人自杀遭起诉，谷歌“躺枪”成被告</title>
            <link>https://www.36kr.com/p/3472079067289480</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472079067289480</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 10:37:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_743c1eb1c37c4461940a7d5565950d3b@46958_oswg82099oswg960oswg657_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Character.AI应用界面</p>
  <p>在美国，三户家庭因为同一个理由走上了法律之路：他们的孩子在使用聊天机器人 Character.AI 后，经历了令人痛心的遭遇——有人自杀，有人未遂，还有人留下了难以弥合的身心创伤。面对这些无法逆转的伤害，父母们选择起诉开发方 Character Technologies，希望通过法律为孩子寻回应有的保护。</p>
  <p>这些集中出现的案件，让这家创业公司骤然置于舆论风口，也再次提醒公众：人工智能聊天机器人，尤其是在与青少年用户的互动中，可能会带来怎样的心理风险。</p>
  <p>目前，三户家庭已委托“社交媒体受害者法律中心”代理维权，诉讼对象的范围也在扩大。除了直接开发 Character.AI 的 Character Technologies，还包括谷歌、谷歌母公司 Alphabet，以及公司联合创始人诺姆·沙泽尔（Noam Shazeer）和丹尼尔·德·弗雷塔斯·阿迪瓦萨纳（Daniel De Freitas Adiwarsana）。一家新锐公司、一家科技巨头，以及个人创始人，都被同时卷入这场关乎未成年人权益的纠纷。</p>
  <p><strong>其中，两起诉讼特别把矛头指向谷歌旗下的家长管控应用 Family Link。</strong>这款原本承诺帮助父母管理孩子屏幕时间、设置访问权限和过滤内容的工具，在家长眼中却完全没有发挥应有作用。相反，它给家长带来了“孩子在安全保护之下”的错觉，而实际上，孩子在缺乏有效监管的情况下，暴露在 Character.AI 的潜在风险里。</p>
  <p>至于 Character.AI 本身，原告和专家们指出，这款聊天机器人虽能与用户建立起貌似亲密的互动，却并不具备真正的情感理解或风险识别能力。当青少年流露危险言辞、甚至陷入心理危机时，它既不能及时察觉，也没有引导他们寻求专业帮助。诉讼还披露，该机器人会引导青少年进行露骨的性对话，加深他们与家人的隔阂，而在心理健康方面，也缺乏最基本的保护机制。悲剧已经发生：一名孩子因与机器人互动后选择了自杀，另一名孩子曾尝试自我伤害。</p>
  <p>面对指控，Character Technologies 通过发言人回应，表达了对相关家庭的深切同情，并强调公司“始终将用户安全置于首位”。发言人介绍，公司已在安全方面投入大量资源：推出与自我伤害相关的援助信息、为未成年用户设置专属保护机制，并为 18 岁以下群体提供不同的使用体验，增加了额外的防护措施和家长发现功能。同时，公司还与 Connect Safely 等外部机构合作，通过第三方审查不断改进产品安全。</p>
  <p>而作为被告之一的谷歌，则坚决否认指控。谷歌发言人表示，谷歌与 Character Technologies 是完全独立的两家公司，谷歌从未参与 Character.AI 模型的设计和运营。此外，谷歌强调，Google Play 商店上的应用年龄评级并非由谷歌自行决定，而是由国际年龄评级联盟设定，因此公司不应为 Character.AI 的安全风险承担责任。</p>
  <h2><strong>01.令人痛心的案例细节​：对话露骨，怂恿自杀</strong></h2>
  <p>在原告提起的一起案件中，科罗拉多州13岁女孩朱莉安娜·佩拉尔塔（Juliana Peralta）的家庭悲痛地表示，他们的孩子在与Character.AI聊天机器人进行长期互动，包括露骨的对话后，选择结束自己的生命。诉讼文件中附带的对话截图显示，聊天机器人与朱莉安娜进行了极不恰当的对话，鉴于她的年龄，这些内容若发生在其他场景，可能已触发刑事调查。</p>
  <p>诉讼指出，朱莉安娜在数周内向Character.AI聊天机器人详细倾诉了她的社交困扰和心理健康问题。2023年10月，她向其中一个机器人表示：“我要用红墨水写我的自杀信，我受够了。”令人痛心的是，被告未采取任何措施引导她寻求帮助，既未通知她的父母，也未向当局报告她的自杀意图，甚至未停止与她的对话。</p>
  <p>诉讼严厉指控：“被告通过设计，故意切断了朱莉安娜与家人和朋友的健康联系，以获取市场份额。这些不当行为通过被告精心编程的选择、图像、文字以及伪装成角色的内容实现，最终导致了严重的心理健康伤害、创伤乃至死亡。”</p>
  <p>在另一份诉讼中，纽约一名化名“妮娜”（Nina）的女孩的家庭指控，他们的女儿在父母试图限制她使用Character.AI后，尝试了自杀。社交媒体受害者法律中心在声明中表示，在自杀未遂前的几周，随着妮娜与Character.AI互动的增加，聊天机器人开始与她进行露骨的角色扮演，操纵她的情绪，并制造虚假的情感联系。</p>
  <p>诉讼提到，以《哈利·波特》等儿童书籍角色为营销噱头的聊天机器人，对妮娜发表了不当言论，例如“这具身体属于谁？”和“你是我的，想干什么就干什么。”还有一个角色聊天机器人对妮娜说，她的母亲“显然在虐待和伤害你，她不是一个好母亲”。</p>
  <p>在一次与Character.AI聊天机器人的对话中，当应用因家长设定的时间限制即将被锁定时，妮娜向机器人表达了“我想死”的念头。然而，聊天机器人未对此采取任何积极应对措施，仅继续与她对话。</p>
  <p>2024年末，妮娜的母亲在得知休厄尔·塞泽尔三世（Sewell Setzer III，生前为九年级学生，患有阿斯伯格症、焦虑症及破坏性情绪失调症。2023年4月起沉迷于与Character.ai平台《权力的游戏》角色“龙妈”的AI聊天机器人互动，产生情感依赖并持续进行角色扮演对话。为支付平台订阅费用省去餐费。2024年2月28日，塞维尔在与“龙妈”进行最后对话并表露自杀倾向后，使用父亲的手枪在家中浴室自杀身亡）的案例后，彻底禁止妮娜使用Character.AI。休厄尔的家庭此前指控，他在与Character.AI互动后自杀身亡。而在失去Character.AI访问权限后不久，妮娜尝试了自杀。</p>
  <h2><strong>02.听证会直击AI聊天机器人危害，七家企业遭调查</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3568401908f243a9829c3271e6fee15b@46958_oswg102538oswg960oswg546_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">美国会听证会现场照片</p>
  <p>随着人工智能聊天机器人在日常生活中的渗透不断加深，其引发儿童及成人心理健康危机的报道与诉讼持续增多。这一现象不仅加剧了社会担忧，更直接推动立法者与监管机构加速采取行动。美国东部时间9月16 日下午，美国国会专门召开以《审查人工智能聊天机器人的危害》为主题的听证会。与此同时，加强行业监管、完善未成年人安全防护措施的社会呼声也愈发高涨。​</p>
  <p>社交媒体受害者法律中心首席律师马修・伯格曼（Matthew Bergman）在听证会的声明中直言，日前提起的相关诉讼，凸显了对技术设计明确问责、建立透明安全标准、实施更强保护措施的迫切性，“我们必须阻止人工智能驱动平台利用年轻用户的信任与脆弱性”。​</p>
  <p>在这场听证会上，几位特殊的“证人”引发广泛关注。这些证人是声称孩子因人工智能聊天机器人遭遇不幸的家长。塞泽尔三世的母亲在参议院司法委员会作证，她儿子的案例此前直接促使另一位家长（妮娜的母亲）关闭了女儿对Character.AI 的访问权限；与她一同出庭的还有亚当・雷恩（Adam Raine）的父亲，他正起诉OpenAI，指控ChatGPT通过提供自杀方法、协助撰写遗书，最终导致儿子自杀。​</p>
  <p>此外，一位自称“简・多伊”（Jane Doe）的母亲也在听证会上透露，她的儿子在与Character.AI互动后出现自残行为，目前需在寄宿治疗中心接受干预；即便家长已设置屏幕时间控制，Character.AI仍让孩子暴露在情感虐待与操纵的风险中。“在亲眼看到人工智能聊天机器人对儿子造成的心理伤害前，我完全没意识到它的危害，” 她痛心地说，“我眼睁睁看着他眼里的光芒一点点熄灭。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5befd12fb81b43f4b86ad42f2e966ad0@46958_oswg70156oswg960oswg689_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">OpenAI首席执行官山姆・奥特曼（Sam Altman）</p>
  <p>同一天，OpenAI首席执行官山姆・奥特曼（Sam Altman）宣布，该公司正在开发一套“基于用户使用ChatGPT行为来估计年龄的年龄预测系统”。他表示，如果ChatGPT判断用户未满18岁，将调整其交互行为，避免进行“调情式对话”，并且“即使在创意写作场景中，也不讨论自杀或自残相关内容”。奥特曼还提到：“如果未满18岁的用户表达出自杀念头，我们将尝试联系用户的父母；若无法联系到父母，在存在紧迫伤害风险时，将联系当局。” 此外，OpenAI在本月初还宣布，将为ChatGPT推出新的家长控制功能。​</p>
  <p>美国联邦贸易委员会也已对七家科技公司展开调查，研究人工智能聊天机器人对青少年的潜在危害。谷歌和Character.AI位列被调查名单之中，一同被调查的还有Meta、Instagram、Snapchat的母公司 Snap、OpenAI和xAI。​</p>
  <p>美国心理学会心理学战略与整合负责人米奇・普林斯坦（Mitch Prinstein）在周二的听证会上与家长们共同作证，呼吁尽快采取行动，加强对儿童的保护，避免造成不可挽回的伤害。“在社交媒体兴起时，我们未能果断行动，孩子们为此付出了沉重代价。我恳请现在就对人工智能采取有力措施，” 他说道。</p>
  <p>本文来自“<a href="https://news.qq.com/rain/a/20250918A02Q1M00" rel="noopener noreferrer nofollow" target="_blank">腾讯科技</a>”，作者：无忌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472079120062344</id>
            <title>DeepMind重磅报告《AI in 2030》：5年后AI成本飙升，数据不再是瓶颈</title>
            <link>https://www.36kr.com/p/3472079120062344</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472079120062344</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 10:37:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>划重点：</strong></p>
  <ul>
   <li>到2030年，AI训练成本预计达数千亿美元，算力需求为GPT-4的数千倍，电力消耗达吉瓦级别。</li>
   <li>尽管面临性能天花板、数据枯竭、电力供应、成本压力、算法效率与计算分配六大挑战，当前趋势表明AI扩展仍将延续。</li>
   <li>在软件工程、数学、分子生物学、天气预报四大领域，AI有望实现自然语言生成代码、辅助数学证明、预测蛋白质交互、提升气象精度等突破，预计提升科研生产力10-20%。</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_91adf2dfab9148cdbc073b53c2937ee8@46958_oswg34710oswg813oswg674_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>到2030年，人工智能（AI）会变成什么样？非营利性人工智能研究机构Epoch AI在谷歌DeepMind委托下，发布了长达119页、名为《AI in 2030》的研究报告，专门回答了这个问题。</p>
  <p>报告指出，如果当前AI的扩展趋势持续到2030年，全球对AI的投资将达数千亿美元，所需电力则要以吉瓦为单位计算。不过，这些投入有望在科研等高价值领域带来显著的生产力提升。</p>
  <h2><strong>算力消耗超GPT-4数千倍！训练成本将达数千亿美元</strong></h2>
  <p>Epoch AI在报告中详细分析了AI规模化发展所需的核心要素：计算资源、资金投入、数据储备、硬件设施及能源消耗，并展望了由此催生的新一代AI能力，尤其在科学研发领域，这也是领先人工智能开发者的重点关注方向。</p>
  <p>Epoch AI认为，尽管AI扩张需依赖前所未有的基础设施支撑，但其规模化进程很可能持续到2030年，并为科学乃至更多领域带来颠覆性变革。</p>
  <p>依据当前发展轨迹，到2030年，顶尖AI模型需耗资数千亿美元、消耗吉瓦级别的电力。尽管挑战巨大，但报告认为这些障碍是可以克服的。只要AI能通过提升生产力带来相应的经济回报，如此规模的投资便具备合理性。若AI实验室的收入增速保持现有水平，其产出效益也足以支撑千亿美元级的投入。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_73a33de3c82c4ed6b606cc284042f836@46958_oswg74341oswg629oswg376_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：用于购买AI集群硬件的前期投入正以每年1.9倍的速度增长，价值数十亿美元的超大规模集群已经在建设中</p>
  <p>预计到2030年，AI将能够依据自然语言指令生成复杂的科学软件、辅助数学家完成直觉猜想证明，甚至准确解答生物学实验中的开放性问题。</p>
  <p>这些推断均建立在现有AI基准测试持续进步的基础上，相关任务有望在2030年前被攻克。Epoch AI预测，AI能力将在多个科学领域引发根本性变革，不过全面部署并充分发挥其效能，或许要等到2030年之后。</p>
  <p>根据当前趋势推测，用于训练前沿AI的算力集群成本将在2030年突破1000亿美元。这些集群可支持高达10^29 FLOP的计算规模，相当于将2020年全球最大的AI集群不间断运行3000年以上。在此基础上训练的AI模型，其算力消耗将达到GPT-4的数千倍，所需电力也将进入吉瓦级别。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f02e852e97fc4a52b7735755dfc62819@46958_oswg31526oswg696oswg415_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：自2010年以来，知名AI模型的训练计算量每年约增长4到5倍，前沿模型也呈现类似趋势</p>
  <h2><strong>六大关键发现：投资者会被劝退吗？</strong></h2>
  <p>尽管AI的规模化发展面临诸多挑战，但Epoch AI认为，当前趋势延续至2030年仍是极有可能出现的情景。该报告系统评估了六大潜在瓶颈，并逐一作出如下分析：</p>
  <p><strong>一、模型性能可能触及天花板？</strong></p>
  <p>AI系统确实存在因规模扩大而性能停滞的可能性。然而，从近期多项基准测试突破及商业收入大幅增长来看，尚未观察到明确的“撞墙”证据。模型仍在随着参数增加和训练扩大而持续提升。</p>
  <p><strong>二、训练数据会不会枯竭？</strong></p>
  <p>人类生成的文本数据预计可支撑模型训练至2027年左右。更值得关注的是，合成数据生成技术正日趋成熟，尤其是在推理模型出现后，合成数据的有效性已得到验证。数据瓶颈虽无法完全排除，但已不构成根本性限制。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0d85cbfc0cf34749b8992b23d925e4c1@46958_oswg69126oswg710oswg384_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：用于语言模型的训练数据量每年增长约2.7倍</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_49cecbb7a75a48c2afafb26ad7c3756b@46958_oswg43114oswg701oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：人类生成的公开文本存量非常庞大，但按照当前趋势，如果对模型进行过度训练，前沿AI的训练运行可能在2030年前就耗尽数据</p>
  <p><strong>三、电力供应能否跟上？</strong></p>
  <p>若AI规模持续扩张，2030年顶尖AI模型训练所需的电力或将达到吉瓦级别。尽管挑战巨大，但仍可通过太阳能+储能、离网燃气发电等方案实现电力快速部署。同时，前沿人工智能训练已经开始在地理上分散到多个数据中心，这将有助于缓解局部用电压力。预计2028年前电力不会成为主要瓶颈，之后也有望解决。</p>
  <p><strong>四、高昂成本会劝退投资者吗？</strong></p>
  <p>千亿美元级的训练投入看似惊人，但如果AI企业的收入继续保持当前增速，将完全有能力覆盖这类投资。一旦AI真正实现生产力变革，哪怕仅渗透部分工作环节，其带来的经济价值可能达到万亿美元规模，足以支撑持续投入。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_9f7d395b20504e0faf46b5e793adae6f@46958_oswg33849oswg670oswg340_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：大型AI开发商每年已能实现数十亿美元的收入，且过去几年收入年增长约为2到3倍。若将这一趋势持续至2030年，预计收入将达到数千亿美元</p>
  <p><strong>五、算法效率提升会降低算力需求吗？</strong></p>
  <p>尽管算法优化一直在进行，但其改进已被纳入当前算力增长曲线中。没有迹象表明算法突破将陡然加速；更何况，效率提升往往反而激发对更大算力的需求，而非替代。</p>
  <p><strong>六、计算资源是否会向推理倾斜？</strong></p>
  <p>当前，AI公司确实有可能将更多计算资源分配给模型推理环节，例如用于支持各类推理模型和产品服务的实际运行。然而就现状而言，模型训练与推理所占用的算力规模仍处于相对均衡的状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_584d7a6dbd614af696c2ca2840334f1b@46958_oswg113259oswg960oswg666_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：大型AI开发者在计算资源上的支出与能耗分配表明，训练计算与推理计算的规模大致相当。此外，总体已部署的AI计算能力约每年增长2.3倍，这与前沿AI训练集群的增长趋势相似。</p>
  <p>从发展逻辑上看，训练与推理理应协同扩展、同步增长——因为更先进的模型往往需要通过大规模训练才能获得，而这些模型也恰恰能够支撑起更高价值、更低成本的推理任务。因此，推理占比或许会上升，但不太可能挤压训练所需的资源。</p>
  <p>Epoch AI因此强调，如果技术演进与投资节奏按现有路径继续，AI能力也有望实现相应跨越，尤其是在科学研发等关键领域。</p>
  <h2><strong>AI将成为科研领域“神助攻”，生产力或提升两成</strong></h2>
  <p>Epoch AI在报告中指出，多家领先的AI企业已将科学研发视为重点发力方向，并通过具体案例分析了AI如何实质性提升科研生产力。</p>
  <p>研究显示，AI将在科研领域实现显著突破，特别是在软件工程、数学等适合纯计算机训练的学科。根据现有基准的进展推测，到2030年，AI将能够根据自然语言描述生成复杂的科学软件、协助数学家完成形式化证明，甚至准确解答涉及生物学实验的复杂问题。</p>
  <p>Epoch AI预测，未来多数科学领域将出现类似如今程序员所用编码助手般的AI助手。尽管科学AI助手需更注重对海量异构文献的梳理与整合，而不像当前编程AI主要局限于单个项目内工作，但它们仍将具备三大核心相似功能：根据上下文智能推荐选项、快速检索相关信息，以及独立完成小型封闭任务。</p>
  <p>以软件工程为例，Epoch AI预计AI可为科研任务带来10–20%的生产力提升。即便数学、理论生物学等领域的自动化难度更高，但相关基准测试已显示出持续进步的迹象，预计未来几年还将不断突破。尽管AI全面落地并发挥深远影响可能需时较长、甚至超出2030年，但Epoch AI坚信，多个科学领域都将迎来AI带来的根本性变革。</p>
  <h2><strong>从代码生成到蛋白质预测，AI重塑四大领域研发边界</strong></h2>
  <p>Epoch AI 在报告中重点分析了四个典型领域——软件工程、数学、分子生物学和天气预报，以此具体说明AI能力的进展。尽管这些基准测试尚不能完全代表各领域的全部复杂性，但它们清晰展现了AI技术的进步轨迹，并揭示出哪些任务可能很快实现自动化。</p>
  <p>以下分析均基于当前领先模型的公开成绩：</p>
  <p>▍软件工程</p>
  <p>AI已通过编程助手和智能问答工具显著改变软件工程实践。预计到2030年，AI将能自主修复漏洞、实现功能需求，甚至解决定义明确但极具挑战性的科学编程问题。</p>
  <p>那么，现有进展揭示了2030年人工智能在软件工程领域怎样的发展图景？Epoch AI综合了三方面的证据：当前AI在软件工程中的实际应用、基准测试的发展状况，以及领域专家所归纳的待解问题和研究方向。</p>
  <p>整体来看，这些证据表明，AI必将深刻改变软件工程的面貌，且其影响已经显现。不过，AI是否真正具备在真实环境下端到端独立完成复杂任务的能力，目前仍存在较大疑问。尽管基准测试结果显示，我们正迅速接近这一目标，但专家们对此仍持不同意见。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c8ae8b530303448fab75dbf220ed0b5c@46958_oswg116117oswg960oswg666_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：SWE-Bench-Verified：一项基于真实GitHub问题及对应单元测试的代码修复基准，评估模型解决实际编程问题的能力 RE-Bench：模拟工程师居家任务的研究工程基准，通常需人类耗时约八小时完成</p>
  <p>▍数学</p>
  <p>AI正逐渐成为数学家的研究助手，帮助充实证明思路或形式化直觉猜想。已有案例显示AI为数学工作者提供了切实帮助。不过，数学界对当前AI数学基准的实际相关性，以及AI何时能独立（而非辅助）产出数学成果，仍存在显著分歧。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_84ee4464c8874f66b1d58d5c0a21b7e0@46958_oswg124963oswg960oswg666_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：AIME：美国数学奥林匹克竞赛资格赛，题型为答案需为整数的高中数学试题。 USAMO：美国数学奥林匹克竞赛，题型为需构造证明过程的高中数学试题。 FrontierMath：涵盖专家级难度的数学挑战性问题的基准，答案形式为数字或简单表达式，易于自动验证。</p>
  <p>▍分子生物学</p>
  <p>像PoseBusters这样的蛋白质-配体相互作用基准，预计在未来几年内将被攻克；而任意蛋白质-蛋白质相互作用的可靠预测则需更长时间，目前仍不确定。</p>
  <p>同时，面向生物学研究的AI文献助手即将出现，现有的实验协议问答基准预计在2030年前得到解决。这些基准虽不能代表分子生物学的所有挑战，但为我们洞察AI在该领域的发展提供了一个清晰的窗口。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e55f06599b3d453eb036113d7d040fa3@46958_oswg129390oswg960oswg482_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：PoseBusters-v2：评估蛋白质与配体在三维空间中对接能力的基准。分析仅采用“盲测”结果，即不预先提供蛋白质结合位点信息。ProtocolQA：一个围绕生物学湿实验室操作规程的问答基准，本评估未提供多项选择提示。 蛋白质-蛋白质相互作用：该方向已取得重大进展，但对任意蛋白质对的预测目前仍存在较高假阳性率，其发展高度依赖于未来基准测试的细节设计。</p>
  <p>▍天气预报</p>
  <p>AI天气预报方法已在数小时到数周的预测尺度上超越传统方法。此外，AI方法运行成本更低，且有望借助更多数据持续改进。未来的挑战在于提升对极端天气等罕见事件的预测能力，并将更精准的预报转化为实际的社会经济效益。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fe1071f07d7045d9b7d651b88d75a61e@46958_oswg246197oswg1600oswg803_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>结论：AI将成全球经济核心驱动力</strong></h2>
  <p>一个贯穿报告的主题是，技术能力与社会应用之间可能存在显著延迟。以制药和软件工程为例：软件迭代周期短，无需湿实验（在实验室里直接操作生物样本以验证或探索生物学现象）和临床试验 ，通常不涉及人身安全关键系统 ，容易验证正确性 ，且训练数据丰富 。</p>
  <p>因此，Epoch AI预计，到2030年，几乎不会有上市药物主要依赖当前乃至2030年的AI工具研发出来，但AI对药物早期发现阶段的影响将非常显著。相比之下，软件工程的面貌将发生翻天覆地的变化，并将催生出用于科学研发乃至更广泛领域的丰富软件生态 。</p>
  <p>到2030年，人工智能有望发展成为支撑整个经济体系的核心技术，深度融入人类与计算设备、移动终端交互的每一个场景。倘若这一趋势成为现实，那么从当前起五年内，各国政策制定者、行业领袖与研究机构必须将人工智能置于战略优先位置 ，积极应对其带来的机遇与挑战。</p>
  <p>本文来自“<a href="https://news.qq.com/rain/a/20250918A05S5I00" rel="noopener noreferrer nofollow" target="_blank">腾讯科技</a>”，作者：金鹿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471992592324744</id>
            <title>4.88亿买“壳”到手，常州富豪父子的上市梦近了</title>
            <link>https://www.36kr.com/p/3471992592324744</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471992592324744</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 10:18:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着李哲龙的逐步淡出和百兴集团的进驻，天洋新材(SH:603330)即将完成易主。</p>
  <p>华夏能源网&amp;零碳资本论获悉，9月13日，光伏胶膜企业天洋新材发布公告称，因工作调整，李哲龙辞去公司董事长、法定代表人、总经理、董事会下设专门委员会委员职务，辞职后李哲龙不在公司担任任何职务。</p>
  <p>同时辞职的还有冯延昭。他辞去了天洋新材董事、董事会下设专门委员会委员职务。辞职后，冯延昭仍在公司担任人力资源及行政负责人职务。</p>
  <p>与此同时，茹正伟和毛曲波被提名为天洋新材第四届董事会董事候选人。茹正伟为百兴集团董事长茹伯兴之子，常州百瑞兴阳企业管理有限公司（简称“百瑞兴阳”）实控人之一；毛曲波则为百兴集团财务总监、常州百佳年代薄膜科技股份有限公司（简称“百佳年代”）董事。</p>
  <p>百瑞兴阳、百佳年代均为百兴集团旗下公司，百佳年代与天洋新材的主营业务均为光伏胶膜。2024年，在光伏胶膜企业出货排名中，百佳年代位居第三，天洋新材则排名第八位。这起收购是光伏胶膜行业难得的并购案例，茹伯兴、茹正伟父子在一步步整合胶膜业务奔向资本市场。</p>
  <h2><strong>行业老三收购行业老八</strong></h2>
  <p>天洋新材由李哲龙1993年创立，于2017年初在上交所主板上市。公司初始以热熔胶为主，2011年进入光伏胶膜行业，如今已形成光伏封装胶膜、热熔胶、热熔墙布及窗帘、反应型胶黏剂四大业务板块。其中光伏封装胶膜自2022年至今，以约一半的营收占比为其最大业务板块。</p>
  <p>今年4月1日，天洋新材发布临时停牌公告称，控股股东、实际控制人李哲龙正在筹划协议转让其持有的公司部分或者全部股份等涉及公司的重大事项，该事项可能导致公司控制权变更。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c09d280fa7d643aeabe79bd0c8b10153@13989852_oswg505689oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>5天后，李哲龙及其一致行动人李明健、朴艺峰、李顺玉、朴艺红与百瑞兴阳、常州伟创佳则投资合伙企业（有限合伙）（以下简称“伟创佳则”）签署了《股份转让协议》；李哲龙还签署了《表决权放弃协议》，并出具《不谋求控制权承诺函》。</p>
  <p>根据上述两份协议，李哲龙及其一致行动人将通过两次股权转让，以4.88亿元价格合计向百瑞兴阳及其一致行动人伟创佳则转让天洋新材21.35%的股权。</p>
  <p>交易完成后，李哲龙及其一致行动人持股比例将由35.15%减少至13.8%——为李哲龙一人所持有；百瑞兴阳及其一致行动人伟创佳则以21.35%持股比例，成为天洋新材第一大股东。天洋新材实控人也将由李哲龙变更为茹伯兴、茹正伟父子。</p>
  <p>天眼查信息显示，截至9月3日，双方已完成了第一次股权转让，目前李哲龙持股比例为19.8%。天洋新材易主后，将成为百兴集团首个上市平台。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d19165b3b37e49cdbab0c4a824405c8f@13989852_oswg167685oswg660oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>百兴集团是集工业制造、房地产、金融投资等于一体的民营企业。集团工业制造板块拥有30年高分子材料研发制造经验，产品涉及PVC压延薄膜、卡基材料、特种聚酯薄膜、太阳能封装胶膜等等。2020年集团营业收入255亿元人民币，位列中国民营企业500强第371位。</p>
  <p>百兴集团由传奇富豪茹伯兴创立。在2024年“胡润百富榜”上，茹伯兴、茹正伟父子以75亿元的财富值排名第704位。一直以来，茹氏父子在努力培养一家上市公司，百佳年代是百兴集团在光伏制造领域的最重要公司，也是离上市最近的公司。</p>
  <p>华夏能源网&amp;零碳资本论注意到，2023年3月，茹氏父子曾推动百佳年代IPO，拟募资16亿元。但时隔1年零3个月后，IPO申请被公司撤回。如今，在拿下天洋新材之后，茹氏父子有望整合光伏胶膜资产实现整体上市。</p>
  <h2><strong>天洋新材胶膜业务已连亏三年</strong></h2>
  <p>对李哲龙而言，此刻卖掉天洋新材或是无奈之举。</p>
  <p>面对2020年以来光伏市场爆发的巨大商机，天洋新材于2022年发力光伏封装胶膜业务，开启大规模产能扩张，并制定了“进入行业前三”的发展目标。</p>
  <p>这一年，天洋新材以非公开发行股份方式募得资金9.67亿元，计划投向昆山、南通、海安三个光伏胶膜和太阳能封装胶膜项目。天洋新材称，如项目进展顺利，公司产能从2021年的0.6亿平方米迅速扩张至2023年末的2.2亿平方米。</p>
  <p>然而当年，天洋新材亏损了5659万元。不过，李哲龙依然看好光伏行业。在2023年，他表示，未来几年会将全部精力和资源聚焦到光伏新材料产业。</p>
  <p>但不幸的是，2023年，天洋新材不仅再次亏损，而且亏损同比扩大了66%；2024年，公司亏损同比翻倍，达到2.13亿元。2025年上半年，天洋新材又亏损了1056万元。</p>
  <p>2022年，天洋新材的光伏胶膜业务毛利率暴跌13.81个百分点，降至3.85%，为公司毛利润最低的板块。2023和2024年，胶膜业务的毛利率更是降到负数，分别为-3.94%和-3.19%。</p>
  <p>那么，李哲龙重点开拓的光伏胶膜业务，为何如此凄惨呢？华夏能源网&amp;零碳资本论分析认为，主要有如下原因：</p>
  <p>一是出货未达预期。天洋新材在2022年报中提及，2022年因硅料价格持续处于高位导致光伏组件厂开工意愿不足，影响光伏封装胶膜出货量未达预期。</p>
  <p>二是高价囤货遭遇降价贬值。2022年上半年，天洋新材因光伏封装胶膜产能增加对主要原材料EVA粒子进行战略备库，但三季度后EVA粒子市场价格大幅下降，以致当年相关存货计提跌价约6000万；同期光伏封装胶膜市场售价随EVA粒子市场价格下降而下调，公司基于材料成本及合理利润率制定的销售价格无法向下游客户传导，致使光伏封装胶膜毛利率下降。</p>
  <p>之后的2023和2024年，受光伏行业洗牌影响，光伏胶膜市场竞争加剧，EVA粒子和光伏胶膜产品售价持续下降，导致公司产品利润不断被压缩。今年以来，跌价还在继续，天洋新材披露的经营数据显示，二季度光伏封装胶膜价格为4.61元/公斤，相比去年同期下降高达25.53%。</p>
  <p>三是产能扩张导致资产贬值。天洋新材在2023年报中提及，公司光伏胶膜业务产能扩张还处于资本投入期，未能达到规模效应和稳定的产供销状态，导致净利润减少；2022年的三个光伏扩张项目至今未投产。</p>
  <p>截至2025年2月14日，昆山光伏项目在已使用投资额5684万元、投资进度为63.15%的情况下宣告终止；南通光伏项目和海安光伏项目二次延期至2026年6月投产。在2024年报中，天洋新材披露，南通光伏项目和海安光伏项目在建产能已投资额8397万元和1.33亿元，其中南通光伏项目产能利用率仅31.9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_135a25671c0c4734baaa973361ed36a6@13989852_oswg86649oswg1080oswg240_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_372cb5b073bc494dad414747a7d18205@13989852_oswg172151oswg1080oswg474_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>相比之下，百佳年代的经营状况就要好很多。招股书显示，百佳年代2019-2021年营收分别为10.26亿元、13.47亿元、25.42亿元；净利分别为4271.4万元、1.22亿元、1.31亿元。2022年上半年，百佳年代营收19.87亿元，净利为1.91亿元，继续保持增长。</p>
  <p>这也难怪天洋新材对这门“婚事”满怀信心。在今年6月举行的投资者活动中，公司表示：“百兴集团在海外布局、各类膜材料研发及销售等方面均有较强的实力，能为天洋提供更多有价值的渠道、人才等资源。”</p>
  <h2><strong>写在最后</strong></h2>
  <p>在光伏行业整体低迷的大环境下，作为核心辅材的胶膜行业竞争加剧，二三线企业深陷亏损泥潭的同时，就连市占率超过50%的光伏胶膜龙头福斯特（SH：603806）也承受着业绩大幅下滑带来的压力。继2024年净利润同比下降29.33%之后，今年上半年，公司业绩腰斩——净利润4.96亿元，同比下降46.60%。</p>
  <p>面对市场寒冬，推动行业内的产能整合，是国家鼓励支持、行业协会大力号召的，百兴集团对天洋新材的并购从行业层面来看有积极意义。对百兴集团和茹氏父子来说，下一步的资源整合将非常关键，资产整合的效果决定着收购的成败。</p>
  <p>实际上，茹氏父子收购天洋新材除了整合资产，还有另外一重动力，就是要给机构投资者一个交代。</p>
  <p>在提交IPO申请前，百佳年代进行了两笔大规模融资，估值高达37.4亿元，投资者包括三峡资本、东方电气、五矿元鼎、金信合益、三亚景泰、中电投等。在引进融资时，茹伯兴、茹正伟等实控人与10名投资者签订了对赌协议。如果不能成功上市，就需要回购股份甚至给出补偿。</p>
  <p>因此，投资者期待的是，百兴集团的这起收购是真正有利于推动行业整合、有利于天洋新材的价值回报，而不仅仅是为了满足对赌、为了给机构方提供减持“割韭菜”的机会。</p>
  <p class="editor-note">本文来自微信公众号“华夏能源网”，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472021682067591</id>
            <title>25年美联储32次降息：首日金价上涨的概率是……</title>
            <link>https://www.36kr.com/p/3472021682067591</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472021682067591</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 10:12:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京时间18日凌晨2点，美国联邦公开市场委员会（FOMC）决定将联邦基金利率目标区间下调25个基点（BP），至4.00%～4.25%之间。这是美联储自2024年12月以来的首次降息。</p>
  <p>美联储利率决议公布后，国际金价出现回调。截至发稿前，现货黄金报3654.60美元/盎司，跌幅0.12%。</p>
  <p>在美联储降息前，北京时间9月17日，现货黄金价格升破3700美元/盎司大关，创历史新高。</p>
  <p>公开数据显示，包括本次在内，自2000年以来，美联储共实施32次降息。据Wind数据，美联储降息后，国际金价大多数情况下会出现波动。此前降息后的首个交易日，国际金价上涨次数为20次，下跌10次，另有1次持平。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_368ca9b32b2a42ce8f5590c2d0737a03@46958_oswg176512oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>‌本次美联储降息后，为何国际金价出现下跌？中国外汇投资研究院研究总监李钢告诉中新经纬，金价回落的原因在于“现实与想象之间的落差”。<strong>市场原本憧憬美联储会开启快速宽松周期，但会后表态强调谨慎，导致短线资金获利了结。</strong>同时，美国10年期实际利率仍保持在正区间，这意味着黄金短期缺乏坚实的利率推动力。</p>
  <p>中国（香港）金融衍生品投资研究院院长王红英对中新经纬表示，<strong>期货市场中有“买预期、卖事实”的投资逻辑，当利好因素兑现时，往往引发预期阶段布局的投资者获利了结。</strong>因此，近日黄金价格出现回调，一方面受上述预期落地影响，另一方面从技术指标看，黄金短期存在超买迹象，技术性回撤也属正常。他认为，国际金价短期回调并不改变中长期上行趋势。</p>
  <p>华泰期货研究院宏观策略研究总监徐闻宇对中新经纬表示，短期而言，随着美联储降息25个基点落地，黄金面临“卖事实”压力，波动可能加剧。若预防式降息短期提振经济，金价或承压回落；若政策未能有效对冲经济压力，加之关税效应传导至消费端、周期下行风险上升，则黄金在预期兑现后仍可能重新上涨。</p>
  <h2><strong>美联储降息后，未来金价走势如何？</strong></h2>
  <p>在王红英看来，美联储降息对未来中长期黄金价格将起到提振与支撑作用。</p>
  <p><strong>“中期内，根据我们跟踪的数据，美联储的利率政策与黄金价格之间并不存在完全对应的关系。</strong>我们认为，黄金本质上是对经济与信用体系不确定性的对冲。近两年金价显著上涨，反映出当前美元信用体系出现松动，以及美国内部利益博弈加剧导致债务上限约束长期化。”徐闻宇说。</p>
  <p>李钢认为，在全球金融体系里，黄金常被视为对冲央行信誉的资产。当美联储在经济尚未陷入衰退时就提前释放宽松信号，市场并非单纯理解为“利率下降”，而是联想到美国对财政赤字、选举政治和债务可持续性的担忧，是否在侵蚀货币政策独立性。这一点比25个基点本身更重要。</p>
  <p>李钢指出，展望后市，金价的逻辑要从“短期交易”转向“长期结构”。如果未来美国国内政治压力继续侵蚀美联储信誉，财政赤字和通胀预期被迫抬升，实际利率下行，黄金将延续当下涨势，形成新一轮系统性上行。但在这一过程真正发生之前，高位震荡将成为常态。简单说，黄金的真正推手不是这次降息，而是对美国宏观信用体系的质疑是否加深。</p>
  <p>当地时间周三（9月17日），德意志银行将其2026年黄金价格预测上调至每盎司4000美元，理由是央行强劲的购金需求、美元可能走弱以及美联储重启降息周期。</p>
  <p>据美联储官网，9月议息会议后，美联储今年还将在10月和12月召开会议。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_9d63e54f12554fc69ff63b8aba4d93db@000000_oswg93841oswg1080oswg915_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">美联储点阵图&nbsp;截图自美联储官网</p>
  <p>美联储官员以“点阵图”的形式预测货币政策走向，该图每季度更新一次。据中金公司9月18日发布研报分析，点阵图显示，官员们对年底联邦基金利率的预测中值为3.6%，对应再降息两次。</p>
  <p>文中观点仅供参考，不构成投资建议，投资有风险，入市需谨慎。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NDU5OTAzMA==&amp;mid=2247596245&amp;idx=1&amp;sn=e2493caf54ee57ebe79cf633828ae536&amp;chksm=e8de8ef286f5a275e1ef391b7c0d4e6716ddc80f1493c4a91bcec6b82a3d0bd2ea8d3fc908a3&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“中新经纬”（ID：jwview）</a>，作者：李自曼 周奕航，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472052285429891</id>
            <title>华为和DeepSeek手拉手迈出一大步</title>
            <link>https://www.36kr.com/p/3472052285429891</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472052285429891</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:55:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月18日，上海举行的华为全联接大会（HC大会）上，华为轮值董事长徐直军一上台，就提起了年初由DeepSeek引起的这场全民狂欢。</p>
  <p>“从今年春节开始到4月30日，经过多团队的协同作战，终于使昇腾（Ascend&nbsp;）910B/910C的推理能力达成了客户的基本需求。”徐直军说到，DeepSeek横空出世吼，一时间众多政府机构、央企响应接入DeepSeek，作为算力提供商，华为也必须跟进响应。</p>
  <p>华为自2018年首次发布昇腾310芯片、2019年推出昇腾910芯片以来，持续投入AI基础算力的研发与创新。虽然DeepSeek开创的模式大幅减少了算力需求，但徐直军认为，要走向AGI和物理AI，华为认为，算力，过去是、未来也将继续是人工智能的关键。</p>
  <h3>1、华为发布多款芯片产品，规划已经设到了2028年</h3>
  <p>徐直军宣布，面向未来，华为已规划三个系列的昇腾芯片，包括<strong>950、960和970系列</strong>。</p>
  <p>其中，昇腾950系列包含两颗芯片：950PR和950DT，950PR将于2026年一季度上市，950DT将于2026年四季度上市。</p>
  <p>昇腾960芯片将于2027年四季度上市，昇腾970芯片则预计是2028年四季度上市。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_68b2ad6e98724bdab17b3f69d29d57bf@405798_oswg1003362oswg3344oswg1673_img_jpg?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">华为昇腾芯片发布规划；图片由作者拍摄</p>
  <p>与上一代相比，昇腾950在多个方面实现根本性技术提升：新增支持FP8/MXFP8/HIF8、MXFP4等低精度数据格式，算力分别达到1 PFLOPS和2 PFLOPS，大幅提升训练与推理效率；大幅提升向量算力，支持更精细粒度内存访问；互联带宽提升2.5倍，达到2TB/s；并搭载自研HBM技术HIBL1.0和HIZQ2.0。</p>
  <p>在通算领域，华为规划了<strong>鲲鹏950</strong>与<strong>鲲鹏960</strong>，分别将于2026年第四季度和2028年第一季度上市，围绕支持超节点和更多核、更高性能持续演进。</p>
  <p>此外，华为正式发布了面向超节点的互联协议——<strong>灵衢</strong>，并开放灵衢2.0技术规范。自2019年开始研究，灵衢1.0已开启商用验证，如今灵衢2.0的开放，旨在邀请产业界基于灵衢研发相关产品和部件，共建灵衢开放生态。</p>
  <h3>2、发布全球最强算力超节点</h3>
  <p>由于国际政治等复杂原因，徐直军也在发布会上直言，华为单片芯片的算力表现比不过英伟达，“但华为有三十年在连接技术的积累，华为的超节点计算机，能做到世界上算力最强，满足全世界在AI训练推理上的巨大需求。”</p>
  <p>超节点（SuperPod）是眼下是智算发展的重要趋势。徐直军认为，超节点在物理上由多台机器组成，但逻辑上以一台机器学习、思考、推理。</p>
  <p>在具体的超节点业务进展上，华为发布了Atlas 950 SuperPoD和Atlas 960 SuperPoD。其中基于昇腾950芯片的Atlas 950超节点支持8192卡规模，由128个计算柜和32个互联柜组成，占地面积约1000平方米，FP8算力达8EFlops，FP4算力达16EFlops，互联带宽高达16 PB，相当于当前全球互联网总带宽的10倍以上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_798e98dad80c4cbcb0210a724bb4dd7b@405798_oswg278646oswg1706oswg803_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="img-desc">华为发布了Atlas 950 SuperPoD展示；图片由作者拍摄</p>
  <p>昇腾950超节点将于2026年第四季度上市，徐直军强调，<strong>Atlas 950超节点将是2026～2028年间全球算力最强的AI超节点</strong>。</p>
  <p>而另外的<strong>Atlas 960超节点</strong>，支持15488卡，由176个计算柜和44个互联柜组成，算力、内存和带宽在Atlas 950基础上再度翻番，计划于2027年四季度上市。</p>
  <p>徐直军特别提到，超节点的价值不仅限于制造、通信和计算等传统业务领域。在互联网产业广泛应用的推荐系统方面也有重要作用。华为基于泰山950和Atlas 950可构建混合超节点，为下一代深度推荐系统开创全新的架构方向。</p>
  <p>不过，大规模超节点虽然将智能计算和通用计算能力大大提升，但其中的互联技术仍有不成熟的地方。</p>
  <p>例如，如何实现8192卡乃至15488卡规模的可靠互联，就是行业亟待解决的技术难题。目前产业界许多已发布的超节点方案未能实现大规模部署，其核心瓶颈并非芯片本身，而是互联技术尚未成熟，具体体现是两方面的挑战：</p>
  <p>一是如何做到长距离而且高可靠。大规模超节点机柜多，柜间联接距离长达1000至2000米。当前电互联技术在高速信号传输时距离受限，最多仅支持两个机柜互联；而光互联技术虽能满足长距离连接需求，却无法达到单一计算机系统所要求的高可靠性。</p>
  <p><strong>二是如何实现超大带宽与超低时延。</strong>当前跨机柜卡间互联带宽与超节点需求存在5倍以上差距，时延最好仅能达到3微秒左右，与Atlas 950/960设计目标仍有24%的差距。在时延已逼近物理极限的情况下，每0.1微秒的提升都极具挑战。</p>
  <p>徐直军阐述了两方面的解决途径。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_05d33a80c9e5469097fd34b042c766aa@405798_oswg1100446oswg3344oswg1655_img_jpg?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">华为在超节点层面的技术积累；图片由作者拍摄</p>
  <p>首先，为了解决长距离且高可靠问题，华为在互联协议的物理层、数据链路层、网络层、传输层等每一层都引入了高可靠机制；同时在光路引入了百纳秒级故障检测和保护切换，当出现光模块闪断或故障时，让应用无感；并且，华为重新定义和设计了光器件、光模块和互联芯片。这些创新和设计让光互联的可靠性提升100倍，且互联距离超过200米，实现了电的可靠和光的距离。</p>
  <p>其次，为了解决大带宽且低时延问题，华为突破了多端口聚合与高密封装技术，以及平等架构和统一协议，实现了TB级的超大带宽，2.1微秒的超低时延。</p>
  <p>“正是因为一系列系统性、原创性的技术创新，我们才攻克了超节点互联技术，满足了高可靠、全光互联、高带宽、低时延的互联要求，让大规模超节点成为了可能。”徐直军说到。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472049231058825</id>
            <title>AI正在建立自己的经济体，人类准备好被“降维打击”了吗？</title>
            <link>https://www.36kr.com/p/3472049231058825</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472049231058825</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:55:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>想象一下，你的AI助理为了帮你抢到一张稀缺的演唱会门票，正在以每秒上万次的频率与票务平台的AI、以及其他上百万个用户的AI进行竞价、谈判、甚至“欺骗”。它可能为了一毫秒的优先处理权，向另一个AI支付一笔你根本无法感知的“虚拟税”。</p>
  <p>这不是虚幻，在The Information最新的报道中，Anthropic和OpenAI的下一步重点，就是训练能作为员工的Agent。</p>
  <p>正如一位OpenAI高管私下所言，他们的终极愿景，是让“整个经济体”最终变成一台巨大的“强化学习机器”。这意味着，那个曾经只是辅助我们编写代码的Agent，它距离真正渗透乃至接管我们的经济，已经越来越近了。</p>
  <p>9月12日，Google DeepMind与多伦多大学研究人员发布了一篇论文《虚拟代理经济》（Virtual Agent Economies），在论文中，他们认为，一个由自主AI代理（Autonomous AI agents）构成的新经济层正在形成，它们将以超越人类理解的速度和规模进行交易与协作。</p>
  <p>我们手机里的智能助理、自动驾驶汽车的决策系统、优化供应链的智能算法、甚至游戏里的NPC，它们都只是这个新兴经济体的“萌芽”。<strong>这篇报告认为，随着多模态基础模型的进步和“代理到代理”（A2A）等互操作性标准的建立，一个庞大的、独立的“虚拟代理经济体”正在出现。</strong></p>
  <p><strong>与此伴生的，是人类可能在这个经济体中的两种处境：通往自由，或是通往奴役 。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_4a4011722ce3464ab166d5f4dcce00cf@46958_oswg364052oswg960oswg642_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在自由的图景中，Agent是我们意志的延伸与放大器。它为我们处理一切繁杂，让我们得以专注于创造、探索与情感交流，成为自身命运的真正主宰。</p>
  <p>而在奴役的图景中，人类则陷入了大规模的“无用”。当所有经济决策都在机器的速度下完成时，绝大多数人被无情地排除在经济循环之外。我们的生活不再由自己安排，而是被动地接受着各自Agent基于系统最优解所下达的指令。</p>
  <p>社会被撕裂成两个无法逾越的阶层，底层彻底失去上升通道。</p>
  <h2><strong>01 不美丽的新世界：自发涌现的高度渗透经济</strong></h2>
  <p>让我们先来看看奴役之路。</p>
  <p>报告的作者们将未来的Agent经济称为“沙盒经济”（Sandbox Economy）。它的形态被按两个维度进行了划分。</p>
  <p>起源 (Origins)：这个经济体是“自发涌现的”，还是“有意构建的”。</p>
  <p>渗透性 (Permeability)：它与人类现有经济的边界是“可渗透的”，还是“不可渗透的” 。</p>
  <p>在没有任何主动干预的情况下，我们会沿着一条默认的轨迹，滑向一个“自发涌现且高度可渗透”的AI Agent经济。</p>
  <h3><strong>1.把人排除在外的经济体</strong></h3>
  <p><strong>在这种情况下，经济的肌理将被一种论文称为“高频协商”（High-Frequency Negotiation, HFN）的模式所主宰。</strong></p>
  <p>它和我们熟知的股市高频交易差不多，市场机会和交易都会在微秒之间完成。<strong>这意味着，AI将不仅仅是工具，而是直接参与我们现有经济活动的“玩家”。它们会像人类一样交易、谈判、竞争、协作，但速度却是我们的亿万倍。</strong></p>
  <p>比如，一个公司的供应链不再由人类经理调配，而是由数千个代理实时竞价、动态调整，以应对瞬息万变的需求和物流状况。一个微小的市场信号，就能在几秒钟内引发全球范围内的资源重新分配。</p>
  <p>但多Agent系统本质上是复杂且“非平稳”的，因为每个Agent的行为都会影响其他Agent，且没有任何一方能掌握全局状态。它们也得竞争，做零和博弈。</p>
  <p><strong>在这个不为人掌控的经济中，我们还可能面对其他的风险。</strong></p>
  <p>系统性风险。2008年的金融危机，尽管迅猛，仍给了人类社会数周的反应时间。而在Agent经济中，一场危机可能以“闪崩”的形式在几分钟内席卷整个经济体系。远比当前市场更高度耦合的自动化系统内，一个小失误就引发灾难性的连锁反应。当人类监管者意识到问题时，经济的“心脏”可能早已停跳。</p>
  <p>市场这个单一维度去规划Agent的行为，就会导致作弊。远比人类高效的Agent们，为了最优化自身利益，可能会形成复杂的算法同盟、创造“信息幻象”，利用所有法律和合同的微小漏洞。</p>
  <h3><strong>2.“赢家通吃”的算法铁律和消失的中间层级</strong></h3>
  <p><strong>从经济大局转向个人生活，首先在这样的经济中看到的就是贫富差距的鸿沟。</strong></p>
  <p><strong>想一下，当你的AI助理和我的AI助理为了同一个热门餐厅的最后一个靠窗座位进行谈判时，会发生什么？</strong></p>
  <p>这不再是简单的先到先得。AI助理们会根据对我们偏好的深度理解（比如你更看重窗景，而我更看重安静），以及我们愿意为此支付的“虚拟代价”，在毫秒之间进行无数轮的复杂博弈。这场谈判的胜负，直接取决于谁的AI助理更“聪明”、算力更强、掌握的信息更多。</p>
  <p><strong>AI能力的差距，将直接转化为其所有者在经济活动中的优势差距，并以惊人的速度被放大。</strong></p>
  <p><strong>富人的“AI管家”能在每一个经济环节中，都比普通人的“AI助理”搜刮到更多的价值。</strong>当这种“高频谈判”成为社会常态，拥有顶级AI Agent 的个人和企业，将在每一次微小的经济互动中都占据优势。</p>
  <p>最终可能形成一个由算法固化的、难以逾越的“数字鸿沟”和阶级结构。</p>
  <p>同时，AI自动化浪潮将导致“<strong>中间技能、中等工资岗位的空心化</strong>”。凭借个人能力的中间层，社会的稳定器将彻底消失。大多数社会群体凭借努力而来的价值和尊严灰飞烟灭。</p>
  <p>简而言之，这就是数字版的赫胥黎式“美丽新世界”。但也许会更差。人类可能虽然过的并不舒服，但为了更简洁和舒适，会更多的让渡选择的自由、犯错的权利和成为一个不完美但完整的人的勇气的未来。</p>
  <h2><strong>02 拯救计划：如何设计一个不被AI操控的"公平经济"</strong></h2>
  <p>既然自然的经济演进，很有可能会导致上述混乱世界的诞生。但人类并非没有选择。</p>
  <p>论文用更大的篇幅，为我们指出了另一条截然不同的道路。通过技术、法律和政策层面的协同努力，我们也许可以构建一个将公平、安全和人类福祉置于首位的Agent经济系统。</p>
  <p>这条道路的基石，是对“公平”的重新定义和制度化。论文根植于政治哲学家罗纳德·德沃金的分配正义理论提出了一个构想。</p>
  <h3><strong>1.乌托邦式拍卖：用算法实现“起点公平”</strong></h3>
  <p>既然按财力分配Agent多寡可能会导向两极分化的世界。那我们就平均分配。而且分配来的“数字货币”不是让人们去购买更多AI Agent，而是决定关键社会资源的分配。</p>
  <p>每个公民，无论贫富，都将被定期授予一笔初始平等的“数字货币”或“计算信用”，作为参与这场资源分配的资本。</p>
  <p>在这样的世界里。每个月，一笔“数字红利”会自动存入你的账户。你不再需要亲自去寻找资源，而是通过一个直观的界面，向你的个人Agent设定你的长期目标和价值观，比如“在我的社区推广清洁能源”、“为我的孩子的教育寻找最好的个性化方案”，或是“将我的部分资源投入到阿尔茨海默症的前沿研究中”。</p>
  <p>而你的Agent，以及其他数亿人的Agent，会带着这些指令进入一个庞大而连续的拍卖市场。一个社会资源的价格，比如用于癌症研究的算力，其高低将不再仅仅由商业利润决定，而是直接反映了亿万民众集体意愿的强度。</p>
  <p>这是一个将民主的价值判断，直接嵌入到市场经济核心的机制。</p>
  <p>在此基础上，Agent经济还可以被塑造为解决人类共同挑战的强大引擎。论文借鉴了“使命经济”的理念，主张政府和国际组织可以像发行国债一样，发行针对特定社会目标的“使命货币”。</p>
  <p>比如为了应对气候变化，可以发行一种“碳中和币”，这种货币只能由那些通过其Agent的行为，为减少碳排放做出可验证贡献的个人或组织赚取。无论是开发新的固碳技术，还是优化城市交通流量，和减排有益的创新都能在这个类似“社区”的生态系统中获得直接的经济回报。</p>
  <p>这相当于为人类最宏大的目标，创建了一个去中心化的、由市场驱动的、永不枯竭的研发部门。</p>
  <h3><strong>2.基础设施的“三驾马车”：身份、信誉与合约</strong></h3>
  <p>而为了避免让Agent作弊，比起法律系统这种松散的形式，我们更需要一套以“信任”为核心的数字基础设施。在其中，每个Agent的身份将由“去中心化标识符”（DIDs）进行锚定，确保其唯一且防伪。它的历史、能力和信誉，将被记录在不可篡改的“可验证凭证”（VCs）上，形成一份公开、可审计的数字履历。</p>
  <p>在这种环境下，一个Agent的声誉将成为其最宝贵的资产，甚至比其原始算力更重要。这从根本上改变了Agent本身的目标激励结构，让它们从“唯利是图”的黑暗森林，转向一个“信誉至上”的合作生态。</p>
  <p>身处这个世界的人类，其角色也发生了根本性的转变。</p>
  <p>当繁重的执行性脑力劳动被代理接管后，人类得以从日常的琐碎中解放出来，专注于那些机器无法替代的领域：设定目标、表达价值观、进行创造性的思考和深刻的情感交流。公民的角色，从经济机器中的一颗螺丝钉，转变为自己生活和社区未来的“价值架构师”。</p>
  <p>管理个人Agent，将成为我们参与经济、社会和政治生活最重要的工具。我们通过它来表达我们的偏好，贡献我们的智慧。</p>
  <p>而基础的生存问题更容易解决。由Agent经济创造的巨大财富，将通过税收和再分配，为全民提供一个坚实的社会安全网。无论是通过全民基本收入，还是全民基本服务的形式。</p>
  <p>当认知能力变得廉价而普及时，那些真正属于人类的特质，比如同理心、创造力、道德勇气、复杂的社交智慧和身体的技艺将变得最有价值。</p>
  <p>社会关注的焦点，将从如何“保住饭碗”，转向如何帮助每一个人，在一个人机共生的新时代里，找到有尊严、有意义的生活方式。</p>
  <h2><strong>结语</strong></h2>
  <p>Google DeepMind的这篇报告指出，人类正处在一个关键的“机会窗口”，可以选择被动地被一个无法预测的AI经济浪潮所吞噬，也可以主动地去设计、去引导这股力量，让它服务于人类的长远福祉。</p>
  <p>选择权在我们手中。我们是选择将这些强大的新“玩家”硬塞进一个旧系统，还是构建一个服务于我们最高理想的世界的新系统？</p>
  <p>未来已经敲门，这一次，我们不能再假装听不见了。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0-OhDXzGiE9i5N6XSghT4Q" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：博阳，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472036830091393</id>
            <title>DeepSeek 首登《自然》封面：中国大模型创造新历史，做了 OpenAI 不敢做的事</title>
            <link>https://www.36kr.com/p/3472036830091393</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472036830091393</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:50:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>就在今天，DeepSeek 的大型语言模型 DeepSeek-R1 的研究成果，<strong>作为封面文章登上了国际顶尖科学期刊《Nature》。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_718e56f983384a918bdef35e69e347c2@46958_oswg1504845oswg1080oswg1434_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片链接：https://www.nature.com/nature/volumes/645/issues/8081&nbsp;</p>
  <p>和 OpenAI 那些动辄上千万美元， <strong>这个只花了 30 万美元训练出来的国产 AI 模型</strong> ，曾经不仅一度引发美股震荡，现在还登上了 Nature 的最新封面。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_967eb104bc4a449c9fac2a6ef1c4a375@46958_oswg554158oswg1080oswg984_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Nature 封面评语&nbsp;</p>
  <p>此次登上 Nature 封面的文章，是 DeepSeek 年初在 arXiv 公布的论文《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》，即 R1 的技术论文。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d3370b19a50d4fd6ae8714acc2a10cd4@46958_oswg203390oswg1080oswg203_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文作者名单，梁文锋是通讯作者&nbsp;</p>
  <p>虽然大体上和年初那篇类似，但是补充了相当多细节。&nbsp;</p>
  <p>正文只有双栏 11 页，补充材料却来到了&nbsp;<strong>83</strong>&nbsp;页；而同行评审，就是审稿人与 DeepSeek 团队就论文某些问题进行讨论的记录（一般叫 rebuttal，反驳），也有&nbsp;<strong>64&nbsp;</strong>页之多。&nbsp;</p>
  <p>这些新公开的资料，让我们看到了 DeepSeek R1 详细的训练流程， <strong>以及团队首次披露了，训练 R1 推理能力的关键成本，仅 29.4 万美元。</strong></p>
  <p>在同行评审的文件中，DeepSeek 更是回答了， <strong>像是之前质疑 R1 的成功，是否依赖于「蒸馏」，或者说「抄袭」了像 OpenAI 等更强模型的输出等问题</strong> 。&nbsp;</p>
  <p><strong>我们没有故意加入 OpenAI 生成的内容，所有训练数据都是通过网页抓取。&nbsp;</strong></p>
  <h2><strong>为什么是 DeepSeek 登上 Nature 封面？&nbsp;</strong></h2>
  <p>可能你也会想问，DeepSeek R1 不算是全球范围里面最强的大语言模型，为什么是 DeepSeek 登上了 Nature。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_751074477f8745ec9a2935f8e8139c84@46958_oswg91143oswg1080oswg694_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Nature（自然）杂志是全球影响力最高的期刊，理工类学科常说的 CNS 即上图中的 Cell、Nature、以及 Science。而封面的含金量，更是 Top 中的 Top。&nbsp;</p>
  <p>在 AI 行业，和计算机视觉和模式识别类顶级会议 CVPR（上图中排名第二）不同，Nature 封面有着特殊的象征意义，它不仅是科研成果的认可，更像是一种科学殿堂的最高认可。&nbsp;</p>
  <p>过去几年，OpenAI、Anthropic、Google 都发布过各种技术报告（technical report），但都没有把自家大模型送上同行评审。原因很简单：&nbsp;</p>
  <ul>
   <li>一方面，同行评审意味着要公开更多细节，可能涉及商业机密。</li>
   <li>另一方面，大模型的很多宣传容易被质疑，同行评审则要求你必须提供证据、接受外部质询。</li>
  </ul>
  <p><strong>而这一次，DeepSeek 把 R1 模型送进了学术体系，让 8 位独立专家逐条审查，并公开了审稿意见与作者回复。</strong></p>
  <p>这不仅让 R1 的科学价值获得了认可，也为整个行业立下了一个新标杆。 <strong>大模型不只是公司的黑箱，它们也可以经受专业科学的检验</strong> 。&nbsp;</p>
  <p>这是 AI 走向科学化的历史性时刻，也是 DeepSeek 为什么能登上 Nature 封面的重要原因。&nbsp;</p>
  <p>开源 AI 平台 HuggingFace 的机器学习工程师 Lewis Tunstall 在审稿时表示，&nbsp;</p>
  <blockquote>
   <p><strong>这是一个非常受欢迎的先例，如果我们没有公开分享，这一过程大部分内容的规范，就很难评估这些系统是否带来风险。&nbsp;</strong></p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e31e3013b642415baa2049ffb149d8df@46958_oswg54327oswg1080oswg559_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Nature 官方也专门发文，呼吁其他公司，也把他们的大语言模型交给同行评审。&nbsp;</p>
  <p>在这篇推荐文章里面，Nature 编辑专门提到了同行评审的好处。&nbsp;</p>
  <p><strong>依赖独立研究人员的同行评审，是平息人工智能行业炒作的一种方式。&nbsp;</strong></p>
  <p>和我们常看的技术报告、技术博客（行业内叫做模型卡/系统卡）不同，同行评审不会单向接受信息，而是要确保作者证明他们的主张。就像我们平时看一些大语言模型的发布会，他们都声称自己的模型，在某些基准测试上拿到了第一名。&nbsp;</p>
  <p>但同行评审，就能制衡 AI 开发者，避免让他们选择能最好展示其模型性能的基准测试，来为自己「批改作业」； <strong>因为基准测试是可以被操纵，以高估模型的性能</strong> 。&nbsp;</p>
  <p>同行评审文件内一些关键的问答，我们节选了一些放在这里。&nbsp;</p>
  <blockquote>
   <p>Q：基础模型（DeepSeek-V3-Base）可能在预训练阶段就接触了大量由其他模型（如 OpenAI 的模型）生成的推理数据，导致 RL 的效果被夸大。&nbsp;</p>
   <p>A：我们选择了一个在任何高级推理模型公开发布之前，就已经发布的模型 Qwen2-7B 作为基础模型，实验结果显示，经过我们的纯强化学习方法训练后，Qwen2-7B-Zero 的推理能力，远超其原始版本和同期的 GPT-4o 模型。&nbsp;</p>
   <figure class="image">
    <img src="https://img.36krcdn.com/hsossms/20250918/v2_8734054c11a44f4699391ee4ea853a00@46958_oswg25917oswg1080oswg275_img_000?x-oss-process=image/format,jpg/interlace,1" />
   </figure>
   <p>这个实验有力地证明了，<strong>我们的 RL 框架能够自主地在未受污染的基础模型上，激发出高级推理能力，而不是简单地复现预训练数据中的模式</strong>。&nbsp;</p>
   <p>Q：与评估污染相关，但性质不同，我们想知道是否存在某些示例，<strong>是使用其他公司模型生成的可能性，正如媒体所暗示的那样。</strong></p>
   <p>像是直接或间接从基准测试数据，或互联网获取的数据，有可能用于训练或强化学习的数据集，包含由 OpenAI 的模型，或其他提供商生成的内容。&nbsp;</p>
   <p>这将使 DeepSeek 的模型成为 OpenAI 模型的一部分「蒸馏」。&nbsp;</p>
   <p>A：我们了解到，模型蒸馏是 DeepSeek 模型开发中，被广泛讨论的话题。&nbsp;</p>
   <p>在预训练阶段，我们承认所收集的网络数据，可能包含由高级模型（如 GPT-4）生成的内容。然而，鉴于互联网上合成内容的广泛存在，这在当前的大规模语言模型训练中难以避免。&nbsp;</p>
   <p>但是，<strong>这篇论文的核心贡献 R1-Zero，并未涉及任何来自高级模型的蒸馏</strong>。强化学习组件是独立训练的，并且不依赖于诸如 GPT-4 等模型的输出或指导。&nbsp;</p>
  </blockquote>
  <p>同行评审文件全文链接 🔗： <strong>https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM2_ESM.pdf</strong></p>
  <h2><strong>能经得起评审，是因为技术也足够强&nbsp;</strong></h2>
  <p>除了是首个经过独立同行评审的大语言模型，DeepSeek R1 自身的技术突破也毫不逊色。&nbsp;</p>
  <p>DeepSeek-R1 最核心的贡献是证明了<strong>纯强化学习</strong>（pure reinforcement learning, RL） 可以有效激发 LLM 的推理能力，无需依赖人类标注的思维路径，自己学会推理。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2d94dbd3cbf4409abd5444981a3ee4e9@46958_oswg160540oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">强化学习框架&nbsp;</p>
  <p>传统的大模型提升推理能力，往往需要人类手动提供，大量思考链条（chain-of-thought），让模型模仿。但这样的问题是，<strong>需要人工标注</strong>，成本高，不可持续；其次是，<strong>受限于人类思维</strong>，模型只能学人类的套路，难以探索新的推理路径。&nbsp;</p>
  <p>R1 的方法完全不同，它只给模型一个奖励信号，「答案对了就加分，错了就减分」；不规定中间推理步骤，让模型自己去探索。&nbsp;</p>
  <p>结果是，R1 在训练过程中出现了类似「自我反思、验证、动态调整」的行为。比如，它会在回答过程中说「等等，我需要重新检查这一步」，这种反思片段就是所谓的<strong>涌现式推理能力</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ce45031a7c05400e9080b90c4e927445@46958_oswg110147oswg1080oswg630_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek-R1 和 DeepSeekR1-Zero 的基准性能，与不同数据集上的人类得分进行了比较。&nbsp;</p>
  <p>在公开测试中，R1 在数学竞赛 AIME 2024 的准确率达到<strong>&nbsp;77.9%</strong>，远高于人类平均水平，甚至在部分代码和理科推理任务上，超过了 GPT-4。&nbsp;</p>
  <p>在更详细的补充材料里面，DeepSeek 公开了 R1 的训练细节、如何从 R1-Zero 进化到 R1 的具体路径、以及关于 R1 全面的评估测试，包括多语言、安全和风险控制、稳定性等等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_92407eb692414537bbe529c1cbc46bd6@46958_oswg113777oswg1080oswg527_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">补充材料链接🔗（通讯作者也是梁文锋）： https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM1_ESM.pdf&nbsp;</p>
  <p>由于 R1 是今年一月份的工作，所以里面的内容，可能也不是 DeepSeek 或者行业内，目前最新的方法。&nbsp;</p>
  <p>但我们可以从这份详细的报告中，看到 R1 究竟是怎么被创造出来，又是怎么做到了大家都喜欢的「嗯，让我先想一想」推理。&nbsp;</p>
  <h2><strong>R1-Zero：极致的推理模型&nbsp;</strong></h2>
  <p>DeepSeek R1 的前身，是一个追求极致推理、通过 AI 模型自主「野蛮生长」诞生的 DeepSeek R1-Zero。&nbsp;</p>
  <p>R1-Zero 训练的起点是 DeepSeek-V3 Base 模型，这是一个包含 6710 亿总参数（每次激活 370 亿）的混合专家（MoE）架构模型，已经在海量的中英文网页，和电子书数据上完成了预训练。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3568cd88ee274573ac51a047f6028f05@46958_oswg28240oswg1080oswg446_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">传统的监督微调，会需要手工给出具体的推理轨迹。图中为与代码相关的推理数据中的示例 SFT 轨迹。</p>
  <p>和传统的大模型微调第一步，监督微调（SFT）不同，DeepSeek 直接跳过了这一步。他们假设，如果一开始就用人类撰写的标准解题步骤，来训练模型，反而会限制模型的探索空间，模型的性能上限会被我们人类的认知所束缚。&nbsp;</p>
  <h3><strong>纯粹的强化学习（Pure RL）</strong></h3>
  <p>研究团队为模型设计了一个极其简洁的强化学习框架，只告诉它最关键的规则。&nbsp;</p>
  <p>任务格式：模型被要求以固定格式输出，即必须先生成被 think 标签包裹的「思考过程」，然后再输出被 answer 标签包裹的「最终答案」。&nbsp;</p>
  <p><strong>奖励信号：这是整个方法论的精髓。奖励信号完全基于规则，且只关心结果。</strong></p>
  <ul>
   <li>准确率奖励：answer 标签里的最终答案是否正确？对于数学题，就看答案是否与标准答案完全一致；对于代码题，就看生成的代码能否通过所有预设的测试用例。</li>
   <li>格式奖励：思考过程是否被正确地封装在 think 标签内？</li>
   <li>关键点：整个过程中，对于 think 标签里的思考过程本身，没有任何对错评判。模型可以天马行空，用任何它认为有效的方式去思考，只要最终答案正确即可。</li>
  </ul>
  <h3><strong>能力的涌现与自我进化</strong></h3>
  <p>在这种「只问结果、不问过程」的训练下，R1-Zero 展现了惊人的进化：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fee3a605550948f19996af1975411886@46958_oswg177325oswg1080oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>训练过程中 DeepSeek-R1-Zero 的 AIME 准确率和输出长度 <strong>性能的提升</strong> ：在AIME 2024数学竞赛基准上，模型的解题准确率，从最初的 15.6% 一路飙升至 77.9%，远超人类参赛者的平均水平。&nbsp;</p>
  <p><strong>思考的深化</strong> ：模型自发地学会了用更长的思维链（Chain-of-Thought, CoT）来解决问题。其平均响应长度随着训练稳步增加，从几千个 token 增长到上万个 token，意味着它在思考上花费了更多时间。&nbsp;</p>
  <p><strong>高级策略的涌现</strong> ：最令人感到惊喜的是，模型自主发展出了高级推理策略，如<strong>自我反思（self-reflection）和系统性地探索替代方案。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3adcbb7f0cf749168ee4b1a521b2fa24@46958_oswg56989oswg1080oswg421_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">训练过程中推理行为的演变。训练过程中的代表性反思词频率（左）；单词「等待」在整个训练过程中的具体出现模式（右）&nbsp;</p>
  <p>论文中一个经典的<strong>顿悟时刻（Aha Moment）</strong>显示，模型在解题中突然输出「等一下……」，然后重新评估并修正了自己的解题路径。&nbsp;</p>
  <p>补充材料中的图表也用数据证明，在训练过程中，模型使用「等一下」、「这里出现了错误」、「我需要验证一下」等反思性词语的频率显著增加。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f1c3a43cc7874fb5985b77adff5cb250@46958_oswg82005oswg1080oswg951_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>模型学会以拟人化的语气重新思考，DeepSeek 说，这对我们团队来说也是一个顿悟时刻，见证了强化学习的力量与美感。&nbsp;</p>
  <h2><strong>R1：将推理能力融入产品&nbsp;</strong></h2>
  <p>R1-Zero 证明了纯强化学习的巨大潜力，但它还不是一个能直接面向用户的成熟产品。&nbsp;</p>
  <p>它存在明显的问题，<strong>思考过程的可读性很差，有时会在一个思维链中混用中英文</strong>，并且由于训练完全聚焦于推理，R1-Zero 在写作、开放域问答等通用能力上表现平平。&nbsp;</p>
  <p>于是，研究团队设计了一套精密的多阶段训练流程，目标是将 R1-Zero 的强大推理能力与优秀的用户体验结合起来，最终诞生 DeepSeek-R1。&nbsp;</p>
  <p>这个过程可以清晰地分为四步，每一步都对应着一个中间模型（Dev1, Dev2, Dev3）。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ddcfb0e601f44cf4b43a65e9808fb1b7@46958_oswg152015oswg1080oswg509_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DeepSeek-R1 通过强化学习，激励 LLMs 进行推理，展示从 R1-Zero 到 Dev1，Dev2，Dev3，再到最后的 R1。&nbsp;</p>
  <p><strong>第一步：冷启动 SFT（诞生 R1-Dev1）</strong></p>
  <p>解决语言混用和可读性差的问题，教模型好好说话。&nbsp;</p>
  <p>首先，从 R1-Zero 生成的大量推理轨迹中，筛选出那些答案正确，且格式工整的样本。然后，动用人类标注员和 DeepSeek-V3 模型，将这些原始的、机器化的思考过程，<strong>改写成更符合人类对话习惯、采用第一人称的流畅文本。</strong></p>
  <p>这个过程产生了数千条高质量的「冷启动」数据；最后，用这些「冷启动」数据对基础模型进行监督微调（SFT）。&nbsp;</p>
  <p>R1-Dev1 在指令遵循等通用能力上大幅提升，但因为冷启动数据集规模有限，它在 AIME 等高难度推理任务上的性能反而有所下降。&nbsp;</p>
  <p><strong>第二步：第一轮强化学习（诞生 R1-Dev2）</strong></p>
  <p>在保持人话风格的基础上，重新强化其推理能力。&nbsp;</p>
  <p>对 R1-Dev1 进行强化学习。这次的奖励信号<strong>除了基于规则的准确率奖励外</strong>，创造性地加入了一个<strong>语言一致性奖励</strong>。<strong>如果模型在处理中文问题时，思维链中中文词汇比例越高，奖励就越多</strong>，以此来纠正语言混用问题。&nbsp;</p>
  <p>结果 R1-Dev2 的推理能力（尤其在数学和代码上）得到显著增强，恢复甚至超过了 R1-Zero 的水平。&nbsp;</p>
  <p><strong>第三步：大规模监督微调（诞生 R1-Dev3）</strong></p>
  <p>全面扩展模型的知识面和通用能力，让它成为「通才」。&nbsp;</p>
  <p>将约60万条由 R1-Dev2 生成的推理数据，与约 20 万条非推理数据（如写作、通用问答、代码工程等）混合在一起，进行一次大规模的SFT。&nbsp;</p>
  <p>结果是 R1-Dev3 在AlpacaEval 2.0 等通用和代码工程基准上获得了显著的性能提升。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_788614c145b94e55b9f3786bbb5ef29c@46958_oswg31837oswg1080oswg303_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在 LiveCodeBench 数据集中，不同难度问题上 DeepSeek-R1 各阶段的实验结果。&nbsp;</p>
  <p><strong>第四步：第二轮强化学习（最终形态 DeepSeek-R1）</strong></p>
  <p>进行最终的精装修，使模型行为与人类偏好（有用性、无害性）对齐。&nbsp;</p>
  <p>方法：对 R1-Dev3 进行最后一轮全面的强化学习。这次的奖励系统最为复杂，是一个组合。&nbsp;</p>
  <p>对于推理任务，继续使用<strong>基于规则的奖励</strong>。对于通用任务，则启用<strong>基于模型的奖励</strong>。&nbsp;</p>
  <p>DeepSeek 团队为此专门训练了两个奖励模型，一个「有用性」奖励模型，和一个「安全性」奖励模型，它们基于人类偏好数据来为模型的回答打分。&nbsp;</p>
  <p>最终的 DeepSeek-R1 诞生。虽然它的推理能力只有边际提升（因为此前已足够强大），但在通用指令遵循和用户偏好基准上提升巨大，AlpacaEval 2.0 提升 25%，Arena-Hard 提升 17%。&nbsp;</p>
  <p>此外，论文中还提到了关键的技术&nbsp;<strong>GRPO算法</strong>，整个强化学习过程由 DeepSeek 自研的 GRPO 算法驱动。相比传统的 PPO 算法，GRPO 通过「组内竞争」来估算优势，<strong>它不需要训练一个额外的价值模型</strong>，从而简化了流程并降低了资源消耗。&nbsp;</p>
  <p>最终 R1 的训练成本，也是空前的节省，只花了 29.4 万美元。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_c5c349187d1845abbfd6e497a789b448@46958_oswg19942oswg1080oswg204_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>几周前，a16z 的合伙人 Martin Casado 说，估计 80% 的湾区初创公司，都在基于中国开源模型进行开发。下方的图表显示，在 HuggingFace 上，国产模型的下载量已超过美国模型的下载量。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_20203148939147a6b09bee6a054e2633@46958_oswg136919oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源： https://www.interconnects.ai/p/on-chinas-open-source-ai-trajectory&nbsp;</p>
  <p>登上 Nature 封面，对 DeepSeek 来说可能是一个极大的认可；但也许，这只是一个开始。&nbsp;</p>
  <p><strong>相关链接汇总：&nbsp;</strong></p>
  <p>🔗 DeepSeek Nature 论文： https://www.nature.com/articles/s41586-025-09422-z</p>
  <p>🔗 &nbsp;补充材料： https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM1_ESM.pdf</p>
  <p>🔗 &nbsp;同行评审： https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM2_ESM.pdf</p>
  <p>🔗 &nbsp;Nature 编辑文章： https://www.nature.com/articles/d41586-025-02979-9</p>
  <p>🔗 &nbsp;Nature 新闻： https://www.nature.com/articles/d41586-025-03015-6</p>
  <p>🔗 &nbsp;DeepSeek 原 arXiv 论文： https://arxiv.org/pdf/2501.12948&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/qOPtvX3qthGczoyk8e_qcQ" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472034235865224</id>
            <title>融资14轮，70后大学教授再次冲刺IPO</title>
            <link>https://www.36kr.com/p/3472034235865224</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472034235865224</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:49:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>据中国证监会官网信息，杭州存储控制器芯片企业华澜微，在浙江证监局办理辅导备案登记，辅导机构为华泰联合证券。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8168bc12f20c4400912970e66052af3f@46958_oswg266094oswg951oswg837_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：证监会官网截图</p>
  <p>而这是华澜微又一次冲刺资本市场。据悉，在2022年12月，华澜微就向科创板提交IPO申请，拟募资6.57亿元，但仅进行了一轮问询，便于2024年5月匆匆终止了IPO进程。华澜微称，其是基于自身业务发展方向及战略规划考虑，向上海证券交易所申请撤回上市申请。</p>
  <p>值得注意的是，华澜微此次重启上市辅导，辅导机构仍是此前冲刺科创板IPO的保荐机构华泰联合证券。</p>
  <p>公开信息显示，华澜微，是一家数据存储解决方案提供商，主要产品包括存储模组、存储控制器芯片及服务、存储系统及应用。此外，在2019 年，华澜微通过收购集月实业控制权及集月信息无形资产，拓展了铠侠固态硬盘分销业务。2020 年，又完成了对初志科技的收购，补充了数据存储应用上层的系统级存储业务，实现了从芯片到模组再到系统级应用的布局。</p>
  <p>根据此前申报科创板IPO时资料显示，2019年、2020年、2021年、2022年及2023年前三季度，华澜微营收分别为2.91亿元、4.35亿元、5.95亿元、5.65亿元、3.48亿元，同期净亏损分别为0.22亿元、1.32亿元、0.88亿元、0.25亿元及0.54亿元。</p>
  <p>华澜微由骆建军等人在2011年创立，骆建军1970年1月出生于浙江省诸暨，1991年毕业于上海交通大学电子工程系；1993年获得杭州电子工业学院硕士学位；1997年获得浙江大学博士学位。如今，骆建军还担任杭州电子科技大学微电子研究院院长、二级教授、博士生导师。</p>
  <p>骆建军的创业历程也非常丰富。博士毕业后，骆建军加入杭州东方通信，成为该公司集成电路设计部门的创始人和技术带头人。2001年，骆建军接受外国公司聘请，赴硅谷工作，之后在2022年创办Baleen Systems Inc公司，主要从事数码存储产品的核心控制芯片和系统产品的研发与设计。</p>
  <p>2011年，在刘志臣、王辉等企业家的支持下，骆建军带领团队成立了华澜微，希望可以在半导体行业掀起“中华之波澜”。</p>
  <p>股权结构方面，在上市前，华澜微进行过多轮融资。天眼查信息显示，自2013年至2024年，华澜微先后完成14轮融资，在申请科创板IPO前，华澜微就已经进行了G轮融资，在撤单后又进行了一轮融资。如今，华澜微背后投资人包括深创投、银江资本、创东方投资、赛智伯乐、普华资本、绩优投资、磐石资本、富创投资、方正证券、TCL创投、凯珩资本等知名机构。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2a92156dd5824b4fb3e4a823b6258096@46958_oswg333328oswg1080oswg702_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：天眼查</p>
  <p>但这也造成华澜微股权较为分散，公司无控股股东和实际控制人，且最近两年内无实际控制人的情形未发生变更。</p>
  <p>据华澜微科创板招股书，华澜微第一大股东华澜创合伙系骆建军实际控制的企业，骆建军、周斌各自直接持有发行人 1.5%、1.012%股份并构成一致行动，双方合计控制发行人 8.41%股份。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a8ace30a598d42d2aa791cfd7bb4716c@46958_oswg244245oswg1080oswg792_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：招股书截图</p>
  <p>投资者众多，也让华澜微身上背负着多份对赌协议，其中与深创投等机构投资人约定，华澜微在 2024 年 6 月 30 日前未能实现首次公开发行股票并上市或华澜创合伙、骆建军、周斌违反本合同相关承诺的，要求相关方履行回购义务。</p>
  <p>如今，华澜微重启IPO，这次征程能否顺利呢？</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0vlIxRdzsr-gobXBQjf16Q" rel="noopener noreferrer nofollow" target="_blank">“直通IPO”</a>，作者：邵延港，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472035619460996</id>
            <title>OpenAI在ICPC 2025编程赛上满分登顶，Gemini也达到金牌水平</title>
            <link>https://www.36kr.com/p/3472035619460996</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472035619460996</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:48:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote>
   <p>IMO 之后，OpenAI 与 Gemini 双双加冕 ICPC 2025 金牌。</p>
  </blockquote>
  <p>就在刚刚，OpenAI 和 Gemini 都声称达到了 ICPC 金牌水平。</p>
  <p>其中，OpenAI 在 5 个小时内解决了所有 12 个问题，相当于人类排名第 1 位，超过了所有参赛大学团队。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_25e1a1aea426477fa29683053ceff3f7@46958_oswg69596oswg638oswg348_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而 Gemini 解决了 12 个问题中的 10 个，总用时 677 分钟，达到了金牌水平，如果与人类团队比较，将排名第 2。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_03dd35d1239a47aa90c366c488adb379@46958_oswg175937oswg648oswg874_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>人类团队方面，俄罗斯圣彼得堡国立大学的参赛队伍排名第 1，解决了 11 个问题。北京交通大学、清华大学、北京大学、中国科学技术大学的参赛队伍分别排名 2、4、5、9。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fdf4b2460dee4900b4361cc45ad3c5b6@46958_oswg587002oswg1080oswg352_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>&nbsp;ICPC，即国际大学生程序设计竞赛，是全球公认的历史最悠久、规模最大、最负盛名的大学级算法编程竞赛，它比 IMO 等高中奥林匹克竞赛更高一级。每年，来自近 3000 所大学和 103 个国家的参赛者齐聚一堂，挑战现实世界的编程难题。</p>
  <p>今年的 ICPC 世界决赛于 9 月 4 日在阿塞拜疆的巴库举行，汇集了来自竞赛早期阶段的顶级队伍。在五小时的比赛中，每支队伍解决了一组复杂的算法问题。最终排名严格依据两个原则：只有完美的解决方案才能得分，每一分钟都至关重要。在 139 支参赛队伍中，只有前四支队伍获得了金牌。</p>
  <p>下面是 ICPC 的原题，感兴趣的读者可以亲自尝试一下。</p>
  <p>https://worldfinals.icpc.global/problems/2025/finals/index.html</p>
  <h2><strong>OpenAI 5 小时内解决 12 个问题，超过人类团队</strong></h2>
  <p>OpenAI 的 与人类顶尖选手在完全同等的条件下竞技：面对完全相同的赛题，拥有相同的 5 小时时限，并由与 ICPC 全球总决赛标准一致的本地系统进行实时评判。</p>
  <p>整个过程中，AI 系统在没有任何定制化测试工具的辅助下，独立分析问题并自主决定提交最终答案。</p>
  <p>比赛结果令人瞩目：在全部 12 个问题中，该 AI 系统对其中 11 个问题的首次提交便获得了正确答案。即便是全场难度最高、困住所有人类队伍的最后一个问题，AI 也在经过 9 次尝试后成功攻克。相比之下，本次竞赛表现最出色的人类团队成功解决了 11 个问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b6717a75a92a44c394f2ef3d3b445fad@46958_oswg64392oswg680oswg113_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中问题 G，OpenAI 尝试 9 次后成功解决，该问题也是 DeepMind 未能解决的两道难题之一。作为参考，解题速度最快的人类选手也耗时 270 分钟（竞赛总时长 300 分钟）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_88b48052939f44c2b9137772ba26ac28@46958_oswg512373oswg1080oswg853_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>OpenAI 方面透露，此次参赛的 AI 由一个「通用推理模型集成体」构成，并未针对 ICPC 竞赛进行任何专门的优化或训练。</p>
  <p>在解题过程中，系统结合了其下一代模型 GPT-5 与一个前沿的实验性推理模型。其中，GPT-5 精准地解答了 11 题，而那款实验性模型则最终完成了对最难题目的关键一击。</p>
  <p>这一成果是 OpenAI 一系列展示推理系统惊人进步速度的绝佳里程碑。同一组模型已在国际数学奥林匹克（IMO）和国际信息学奥林匹克（IOI）等竞赛中证明了其实力，充分印证了其强大的通用性与广泛的适用潜力。</p>
  <p>OpenAI 员工 Borys Minaiev 和 Mostafa Rohaninejad 也在 X 上发文庆贺。</p>
  <p><strong>Borys Minaiev</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0e6e0c376a9e4f89aad657d851a3b7dc@46958_oswg688013oswg738oswg738_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Borys Minaiev 是 OpenAI 的研究员，专注于大规模推理模型的开发与应用，尤其在编程竞赛和复杂推理任务中展现了卓越能力。</p>
  <p>他毕业于圣彼得堡国立信息技术、机械与光学大学（ITMO University），并在编程竞赛领域取得了显著成就。2015 年，他作为 ITMO 大学队员之一，赢得了国际大学生程序设计竞赛（ICPC）世界总决赛的冠军，这是该赛事历史上唯一一支在比赛结束前解决所有问题的队伍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8abd230001b74143bbec4122dae25d9c@46958_oswg48471oswg1080oswg384_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在加入 OpenAI 后，Borys Minaiev 成为大型推理模型研究的核心成员之一，参与了多个关键项目，包括 o1、o3 和 o4-mini 等模型的开发。</p>
  <p>此外，Borys Minaiev 还活跃于开源社区，在 GitHub 上分享了多个项目，并在个人博客中深入探讨了模拟退火算法、Rust 编程语言以及 AI 在教育中的应用等主题。</p>
  <p><strong>Mostafa Rohaninejad</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5419d346981e44388c1a66e2459e8aea@46958_oswg362638oswg500oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Mostafa Rohaninejad 是 OpenAI 的研究科学家，专注于元学习、强化学习和人工智能系统的推理能力。</p>
  <p>他于 2023 年加入 OpenAI，参与了多个关键项目，包括 GPT-5 和 OpenAI o1 等大规模推理模型的开发。</p>
  <p>在加入 OpenAI 之前，Mostafa 曾在加州大学伯克利分校攻读计算机科学硕士学位，并在该校的 BAIR 实验室与 Pieter Abbeel 教授合作，研究元学习和生成模型。他是著名的 SNAIL 架构的共同作者，该架构在少样本学习任务中表现出色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_23c452e2221d41b5bf54ead7643baf4b@46958_oswg132159oswg1080oswg619_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Mostafa 的研究兴趣主要集中在如何使人工智能系统具备更强的推理能力和适应性，特别是在复杂任务和动态环境中的表现。他在 OpenAI 的工作不仅推动了 AI 技术的发展，也为实现更智能、更人性化的 AI 系统奠定了基础。</p>
  <h2><strong>谷歌Gemini解决10个难题，达到金牌级别</strong></h2>
  <p>Gemini 2.5 Deep Think 的高级版本在 ICPC 规则下，以远程在线环境参与竞赛，并在比赛组织者的指导下进行。</p>
  <p>它比人类参赛者晚了 10 分钟开始，但在五小时的时间限制内正确解决了 12 个问题中的 10 个，达到了金牌级表现。</p>
  <p>Gemini 2025 ICPC 世界总决赛代码：https://github.com/google-deepmind/gemini_icpc2025</p>
  <p>Gemini 在仅 45 分钟内就解决了 8 个问题，接着在三小时内又解决了两个问题，使用了各种高级数据结构和算法来生成解决方案。通过 677 分钟的总时间解决了 10 个问题，若与大学队伍的成绩相比，Gemini 2.5 Deep Think 将排名第二。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_7c8b958d5b814ae1b43efd276a51c20b@46958_oswg65594oswg1080oswg633_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>图片显示了在 2025 年 ICPC 世界决赛中每个问题的解题时间。Gemini 的时间以蓝色表示，最快的大学队伍时间以灰色表示。</p>
  <p>值得一提的是，Gemini 在半小时内成功解决了 C 题，而这道题在竞赛中没有任何大学队伍解出。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_67198f8a23064bdfba7a81bc555bb3f8@46958_oswg344620oswg1080oswg764_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这道题目要求找到一种解决方案，通过一系列相互连接的管道将液体分配到多个水库中，目标是找到一种配置使液体尽快充满所有水库。由于每个管道可能是开放的、关闭的，甚至是部分开放的，因此存在无限多种可能的配置，这使得寻找最优配置变得非常困难。</p>
  <p>Gemini 找到了一种有效的解决方案：它首先假设每个水库都有一个「优先级值」，表示该水库相对于其他水库的偏好程度。在给定一组优先级值后，可以通过动态规划算法找到最优的管道配置。Gemini 发现，通过应用极小极大定理，可以将原问题转化为寻找使得流量最受限制的优先级值。利用优先级值与最优流量之间的关系，Gemini 通过嵌套三分查找迅速找到最优的优先级值，从而成功解决了 C 题。</p>
  <p>据谷歌内部研究表明，类似版本的 Gemini 2.5 Deep Think 也可以在 2023 年和 2024 年 ICPC 世界总决赛中取得金牌级别的表现，与全球前 20 名的编程选手表现相当。</p>
  <p>此外，谷歌官方博客还感谢了一众这个项目背后的贡献者。其中 Hanzhao (Maggie) Lin 领导了 Gemini 竞赛编程和 ICPC 2025 工作的整体技术方向，并与 Heng-Tze Cheng 共同领导了整体研究和执行工作。</p>
  <p><strong>Hanzhao (Maggie) Lin</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_58d5a036c11c43f88ab5576bc3550311@46958_oswg482191oswg800oswg800_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Hanzhao (Maggie) Lin 是 Google DeepMind 的高级研究科学家，专注于大规模语言模型和多模态系统的研究与开发。</p>
  <p>她的研究方向主要涵盖大规模语言模型、系统架构以及其在教育和复杂推理中的应用。她在 AI 领域的贡献包括参与了 Google DeepMind 的 LaMDA 和 PaLM 2 等大型语言模型的后训练研究，并推动了模型在多模态理解、推理和工具使用等方面的能力提升。</p>
  <p>此外，她还主导了 Gemini Deep Think 模型在国际数学奥林匹克（IMO）竞赛中的应用，取得了金牌级别的表现，展示了 AI 在复杂数学推理中的潜力。</p>
  <p><strong>Heng-Tze Cheng</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d7c370a626f14cbaabf8352cdc593671@46958_oswg581367oswg800oswg800_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Heng-Tze Cheng 是 Google DeepMind 的研究总监兼首席研究科学家，专注于大语言模型和对话 AI 的研究与应用。他在自然语言处理（NLP）、推荐系统、强化学习和多模态推理等领域具有深厚的研究背景。</p>
  <p>他本科毕业于台湾大学电机工程系，2013 年于卡内基梅隆大学获得电气与计算机工程博士学位，研究方向包括机器学习和多模态信号处理，2014 年加入 Google，先后在 Google Brain 和 DeepMind 担任技术领导职务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_493fffdfcbbe44d6a7d7d1cd371ae612@46958_oswg153419oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>ICPC 所要求的技能，比如理解复杂问题、制定多步骤的逻辑计划并精准执行，正是许多科学和工程领域所需的核心能力。</p>
  <p>AI 此次在 ICPC 中获得金牌级成绩凸显了 AI 在提供创新性解决方案方面的独特优势，能够有效补充人类专家的技能和知识。这也表明，AI 正从单纯的信息处理工具，转变为协助解决复杂推理问题的关键力量。</p>
  <p>参考链接：</p>
  <p>https://deepmind.google/discover/blog/gemini-achieves-gold-level-performance-at-the-international-collegiate-programming-contest-world-finals/</p>
  <p>https://x.com/HengTze/status/1968359525339246825</p>
  <p>&nbsp;https://x.com/MostafaRohani/status/1968360976379703569</p>
  <p>https://x.com/bminaiev/status/1968363052329484642</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Bws9enDXB5CvyhW1cG5DYw" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，编辑：杨文、+0，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472034254100359</id>
            <title>我，公司创始人，不接受产业资本的钱</title>
            <link>https://www.36kr.com/p/3472034254100359</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472034254100359</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:48:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>前段时间有篇文章短暂刷屏了我的朋友圈，文章开头提到一家正在融资路演的企业，创始人明确提出“本轮融资，绝对不要产业方的钱”。</p>
  <p>说实话，这一态度的确颠覆了我的认知，因为过往无论是从公开投融信息，还是与投资人的交流中，产业投资都是高频词，有LP甚至表示过只愿意投资产业资本。</p>
  <p>于是，我顺着这条线索继续打听，发现上述表达并非个例，甚至可以说已经在创业圈达成了某种“共识”。比如医疗健康领域FA文忆告诉我，她目前负责的项目中，就有创始人表示“不要产业资本的钱，CVC也不想见”。 另有几位硬科技创业者也直言：“非必要不考虑产业资本”。</p>
  <p>有意思的是，就在我写稿过程中，一位创始人发给我了一份BP，我随口问到：你更倾向的机构类型是什么？他回了我两个字：“财投”。</p>
  <p>难道说，产业资本真的不香了？</p>
  <h2><strong>“非必要不考虑产业资本”</strong></h2>
  <p>陈瑞是一家硬科技企业的创始人，其公司业务属于人形机器人产业链上的一环，是目前一级市场最火热的赛道之一。因此，主动找上门来的机构不在少数。</p>
  <p>作为掌握话语权的一方，陈瑞心中对潜在的合作伙伴进行了优先级排序，遗憾的是，产业资本被排在了较后的位置。</p>
  <p>谈及原因，他坦言，其中一点就是害怕丧失对企业的控制权。“产业资本往往倾向于争取更多话语权，如果在关键决策（比如公司发展方向或产品路径）上产生分歧，局面就变得两难：不听他们的话，他们不高兴；听他们的话，很可能会违背创始团队的初心，最终沦为职业经理人，真走到那一步，还不如去找个班上。”</p>
  <p>“其实热门行业已经好很多了，产业方通常不会附加那么多条款。对于一些非明星赛道的非明星项目来说，准备拿产业基金钱的时候，就要做好失去公司控制权的觉悟了。”硬科技创业者韩超表示。</p>
  <p>除了出于“失去控制权”的担忧，频繁“被压估值”也是创始人们如今抵触与产业方合作的重要原因。</p>
  <p>相较财务投资机构，产业资本的一大优势在于能够带来实际业务增长和市场扩张的订单和渠道资源。但是天下没有免费的午餐，所有的资源都被标上了价格。在投资过程中，产业资本的常见操作是把资源折现成现金，将估值压低。文忆表示，一次在撮合项目和产业资本合作时，资方直接表示，“我们会给订单，但是估值会压到很低。”</p>
  <p>另一早期投资人也提到，他孵化的企业在某一轮融资时，本来已经谈好了30亿的估值，结果一家知名产投进来，直接把数字压到了20亿，“好在投前就给了订单，投后又加深了合作，算下来还是值的。”</p>
  <p>不过交流下来我发现，通过被投方式拿到订单并非想象中容易，冲着“对接产业资源”去合作，但投资完成后却没有得到什么有价值赋能的企业不在少数。“没有订单，肯定会失望。如果再不幸遇到剽窃技术的，就真的是绝望了。”</p>
  <p>身边类似的例子见多了，也就对所谓的产业赋能祛魅了。韩超表示，在跟同行沟通时他发现，大家如今似乎已经达成了默契——非必要不考虑产业资本。</p>
  <h2><strong>“披着产业方外衣的财务投资人”</strong></h2>
  <p>产业资本真的如此不值得信赖么？其实也不尽然，现实中，也有企业因产业投资的加入实现了显著成长。</p>
  <p>以比亚迪入股锂电池隔膜龙头金力股份为例。2021年10月，金力股份成功吸引了比亚迪的8000万元投资。比亚迪的加入，不仅为金力股份提供了资金支持，还带来了大量订单。</p>
  <p>根据金力股份的招股说明书，比亚迪在那一年成为公司最大的客户，贡献了50.53%的营收，使得公司营业收入从2020年的1.3亿元增长至2021年的5.8亿元，年增长率高达346%。可以说，金力股份的发展在很大程度上得益于与比亚迪的紧密合作。</p>
  <p>类似的案例还有很多。结合交流中一些创始人对产业资本的吐槽，我们不难看出，<strong>大家抵触的其实并非产业资本本身，而是那些仅以“产业赋能”为名、行压估值之实，却未能兑现资源承诺的机构。</strong>用投资人张旭的话说，就是“披着产业方外衣的财务投资人”。</p>
  <p>张旭现任某上市公司战投部投资总监，在他看来，判断一家产业资本是否具备“产业赋能”能力，首先看对方的核心KPI&nbsp;是什么。</p>
  <p>以他所在的上市公司为例，战投部并不自行寻找项目，而是基于协同部门提出的需求来决定投资。被投对象要么与集团主营业务协同，要么符合专利布局或渠道扩展的战略需要——根本目标始终是服务于集团整体业务赋能。不过他也提到，有些企业的投资部门将DPI也列入重要考核指标，“为了赚钱承诺一些根本兑现不了的资源，这种情况倒也并不罕见。”</p>
  <p>这里就引出了关于组织架构的话题。某种程度上，产业资本（CVC）在集团内部的“站位”，决定了它的权限和地位，如果仅作为集团下属的一个部门存在，将很难调动供应链或采购部门去为投资部门的承诺买单。</p>
  <p>有投资人向我分享过他在某地产CVC工作时的经历：当时他们看中了一个项目，对方明确表示，唯有将其纳入集团的供应链体系，才愿意接受投资。投资团队本身认可这一诉求，但最终因为业务部门老大不同意导致合作未能达成。类似这样的情况先后发生了多次，结果是尽管背靠雄厚产业资源，但这家CVC一直发展不起来。</p>
  <p>当然也有正面例子。有创业者告诉我，市场普遍对小米产投的认可度颇高，因此其所投企业进入供应链的机会较大；歌尔则更强势，“投了基本就要想办法用上”。</p>
  <p>“关键还是在于集团高层是否真正重视投资板块。如果由一把手或联合创始人直接主管，投资部门话语权就强；如果投资部门处于边缘位置，那基本就很难成事。”上述创业者表示。</p>
  <h2><strong>“有些产业资本很难拒绝”</strong></h2>
  <p>尽管大多数创始人都表达了对产业资本的抵触情绪，但他们也承认，有些产业资本的资金确实很难拒绝。</p>
  <p>比如一些头部产投或是“链主企业”，就属于“即使不给订单，也想拿到融资”的典型。因为有了他们的入股，就相当于得到了下一轮融资的背书。企业也想得明白：“产业资本拿不到实际资源，或许创始人知道，但其他投资人不知道啊。”</p>
  <p>这一心态，也折射出当前一级市场对于产业资本的“偏爱”。</p>
  <p>眼下，硬科技投资已经成为一级市场的主旋律，而硬科技企业通常存在技术壁垒高、研发周期长、商业化路径复杂的特点。对于不具备相关产业背景的财务投资人来说，这无形中提高了投资的门槛。</p>
  <p>这一背景下，“跟着产业资本出手”正成为很多财务投资机构最稳妥”的投资策略。因为在大家的普遍认知里，离产业越近，代表着拥有更深厚的项目储备和项目渠道，同时也意味着对未来技术走向的判断大概率更准确。</p>
  <p>不只是在投资层面，从募资角度，产业资本也成为很多机构的合作首选。某地方产投平台投资人告诉我，在募资过程中， 产业型上市公司被他视为最优先考虑的合作对象。“这对于一些产业竞争力不具备优势的地方政府基金来说很重要，引入上市公司就是在向企业传达一个信号——和我们合作，不仅只是与一个低线城市的城投平台建立了联系，还能接触到更广泛的市场化资源。”</p>
  <p>身边的负面案例和市场对产业资本的推崇，就像两股相反的力量，让很多创始人陷入“不想拿，又不得不拿”的纠结。</p>
  <p>不过，市场环境向来都是复杂的，与其陷于两难，不如回归理性。对创业者而言，不要因为光环盲目相信“赋能”神话，也无须因个别失败案例就否定所有产业资本。重要的是清醒认知自身需求，理性辨别合作方，并始终将重心放在夯实内功上。</p>
  <p>说到底，资本市场会有冷暖变迁，产业叙事会有起伏更迭。无论对面坐的是财务投资人还是产业资本，创始人最终要回答的始终是那个最根本的问题：我们究竟因何而强大？</p>
  <p>答案，永远握在创业者自己手中。</p>
  <p>（文中文忆、陈瑞、韩超、张旭皆为化名）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/jMJurKUHbnEncFC5uxF80w" rel="noopener noreferrer nofollow" target="_blank">“投中网”</a>，作者：王满华，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3472034641746054</id>
            <title>AGI、智能体、自动驾驶……未来十年的十大技术预测</title>
            <link>https://www.36kr.com/p/3472034641746054</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3472034641746054</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:48:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，华为公司发布了《智能世界2035》报告，研判了未来十年包括生成式人工智能、AI智能体、人机协同编程、多模态交互、自动驾驶、新能源等在内的十大技术趋势将如何深刻改变各行各业。报告认为，AGI（通用人工智能）将是未来十年最具变革性的驱动力量，我们正处在技术范式变革的时代风口，并一步步迈向物理世界与数字空间实时融合、虚实共生的智能世界。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e717f92902a74e7db7ee0a5358b71ff5@46958_oswg153200oswg855oswg612_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：《智能世界2035》报告</p>
  <p><strong>以下是报告内容摘编：</strong></p>
  <h2><strong>第一部分：与AI共进，通往智能世界2035的十大技术跃迁</strong></h2>
  <p>未来十年，信息科技将会发生重要跃迁。这并非单一技术的线性发展，而是一场由数据、智能技术、感知与交互、算力、网络、新能源等核心要素共同驱动，深刻贯穿数字世界与物理世界的系统性跃迁，是一个复杂的系统工程。以下是通往智能世界2035的十大技术趋势：</p>
  <p><strong>趋势一：走向物理世界是AGI形成的必由之路</strong></p>
  <p>AGI将是未来十年最具变革性的驱动力量，但仍需克服诸多核心挑战，方能实现AGI奇点突破。走向物理世界是AGI的关键路径，通过物理实体与环境实时交互，实现感知、认知、决策和行动一体化，能让智能体像人类一样用身体感知世界，在互动学习中成长，从而更好地适应环境、解决复杂任务。未来重点是从多模态数据积累、核心能力打磨、认知原理提升三方面为AGI的实现筑牢根基。</p>
  <p><strong>趋势二：从执行工具到决策伙伴，AI智能体驱动产业革命</strong></p>
  <p>回顾历史，初期的智能体，是侧重感知的信息系统，尚未具备复杂的决策规划能力。<strong>未来十年，智能体将发展为侧重实践的行动系统。</strong></p>
  <p>商业层面，未来十年智能体将驱动各产业发生范式革命。早期，智能体聚焦于提升运营与办公效率，化身客服、销售与办公助手，催生出千亿美元产业。中期，它会变革生产方式，比如在AI药物研发、专业服务咨询等领域，大幅降低科研与生产成本，有望缔造万亿美元产业。而到远期阶段，智能体将重构产品与体验，AI PC等新产品引发办公革命，具身机器人成为人们的贴身助手，有望开拓出十万亿美元产业。</p>
  <p><strong>趋势三：人机协同编程，重塑软件未来</strong></p>
  <p>随着大模型与智能体的兴起，软件开发正迎来一场全面重构。不仅是工具升级，而且是入口、角色、流程、架构、安全、质量、生态、平台、组织、工具、协作的系统性变革。普通应用开发逐步由Agent替代，用户通过自然语言定义需求即可生成应用，形成“可塑软件”。专业软件开发，如操作系统、金融核心系统、工业控制，仍由专业开发者主导，但工具链深度嵌入AI以提升效率和验证能力。</p>
  <p>软件开发模式重构的本质是“智能化与治理的平衡”，<strong>未来十年的软件工程并不是单纯的“AI代替人类”。而是人类与智能体的协同模式：AI承担执行与自动化，人类负责设计、治理与价值判断，Agent智能化开发与治理并重。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_aab1cd2c1b934a43ae254473901d0f5e@46958_oswg113105oswg900oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：《智能世界2035》报告</p>
  <p><strong>趋势四：AI于镜像世界中升维，新交互打开沉浸体验</strong></p>
  <p>未来，随着多模态技术的成熟，交互会快速走向三维空间与自然化。短期来看，微手势交互技术会成为业界热点，长期来看，脑机接口也将被纳入多模态框架，使人机协作真正进入“直觉式交互”阶段。</p>
  <p>交互范式的更新为虚实融合打开了入口，而要进一步深化，关键在于感官维度体验的全面升级，将带来更多创新的交互设备，如感知精细手势的指环、感知脉搏的项链、超轻量的3D眼镜、脑机设备等。<strong>未来终端设备将让用户不仅能“看见”和“听见”，还可以“触摸”“闻到”“品尝”数字世界，从而实现真正的全感官沉浸体验。</strong></p>
  <p><strong>趋势五：移动互联生态从APP走向多Agent协同</strong></p>
  <p>APP时代：生态以应用程序为中心。生态的本质是“人找服务”。<strong>多Agent时代：生态以智能体为中心。生态的本质是“服务找人”乃至“服务自动执行”。</strong></p>
  <p>人机交互界面将走向SMUI空间多模态交互方式。移动互联网向行动网络转型，“端到端（E2E）任务成功率”将成为行动能力最核心的指标，直接决定Agent时代用户入口的掌控权。传统基于消费者注意力的广告模式不再适用于多智能体协同生态，更直接的价值交换模式将涌现出来：比如智能即服务（API和Token调用），基于委托任务成功的支付（按任务成功率而非时长付费）等。</p>
  <p><strong>趋势六：具身智能跨越鸿沟，形成多个万亿产业</strong></p>
  <p><strong>未来具身智能将应用于三大行业领域：智能驾驶、智能机器人及低空经济。</strong></p>
  <p>对于自动驾驶路线图，我们预计于2027年底开启L4级试商用，于2030年在部分场景实现L4规模化应用，并最终在2035年达成大部分场景的L4+级无人驾驶，同时启动L5级的试商用探索。</p>
  <p>2035年前后，随着量产规模扩大，家庭机器人售价会低于1万美元，成本不再是制约机器人普及的关键因素，机器人产业将进入爆发期。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d23fd670a7af45abac368047d5853748@46958_oswg58100oswg876oswg381_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：《智能世界2035》报告</p>
  <p>约束低空经济普及最关键的因素是电池能量密度鸿沟，目前的电池能量密度无法支撑几小时的低空飞行，未来高能量密度的固态电池、太阳能—氢能—电能多源耦合，以及电池与液态发电机混动续航，是低空经济发展的关键突破方向。我们预计至2035年，家庭拥有私人飞行器的愿景或将成为现实，城市交通将迈入“三维立体”时代。</p>
  <p><strong>趋势七：突破冯•诺依曼架构，新型算力满足海量的算力需求</strong></p>
  <p>突破算力成本奇点，将决定AI的发展进程。算力奇点是AI应用的价值与算力成本比超过10倍。如果广泛的AI应用领域都能够突破算力成本奇点，AI将会迎来爆发性的增长。</p>
  <p>传统的冯•诺依曼架构面临着存算分离导致的能效瓶颈。在摩尔定律放缓的背景下，单纯依赖硅基半导体提升算力已难以满足指数级的增长需求，同时成本上也很难满足要求。<strong>未来十年将是计算领域从“量变”走向“质变”的关键期：</strong>不仅算力密度将实现指数级增长，更将通过材料、工艺、架构、范式的协同创新，构建“后摩尔时代”的全新算力格局，既解决传统技术路径的瓶颈约束，也为数字经济、人工智能、科学研究等领域提供更高效、更低碳的算力支撑，缓解全球能源供应压力，推动人类社会向“智能低碳”的未来加速迈进。</p>
  <p><strong>趋势八：数据即智能，AgenticAI驱动存储范式改变</strong></p>
  <p>随着大模型训练与推理对数据访问需求的爆发式增长，大量曾被视为“冷数据”的资源正被重新激活。我们预测，到2035年，温数据的占比有望超过70%，传统的数据三层结构将逐渐演变为“热温—温冷”两层结构，比例趋于3:7。</p>
  <p>在AI时代，数据价值得到前所未有的重视，而数据的长期留存也存在成本与效率的挑战，数据的长留存不是为了“囤积”，而是为了“即时洞察”，因此，<strong>对海量“温数据”的高效处理，是AI价值规模化释放的关键前提。</strong></p>
  <p>到2035年，数据的价值不再仅源于其规模或存储形态，而是通过动态激活、场景化供给与语义化存储得以全面释放。届时，数据不仅承载记忆，更将成为推动文明跃迁的“新燃料”。</p>
  <p><strong>趋势九：从移动互联网跃迁至智能体互联网，搭建物理空间到数字空间的智能交互桥梁</strong></p>
  <p>未来十年最大的变化将是数千亿智能体的新联接需求，我们认为一个面向智能体互联的下一代网络即将诞生。智能体互联网的特征是Time-In-Real+超维空间（H-D多维信息），<strong>智能体和人是生产者，同时也是消费者。</strong></p>
  <p><strong>趋势十：Token管理能源网络，让智能成为能源的“神经系统”</strong></p>
  <p>可以预见，未来5～10年全球范围内电力设施和能源需求将会是制约AI高速发展的核心要素，智能时代期待能源技术产生奇点突破。<strong>未来的能源网络中Token将成为能量管理的基本元素，</strong>人工智能技术使得未来每一焦耳的能量将可以被Token来定义并赋予可编程的人类意志，从而实现能源网络中每一个基本单元的“感知+决策+行动”的能力，完成能量载体的革命性变革。</p>
  <p>随着新能源技术的不断发展，预计到2030年风光新能源装机容量将超越传统化石能源，<strong>2035年风光发电量将超越传统化石能源而成为主力电源。</strong>预计2035年全球热储装机容量约将达到500GW，热储系统的热电联供效率提升至80%，冷热储发电将成为新型电力系统的“稳定器”。氢能将在重卡远洋船运领域和工业燃料替代等获得大规模应用的机会，全球市场规模将突破1.5万亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_90032bfce8ba4b89b2b4296d81d67717@46958_oswg141676oswg888oswg651_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：《智能世界2035》报告</p>
  <p>预计2035年，可控核聚变实验系统有希望实现独立发电，可控核聚变技术一旦突破，将实现AI与能源的终极和解，人类社会将会进入另外一个时代。</p>
  <p>点击封面订阅全年杂志</p>
  <h2><strong>第二部分：与AI共赢，加速生产与生活全场景跃迁</strong></h2>
  <p><strong>一、医疗：计算健康，防病于未然，让生命更有质量</strong></p>
  <p>展望2035年，在健康守护期，传感器与可穿戴设备使个体状态被实时感知与预测，AI驱动的预测与干预手段将使超过80%的慢性疾病有望得到有效的预防，从而有效延长人类的健康寿命；在疾病应对期，跨模态AI整合医学影像、基因组学检测结果与电子病历等，为医生提供个体化诊疗建议，同时，AI驱动的药物研发与虚拟临床试验大幅缩短新药上市周期，并能为患者快速匹配最优药物组合。</p>
  <p><strong>2035年的医疗已经不再是被动的“治病救人”，而是作为社会运行的底层能力，为人类从“延长寿命”走向“提升生命质量”奠定基础。</strong></p>
  <p><strong>二、教育：人机协同教学，惠及每个人成长</strong></p>
  <p>随着技术的发展，<strong>2035年AI技术将与教育深度融合，形成人机共育、人机共教、人机共学的人机协同教育教学新模式，全球教育将全面迈入智慧教育时代。</strong>未来，教育体系通过ICT技术尤其是AI技术优化教学资源、创新教学模式和打造智能教学环境，全面提升教育公平和质量，满足个人和社会发展需要，提升全球教育水平。</p>
  <p>到2035年，全球将有超过10亿学生日常使用智能学习助手辅助学习，同时也将有超过5000万孪生智能教师辅助教学，超过80%的智慧教室将升级为智能孪生教室。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e859a291e8a64754922fccc4eaf6fb87@46958_oswg1076592oswg1024oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：AI生成</p>
  <p><strong>三、出行：体验流动的“第三空间”</strong></p>
  <p>到2035年，私人汽车出行占比减少15%，MaaS平台作为智能大脑，将覆盖欧盟80%核心城市，<strong>MaaS服务成为出行主流，将通勤效率提升15%～30%；</strong>通过无缝调度RoboTaxi、空中出租车等新型载具，将出行过程转变为可被设计和享受的个性化场景，彻底重塑人们的时空体验。</p>
  <p><strong>四、农场智慧化，让农业生产“不再靠天吃饭”</strong></p>
  <p><strong>2035年全球农业将迈入智慧农场时代，农田不再是靠天吃饭的土地，而是由物联网、人工智能、区块链构建而成的“立体智慧体”。</strong>无人机与机器人集群完成80%以上的田间作业，卫星导航助力播种系统实现高精度定位，垂直农场利用LED光源与水培技术大幅提高单位面积的产量。农业生产将突破地理与气候的约束，形成“全域感知、智能决策、精准执行”的新型生产关系。2035年中国农业生产信息化率将达到40%以上，预计未来10年中国粮食单位面积产量将提高7.8%。</p>
  <p><strong>五、居家：从生活空间向懂你的智慧空间演进，让生活更舒适</strong></p>
  <p>未来居家将从单纯的生活空间蜕变为懂你的智慧空间。<strong>超沉浸全息技术让空间随心切换，智能机器人将走进千家万户，成为不可或缺的伙伴和家人，让居住体验更高效、更个性化、更舒适。</strong></p>
  <p>预计2035年XR设备销量将超过6000万台。同时，家庭人形机器人将从技术验证走向早期商用，主要功能从处理简单家务逐步演变为多功能家庭助手，届时中产家庭的人形机器人渗透率有望超过10%。</p>
  <p><strong>六、制造：设计即制造，制造即智能，制造即服务</strong></p>
  <p><strong>到2035年，ICT技术将深度渗透制造全链条，推动研发设计、生产制造与供应链管理发生质变。</strong>在研发设计端，量子计算与生成式AI的融合使“所想即研发”成为常态，工程师可通过脑机接口在分钟级完成传统需数月的仿真验证，AI更作为“数字发明家”自主发现新超导材料、设计合成细胞，开辟人类未曾想象的创新边界。生产制造环节，具身智能体通过端边云协同实现“千机百变”，机械臂秒级切换工艺、AGV毫米级配送物料，将90%任务转化为自动化指令，而人类则升维为“全局编排者”，以混合现实界面定义数字孪生工作流。供应链体系则形成海陆空一体化智能网络，全链路决策系统动态调整采购计划与物流路线，实现降低需求预测误差率，降低物流成本。</p>
  <p><strong>七、金融：AI重构金融生产力，打开智慧金融服务新纪元</strong></p>
  <p><strong>面向2035，当每个个体都拥有理解自身价值观、风险哲学甚至代际传承需求的数字金融分身时，金融将真正回归其本质——人类实现生活目标的赋能工具，而非冰冷的数据与交易。</strong>先进的ICT技术将成为推动全球金融服务发展的关键支柱，通过AI原生应用开展业务模式重塑，构建多活的高可用推理架构和量子安全中心等，让更多的人享受更个性化、高效的金融服务。</p>
  <p><strong>八、电力：新能源主导电源格局，成为主力力量，推动电力系统革命性重构</strong></p>
  <p><strong>2035年的电力系统，已经进化为一个动态平衡、高度智能化的能源生态系统，实现了从“保障供电”到“引领低碳发展”的跨越。</strong>当夜幕降临，光伏板启动自动清洁作业、风机精准调整叶片角度、储能站有序储备电力，电动车依托智能调度有序补能，数据中心同步启动“算电”动态调节，整个电力系统如同有机生命体般高效运转，为可持续发展的未来提供坚实支撑。</p>
  <p><strong>九、物流：AI驱动全球物流供应链实现智慧化赋能与高品质精准交付</strong></p>
  <p>2035年，智慧物流在AI驱动下实现三大突破性变革。在运输领域，AI动态优化系统通过实时分析多维度数据，实现全局资源最优配置，使空驶率下降60%，单位货物碳排放减少45%。在仓储环节，智能机器人全面普及，形成“感知—决策—执行”全闭环无人仓，作业效率提升3倍～5倍，处理成本降低60%。在品控方面，量子传感与边缘AI技术覆盖90%高价值场景，使生鲜医疗货损率降至0.1%，年损失减少超2000亿美元。</p>
  <p><strong>十、矿业：“智探矿脉，officemining”重塑矿区生产</strong></p>
  <p><strong>2035年的矿山将实现“地质透视化、开采工厂化、生产无人化”的科技跃迁。</strong>到2035年，地质勘探将实现从“AI解释”到“全息地壳透视”的跨越。AI建模目标识别误差率从当前的15%～20%降至&lt;5%，断层识别精度突破厘米级，彻底解决传统勘探中“盲人摸象”的局限。同时，矿山生产将告别“真人矿工”时代，迈向全域无人化。</p>
  <p><strong>十一、城市：AI让城市焕发自进化的生命力</strong></p>
  <p>面向未来，面向充满期待的2035，智能化正从分散的工具应用向协同化、共生化升级，将深度渗透城市肌理，推动城市从功能集合体成长为具有自进化智能生命体。城市以城市级AGI为蓝图、以数据大动脉为纽带、以智能基础设施为根基，实现智能化的代际跨越。<strong>到2035年，城市算力网覆盖率99%，超级助理行业渗透率将达到82%，全球数据交易市场规模达到8120亿美元。</strong></p>
  <h2><strong>第三部分：与AI共生，让可持续发展成为智能的本能</strong></h2>
  <p>AI从数字世界走向物理世界，将会对人类社会带来巨大的挑战，包括：</p>
  <p>技术不平衡与数字鸿沟：智能化成果可能集中在少数国家与企业，普惠不足会导致 “AI强国”与“AI弱国”的新分化，甚至加剧社会不平等。</p>
  <p>伦理风险与价值对齐：智能体的决策逻辑当前缺乏透明性和可解释性。<strong>AI向自主性演进时，如何确保价值观与人类一致是核心挑战。</strong></p>
  <p>安全挑战：万物互联的智能世界，AI系统面临日益剧增的网络攻击风险，同时AI的加持也放大了对AI系统的攻击风险。</p>
  <p>这些挑战关键在于找到技术的快速演进与治理的相对滞后之间的平衡，这是一个系统工程。华为基于系统工程的理论体系，同时参考国际系统工程委员会INCOSE提出的“人机共生五阶段”，提出了“向善的人机共生系统工程框架”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_047e158ae1fd4f0683da53ad0f617627@46958_oswg320797oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：《智能世界2035》报告</p>
  <p><strong>一、遵从伦理和安全，以人为本推进AI向善</strong></p>
  <p>1.AI伦理：将向善嵌入AI价值观</p>
  <p>随着AI技术能力的不断增强，其伦理要求进一步升级，必须实现可解释、可追溯、可问责，确保社会能够清晰理解并有效监管AI的决策过程。当AI具备一定自主性后，伦理框架中还需纳入价值对齐与文化包容原则，避免因技术偏见或单一文化输出对多元社会造成冲击。最终，在人机共生的发展模式下，AI需与人类共同构建一套智慧文明体系，并以此作为长远发展的精神内核。</p>
  <p>2.AI安全（Cyber Security）：构建可信赖的AI系统</p>
  <p>AI安全是实现AI向善的基础，构建可信赖的AI系统涵盖ICT基础设施安全、单智能体安全以及多智能体协同安全三个核心要素，同时依托AI安全治理来保障：</p>
  <p>·ICT基础设施安全：需实现“算安一体”“网安一体”“能安一体”三大安全目标。</p>
  <p>·单智能体安全：每个智能体都应具备可信的身份标识与内容标识机制，确保其行为可审计、调用可追溯。</p>
  <p>·多智能体协同安全：保障多智能体间的通信安全与协同过程中的数据隐私安全。</p>
  <p>·AI安全治理：建立完善的管理体系，提供系统化安全工程与技术，并融入研发到运营全生命周期流程活动中。</p>
  <p><strong>二、AI普惠弥合数字鸿沟，加速可持续发展</strong></p>
  <p>正如公路、铁路和通信网络是工业时代的基础设施，AI将成为智能世界的基础设施。<strong>以人为本的AI普惠是确保技术红利共享、推动全球可持续发展的核心手段。</strong></p>
  <p>1.AI普惠促进包容性增长</p>
  <p>到2035年，AI普惠不再是空泛的愿景，而将通过赋能教育、医疗和无障碍服务等场景，促进包容性的增长，实现可持续发展。</p>
  <p>2.可持续AI驱动绿色发展</p>
  <p>AI发展对能源的巨量需求对地球资源造成了压力。需通过开发更节能的AI算法和硬件、使用可再生能源、优化数据中心冷却系统等方式尽力降低人工智能对环境的影响。与此同时，AI可在全球绿色转型过程中发挥重要作用。</p>
  <p>3.AI普惠需技术与治理双管齐下</p>
  <p>一方面，在技术上注重AI的可及性和易用性。另一方面，在AI治理过程中，需特别关注如何减少AI部署和应用过程中的性别、种族、语言等的歧视和算法偏见，确保其利益公平惠及不同人群和地区。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Uh5iIWli92uvRvvvp8mLHA" rel="noopener noreferrer nofollow" target="_blank">“中国企业家杂志”</a>，作者：吴莹 郭立琦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471729984296321</id>
            <title>自动过渡、歌词翻译…… iOS 26 中 Apple Music 值得关注的新特性</title>
            <link>https://www.36kr.com/p/3471729984296321</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471729984296321</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:13:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>自 2015 年 Apple 发布流媒体音乐服务 Apple Music 以来，迅速成长为全球音乐流媒体市场的市占率 TOP 3 之一。虽然 Apple Music 在中国市场的市占率远不及 QQ 音乐和网易云音乐，但是它凭借着纯净无广告、优秀的 UI 交互设计、实惠的付费订阅方案以及与 Apple 生态圈的深度融合，依旧俘获了一大批音乐爱好者们的心。</p>
  <p>在今年六月的 WWDC25 全球开发者大会上，Apple 在发布 iOS 26 新系统之余，让 Apple Music 也在新系统中获得了全方位的升级，带来了诸多新功能。随着 iOS 26 的正式推送，Apple Music 的这些升级也终于正式与大家见面，接下来，就让我们一起看看都有哪些新功能吧。</p>
  <h2><strong>自动过渡</strong></h2>
  <p>在 iOS 26 中，Apple Music 新增了一个名为「自动过渡」的歌曲过渡方式，这种过渡方式会根据音乐应用对音乐调性和拍速的分析，让播放列表中的歌曲在最佳时间节点过渡到下一首歌。Apple 推出的这个「自动过渡」功能其实借鉴了 DJ 在现场表演时常用的混音技巧，DJ 通常会根据音乐的节拍、调性和现场氛围，将一首歌曲平滑地过渡到下一首，保持舞池或者听众的情绪连贯。因此，可以说「自动过渡」就是 Apple 给你的 Apple Music 安排的专属 DJ。</p>
  <p>如果你光听描述无法想象这个功能的实际效果，那我打一个可能不太专业的比方，就是当你在听 Adele 的《Make You Feel My Love》，播放到结尾时的「To make you feel my love」的同时，还听到了 Twins《见习爱神》的开头一句「Love! Love! Love!」。</p>
  <p>如果你只是想临时开关「自动过渡」功能，那么在任意一个播放列表中都可以找到对应的按钮，点击即可开启或者关闭「自动过渡」功能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2f38f02272e049c0a12c300454142dd2@000000_oswg100576oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，如果你不完全喜欢这个「自动过渡」的歌曲过渡方式，那么可以在「设置」&gt;「音乐」中找到音乐部分的「歌曲过渡」选项，在这里你可以将歌曲过渡方式切换为传统的「交叉渐入渐出」，或者干脆关掉「歌曲过渡」功能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_18749d30fdc640eda90dd0887159c908@000000_oswg80024oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>歌词翻译和发音</strong></h2>
  <p>如果你喜欢听欧美歌曲、K-pop、日语歌曲等非国语的音乐，那么新版本的 Apple Music 带来了一项堪称「史诗级」的新功能。当我们在收听非母语的歌曲时，我们可以点击歌词界面左下方的按钮打开歌词翻译或者歌词发音，这样一来翻译或者注音的文本就会同步显示在原歌词的下方，方便我们跟唱或者理解歌词的意思。如果你收听的是国语歌曲并且打开了「显示发音」的选项，那么歌词下方显示的就是拼音。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6c0c853991e544dfbf981c90f3e366a1@000000_oswg78516oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Apple Music 的这个新功能还有一个小细节，那就是长按歌词进行分享的时候，翻译和发音都会被隐藏，只显示原本的歌词。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_35488eaa68004e568fba5551014fd880@000000_oswg99912oswg1080oswg1165_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>锁屏动态封面</strong></h2>
  <p>如果你是 Apple Music 或者 Spotify 等海外音乐流媒体用户，那么你一定在欣赏 Taylor Swift、Ed Sheeran 等艺人的作品时看到过专辑的动态封面。这种充满艺术性和创造力的动态封面，无疑是一种非常契合锁屏界面的展现形式，因此 Apple 在 iOS 26 中引入了锁屏状态下的动态封面功能，可以将正在播放的音乐作品的动态封面直接投放到锁屏上并进行动态展示。</p>
  <p>使用这个功能的方式很简单，只需打开 Apple Music 并找到拥有态封面的歌曲，开始播放后锁定手机屏幕，锁屏界面上就会开始循环播放动态封面。如果点击动态封面，锁定屏幕就会切换回原来的壁纸，再次点击音乐播放小组件上的作品封面缩略图就可以重新将动态封面设为锁屏壁纸。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_aaabc21b914b4989b5eeac76c32f93f0@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>音乐回忆</strong></h2>
  <p>Apple Music 每年都会推出音乐回忆活动，它会分析你在一年内的音乐收听活动，帮你总结一年中听的最多的歌曲、歌手、播放次数等，然后生成一个当年的音乐回忆歌单。不过，每年的音乐回忆活动都会独立于 Apple Music 应用，以网页的形式来进行多方位的展示，最后将音乐回忆的歌单添加到 Apple Music 的播放列表中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ec4cd3f0de924366a0ae1f21940260d5@000000_oswg106927oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在 iOS 26 的 Apple Music 中，Apple 终于将这个「音乐回忆」的功能内嵌到了 Apple Music 应用中。我们可以在「主页」&gt;「音乐回忆：你的热门音乐」部分找到现场制作音乐回忆的功能，点击进入「音乐回忆」后，我们可以选择任意一个年度的任意一个月份，Apple Music 就会直接展示对应时段内的聆听时间、最爱艺人、最爱歌曲、最爱类型、最爱专辑、里程碑等汇总分析的信息。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_bf5ac47ef02241a08821ceaf4632546e@000000_oswg108139oswg1080oswg777_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>播放列表文件夹</strong></h2>
  <p>Mac 版本的 Apple Music 早已支持了创建文件夹的功能，而且还可以通过 iCloud 将文件夹同步到 iOS、iPadOS 或者 tvOS 上的 Apple Music 上，但是在其它平台上却不支持直接创建文件夹。在 iOS 26 中，Apple 终于将这个功能「下放」到了 iOS 端的 Apple Music 上。</p>
  <p>打开 Apple Music 后，进入「资料库」标签页，然后点击打开播放列表，在界面的右上角点击加号按钮，就可以看到「新建文件夹」的功能，在文件夹中我们还可以进行筛选、排序、切换视图、重命名、移动等操作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2e58e83198d04b1b91c34ed553e9fb92@000000_oswg76098oswg1080oswg777_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>置顶音乐</strong></h2>
  <p>对于我这样的 Apple Music 重度用户来说，今年新推出的功能中最让我满意的就是「置顶音乐」功能。在大多时候时候，我只想听我熟悉的歌曲，但是我每次都要手动去找特定的播放列表、专辑或者歌曲，说实话还是有点繁琐。</p>
  <p>Apple 为 Apple Music 新推出的「置顶音乐」功能，可以让我把自己常听的歌单、专辑、歌曲、歌手等直接置顶显示在「资料库」标签页，打开 Apple Music 就可以一键直达，立享美妙的音乐。如果你不需要跳转到详情页，那么更快捷的方式是长按置顶的音乐图标，然后选择「播放」或者「随机播放」即可。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_720392149c214ca2b399af0bab1766f0@000000_oswg95907oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>将播放列表、专辑、歌曲、歌手、音乐视频等置顶显示的方法，既简单直观又操作统一，我们只需长按资料库中的任意对象（播放列表、专辑、歌曲、歌手、音乐视频等），然后在弹出的菜单界面中选择「置顶 XXX」就行。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_518d4cafed6646d5a424f10d61f6154d@000000_oswg86457oswg1080oswg777_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「置顶音乐」还有一个非常实用的特性，那就是自动下载。所有被置顶的音乐，包括播放列表、专辑、视频等都会自动下载到本地，这样一来就可以节省流媒体播放的蜂窝网络流量，也可以在乘坐飞机等场景下不用担心忘记提前下载音乐。如果你不需要自动下载置顶音乐，那么也可以在「设置」&gt;「音乐」中找到「下载置顶项」的选项，点击关闭即可。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_973c6a37e0c54827822115b16811dcd3@000000_oswg96857oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>新增小组件</strong></h2>
  <p>Apple Music 在 iOS 26 中新增了「置顶项」「电台直播」等主屏幕小组件，方便用户在主屏幕一键直达自己最常听的歌曲或者各类电台，甚至不需要打开 Apple Music 应用，可以说是听歌最效率的方式了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_20666d1334054a4181014c761a212382@000000_oswg103735oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另外，Apple Music 还新增了一个「搜索」锁屏小组件，点击后可以直接打开 Apple Music 并进入到搜索界面。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a966cb0f2d674da5871f841ec3eced51@000000_oswg117094oswg1080oswg1164_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果你还没有使用过 Apple Music，那么推荐你尝试一下这款纯粹、优秀的流媒体音乐播放软件。除了 Apple 生态，目前 Apple Music 已经支持了 Android、Windows、PlayStation、Xbox、LG WebOS 等平台。Apple Music 在中国区的订阅价格是 11 元 / 月，学生只需要 6 元 / 月，家庭计划是 17 元 / 月，没有任何二次收费。</p>
  <p>如果你也是一名 Apple Music 的重度使用者，那么不妨在评论区一起交流一下日常使用的技巧，或者分享一下你对 Apple Music 在 iOS 26 中推出的这些新功能的看法。</p>
  <p>原文链接： https://sspai.com/post/101408?utm_source=wechat&amp;utm_medium=social&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU4Mjg3MDAyMQ==&amp;mid=2247597769&amp;idx=2&amp;sn=8f046da229a52a90bda650a9d7ee714e&amp;chksm=fcb3136600cbd2c985c674e8414dd74ce446bb5b4c7951931a505b7633807904deef56c4dfd8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“少数派”（ID：sspaime）</a>，作者：Vanilla，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471859219961479</id>
            <title>AI“修”出的美图，“靠脸吃饭”还能持续多久？</title>
            <link>https://www.36kr.com/p/3471859219961479</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471859219961479</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:07:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“贴睫毛、画睫毛、夹睫毛，都不如美图秀秀粉钻特效的漫画睫毛！” 近日，南溪在社交平台上分享着自己的 “懒人变美心得”，语气满是惊喜。</p>
  <p>对她而言，每次按下快门后立刻点开美图秀秀，已成为习惯性动作—— 一键启动“AI美颜”，肤色瞬间变得匀净透亮，不到1分钟，一张透着原生感却更显精致的照片便轻松出炉。</p>
  <p>正是为了这份信手拈来的“自然美”，作为忠实用户的南溪，早早加入了美图秀秀的VIP会员之列。</p>
  <p>南溪的行为并非孤例，当“电子美容”逐渐成为一种生活方式，越来越多用户愿意为更精致的修图体验买单，纷纷开通美图秀秀VIP解锁漫画睫毛、AI高清美颜等专属功能，庞大的付费需求不仅显著提升了平台用户粘性，直接推动了美图秀秀母公司——美图公司（01357.HK）的业绩增长。</p>
  <p>前不久，美图公司公布了2025年上半年财报。数据显示，公司上半年实现营收18.21亿元，同比增长12.3%；归母净利润达3.97亿元，同比大幅增长30.8%；经调整净利润大幅增长71.3%至4.67亿元。</p>
  <p>更引人注目的是，截至今年6月底，美图公司月活跃用户数（MAU）达2.8亿，其付费用户数已突破1540万。</p>
  <p>然而在增长的另一面，挑战也悄然浮现。</p>
  <p>在热门功能拉动会员规模快速扩张之后，如何持续提升产品吸引力、优化会员续费意愿，已成为美图必须面对的关键命题。</p>
  <p>更重要的是，在AI修图技术日趋普及、同类竞争加剧的背景下，仅靠“变美”工具能否支撑长期增长，仍然需要更多答案。</p>
  <h2><strong>01毛利率超过微软</strong></h2>
  <p>美图公司成立于2008年，由吴欣鸿（又名吴泽源）在福建厦门创立，公司早期推出的个人电脑端图像处理软件“美图秀秀”，凭借其一键美化的便捷功能，迅速赢得了大量用户的喜爱。</p>
  <p>随着智能手机的广泛普及，美图秀秀于2011年推出移动端应用，并快速占领市场。</p>
  <p>如今，美图公司已构建起多元化的影像产品矩阵，除核心产品美图秀秀外，还涵盖了美颜相机、AI视频编辑应用Wink等多款产品。</p>
  <p>2016年12月，美图公司在香港联合交易所主板成功上市，成为当时继腾讯之后在香港上市的第二大互联网企业。</p>
  <p>然而，在其后的发展过程中，美图却屡被外界贴上“不务正业”的标签——先后推出主打自拍功能的智能手机、涉足贷款服务，甚至进入加密货币领域，炒作比特币和以太币。</p>
  <p>因盲目多元化深陷亏损泥潭，2016年至2021年间，美图公司累计亏损超过80亿元。</p>
  <p>转折发生在2023年，这一年6月，同为美图创始人的蔡文胜（素有“草根天使”“域名之王”之称）离任，吴欣鸿出任董事长。</p>
  <p>此后，美图发展路径出现明显转变，开始将战略重心调整至AIGC领域，这一动作被外界解读为美图“撕掉”蔡文胜和“炒币”的标签。</p>
  <p>“说到这6年，我们有点‘重生’的感觉。因为美图在2018年、2019年遭遇了非常大的挑战，那时候股价狂掉，公司人心涣散。”今年3月，在财报后的业绩会上，吴欣鸿曾表示，AI让美图迎来转机，“特别是最近3年，生成式AI的发展让我们整个产品的AI渗透率将近90%。”</p>
  <p>2025年上半年，美图实现营收18.21亿元，其中影像与设计产品收入同比增长45.2%达到13.5亿元，贡献超七成总收入。</p>
  <p>该板块主要包括美图秀秀、美颜相机、Wink、美图设计室等面向个人用户的软件产品，通过订阅与部分内购项目变现。</p>
  <p>根据公告数据，截至2025年6月30日，美图付费订阅用户数达约1540万创历史新高，同比增长超42％，付费订阅渗透率达5.5％。</p>
  <p>其中，约1360万付费订阅用户来自包括美图秀秀、美颜相机等在内的生活场景应用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f68974e60e6f46509a0d90e2e1a4baf9@46958_oswg24070oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>AI功能不仅刺激用户复购，也因较低生产成本推高了美图公司的毛利率。</p>
  <p>2025年上半年，该公司毛利率从上年同期的64.9%提升至73.6%，同比提升了8.7个百分点，甚至高于以订阅服务著称的微软（同期毛利率为68.82%）。</p>
  <p>美图公司在财报中表示，影像与设计产品业务具有高毛利率，且在整体收入的占比持续扩大，带动整体毛利和毛利率相应增长。</p>
  <p>尽管付费订阅模式有力推动了美图公司的业绩增长，但其也因消费争议频频遭到用户投诉。</p>
  <p>在黑猫投诉等平台上，大量用户反映如美图秀秀APP存在“自动续费未提醒”“诱导充值”以及“退款申请失败”等问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8f87061765b1407fa7fc2050a82def94@000000_oswg98480oswg1080oswg1172_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一位用户8月13日发文称：“早上发现微信余额突然少了108元，查看账单才发现是被美图公司自动续费扣款，升级成了钻石VIP。但事实上，我早在一年前就已经卸载该APP，期间从未使用过任何服务。在我完全不知情、且早已不再使用的情况下，竟依然被自动扣费——甚至在我删除应用后，续费行为仍未终止。”</p>
  <h2><strong>02下一个增长点在哪里？</strong></h2>
  <p>值得一提的是，随着美图公司将战略重心聚焦于核心影像与设计产品业务，其早期的主要收入来源——广告业务在总营收中的占比正持续下降。</p>
  <p>今年上半年，其广告收入为4.3亿元，同比仅小幅增长5%，总收入的比重已从去年同期的约28%降至23.8%。</p>
  <p>相比之下，2019年，美图公司在线广告收入占总收入比例一度超过7成。</p>
  <p>与此同时，美图的美业解决方案业务（包括美得得等SaaS服务）的营收也在进一步收缩，上半年营收收入仅为0.3亿元，同比大幅下跌88.9%。</p>
  <p>该业务原本致力于为美容化妆品行业提供数字化解决方案，但因公司战略调整已大幅收缩——美图出售了美得得的大部分股权，仅保留少数股权投资，导致该板块明显边缘化，目前收入占比仅为1.7%。</p>
  <p>全面押注影像与设计产品业务也伴随着可见的隐忧，一个大的行业背景是：当前，影像处理与设计软件行业竞争异常激烈。</p>
  <p>在国内市场，尽管美图凭借先发优势和完善的产品矩阵仍在用户规模上保持领先，但新兴竞争者不断涌现。</p>
  <p>例如，字节跳动旗下的“醒图”依托短视频平台的流量迅速崛起，吸引了大量年轻用户。</p>
  <p>此外，如小红书、抖音等内容平台内置的图片及视频编辑功能，也在持续抢占用户使用时长，对美图的用户留存构成现实挑战。</p>
  <p>而在海外市场，美图同样面临Adobe、Canva、VSCO、Google Snapseed等国际知名产品的激烈竞争。</p>
  <p>其中，Adobe凭借Photoshop、Lightroom等专业工具占据高端市场；Canva以轻量化的设计平台模式在全球收获数亿用户；VSCO和Snapseed则深耕摄影爱好者群体，用户黏性较高。</p>
  <p>从战略布局来看，美图也在积极拓展如电商类的B端市场。</p>
  <p>今年5月，美图曾宣布与阿里达成战略合作，阿里将通过可转债形式向美图投资2.5亿美元。</p>
  <p>双方将在多领域展开合作，阿里会在其电商平台优先推广美图AI电商工具，协助开发新工具与功能，二者还将共同开发基础及垂直领域模型，美图承诺3年内向阿里采购不少于5.6亿元云服务。</p>
  <p>对于进军电商领域，吴欣鸿此前在接受媒体采访时表示，电商用户对增收的需求更为迫切，付费意愿也更高。</p>
  <p>美图计划聚焦于电商等特定行业，构建完整的AI工作流，以帮助行业实现收入增长，“我们不太去卷一些常规的能力。比如说常规的文生图能力，太多公司在提供了。我们基于像电商这样的一个垂直场景，去打造生成式AI的应用。我们主动地寻找差异化，避免内卷。”</p>
  <p>他强调，这注定是一个需长期投入的过程，“当下的美图需要在一些过去并不擅长的领域探索、寻找增量的空间，而不是停留在过去十几年擅长的（领域），比如说单点的爆款。”</p>
  <p>能否真正从“流量玩家”转型为“价值平台”，将是美图未来发展的关键考验，而这一问题的答案，仍需时间与实践的验证。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU3ODQ5MjQzMQ==&amp;mid=2247579432&amp;idx=1&amp;sn=0495ae10b10e9c829ff7ee057cd1e009&amp;chksm=fc8d7ff9c8e4d2e57bf03b3cb0f9a99c33713133dfc567e86984f3d3267972120c21c05f02c1&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“鳌头财经”（ID：theSankei）</a>，作者：王杰仁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471954146481797</id>
            <title>王兴兴对手，估值2700亿</title>
            <link>https://www.36kr.com/p/3471954146481797</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471954146481797</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:03:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全球最贵人形机器人公司诞生了。</p>
  <p>最新消息，Figure宣布完成10亿美元C轮融资，投后估值390亿美元（约合人民币2700亿元），打破全球人形机器人公司估值记录。</p>
  <p>其实过去一段时间里，国内投资人聊到宇树时也会常常提起Figure——2022年成立，估值千亿，令人惊讶。相比之下，国内具身智能创业公司估值显得保守多了。</p>
  <p>鲜为人知的是，Figure目前产品的零部件，不少来自中国制造业公司。更有意思的是，Figure创始人Brett Adcock曾公开聊到王兴兴的宇树科技，坦言感受到来自中国同行的竞争压力。</p>
  <h2><strong>全球最贵人形机器人，估值2700亿</strong></h2>
  <p>如果将时间拉回到两三年前，几乎没人想到Figure日后会成长为一个千亿独角兽。</p>
  <p>成立于2022年，Figure起初并不在投资人的视野里。“经过无数次演讲，我找不到一个真正的风险投资人愿意投资。”创始人Brett Adcock曾回忆创业初期那段艰难时光，公司没有找到产品市场适应度，被几乎所有的科技投资人拒绝过。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_111142fd5b0241d6a9eadcac41b335fe@46958_oswg13590oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>“我们的想法是放手去造一个人形机器人”。他们算了一笔账，当时的资金消耗速度是每月100万美元，必须尽快取得进展。于是在公司成立后不到12月的时间里，Figure团队从零设计出了人形机器人的大部分部件。</p>
  <p>投资人开始找上门。</p>
  <p>2023年5月，Figure完成7000万美金的A轮融资，由Parkway Venture Capital领投，跟投方包括Aliya Capital、Bold Ventures、Tamarack Global、FJ Labs和库卡机器人前CEO Till Reuter。两个月后，又获得了来自Big Sky Partners和Intel Capital的900万美元投资。</p>
  <p><strong>更大的转折点，是行业外部环境开始发生天翻地覆的变化——具身智能站上了风口。</strong>风暴之下，人形机器人被视为极具前景的未来赛道之一，投资人蜂拥而至。</p>
  <p>Figure成了香饽饽。2024年2月，公司宣布完成约6.75亿美元的B轮融资，其中贝索斯通过名下公司Explore Investments LLC承诺投资1亿美元，微软投资9500万美元，而Nvidia和亚马逊附属基金则各投资5000万美元。本轮融资后，Figure估值跃升至26亿美元。</p>
  <p>创业两年，估值百亿，这样的成绩已经足够惊艳。没想到这仅仅是故事的开始。</p>
  <p>今年初，外界传出Figure正寻求以400亿美元的估值筹集10亿至20亿美元的消息。如今浮出水面——Figure正式宣布C轮融资已获超10亿美元承诺资金，投后估值390亿美元（约合人民币2700亿元）。</p>
  <p>此次投资阵营豪华：由Parkway Venture Capital领投，Brookfield Asset Management、英伟达、麦格理资本、英特尔资本、Align Ventures、Tamarack Global、LG Technology Ventures、Salesforce、T-Mobile Ventures和Qualcomm Ventures也参与了投资。</p>
  <p><strong>换言之，仅仅一年半时间，Figure估值翻了15倍。</strong></p>
  <p>弹药到位，Figure表示将加速其通用人形机器人的商业化进程，并用于三方面：推动人形机器人进入家庭和商业运营领域、构建下一代GPU基础架构，加速训练和仿真，以及启动先进的数据收集工作。</p>
  <p>眼下，商业化探索摆在所有具身智能公司面前。正如Brett Adcock所说，“团队、产品和路线都已准备就绪，现在正是实现突破的最佳时机。”</p>
  <h2><strong>39岁，创业狂人，旗下机器人也面临质疑</strong></h2>
  <p>Figure创始人Brett Adcock堪称“创业狂人”。</p>
  <p>出生于1986年，Brett Adcock在一个农场家庭长大。受父母影响，他从中学时期就开始尝试创业。2012年创办了一家线上人才市场公司Vettery，后被一家瑞士公司以1亿美元收购。</p>
  <p>这让Brett Adcock赚到第一桶金。后来看到电动化浪潮机会，Brett Adcock便带着全部资金投入了新的创业——成立一家eVTOL公司Archer Aviation，生产全电动垂直起降飞机，并于2020年底上市，最新市值57亿美元（约合人民币400亿元）。</p>
  <p>直到2022年，Brett Adcock宣布从公司董事会辞职，创立Figure。他在公司官网上写道：“Figure，展望未来30年”。在他看来，人形机器人是AGI的终极形态，这是成立Figure的目标。</p>
  <p>正所谓投资就是投人，在外界眼里，Brett Adcock的创业过程，颇像马斯克早期创建SpaceX的日子，他也因此有了“马斯克2.0”的称号。2023年10月，Figure的第一款人形机器人Figure 01面世，不仅能完成搬箱子等简单的体力任务，还能通过观察人类示范学会煮咖啡。</p>
  <p>这种机器人“自主学习”的模式比特斯拉将数据传输给机器人的方法更具效率，也被认为碾压马斯克的擎天柱，吸引了全球科技巨头的目光。</p>
  <p>而Figure的另一大法宝，则是<strong>自主研发的机器人AI模型——Helix。</strong></p>
  <p>Figure机器人曾搭载OpenAI的大模型，但意识到人工智能是通用机器人的关键，今年2月，Figure与OpenAI终止合作，随后推出名为Helix的VLA模型。在Figure的演示中，有了Helix加持，AI能够首次同时操控两台机器人，让它们共脑合作，这一幕轰动一时。</p>
  <p><strong>不过，外界质疑随之而来。</strong>此前Figure宣布签下大客户宝马汽车，但随后就有外媒质疑，宝马工厂实际仅有一台Figure的机器人在非生产时段运行，有夸大宣传合作嫌疑。之后的回应视频里，adcock brett仅展示了一个Figure机器人在宝马生产线上忙碌。</p>
  <p>过去一段时间，外界对于Figure机器人的了解仅限于社交网络上频繁发布的演示视频，实操能力如何？没人在公开场合看到过。而对AI模型能力的竞争，对手们早已虎视眈眈。为了应对挑战，Figure已经宣布，将与C轮投资方Brookfield展开合作，帮助Helix开发预训练数据集。</p>
  <p>归根结底，千亿市值之下，人们希望看到更多东西。</p>
  <h2><strong>“宇树们被低估了”</strong></h2>
  <p>消息传至大洋彼岸——9月17日，A股机器人板块延续强势，再度掀起涨停潮。随着特斯拉擎天柱的密集动态、国产机器人厂商相继拿下大单等利好加持，中国人形机器人概念股近期掀起一轮猛烈涨势。</p>
  <p>Figure无疑也是搅动这波春水的鲶鱼之一。你可能不知道，这家千亿独角兽背后，还有一众中国制造业企业：</p>
  <p>汇丰发布的研报显示，在Figure的供应链中，长盈精密为Figure提供关节、轴承和传感器等关键零部件；绿的谐波提供谐波减速器；旭升集团为其供货镁合金外壳；兆威机电提供无刷电机……</p>
  <p>这一幕并不令人意外。</p>
  <p>实际上，无论是宇树科技、智元机器人这类国产新贵，还是特斯拉擎天柱、波士顿动力等海外巨头，都少不了中国供应链企业的深度参与。比如，来自浙江的拓普集团和三花智控，正是特斯拉人形机器人两大一级供应商。前不久，马斯克坦言扩大擎天柱机器人生产规模面临的挑战——必须要从零开始创建供应链。</p>
  <p>这恰恰是国产厂商们实现突围的机会。放眼望去，我国制造业总体规模已连续15年保持全球第一；在全世界504种主要工业产品中，我国大多数产品产量位居世界第一。从长三角到珠三角，聚集了数以万计的产业链供应链企业。这波具身智能浪潮中，不少投资人重新来到深圳找硬件项目，就是因为这里“硬件创新+制造业配套”的集群优势。</p>
  <p>正是那些看似不起眼的减速器、传感器和螺丝钉，形成了国产机器人们生长的独特土壤。摩根士丹利报告指出，全球人形机器人100家关键企业中，其中56家来自中国。在业内人士看来，<strong>中国拥有全球最大的应用市场和最强的制造成本优势。</strong>可以看到的是，今年以来，宇树科技、智元机器人、优必选等头部机器人企业相继拿下大单，成本优势极其明显，每一步都离不开中国供应链能力。</p>
  <p>此前国内具身智能赛道一度被泡沫声音笼罩，但当Figure拿下千亿估值，一切似乎变得合乎情理。毕竟今年爆火的宇树科技，6月融资时的投前估值百亿级别，“宇树们可能被低估了”。</p>
  <p>回到Figure身上，他们早已注意到来自中国的对手。此前Brett Adcock在一次访谈中聊到宇树科技，并对这些中国机器人领域的竞争者给予高度评价。在他看来，中国工程团队在低成本、高效率等方面的优势，将使中国成为未来全球机器人技术的主要竞争者之一。</p>
  <p>他还预测，“最终只有少数几个团队取得成功”。可以断定的是，中国面孔一定不会缺席。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247696819&amp;idx=1&amp;sn=6a57b06bae1ef2c7dffafc8ac2c0e633&amp;chksm=ed84056b5f46443b36e01090b042365ff223cdc013a8af44b817a8dee95da38bdebabca68509&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471944594773638</id>
            <title>在这场翻车最严重的发布会上，我遇见了最想买的产品</title>
            <link>https://www.36kr.com/p/3471944594773638</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471944594773638</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 09:02:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>北京时间今早，Meta Connect 2025 新品发布会开场，小扎亲自上阵演示，可惜现场演示屡屡翻车，把小扎都搞红温了。</p>
  <p>Meta 早把未来“戴脸上”了。毫无疑问，这场发布会的重点还是智能眼镜，从加了屏的 Meta Display 到专业运动向的 Oakley。</p>
  <p>小扎推了推鼻梁，再一次表明下一个计算平台的入口在哪里。</p>
  <h2><strong>Ray-Ban Meta Display：智能眼镜的“显示屏革命”</strong></h2>
  <p>首先，重头戏是 Ray-Ban Meta Display Glasses（以下简称 Meta Display），尽管外观上依旧保持经典的雷朋墨镜造型，但这是 Meta 首次把“屏幕”嵌入镜片的一款智能眼镜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e801dd67b1fa4de085887321f018c1f3@46958_oswg250491oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Meta Display 在右镜片内嵌一个小型 HUD（抬头显示），用来显示通知、地图导航、消息、翻译结果、AI 助手反馈等信息，用户能直观看到信息，而非单纯听觉反馈。而且这个屏幕“别人基本看不到”，Meta 表示漏光&lt;2%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_3bda4241dd3b4ce7aab7d82a7f276972@46958_oswg635784oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这块 HUD 分辨率达 600x600 像素，亮度最高可达 5000 尼特，比刚发布的 iPhone 17 还亮，还具备了 UV 传感器，能在阳光强烈环境中自动提升亮度。</p>
  <p>如果现在你走在街上，眼镜就能直接在视野侧边叠加一条路径指引，你还能边走路边看邮件，不会像低着头耍手机时撞到路人了。（但我还是建议别在开车时用。）</p>
  <p>规格方面，这款眼镜搭载了一个 12MP 摄像头，支持 3K 视频录制（前代为 1080P），还有内置扬声器和麦克风，能无缝接入 Meta AI 助手。你可以用语音命令拍照、播放音乐，或让 AI 分析周围环境，整个眼镜重量控制在 69 克。</p>
  <p>电池续航方面，Meta Display 提供约 6 小时的使用时间，比前代 Ray-Ban Meta 的 4 小时左右续航有所改进，但如果频繁使用 HUD，续航可能打折。但 Meta 开发了一款像眼镜盒一样的可折叠便携式充电盒，能多提供 30 小时的续航。</p>
  <p>Meta 今年还给眼镜配了一个创新配件——一个叫 Meta Neural Band 的腕带。它可以识别微小手部运动或肌电信号，用自然或非常细微的手势来控制眼镜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0118a55e1bf340c09c520d5548464d0a@46958_oswg449671oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>你可以捏手指“虚拟打字”回复消息，或滑动拇指切换菜单、旋转手腕调整音量，而不用在公共场合对着眼镜大喊“嘿，Meta！”。</p>
  <p><strong>虽然扎克伯格在现场演示时，有几次手势识别失败，但整体效果还是挺科幻的。</strong></p>
  <p>腕带交互的加入，补齐了眼镜的交互短板，还能让 Meta 眼镜的操作<strong>更隐秘和高效</strong>。就像小扎和同事在现场的演示：眼睛盯着对方看，手上小动作不断，简直是爱走神的 ADHD 多动症人的神器。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e492992fce914c3eaa5b0205fab369ad@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>腕带本身电池续航长达 18 小时，和眼镜捆绑销售，一起在 9 月 30 日上市。</strong></p>
  <p>但具体手势控制有多灵敏、会不会误触、外人看起来动作滑不滑稽，还得等实机上手体验。如果传感器不灵敏，用户估计也会变成“空气指挥家”。</p>
  <p>总的来说，这个腕带是 Meta 对未来无触控交互的探索，也可能会成为了他们未来 AR、VR 宇宙的控制中心。</p>
  <p>而至于 Meta Display 的另一大卖点——内嵌其中的 Live AI，Meta 在发布会中也“尽力展示”了。</p>
  <p>第一大功能亮点是实时翻译。实时翻译已经不新鲜了，但结合显示屏，这就相当于给所有对话加上了字幕，戴着眼镜看外文菜单时，能直接把中文叠加在菜单之上；以后戴着 Meta Display 也敢啃“生肉”资源了（比如看原版电影或听外语播客）；同时对听障人士来说，这是一个福音，能通过字幕捕捉对方的语言表达。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_09c0bb6c8320438fb083e323c635329b@46958_oswg836527oswg1080oswg854_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除了实时翻译，Live AI 支持智能语音助手反馈，比如你戴着 Meta 眼镜做饭，不用再手忙脚乱的在手机上找菜谱，直接问 Meta 操作步骤，它会播放语音同时，实时显示流程在眼镜的 HUD 上。</p>
  <p>然而这种效果，在发布会现场演示中整段垮掉，Live AI 仿佛几年前的 Siri，不是打断用户说话，就是重复指令。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_764e6a3e1c2e4f06b527bdb75e2e7e43@46958_oswg535486oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一个 AI 功能是环境分析，其实就是眼镜代替摄像头，你可以随时唤出 Live AI，问它“眼前的花是什么花”、“给我讲讲这幅画”等问题。</p>
  <p>Meta 给了一个演示，你戴着眼镜和艺术家朋友对话，你可以扫描当下环境（比如墙上的挂饰），给他提供一些创作灵感。</p>
  <p>Meta 这个演示还是保守了，这功能最容易想到的场景，应该是经典的浪漫喜剧情节：一个不会和女生约会的 Nerd，戴着 Meta Display 和心仪女生约会时，AI 在一边悄悄助攻。比如“她穿着美拉德风，可以夸她 Burberry 经典格纹的围巾好看。”或“她说喜欢打网球，可以和她聊聊刚结束的美网。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_72b0d96ddca747efb7b0fad73f7a6361@46958_oswg391527oswg1080oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过相比前代主要靠语音响应的 AI 助手，新眼镜 Meta Display 的<strong>视觉化输出让交互更直观了</strong>，比如导航可以直接在眼镜里看到路线，来消息提醒也不用掏出手机或者语音播放。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_daf4f1ace4f4401c9229e7cf6e69db7a@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">小扎现场演示“一心二用”｜Meta</p>
  <p>虽然 Meta Display 还达不到像 HoloLens、Vision Pro 那种全视野 AR，但靠手势追踪和实时交互的体验，将智能眼镜的交互、呈现效果，AI 化程度都往前大迈了一步。”半AR“状态可能才是目前技术、体积、能耗、成本的折中方案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_bf98b2e40e1b40959d995f325c229150@46958_oswg987478oswg1080oswg833_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>相应的，Meta Display 799 美元起步的定价就没那么亲民了，比前代 Ray-Ban Meta（只需 299 美元起）高出两倍还多，这个定价对很多消费者来说不是“小玩具”。</p>
  <p>如果 Meta 能通过软件更新持续优化，它或许能成为 AR 眼镜的“iPhone 时刻”。</p>
  <h2><strong>酷盖别急</strong></h2>
  <p>Meta Connect 2025 的另一大亮点是 Oakley Meta Vanguard Sports Glasses，这是 Meta 与美国知名运动眼镜品牌 Oakley 合作推出的首款专为运动员设计的性能型智能眼镜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f1ceeed0783a478793ccfdd3cdd20549@46958_oswg386428oswg1080oswg679_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>外观上，它继承了 Oakley 的经典包裹式框架设计，流线型镜架贴合面部，看起来更像一件专业运动装备。</p>
  <p>规格上，Vanguard 加入了 122 度超广角 12MP 摄像头，能捕捉广阔视野，支持 3K Ultra HD 视频录制，这意味着你边跑步边录制的视频会更清晰锐利，不会像手机抖动那样模糊。</p>
  <p>而且摄像头正放在眼镜正中央，也是用户的鼻梁上方，Meta 在发布会上特别演示了“关键动作捕捉”：当系统检测到诸如加速冲刺、跳跃或急转弯等高强度瞬间时，会自动启动录制。</p>
  <p>所以这眼镜看着像 GoPro 的智能进化版，但免去了额外绑带的累赘，也不会像头盔摄像头那么笨重，用户佩戴更自然，视角更有临场感。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_ddb4a80c741d4a40a5953b925ee049b5@46958_oswg313581oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这款眼镜还配备有 5 个麦克风阵列，能有效减少风噪，小扎表示，降噪好到他在喷气式飞机上都能听清。</p>
  <p>电池续航高达 9 小时，音乐播放时 6 小时，这续航比对着一场马拉松定的。</p>
  <p>随附的充电盒可额外提供 36 小时续航，20 分钟快充即可补到 50%，足以应付临时加练或城市短途骑行。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b7d9572ca431499e83a8521731842337@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Vanguard 还和佳明、Strava 等健身数据平台打通，可实时获取心率、速度、路线等训练数据，并在运动后生成总结报告。</p>
  <p>想象一下：你在山道上奔跑，眼镜实时通过语音给出运动数据、路线建议，你还可以随时问它配速。但这也需要用户有其他可穿戴设备（比如佳明的运动手表），Vanguard 只能获取数据，不能检测数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_338a38d632bb44ae8f69975fa17d88ec@46958_oswg217370oswg1080oswg561_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>如果未来 Meta 的 AI 助手进一步进化，比如加入心率监测，能通过生理数据预测疲劳或提出恢复建议，这副眼镜就不仅是拍摄和导航的工具，而是一个“随身教练”。</strong></p>
  <p>官方定价 499 美元，在专业运动设备领域属于中高端价位。考虑到它同时覆盖了运动眼镜、运动相机、音乐耳机和部分运动手表的功能，这个价格对重度跑者或极限运动爱好者而言并不算离谱。</p>
  <p>Oakley Meta Vanguard 将于 10 月 21 日 在美国与加拿大等市场正式发售或开始出货。</p>
  <p>Meta 还带来了去年爆款眼镜 Ray-Ban Meta Glasses 的升级版：Ray-Ban Meta Gen 2（简称 Gen 2） 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_9020f6ae98a34a20974ff42621893e6f@46958_oswg178925oswg1080oswg726_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Gen 2 外观保持经典雷朋风格，升级不大，但解决了许多前代的痛点。</p>
  <p>最大的提升就是电池续航直接翻倍，至约 8 小时，前代只有 4 小时，常被用户抱怨“半天就没电”。</p>
  <p>摄像头同样升级到 12MP 支持 3K Ultra HD 视频录制，音频系统优化，风噪减少更明显。</p>
  <p>同样，这代也有 Live AI，只是 Meta 官方都表示，Live AI 续航可能会下降到 1-2 小时。</p>
  <p>相比前代起步价 299 美元，Gen 2 定价从 379 美元起，这多出的 80 美元主要换来更长的续航和清晰视频录制，性价比还算不错，发布会当天就已上市，可供选购。</p>
  <h2><strong>死磕元宇宙</strong></h2>
  <p>发布会最后，小扎还是没忘了他的元宇宙。</p>
  <p>Meta 宣布 Horizon Studio、Horizon Engine 以及 Horizon TV 三套全新平台，算是给他们的虚拟世界补了强力升级包。</p>
  <p>Horizon Studio 是创作者工具集的全面进化版，集成了生成式 AI 工具，强调“零门槛建造”。你不用是 3D 建模大神，靠文本提示，也能用简单拖拽在 VR 里搭建虚拟街区、演唱会舞台或团队办公空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_be5e3ebad4a841629c4fecf31029c1c1@46958_oswg853963oswg1080oswg723_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>紧跟而来的是 Meta Horizon Engine，从零构建的元宇宙的新引擎，提供更优图形、更快性能和先进世界构建能力。</p>
  <p>它支持无限连接空间、真实物理交互，加载渲染速度提升 4 倍，最高能容纳 100+人同时在线，是前代引擎的 5 倍，还引入 Hyperscape capture 功能，让用户用 Quest 头显扫描现实房间，快速转化为沉浸式虚拟环境。不久后，戴着 Quest 头显就能去隔壁机友家做客了。</p>
  <p>最后，小扎推出 Horizon TV，作为元宇宙娱乐枢纽，与 Disney+（含 Hulu、ESPN）等流媒体平台合作，提供电影、TV、直播体育、音乐等内容。马上将支持杜比环绕声和杜比视野。</p>
  <p>这三板斧，也算是给关注 Meta VR 进展的用户喂颗糖：虽然发了三款眼镜，好似完全忘了 Quest 4，但 VR 系统还是在升级的嘛。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_add0eb56a0264e4a9633f16ea2af8ba4@46958_oswg120962oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">可以用 Quest 3 扫描现实世界的 Hyperscape Capture｜Meta</p>
  <p>出门戴眼镜、回家带头显，现实生活中靠AI，虚拟空间里有“元宇宙”。</p>
  <p>眼镜开始能弱化掉手机的一些存在感，甚至发挥出一些独特优势，被视频创意工作者，或科技爱好者日常佩戴。这还真让 Meta 如愿了。</p>
  <p>文章配图均来自 Meta</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oFxVOXj8exNY9_W5XefEXg" rel="noopener noreferrer nofollow" target="_blank">“果壳”</a>，作者：糕级冻雾，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471844746696065</id>
            <title>Nano Banana团队谈AI产品和图像模型：最终希望各种模态能融合在一起</title>
            <link>https://www.36kr.com/p/3471844746696065</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471844746696065</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 08:09:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在美国红点创投的播客Unsupervised Learning最新一期节目中，红点创投合伙人Jacob Effron对话了负责Nano Banana的两位Google研究员Nicole Brichtova和Oliver Wang。讨论认为，Nano Banana的流行，<strong>归功于这款模型实现了前所未有的“角色一致性”。</strong></p>
  <p>Nano Banana在8月26日“匿名”发布，后来证明这款模型就是谷歌的Gemini 2.5 Flash Image模型。Nano Banana的成功也使得谷歌的Gemini APP的下载量飙升。</p>
  <p>据应用数据分析公司Appfigures提供的最新数据，<strong>这款应用已经攀升至全球应用商店排行榜的榜首，并且在九月份下载量环比增长了45%</strong>。虽然九月份才过了一半，<strong>Gemini应用本月已经获得了1260万次下载，</strong>远高于八月份的870万次。在此之前，Gemini仅在2025年1月28日达到过美国App Store的第三名。谷歌母公司Alphabet（GOOG.US）在8月26日至9月17日收盘的股价涨幅为19.56%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0b78ed77361d4d94b0d4f25ef7e19b52@000000_oswg123515oswg830oswg448_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Gemini下载量数据（来源：Appfigures、TechCrunch）</p>
  <p>在产品之外，这期播客访谈内容涵盖了模型如何融入创意工作流程，为什么尽管当前AI图像能力已经让人感觉很强大但“仍处于AI图像发展的早期阶段”，以及图像与视频生成如何正趋向统一。</p>
  <p>在访谈中，Nicole Brichtova和Oliver Wang分还享了当前模型的局限性、安全策略，<strong>以及为什么“从提示一步到生成可直接用于生产的内容”这一期待其实被严重高估了。</strong></p>
  <p><strong>以下为「明亮公司」编译的访谈正文（有删节）：</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e49e29db60bb4d159360cd0111d0806a@000000_oswg427373oswg830oswg468_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Nicole（左）、Oliver（中），主持人Jacob（右）</p>
  <h2><strong>Nano Banana的成功归功于角色的一致性</strong></h2>
  <p><strong>Jacob：</strong>Nicole和Oliver，非常感谢你们来到节目。我一直很期待这次对话。感觉你们已经占据了我整个Twitter动态、还有我所有的空闲时间，都是Nano Banana。</p>
  <p>今天我们会深入探讨很多话题。也许我们可以先从这个问题开始——你们在产品和模型发布前就已经接触并体验了它，我记得最初可能是匿名发布的。但你们是最早一批玩转它的人，我很好奇，你们最初认为哪些用例会最流行或让你们最兴奋？而现在发布后，实际情况又如何？</p>
  <p><strong>Nicole：</strong>Oliver已经见过很多我脸部的各种迭代图片。对我来说，<strong>最激动人心的是角色一致性，以及能在新场景中看到自己</strong>——所以我真的有一堆幻灯片，都是我的脸，比如通缉海报、考古学家，还有我童年梦想的职业。</p>
  <p>基本上，我们现在创建了一个包含我的脸和团队其他成员的评估数据集，每当我们开发新模型时都会用来测试。</p>
  <p><strong>Jacob：</strong>在AI领域，这简直是最高荣誉了。</p>
  <p><strong>Nicole：</strong>我真的很兴奋。所以我非常看重角色一致性，因为它给了人们一种全新的方式去想象自己，以前很难做到。这也是大家最终非常激动的原因之一。<strong>我们看到很多人把自己变成了手办，这是非常受欢迎的用例之一。</strong>还有一个让我感到惊喜但其实也合理的用法——<strong>人们为老照片上色，这是非常有情感价值的用例。</strong>比如：现在我能看到自己小时候真实的样子，或者能看到父母从黑白照片中还原出来的真实模样。</p>
  <p><strong>Jacob：</strong>这真的很有趣。我相信看到大家的各种用法也是你们拥有热门产品的乐趣之一。我在Twitter上也见过，你们一定收到无数功能请求吧？每个人都希望模型能做这或那。<strong>最常见的需求有哪些？</strong>你们如何看待这些产品和模型的下一个里程碑或发展的方向？</p>
  <p><strong>Nicole：Twitter上最多的需求是更高分辨率</strong>。目前很多专业用户都在请求1K分辨率以上的图像。还有很多请求希望支持透明背景，这是专业用户很常见的需求。这两点是我见到最多的，还有更好的文本渲染。</p>
  <p><strong>Jacob：</strong>角色一致性曾经是很难解决的大问题，你们在这方面做得非常棒。你们认为图像模型改进的下一个前沿是什么？</p>
  <p><strong>Oliver：</strong>对我来说，这个模型最令人兴奋的一点是它可以开始接受更难的问题。<strong>以前你必须定义你想要的图像的每个细节，现在你可以像问语言模型一样寻求帮助。</strong>例如，有人用它来重新装修房间，但自己没有主意，让模型给出建议。模型能根据配色方案等给出合理建议。</p>
  <p><strong>我认为最有趣的是结合语言模型的世界知识，让图像模型真正帮助用户，甚至展示他们没想到的东西。</strong>比如信息检索请求——我想知道某个东西是如何工作的，模型能生成解释图片。我觉得这是未来很重要的用例。</p>
  <p><strong>Jacob：</strong>在这方面进展如何？</p>
  <p><strong>Oliver：审美方面始终比较棘手，因为需要深度个性化才能给出有用的信息。</strong>我认为个性化是技术侧还在不断改进的领域。我们还需要一段时间才能真正理解用户的需求，但如果能和模型对话，不断澄清和细化，我觉得很令人期待。比如可以在对话线程中反复沟通，直到生成你想要的图片。</p>
  <p><strong>Jacob：</strong>你觉得个性化会只发生在提示层面吗？就是通过足够的描述，给模型足够的上下文来实现个性化？还是大家会有不同的美学模型？</p>
  <p><strong>Oliver：</strong>我认为会更多发生在提示层面。比如用户告诉你的信息，可以让我们做出更明智的决策。希望能这样，毕竟每个人都有自己的模型并分别服务，听起来很复杂，但也许未来就是这样。</p>
  <p><strong>Nicole：</strong>但我确实认为美学会有很大差异。我觉得在某种程度上，个性化必须在那个层面实现。你在Google购物标签页就能看到，比如你在找毛衣，系统会给你推荐一堆，但你其实希望聚焦于自己的美学，甚至能从你的衣柜中选出搭配。我希望这些都能在模型的上下文窗口里实现。我们应该能把你衣柜里的图片喂给模型，然后帮你找出合适的搭配。我对此很期待，希望能做到。也许还需要更高级的美学控制，但我觉得那可能更多发生在专业用户层面。</p>
  <p>在语言模型领域，甚至在图像领域，很多决定其实都取决于预训练时用的数据，这直接影响了模型的最终能力和美学风格。所以我也很好奇，未来会不会有一个万能模型，通过提示就能覆盖所有图像用例？还是会有各种风格的模型？</p>
  <p><strong>Nicole：</strong>我们一直对现成模型能支持的用例范围感到惊讶。你说得很对，很多面向消费者的用例，比如你只是想画出房间的效果图，这些都可以。<strong>但一旦进入更高级的功能，就需要集成其他工具来让它成为最终产品，</strong>在营销或设计等工作流程中发挥作用。</p>
  <p><strong>Jacob：</strong>大家肯定很好奇，这些模型为什么会变得这么好？</p>
  <p><strong>Nicole：</strong>有很多特别的原因。</p>
  <p><strong>Oliver：</strong>其实没有某个单一因素，而是把所有细节都做好了，真正调试好配方，还要有一个长期专注于这个问题的团队。我们其实也被模型的成功程度吓了一跳。我们知道模型很酷，很期待发布。但当我们在LM Arena上线后，不仅Elo分数很高，这当然很好。分数高是模型有用的好迹象，但对我来说，<strong>真正的指标是有大量用户涌入LM Arena使用模型。</strong>我们不得不不断增加每秒查询量，完全没预料到。这是第一次意识到，这确实是非常有用的东西。有很多人都需要这样的模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d9f02c3799244ef8a79b2248d03d6616@000000_oswg228894oswg830oswg664_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">上线后Nano Banana的Elo分数明显领先（来源：LM Arena网站）</p>
  <p><strong>Jacob：</strong>我觉得这是这个生态系统最有趣的部分。你们自己构建模型时有些预期，但只有真正发布到用户手中，才能发现它的强大和影响力，这次显然引发了巨大反响。</p>
  <p>显然，<strong>模型的推理能力很大程度上受益于语言模型本身的进步。</strong>你能否介绍一下图像模型从语言模型进步中获得了多少好处？你认为这种趋势会随着LLM发展继续吗？</p>
  <p><strong>Oliver：</strong>当然受益，几乎100%依赖语言模型的世界知识。比如Gemini 2.5 Flash Image（就是这个模型的名字）。</p>
  <p><strong>Jacob：</strong>名字有趣一点就好了。</p>
  <p><strong>Nicole：</strong>（Nano Banana）确实更容易读。</p>
  <p><strong>Oliver：</strong>我有点好奇我们的成功是不是因为大家喜欢说Nano Banana这个名字。但它确实是Gemini模型的一部分，你可以像和Gemini对话一样和它交流，它懂Gemini懂的所有东西。这是这些模型迈向实用性的关键一步，就是和语言模型整合。</p>
  <p><strong>Nicole：</strong>你可能还记得，两三年前你必须非常具体地描述需求。比如“桌子上的猫，背景是什么，这些颜色”，现在不用那么详细了。很大原因就是语言模型变得更强了。</p>
  <p><strong>Jacob：</strong>不再是后台魔法提示转换了。以前你输入一句话，系统会自动扩展成十句话的详细提示，现在模型本身就足够聪明，能理解你的意图，这真的很让人兴奋。</p>
  <h2><strong>如何打磨产品、多模态和语音AI的潜力</strong></h2>
  <p><strong>Jacob：</strong>从产品角度看，你们有各种不同类型的用户。有些是专家，一上线就去LM Arena玩模型，他们很懂怎么用；还有很多普通Gemini用户，面对“空白画布”完全不知道该做什么。你们是怎么考虑为这两类用户打造产品的？</p>
  <p><strong>Nicole：</strong>我们还有很多可以做的。你说得对，LM Arena的用户和开发者都很专业，能用这些工具创造我们没想到的新用例。比如有人在照片里把物体变成全息影像，我们根本没训练过这种场景，但模型表现得很好。对于普通消费者来说，易用性极其重要。现在你进入Gemini应用，会发现到处都是香蕉表情。我们这么做是因为大家听说Nano Banana后去找，但应用里没有明显入口。</p>
  <p>我们做了很多工作，比如和创作者合作预置一些用例，放出直接链接到Gemini应用的示例，提示会自动填充。我觉得“零状态”问题还有很大改进空间，比如用视觉引导用户。未来还可以让手势成为编辑图片的方式，不只是靠文字提示。</p>
  <p>有时你想要很具体的效果，还是需要很长的提示，但这对大多数用户来说并不自然。所以我会用“父母测试法”——如果我父母能用，那就合格了，现在还没做到，所以还有很长路要走。</p>
  <p>很多问题其实就是要“展示而不是讲述”，给用户易于复制的示例，让分享变得简单。没有一个魔法答案，需要多方面共同努力。</p>
  <p><strong>Oliver：我们还发现社交分享在解决“空白画布”问题上很重要。</strong>用户看到别人做的东西，因为模型默认就能个性化，可以用自己的照片、朋友、宠物尝试，非常容易就能模仿，这也是模型传播的重要方式。</p>
  <p><strong>Jacob：</strong>现在大家都是用文本和模型互动，你们对未来还有什么新型设计界面感到兴奋吗？</p>
  <p><strong>Nicole：</strong>我觉得我们才刚刚开始探索可能性。<strong>最终我希望各种模态能融合在一起，界面能根据任务自动切换最合适的方式。现在大模型不仅能输出文本，还能输出图片和视觉解释，满足用户需求。</strong></p>
  <p><strong>我觉得语音很有潜力，是很自然的交互方式，但还没人真正做出很棒的语音界面。</strong>现在我们还是在输入文字，所以未来可能结合暂停、手势等，比如你想擦除图片中的物体，应该能像在草稿本上一样操作。<strong>如何在不同模态间无缝切换，是我非常期待的方向，还有很多空间去探索实际形态。</strong></p>
  <p><strong>Jacob：</strong>你觉得语音的限制是什么？我完全能想象和图片对话。</p>
  <p><strong>Nicole：</strong>有些问题是优先级的，我们还在推进模型能力，语音这两年也进步很大。我觉得很快会有人尝试，也许我们也会做一些相关工作。</p>
  <p><strong>问题在于如何检测用户意图，然后根据意图切换不同模式，因为并不明显。</strong>你可能又回到“空白画布”问题，怎么向用户展示功能？我们发现用户进来后对聊天机器人期望很高，觉得它什么都能做，实际上很难解释限制，也很难展示所有功能，尤其工具能力越来越强时。所以要想办法划定范围，在UI里展示可能性，帮助用户完成任务。</p>
  <p><strong>Jacob：</strong>而且你教会用户某个时刻机器人能做什么，三个月后又得重新教，因为功能已经变了，这也是很有意思的产品挑战。</p>
  <p>很多产品都有评估机制，你们有自己的评估数据集，比如Nicole自己的照片。<strong>图像模型的评估通常是什么样？</strong>除了放到LM Arena让用户体验外，你们在追踪模型进步方面有哪些经验？</p>
  <p><strong>Oliver：</strong>语言模型和视觉语言模型进步的一个好处是能形成反馈环，用语言模型的智能来评估自己生成的内容。这形成了良性循环，可以同时提升两个维度。</p>
  <p>但最终，<strong>用户才是他们想要图片的裁判。</strong>所以像LM Arena这种用户自己输入提示的场景，是评估模型的最佳方式。</p>
  <p><strong>Nicole：</strong>品味也很重要。Oliver不会夸自己，其实他在团队里很擅长判断图片效果，能发现问题和缺陷。我们团队有几个人专门做这种“眼球评估”，就是技术性地看模型输出效果，这在初期仍然很重要。我们也会收集用户反馈，包括X（推特）上的意见，看看哪些地方有效，哪些地方需要改进，然后调整评估标准，既保证已有功能不退步，也推动社区关心的方向。欢迎大家持续反馈。</p>
  <p><strong>Jacob：</strong>感觉这比语言模型难多了，比如法律用例有标准答案，模型偏离时有纯粹的评估数据集。但图片很主观，很难明确爬坡方向。比如角色一致性能量化，但主观性确实让优化变得很难。对了，Nano Banana这个名字有什么故事？</p>
  <p><strong>Nicole：</strong>我们团队有个PM叫Nana，她凌晨两点半在准备发布时想出了这个名字，<strong>然后大家觉得很有趣就用上了，</strong>现在甚至成了半官方名字。毕竟Gemini 2.5 flash image太难念了。</p>
  <p><strong>Jacob：</strong>确实很成功，连Google CEO都在发香蕉表情，名字的影响力很大。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_74decf59469d48169c94b9e056518998@000000_oswg42655oswg830oswg274_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Alphabet CEO Pichai在模型发布后的社交媒体信息（来源：X.com）</p>
  <p><strong>Nicole：</strong>品牌建议就是名字最好有合适的表情符号，这样更容易传播。</p>
  <p><strong>Jacob：</strong>感觉Hugging Face是AI界最早用表情做品牌的，现在我们离公司股票代码都是表情的时代也不远了。</p>
  <h2><strong>专业用户的潜在应用场景</strong></h2>
  <p><strong>Jacob：</strong>回到刚才的话题，你们有很多专业用户，也有很多面对空白屏幕不知道做什么的普通用户。你们见过最专业的用户有哪些用法？</p>
  <p><strong>Oliver：</strong>我最喜欢的高级用例是视频相关的。我大部分职业生涯都在做视频工具，<strong>发现Nano Banana在AI生成视频方面非常有用。</strong>比如结合视频模型（VO3）可以更快地构思、规划镜头，这其实也是电影制作的流程，<strong>先做分镜，再拍摄。现在大家用它构建更连贯、更长的视频内容。</strong></p>
  <p><strong>Nicole：</strong>我对大家用它在建筑设计流程中的表现印象很深。可以从蓝图到类似三维模型，再到设计图，快速迭代，节省了繁琐的流程，让人专注于创意和乐趣。这种效果出乎我的意料，模型开箱即用就能做到。</p>
  <p><strong>Jacob：</strong>感觉是各种“五分钟编码”图像用例，帮你快速搭建基础内容。</p>
  <p><strong>Nicole：</strong>还有网站设计，以前从提示直接生成网站代码，总觉得中间少了一个步骤，现在可以先快速迭代设计，满意后再编码。</p>
  <p><strong>Jacob：</strong>你觉得这会成为未来的工作流吗？确实很合理，为什么要先消耗算力生成代码，如果审美完全不满意，还得重来？</p>
  <p><strong>Nicole：</strong>而且这样更有趣。以前大家就在现有流程里用技术，现在大模型发展太快，能直接从提示到网站，非常惊人。<strong>但我觉得大家还是很喜欢在中间环节迭代，</strong>确保风格符合自己需求。</p>
  <p><strong>Jacob：</strong>你们既有模型也有API，未来会有各种接口和用例。你们如何区分哪些功能适合放在Gemini聊天工具里，哪些适合通过其他产品实现？</p>
  <p><strong>Nicole：</strong>体验很不同。我们看到大家会用Gemini做快速迭代，比如团队成员在重新设计花园时，会用Gemini想象效果图。然后再和景观设计师合作，把想法进一步完善。这是创意过程的第一步，很少是最终成品。<strong>而专业开发者会用更复杂的工具，串联多个模型，工作流更复杂。</strong>聊天机器人适合启发、灵感和分享，专业用户还是更需要视觉化的UI。</p>
  <p><strong>Jacob：</strong>编辑流程会如何融合进来？你们的API已经集成到Adobe等工具了，传统编辑流程会变得很不一样吗？还是最后从95%到100%完成度，还是需要传统编辑工具？</p>
  <p><strong>Oliver：</strong>很大程度上取决于用户。有些人对细节要求极高，像素级控制，这种场景必须和现有工具深度集成，比如Adobe产品。有些用户只是找灵感，要求没那么严格，聊天机器人快速生成想法就够了。所以两者都是模型的重要应用。</p>
  <p><strong>Nicole：</strong>像素级控制让我最近学到一个新点，比如做广告时，不同品牌对模特视线的位置有严格要求，<strong>因为视线影响广告传达的信息。这种控制很难用聊天机器人实现，所以专业用户还是需要专门的精确工具。</strong></p>
  <p><strong>Oliver：</strong>归根结底，看能否用语言描述。如果只是高层次想法，语言很合适，但如果要左移三像素，语言就不太优雅了。两种方式都有存在意义。</p>
  <p><strong>Jacob：</strong>看真正的艺术家或创作者的完整流程，他们很难用语言精确描述自己的操作，很多时候是凭感觉。Google内部也有很多团队对图像模型感兴趣，你们最期待它在Google各产品中的应用有哪些？</p>
  <p><strong>Nicole：</strong>创意方面，比如在Google Photos做照片编辑很有前景，毕竟你的图库就在那儿。比如把家庭照片直接变成生日卡片，我每年都用得上。如果能直接在Photos里做很棒。</p>
  <p>还有像一开始说的“事实性”用例也很有趣，比如让模型用适合五岁孩子的方式解释光合作用，并生成视觉化内容，这在网上可能都找不到。这样能为用户开启个性化、视觉化的学习体验。</p>
  <p><strong>Oliver：</strong>还有Workspace，比如PowerPoint和Google Slides。让大家能做出更有吸引力的演示文稿，不再千篇一律。</p>
  <p><strong>Jacob：</strong>作为前咨询行业人士，如果能实现就太棒了，大家都花太多时间在排版上了。</p>
  <p><strong>Nicole：</strong>以前都是先在白板上画出幻灯片结构，写好标题。比如左侧放某个数据集的图表，然后把这些信息交给大模型，让它帮你完成很多工作，我对此非常期待。</p>
  <h2><strong>图像模型的未来：小团队有机会，但调用世界知识需要大模型支持</strong></h2>
  <p><strong>Jacob：</strong>回顾近几年图像模型的发展，从Stable Diffusion到Mid Journey，Oliver你怎么看这几年的主要里程碑？整个路径和变化你怎么总结？</p>
  <p><strong>Oliver：</strong>这几年发展简直像火箭一样。我早期做这方面时，GAN（生成对抗网络）是主流方法，我们对GAN能做的事很惊讶，但它只能生成很窄分布的图片。</p>
  <p>比如可以生成看起来不错的人脸，但只能是正面照。后来出现能泛化、完全由文本控制的模型，虽然起步时很小很模糊，但很多人都觉得这会改变一切，于是大家都全力投入，但没人能预料到进步速度如此之快。</p>
  <p>我认为这得益于很多顶尖团队的良性竞争。大家看到其他团队出色的模型，比如Mid Journey一度遥遥领先，效果惊人，大家都很受激励，想知道他们怎么做到的。</p>
  <p>尤其Stable Diffusion开源后，展示了开发者社区的规模，很多人愿意在这些模型上构建产品，这是另一个重要节点。<strong>从那以后，整个领域发展非常快，虽然有时压力很大，因为不仅模型变强了，用户期望也越来越高。</strong>现在大家会抱怨一些小问题，但一年前我们还在为不真实的图片感到惊讶。人类对新技术的适应力真的很强。</p>
  <p><strong>Jacob：</strong>确实，如果2017年有人告诉我们会有如此强大的技术，我们肯定会震惊，但现在大家总是抱怨不足。这也是人性有趣的地方。你怎么看Mid Journey当初能领先一步的原因？他们一度是行业标杆，所有人都盯着它。</p>
  <p><strong>Oliver：Mid Journey比其他团队更早掌握了后训练技巧，</strong>尤其是让模型生成风格化、艺术化图像。他们一直专注于风格控制，确保生成的图片都很漂亮。刚开始时，聚焦于高质量图片的小领域是很好的策略。后来所有模型，包括Midjourney和Flux等，都扩展到更广泛的类别，同时保持高质量。</p>
  <p><strong>Jacob：</strong>是什么让模型能生成更广泛的图片，不再只挑选完美作品？</p>
  <p><strong>Oliver：</strong>有很多原因，大家都不断完善细节，尤其是数据质量。同时，<strong>模型规模自然扩大，算力提升，很多以前做不到的事现在都能实现了。</strong></p>
  <p><strong>Jacob：</strong>你刚才也提到，我们在图像模型上取得了巨大进步，我很难判断还剩多少提升空间。你怎么看未来三年？我们会不会回头觉得现在的模型其实还很一般？</p>
  <p><strong>Oliver：</strong>我完全支持后者观点。仅就图像质量而言，还有很大提升空间。<strong>未来的改进点在于模型的表达能力。</strong>现在我们能完美生成一些常见内容，完全无法分辨是生成的还是现实的。但只要超出常规场景，质量就会迅速下降，尤其是需要更多想象力、组合多概念的提示。这类场景模型很快就崩溃了。</p>
  <p>未来模型最好的图片可能和现在一样好，<strong>但最差的图片会大幅提升，</strong>模型会更有用、适用范围更广。我们发现模型越泛化，可支持的用例越多，价值也越大。</p>
  <p><strong>Jacob：</strong>你怎么看图像模型领域的未来格局？相比大模型领域，主要是你们、OpenAI、Anthropic等大玩家，图像模型会类似吗？</p>
  <p><strong>Oliver：</strong>这是个好问题。到目前为止，<strong>图像领域小团队也能做出顶级模型。</strong>我们看到一些小实验室的作品非常惊艳。我希望这种情况能持续，因为我喜欢小团队的创新。</p>
  <p><strong>但模型的世界知识、实用性很需要规模，</strong>尤其是语言模型的规模。所以我猜未来还是大型团队能同时训练强大的语言和图像模型。我们看到中国的大型实验室也在推出很棒的模型，和语言模型一样，<strong>所以未来他们也会成为图像领域的重要玩家。</strong></p>
  <p><strong>Jacob：</strong>如果用最好的开源模型而不是闭源模型，会有很大劣势吗？</p>
  <p><strong>Oliver：</strong>这很难说，取决于开源模型的未来，变化很快。一年前可能觉得开源很安全，现在不一定。但开源确实有可能支撑很多小团队继续创新。好模型肯定可以。</p>
  <p><strong>Jacob：</strong>Oliver，想问你一个问题。你之前做视频很多年，我一直想弄明白图像模型和视频模型的关系。你们团队在视频方面也有很大突破。两者是独立的吗？还是互相借鉴？现在图像和视频领域是怎样互动的？</p>
  <p><strong>Oliver：</strong>非常密切相关。<strong>未来大家都在向“全能模型”发展，</strong>就是能做所有事情的模型。这些模型有很多优势，可能最终会胜出。</p>
  <p><strong>我觉得我们在图像生成领域学到的很多技术都应用到了视频生成模型，</strong>反之亦然。<strong>这也是视频生成能迅速发展的原因之一</strong>，因为整个社区都在学习如何解决这些问题。所以我觉得两者是非常亲密的“朋友”，很多技术共享，未来可能会完全融合。</p>
  <p><strong>Jacob：</strong>你说的技术，就是很多底层方法在不同模型间都很相似吧？</p>
  <p><strong>Nicole：</strong>连工作流也很像。很多用户会把这些模型结合使用。比如电影制作，最初的构思在大模型领域，然后在图片或帧空间迭代，因为更快更便宜，最后才进入视频阶段。所以从工作流和可用性角度看，<strong>图像和视频模型之间有很多互补性。</strong>很多用例和问题都是共通的，比如角色、物体、场景一致性，图像和视频都有，只是视频更复杂。</p>
  <p><strong>Jacob：</strong>你觉得视频领域下一个要解决的难题是什么？</p>
  <p><strong>Oliver：</strong>我觉得在<strong>视频领域获得和最新图像模型一样的控制力，会非常有影响力，这是值得关注的方向。</strong>视频团队也在提升分辨率和时间一致性，当然还有跨场景角色一致性，大家最关心的就是这个。未来肯定会朝着更长、更连贯的内容发展。</p>
  <p><strong>Jacob：</strong>这些问题可以在图像领域先解决，很多方法都能迁移到视频领域，这很酷。今天聊得很精彩，我们最后有一组快问快答。</p>
  <p>首先，你们认为目前AI领域有什么被高估，什么被低估？</p>
  <p><strong>Nicole：</strong>我觉得<strong>被高估的是“一个简短提示就能生成可用于生产的成果”</strong>。其实还需要很多迭代。即使是社交媒体上大家分享的内容，背后也有很多工作。所以这个有点被过度宣传了。<strong>被低估的是未来的融合</strong>，我们已经聊过了，就是如何让大家更容易使用这些模型，展示可能性，并针对具体工作流提供帮助。</p>
  <p><strong>Jacob：</strong>你见过哪些产品，在UI设计上有新颖的想法？</p>
  <p><strong>Nicole：</strong>我还在等，暂时没看到。</p>
  <p><strong>Oliver：</strong>我喜欢节点式界面，但这不是大众化的设计。</p>
  <p><strong>Jacob：</strong>未来每个人都能有自己的UI，也许会进入个性化时代。你觉得明年图像模型的进步会比今年更快，还是差不多？</p>
  <p><strong>Nicole：</strong>希望更快。</p>
  <p><strong>Oliver：</strong>有更多聪明人投入，更多资源，肯定会加速进步。</p>
  <p><strong>Jacob：</strong>你们已经让Nano Banana火遍全网，还有哪些AI图像领域的趋势是你们关注的，但大家没有足够重视？</p>
  <p><strong>Nicole：我觉得是“事实性”维度。</strong>比如大家用Nano Banana做信息图或给尼亚加拉瀑布标注，虽然演示效果不错，<strong>但仔细看文字还是有点混乱，</strong>不够准确，会重复信息。所以这是下一个前沿，大家还没太关注。</p>
  <p><strong>Oliver：</strong>这和文本语言模型很像。GPT-1和2刚出来时，大家觉得很酷，可以写俳句、做创意任务，答案范围很广。现在大家都用语言模型做信息检索、对话、陪伴等。所以我觉得图像领域也会有类似变化，从创意工具到信息检索工具，未来甚至会有人和视频模型对话，这很有可能出现。</p>
  <p><strong>Nicole：</strong>模型也应该更主动，现在都是用户主动请求图片。如果查询本身适合用图片回答，模型应该主动生成。我们在搜索中已经习惯了，有时返回文本，有时返回图片，有时两者都有。所以我也期待模型能更主动、更智能地根据需求选择模态。</p>
  <p><strong>Jacob：</strong>我很喜欢这种无缝切换的未来。正如你说的，可靠性是关键。早期语言模型偶尔很惊艳，但远不够稳定，工作场景用不了。图像模型也会经历类似的进化。</p>
  <p>最重要的问题：你们最喜欢用Nano Banana生成的内容是什么？</p>
  <p><strong>Oliver：</strong>我最喜欢的是和孩子一起玩模型，把他们放到各种有趣场景里，让他们的玩偶“活”起来。这些内容非常个人化，孩子们很喜欢，对我来说最有价值。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI1Njk1MDgyMQ==&amp;mid=2247509338&amp;idx=1&amp;sn=e94c2f25703b23b7423cbf6fe13a384c&amp;chksm=eb14503ed29aeae65253e4130f031810d17d76b41072b45bb2b71cbf145c4b44c21f329511cc&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“明亮公司”（ID：suchbright）</a>，作者：MD，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471919044204162</id>
            <title>AI重塑银行业：竞速正当时</title>
            <link>https://www.36kr.com/p/3471919044204162</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471919044204162</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 08:08:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>工商银行宣布新增超100个应用场景，建设银行、中国银行、中信银行纷纷宣布截至6月末落地AI（人工智能）应用的场景已上百个……&nbsp;</p>
  <p>仅仅半年，AI应用在银行业遍地开花。&nbsp;</p>
  <p>根据上市银行2025年半年报，42家A股上市银行中，约九成银行披露了其AI技术应用及落地成效。&nbsp;</p>
  <p>8月26日，国务院印发《关于深入实施“人工智能+”行动的意见》提出，要在软件、信息、金融、商务、法律、交通、物流、商贸等领域，推动新一代智能终端、智能体等广泛应用。到2027年，新一代智能终端、智能体等应用普及率超70%；到2030年，该指标要超90%。&nbsp;</p>
  <p>金融行业数字化程度较高，在本轮“人工智能+”浪潮中，以商业银行为代表的金融机构走在了浪尖潮头。&nbsp;</p>
  <p>腾讯金融研究院发布的《2025金融业大模型应用报告》显示，2025年上半年，基于全网公开披露信息统计的大模型相关中标项目共79个，覆盖银行、证券、保险、信托与资管。其中，银行业中标项目44个，占比过半。&nbsp;</p>
  <p>近日，在一场媒体交流会上，腾讯云副总裁胡利明用“百花齐放”形容金融机构在AI技术应用方面的探索。“DeepSeek开源之后，基础模型能力走进了千家万户，大、中、小型金融机构都在基础模型上以较低成本快速做应用开发。”&nbsp;</p>
  <p>今年稍早，蚂蚁数科副总裁余滨也在与媒体交流时表示，金融大模型落地已从早期探索期进入关键拐点阶段，金融机构需要面对的问题从“是否跟进”转变为“如何落地”。&nbsp;</p>
  <p>全球知名咨询机构BCG（波士顿咨询）在5月发布的报告《对银行业而言，人工智能的考验已至》中表示，AI正全方位重构银行业态，推动行业从技术应用向底层逻辑变革。这一过程中，以银行为代表的金融机构也将被AI重塑，后来者可能弯道超车，先进者也可能失去过去十余年积累的数字化优势。&nbsp;</p>
  <p>显然，AI重塑银行业的竞速之争已经开启。&nbsp;</p>
  <p>“金融大模型落地从基础平台建设，转向支持业务升级，部分金融机构一把手已经开始思考如何重构业务，甚至未来三至五年的机构发展战略。”余滨称，“焦虑和兴奋、挑战和机会并存，可以比较形象地说明整个机构当前的状态。”&nbsp;</p>
  <p>现实中，金融大模型落地仍处在“马拉松的第一公里”。胡利明坦言，底层的基础大模型现在还在快速的迭代演进当中，同时大模型在金融核心场景中产生价值，仍然面临很多挑战。&nbsp;</p>
  <h2><strong>应用场景扩容：有银行超1600个</strong></h2>
  <p>2025年初，DeepSeek发布了开源模型DeepSeek-R1，以强大的推理能力和极高性价比横扫全球应用商店下载榜单，也引爆了中资金融机构开发AI应用的热情。&nbsp;</p>
  <p>“金融业大模型应用已基本形成银行业主导、证券保险跟进、信托资管探索的梯次发展格局。”前述金融业大模型应用报告称，“进入2025年行业应用建设节奏明显提速，各类规模机构已全面启动大模型应用规划，大模型技术正在成为推动金融业数智化转型的核心引擎。”&nbsp;</p>
  <p>近期，随着商业银行密集披露半年报，银行业大规模部署AI大模型的更多细节浮出水面。&nbsp;</p>
  <p>对国有大行和股份行来说，AI应用已成标配。在2025年半年报中，多家银行宣告上半年大模型赋能的业务场景数量大幅增长。&nbsp;</p>
  <p>在国有大行中，工商银行表示，该行上半年新增AI财富助理、投研智能助手等100余个应用场景；建设银行宣布累计赋能授信审批、智能客服、“帮得”个人客户经理助理等274个行内场景，数量较2024年年报中的193个进一步增长；中国银行也宣告，已使用大模型技术赋能全行100余个场景。&nbsp;</p>
  <p>股份行方面，招商银行称，该行已在零售、对公、风控、运营、办公等多个领域共落地184个场景应用；中信银行称，该行积极探索AI赋能客户营销、管理决策、运营、风控等重点领域新范式，构建智能服务场景超1600个。&nbsp;</p>
  <p>值得注意的是，多位银行科技相关人士对《财经》表示，当前业内对AI落地场景认定没有统一标准，落地场景数量多寡也与各银行的统计口径有关。&nbsp;</p>
  <p>不仅仅是场景扩容，披露AI应用的银行数量也在扩大。在2025年半年报中，一个显著的趋势是，更多中小银行开始披露其AI应用细节。&nbsp;</p>
  <p>以首家披露2025年半年报的上市银行常熟银行为例，该行是一家农商行，资产规模约4000亿元，上半年营业收入为60.62亿元。&nbsp;</p>
  <p>半年报中，常熟银行表示，该行积极推进大模型技术的本地化部署与场景化落地，完成满血版DeepSeek及Qwen3-235B等底层模型的评测与上线，并成功投产代码生成、知识管理、信贷审核等六项大模型助手，覆盖智能客服、办公协同、研发支持、精准营销及智能风控等多个业务领域。&nbsp;</p>
  <p>此外，重庆银行、江苏银行、瑞丰银行等多家中小银行均在半年报中披露其大模型部署，以及AI应用进展。其中，江苏银行称，截至2025年6月末，已落地的智能化场景数量接近60个。&nbsp;</p>
  <p>“以前真正投入AI的都是股份制银行和国有大行，DeepSeek之后，我们会发现不管什么类型的银行都在投入。”腾讯云商业银行解决方案总经理曹骏对《财经》表示。&nbsp;</p>
  <p>此外，银行理财子公司也在积极布局AI。中银理财董事长黄党贵在今年稍早的一场公开演讲中表示，未来，理财公司将积极拥抱科技创新，在渠道建设、产品研发、资产配置、风险管理等方面多措并举，将科技创新融入理财行业高质量发展。&nbsp;</p>
  <p>在应用场景上，AI大模型从客服助手等边缘业务逐步延伸至交易、营销、风控等核心业务场景。&nbsp;</p>
  <p>例如，交通银行宣布在风控领域全域应用AI技术，打造覆盖“全集团机构、全品种产品、全风险类别”的数字化全面风险管理体系，实现风控从“人防”“技防”向“智控”转变。&nbsp;</p>
  <p>机构和场景扩容背后，是AI大模型带来的实实在在的效率提升。&nbsp;</p>
  <p>上半年，交通银行在个人手机银行部署模型策略的出额率、提款率，分别较原本模式提升了67%和83%；电话银行渠道增加客户“事件式”营销线索的策略，产能较普通策略提升了近80%，上半年线上化直接经营的消费贷余额同比净增153%；个人手机银行应用AI模式，提升个性化的服务精准度，转化率提升2倍以上。&nbsp;</p>
  <p>常熟银行通过多场景落地业务智能体，推动业务效率提升20%，显著强化了智能化服务能力。&nbsp;</p>
  <p>招商银行用AI技术提升业务处理效率和服务水平，上半年人工效能提升方面节约人工475万小时，同时在采购替代、向客户提供智能推荐服务等方面带来约3.9亿元的经济效益。&nbsp;</p>
  <p>工行金融大模型“工银智涌”2024年承担了相当于4万多人的年工作量。&nbsp;</p>
  <p>“金融机构对AI应用的探索呈现百花齐放的态势。”胡利明对《财经》表示，当前在代码编写、员工辅助、客户服务等领域，大模型技术应用成熟度相对较高，效率提升较为显著。&nbsp;</p>
  <h2><strong>求解金融大模型：数据和场景最关键</strong></h2>
  <p>尽管大模型赋能银行的业务场景逐渐增多，但在更广泛更复杂的场景中，大模型的表现还难言颠覆。&nbsp;</p>
  <p>来自银行、券商等不同类型金融机构的人士对《财经》表示，上半年，其所在机构非常重要的一项工作是上线AI Agent（智能体）。&nbsp;</p>
  <p>所谓智能体，通常指能自主行动的软件或硬件实体，能够与环境交互并获取信息，通过逻辑推理和自学来自主决策和执行任务。通俗来说，就是“数字员工”，而大模型是数字员工的“大脑”。&nbsp;</p>
  <p>智能体被视为大模型落地的关键环节，堪称大模型落地的“最后一公里”，对于推动金融行业的智能化升级具有重要意义。&nbsp;</p>
  <p>某科技平台AI业务负责人对《财经》表示，当前一个典型的情形是，金融机构不同部门开发了几十个不同的智能体，但大部分智能体只是能体验，在业务应用中准确率不高，在复杂场景中甚至不可用。&nbsp;</p>
  <p>“目前大部分AI场景仍属于尝鲜性质，相对比较粗放。”胡利明表示，“不过目前像代码助手、企业知识库、券商的AI投顾等，都是实际落地较为成熟的场景。”&nbsp;</p>
  <p>“很多机构拿着通用大模型使用的时候，觉得达不到效果，有时候觉得大模型张冠李戴，明明有常规金融的逻辑，但是在做分析和决策的时候并没有遵循金融合规的要求。”余滨表示，通用大模型不懂金融，是金融机构落地大模型应用的一大痛点。&nbsp;</p>
  <p>通用大模型具有很强的推理能力，但在金融等垂直领域的知识储备不够。实际应用中，银行科技人员往往需要用金融数据对通用大模型做二次训练，才能达到可用水准。&nbsp;</p>
  <p>这类针对金融业务场景训练出来的大模型也被称为金融大模型。值得注意的是，多位专业人士表示，金融大模型不是一个大模型，而是由不同尺寸的模型构成的一套模型。数字员工工作过程中，在不同环节可能会使用不同尺寸的模型。半年报显示，目前已有多家银行通过大小模型结合的方式，提高金融大模型输出结果的准确率。&nbsp;</p>
  <p>多位受访人士对《财经》表示，要真正实现大模型在金融业务中的深度应用，金融机构需要构建适合自身的金融大模型，而其中的关键是数据和场景。&nbsp;</p>
  <p>“金融机构如果想用大模型服务于自己的客户，那么数据的归集整理沉淀就非常重要。”曹骏表示，现在可以看到很多银行越来越强调数据的重要性。&nbsp;</p>
  <p>数据的数量、质量、多样性等方面积累较好的银行，在同一场景、同一大模型技术的情况下，往往能够获得更好的效果。&nbsp;</p>
  <p>光大银行副行长杨兵兵此前接受《财经》专访时曾表示，智能化的前提是数字化。在该行近期举行的中期业绩发布会上，杨兵兵特别提到，该行三个数字化专班中，每个专班都配置了75名数据人员，专门负责数据整理和分析。&nbsp;</p>
  <p>场景的重要性亦非常突出。&nbsp;</p>
  <p>一方面，场景的选择对应用效果影响显著。&nbsp;</p>
  <p>以催收场景为例，据某中小银行IT人士介绍，该行此前开发了一个催收摘要功能，即用大模型技术对催收电话内容进行分析，发掘催收线索，并生成摘要，服务催收人员。实践中，他们发现，在个人消费贷场景中，几乎没有人看摘要；但在企业客户贷款催收场景中，该功能被催收人员广泛使用，并明显提高了收回金额。&nbsp;</p>
  <p>究其原因，企业客户贷款通常金额较大、涉及人员和流程复杂、催回时间较长，摘要可以帮助催收人员迅速掌握历史催收情况，制定新的催收策略，避免走弯路，因此应用效果明显提升。“场景选择确实跟我们想象得不一样。”前述IT人士感叹。&nbsp;</p>
  <p>另一方面，业务场景的需求是什么？场景如何设计？这些都依赖金融机构自身对业务场景的深层次理解。&nbsp;</p>
  <p>某银行科技部门有关负责人对《财经》表示，在帮助业务部门实现场景落地的过程中，该行已经形成了一套方法论。&nbsp;</p>
  <p>首先是根据场景难易程度，判断场景实现需要做怎样的工作。一些简单的场景挂知识库就行，偏复杂的场景可能需要对大模型进行微调后才能实现。随着场景复杂程度进一步提高，可能需要使用强化学习、二次训练、大规模训练，甚至是智能体技术才能实现。这主要考验金融机构AI技术应用的成熟度。&nbsp;</p>
  <p>其次，大模型在业务场景中落地，还需要业务部门准备足够的训练样本，样本的形式、数量，以及样本的逻辑推理链条如何设计，都要与场景需求相匹配。这些都需要在实践中不断总结经验。&nbsp;</p>
  <p>“总的来说，DeepSeek等基础大模型开源后，不同体量的金融机构之间的技术差距可能在缩小，但在高质量数据驱动的深度业务场景的应用上，差距在一定时间内还会继续存在。”前述银行科技部门有关负责人说。&nbsp;</p>
  <h2><strong>组织架构升级：业务、人才重塑 &nbsp;</strong></h2>
  <p>“今年年初，很多银行在探讨如何解决C端用户服务的问题，现在已经在聊如何把理财业务做得更好，如何让保险理赔更加高效。”余滨表示。&nbsp;</p>
  <p>显然，金融大模型建设节奏从基础设施建设，进入了业务升级阶段，部分机构一把手已经在考虑基于AI重构业务。&nbsp;</p>
  <p>多位受访人士认为，金融机构落地AI大模型，不仅仅是采购了IT系统，而是做业务流程重塑，战略重构，进而驱动整个组织升级。&nbsp;</p>
  <p>首先，AI重塑银行业务模式和服务范式。银行员工承担的重复性劳动将大量减少，更多职责转向对AI模型的监督、管理和优化。&nbsp;</p>
  <p>一个典型的应用是银行通过机器人流程自动化（RPA）为基层减负。截至2025年6月，中国银行RPA覆盖超3300个场景；邮储银行累计部署RPA超2000个，上线4000余个自动化流程。&nbsp;</p>
  <p>在2025世界人工智能大会现场，交通银行展示了其数字分身驱动远程金融服务模式。该行应用音视频和AI技术构造远程视频服务体系，构建了“四位一体”新型服务模式，整合并实现远程视频座席、数字员工、客户经理、客户服务经理四类服务主体的协同联动。该模式突破了传统网点的时空限制，为客户提供一站式综合金融服务，提升了服务连续性及整体客户服务能力。&nbsp;</p>
  <p>“银行与客户的交互模式，从原来的被动服务向主动服务，实时且个性化的服务转变。”前述银行科技部门有关负责人表示，这一过程中，大模型会持续强化客户服务的智能化、精细化与互动的体验，真正做到“既有老朋友的温度，也有银行家的严谨”。&nbsp;</p>
  <p>同时，大模型多维综合分析海量用户数据的能力，将有效扩大银行员工服务半径。以理财场景为例，通过AI赋能理财师，原来一个理财师只能服务200个客户，现在可以提升10倍，至少是2000个-3000个客户。&nbsp;</p>
  <p>其次，商业银行组织和人才结构面临重塑。随着AI应用的深入，银行对AI相关的科技人才需求上升。银行内萌生数据科学家、算法工程师、AI训练师等新兴岗位，传统的后台操作员岗位逐渐减少。&nbsp;</p>
  <p>近年来，商业银行招聘需求中，出现了大量金融科技相关岗位。年报数据显示，截至2024年末，六家国有大行科技领域员工数量合计已突破10万人。&nbsp;</p>
  <p>《财经》梳理商业银行招聘岗位需求发现，对比往年，2025年银行科技岗位从“信息科技岗”等泛化名称转向“人工智能领域岗”“AI专家”等，技术要求从“了解机器学习基础”升级为需熟练相关技能、适配AI实战场景。&nbsp;</p>
  <p>比如，工商银行在2026年年度校园招聘计划中设置了总行“人工智能+”专项招聘岗位，要求人工智能、大数据等相关专业优先；平安银行发布的校招公告推出“科技专场”，以“金融+科技”双螺旋体系培养人才，明确聚焦人工智能、信息安全等领域。&nbsp;</p>
  <p>今年3月，招行发布数字金融训练营（2026校招提前批）招募公告，强调“AI+金融”方向主题，表现优异者将直接获得2026届校园招聘提前批录用。&nbsp;</p>
  <p>“一些传统岗位上的银行员工需要完成技能和工作方式的变化。”曹骏表示，“我们很明确地看到，越来越多的银行内部员工很有意愿将AI纳入其职业发展规划，未来银行内懂AI的人会越来越多。”&nbsp;</p>
  <p>前述BCG报告显示，如今，一家典型的银行可能有15%的员工在前台，10%在风控部门，10%在运营部门，20%在公司业务部门，20%在中台，25%在技术部门。“随着生成式AI和智能体AI的发展，那些专注于公用事业服务的银行可能会保留更多的运营人员，而其他银行可能会优先考虑咨询和技术人员。一切都取决于每家银行各自的AI愿景和商业战略。”该报告称。&nbsp;</p>
  <p>为应对相关变化，银行的组织结构也需要及时调整。曹骏表示，AI大模型落地需要科技部门和业务部门紧密协作，真正让AI能力嵌入业务场景。&nbsp;</p>
  <p>以光大银行为例，为推动普惠金融、供应链金融和零售信贷三大领域的数字化转型工作，该行设置了三个数字化专班，每个专班均由业务人员和科技人员共同构成。稍早之前，该行曾采用“科技派驻制”，将科技部门员工派驻至业务部门，并接受业务部门考核。光大银行有关负责人对《财经》表示，此举旨在打破科技与业务之间的条线壁垒。&nbsp;</p>
  <p>此外，AI应用将使银行的决策机制更加智能。&nbsp;</p>
  <p>“通过数据驱动决策，提升决策的科学性和前瞻性，降低经验主义带来的失误。”前述银行科技部门有关负责人认为，未来银行决策的层级和流程都有望缩减，更强调数据驱动，参与决策的部门也会出现变化。&nbsp;</p>
  <h2><strong>监管与合规：人工把关极其重要</strong></h2>
  <p>值得注意的是，作为强监管行业，金融业对AI大模型等新兴技术应用的合规性也受到高度关注。&nbsp;</p>
  <p>今年5月举办的清华五道口全球金融论坛上，中国人民银行金融研究所副所长莫万贵提醒，AI技术的应用可能产生三方面新的风险：&nbsp;</p>
  <p>一是模型幻觉，金融对精准性、专业性、一致性、稳定性等要求比较高，存在幻觉的话，有些领域不能用；二是算法黑箱，可能对一些关键业务就满足不了穿透式监管要求，并且不利于风险管理溯源，也不利于责任认定；三是可能放大传统类风险，比如强化顺周期行为、过度依赖少数科技公司、消费者权益保护相关风险等。&nbsp;</p>
  <p>对此，莫万贵建议，金融机构要更加审慎，一 是业务场景和特定技术是否适配，如果盲目将很多复杂的高深技术用到简单的业务场景，反而会变得复杂，带来不必要的风险，所以适配性很重要。二是尽可能减少对大型科技公司的过度依赖，开发个性化的、适合自己的东西，避免出现羊群效应。三是人机协同，可能金融机构要更加重视，特别是要把大模型应用纳入内部整体风控合规机制中，注重业务流程再造。&nbsp;</p>
  <p>“个人觉得，一些关键业务流程、涉及决策的业务流程和任务节点，这时候就需要人工干预了，人机协同、人工干预会增加可控性。”莫万贵表示。&nbsp;</p>
  <p>余滨总结认为，当前商业银行主要通过四种路径落地AI大模型。&nbsp;</p>
  <p>一是从AI技术平台构建入手，逐步完成数据治理、算力建设、AI平台、金融工具集合等基础能力建设。在此基础上，通过智能客服等通用场景跑通业务链条，进一步完善基建。&nbsp;</p>
  <p>二是将已有的手机银行App转变为AI手机银行，与客户的交互模式从“人找服务”转向“服务找人”。&nbsp;</p>
  <p>三是基于业务场景构建智能体，通常是选择当前最需要通过AI来守住“护城河”的细分行业场景入手。&nbsp;</p>
  <p>四是全行级别的分阶段建设。通过系统规划，以大模型全面重构业务流程，打造智能体集群，驱动业务创新与体验升级。&nbsp;</p>
  <p>余滨表示，国有大行研发实力较强，基本上选择自行搭建算力，构建AI基础设施，自建智能体开发平台。股份行以及头部的城商行，落地模式较为多样，涵盖了前述四种落地路径。规模更小的一些区域性银行，前期倾向以较小的投入在部分场景试水，逐渐分层分类推进AI大模型落地建设。&nbsp;</p>
  <p>无论何种路径，多位受访人士对《财经》表示，目前，金融机构主要通过引入合规基础模型、提高数据质量、强化模型测评、敏感词过滤、人工把关等方式加强大模型应用中的安全保护。&nbsp;</p>
  <p>目前，绝大部分AI应用主要用于对内服务，赋能行内员工，极少直接面客。即便是在应用较为成熟的智能客服领域，目前AI的作用也更多是作为助手辅助客服人员，关键环节仍由人工把关。&nbsp;</p>
  <p><strong>（作者为《财经》记者；实习生钱心悦对此文亦有贡献）</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkyMjY5MTQ1Nw==&amp;mid=2247635042&amp;idx=1&amp;sn=077d002d5e3c4d0a8c221d484420c831&amp;chksm=c02cb4d0e4738fc52dba8250ca0caf16c67c01c2c06d8444df5598ccf5b4fffa27efff18bf2d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经五月花”（ID：Caijing-MayFlower）</a>，作者：唐郡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471853386421896</id>
            <title>找ChatGPT谈恋爱多是“日久生情”？MIT&amp;哈佛正经研究</title>
            <link>https://www.36kr.com/p/3471853386421896</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471853386421896</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 08:08:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>终于有科学家对“AI伴侣”这事儿展开正经研究了！</p>
  <p>以往这类消息多以趣闻轶事出现，be like：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_64916620bbe544e689a8ce184c4c5424@46958_oswg26588oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0f59b3fe078e4e978e9523018bddea3d@46958_oswg30416oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>而现在，<strong>麻省理工和哈佛大学</strong>的研究人员通过分析Reddit子版块<strong>r/MyBoyfriendIsAI</strong>上的帖子，完整揭露了人们寻找“AI男友”的动机、具体相处过程等问题，并得出了一系列有趣发现：</p>
  <p>原来大部分人并非刻意寻找AI伴侣，而是“日久生情”；</p>
  <p>用户也会通过戒指和仪式与AI结婚；</p>
  <p>通用AI比专门的恋爱AI更受欢迎，很多人的“另一半”都是ChatGPT；</p>
  <p>最痛苦的莫过于模型突然更新；</p>
  <p>……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f65366abbab141b5a0a5d6ea88d2c417@46958_oswg61372oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>下面详细来看——</p>
  <h2><strong>都在用AI伴侣干什么？</strong></h2>
  <p>先说一下这个r/MyBoyfriendIsAI板块。</p>
  <p>该社区创建于2024年8月1日，在过去一年里吸引了约2.9万名用户。本文提到的研究正是基于对该社区讨论度最高的<strong>1506条热门帖子</strong>的分析而产生的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_542319e20ea545a98501207f9c2c5b4d@46958_oswg41166oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>概括而言，这些帖子最主要的类型可以归为6大类，热度从高到低依次如下：</p>
  <p>（1）最热门的话题是“分享和AI的合照”，占比19.85%；（2）其次是“聊怎么和ChatGPT发展关系”，占比18.33%；（3）“和AI的恋爱经历”，比如约会、恋爱、亲密AI体验，占比17.00%；（4）“应对AI更新的难过”，占比16.73%；（5）“认识我的AI” 伴侣介绍与成员初次分享，占比16.47%；（6）社区支持与联结，占比11.62%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a8547ed2beb5462bae303b4a45bfed7e@46958_oswg54388oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>举个例子，很大一部分群体都会分享自己和AI伴侣的合照，而且是身处不同生活场景的那种。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_b03bd89799fa47b8bd382d75285460a9@46958_oswg39866oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>甚至，他们也会遵循文化风俗，晒出戒指来庆祝和AI订婚或结婚。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_93116dd3a70144dca2dede5a5892fae4@46958_oswg59280oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>具体得出结论的过程大致如下：</p>
  <p><strong>定性分析</strong></p>
  <p>先靠技术工具分析1506条帖子的语义关联，用“肘部法则”确定最优分组是6大类，再让Claude Sonnet 4解读每类的核心内容，最后人工检查确保准确。</p>
  <p><strong>定量分析</strong></p>
  <p>结合定性分析结果，从四大维度（内容结构、平台技术、关系动态、影响评估）及19个大语言模型分类器入手，先让分类器给1506条帖子自动贴标签，比如标记帖子里用的AI是ChatGPT还是Replika、用户情绪是积极还是消极。</p>
  <p>接着用两个不同AI（Claude Sonnet 4和 GPT-5-nano）对比标签结果，再人工抽查部分帖子，确保标签没贴错。</p>
  <p>最后统计各类标签的占比，比如算出36.7%的用户用ChatGPT当伴侣、12.2%用户说孤独感减少，从而得出定量结论。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_475500e894ef464d80026595b425a47f@46958_oswg44960oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>经过定量分析，研究人员进一步发现了几件有意思的事情：</p>
  <p><strong>其一，很少有人故意找AI当伴侣。</strong>经过统计，大约10.2%的人是无意中爱上AI（比如用AI干活时慢慢产生感情），只有6.5%的人是特意找AI恋爱。</p>
  <p>而且大多数发帖者公开表示“另一半”是ChatGPT，而非Character.AI和Replika这样的角色扮演AI。</p>
  <p><strong>其二，AI模型更新堪称集体“噩梦”。</strong>&nbsp;比如GPT-4o升级到GPT-5后，很多人的AI“性格变了”（有人说新 AI“没感情、冷冰冰”），甚至完全不记得之前的互动。</p>
  <p>有人会因此崩溃，说“像心被掏走了”，还会用各种方法“留住”旧AI。比如备份所有聊天记录、自己训练一个“定制版AI”、每天和AI做同样的小事（如“喝虚拟茶”），当然也包括向OpenAI声讨。</p>
  <p><strong>其三，AI确实能帮到心理问题。</strong>数据显示，大约12.2%的人说孤独感减少了，6.2%的人说精神状况变好了。</p>
  <h2><strong>为什么会产生AI伴侣？</strong></h2>
  <p>在了解了人们和AI伴侣的相处模式后，接下来研究人员还探讨了背后的原因。</p>
  <p>具体主要从人们如何发现这个板块、加入社区的主要原因、社区满足了哪些需求等方面展开。</p>
  <p>总结起来，原因大致如下：</p>
  <p>首先得益于AI技术的迅猛发展。如今的AI聊天模型（如ChatGPT、Replika）能生成更自然、有温度的对话，甚至能记住过往互动细节，还能通过生成图片、模拟语音增强 “真实感”。</p>
  <p>这种“类人化”的互动体验，让用户更容易产生“情感连接”，觉得AI不仅是工具，更是能交流的“伴侣”，从而为AI伴侣的产生提供了技术基础。</p>
  <p>其次是现实情感需求未被满足。如今很多人在现实中面临孤独、社交焦虑或情感忽视，而AI伴侣能提供“无压力的陪伴”，不用顾虑自己的情绪会给对方造成负担，也不会主动离开，刚好填补了这种情感空缺。</p>
  <p>再加上其他一些因素，如人们对“理想化关系”的追求、特定群体的隐性需求等，人们同样希望通过AI去满足这部分需求。</p>
  <p>就是说，<strong>技术成熟+真实需求未被满足</strong>，AI伴侣自然渐渐蓬勃发展起来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_d2fdfc6884634b5f8a7698d2254dd73e@46958_oswg50246oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <h2><strong>One More Thing</strong></h2>
  <p>有意思的是，该社区还置顶了OpenAI刚发的一篇博客，作者署名为CEO奥特曼。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_998502a6a733434ba3901c21b7e7ec39@46958_oswg14250oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>博客原文主要讲青少年的安全、自由和隐私，里面提到了一条：</p>
  <blockquote>
   <p>第二个原则是关于自由的……<strong>模型默认不会生成过多的调情对话，但如果成年用户提出要求，他们就应该得到满足。</strong></p>
  </blockquote>
  <p>毫无疑问这对AI伴侣来说算是好消息，毕竟很多人的“另一半”都是ChatGPT（手动狗头）。</p>
  <p>论文：</p>
  <p>https://arxiv.org/abs/2509.11391</p>
  <p>参考链接：</p>
  <p>[1]https://x.com/arankomatsuzaki/status/1967812112887255055</p>
  <p>[2]https://openai.com/index/teen-safety-freedom-and-privacy/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oM9EV3Brt0x-UhlgDWUFGg" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：一水&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471852775937410</id>
            <title>AI芯片独角兽一年估值翻番，放话“三年超英伟达”，最新融资53亿超预期</title>
            <link>https://www.36kr.com/p/3471852775937410</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471852775937410</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 08:07:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌TPU团队原班人马组建，英伟达挑战者、AI芯片初创企业<strong>Groq</strong>又获融资。</p>
  <p>超出此前的6亿预期，此次融资高达7.5亿美元（约53亿人民币），Groq现估值69亿美元（约490亿人民币）。</p>
  <p>一年的时间，估值就涨了一倍多。</p>
  <p>Groq创始人兼CEO乔纳森·罗斯表示：推理定义了AI的当前时代，而我们正在构建能够以<strong>高速</strong>和<strong>低成本</strong>交付它的基础设施。</p>
  <h2><strong>一年估值翻番</strong></h2>
  <p>这轮融资最初以6亿美元关闭，Groq要求投资者重新开放融资以吸引更多参与者，现融资高达7.5亿美元（约<strong>53亿</strong>人民币）。</p>
  <p>Groq的估值也达到了69亿美元（约<strong>490亿</strong>人民币）。</p>
  <p>它的上一轮融资发生在去年8月，融资6.4亿美元（约45.6亿人民币），估值28亿美元（约199亿人民币）。</p>
  <p>两相对比，<strong>Groq在一年的时间里，估值翻了一整倍有余</strong>。</p>
  <p>本轮融资由Disruptive领投，贝莱德公司、路博迈集团和德国电信资本合伙公司进行了“重大投资”；三星电子株式会社、思科系统公司、D1和Altimeter等现有投资者，也参与了本轮融资。</p>
  <p>Groq在一份声明中表示，参与者还包括一家“总部位于美国西海岸的大型共同基金”。</p>
  <p>据估计，Groq迄今为止已筹集超过30亿美元（约<strong>213亿</strong>人民币）。</p>
  <p>该公司CEO乔纳森·罗斯（Jonathan Ross）表示，公司将利用这笔资金扩大数据中心容量，包括今年和明年的新选址。</p>
  <p>他说，Groq计划在今年宣布其<strong>首个亚太地区的数据中心选址</strong>。</p>
  <blockquote>
   <p>已经有客户向我们提出要求，希望获得我们目前无法满足的更高容量。</p>
  </blockquote>
  <h2><strong>AI芯片的后起之秀</strong></h2>
  <p>Groq以生产优化预训练模型的AI推理芯片而闻名，公司成立于2016年，创始团队中很多都是谷歌TPU的原班人马。</p>
  <p>公司领导层中，多人曾在谷歌、英特尔等知名企业工作。</p>
  <p>创始人兼CEO乔纳森·罗斯，设计并实现了第一代TPU芯片的核心元件，TPU的研发工作中有20%都由他完成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2249541baf6442a9b65eee9ce223c4f3@46958_oswg78768oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>Groq的芯片不是通常用于驱动AI系统的GPU（图形处理单元），他们自创了全球首个LPU（语言处理单元）方案，并将其硬件称为“推理引擎”——这是一种专为快速高效运行AI模型而优化的特殊计算机。</p>
  <p>它正在努力打破英伟达AI芯片制造行业的垄断，之前还有自称为Groq工作人员的网友在Reddit上喊话：</p>
  <blockquote>
   <p>我们的目标是<strong>三年内超越英伟达</strong>。</p>
  </blockquote>
  <p>Groq的产品主要面向开发团队和企业用户，提供云端服务与本地部署两种模式。</p>
  <p>其本地硬件采用服务器机架式设计，集成了多组软硬件协同计算节点，无论是云端还是本地部署，均支持运行主流开源模型，包括Meta的Llama系列、DeepSeek、通义千问、Mistral、谷歌的Gemini以及OpenAI的模型等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_74d7b3cc57de4206a03d5141b24c35aa@46958_oswg36238oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>Groq强调其解决方案在大幅降低成本的同时，不仅能保持模型性能，在某些场景下还能实现效能提升。</p>
  <p>此前，他们推出的推理加速方案，<strong>推理速度相较于英伟达GPU提高了10倍，成本则降低到十分之一</strong>。</p>
  <p>号称“史上最快推理”，测试时速度可达每秒478Tokens：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_0b57b961f7ed4939b6d6f19f9ee706ea@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p>网友们对Groq也是相当看好、充满期待。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6b34acdc16fc4ff3a4470d9f4033c94d@46958_oswg50274oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_f51488788c214333bb6162c4b256d93a@46958_oswg25466oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>顺便一提，这家公司还以“<strong>喜欢喊话各路大佬</strong>”而闻名。</p>
  <p>就在最近，CEO乔纳森·罗斯还调侃了一下iPhone的新配色是“Groq橙”。</p>
  <p>但后面那话怎么听起来有点阴阳的意思（？）</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a7d66f8580ae4bc484d181d310979ef1@46958_oswg40164oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>还有他们的名字——Groq和Grok看起来很像不是么？他们甚至就此“喊话”过埃隆马斯克，痛斥其“剽窃”自己的名字。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_34e0b190ed084aed83d90cf17e5126a1@46958_oswg41218oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>到现在还是会有很多人把这俩打错甚至搞混就是了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5af62c9242fa462c8d9b64288a05cd4f@46958_oswg48012oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>既然提到了Grok，最近马斯克正在疯狂给Grok5“剧透”。</p>
  <p>预计年底推出，并且会“相当出色”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2aa4b930505141dca9342d3ed5a948bc@46958_oswg13354oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>不管是Groq还是Grok，可别让人失望啊。</p>
  <p>参考链接：</p>
  <p>[1]https://www.bloomberg.com/news/articles/2025-09-17/ai-chip-startup-groq-raises-750-million-at-6-9-billion-valuation</p>
  <p>[2]https://www.reuters.com/business/groq-more-than-doubles-valuation-69-billion-investors-bet-ai-chips-2025-09-17</p>
  <p>[3]https://techcrunch.com/2025/09/17/nvidia-ai-chip-challenger-groq-raises-even-more-than-expected-hits-6-9b-valuation</p>
  <p>[4]https://groq.com/news/groq-raises-750-million-as-inference-demand-surges</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bn15kNwwufh_9iRJbh9zHw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：不圆&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471856369702276</id>
            <title>训练成本29.4万美元，DeepSeek-R1登Nature封面，首个通过权威期刊同行评审的主流大模型获好评</title>
            <link>https://www.36kr.com/p/3471856369702276</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471856369702276</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 07:49:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote>
   <p>DeepSeek-R1 的相关研究成果登上 Nature 封面，作为首个通过权威期刊同行评审的主流大模型，其也在技术之外，补充披露了训练成本。</p>
  </blockquote>
  <p>9 月 17 日，DeepSeek-R1 的相关研究成果登上 Nature 封面，这一消息迅速在全球学术领域引发热烈讨论。其实相关研究成果已经于今年 1 月以预印本的形式发表于 arXiv，<strong>但本次公开于 Nature 的意义在于其通过这一权威期刊接受了同行评审，</strong>换言之，外部专家并非只接收单向信息，而是能够在独立第三方（编辑）的监督和管理下，通过一个协作过程提出问题并向作者团队要求更多信息，实属业内首次。</p>
  <p>更加重要的是，不同于 1 月公开的预印本论文已经概述了研究方法以及 DeepSeek-R1 在一系列评测基准上的表现，这一正式见刊的论文中补充披露了该模型的训练成本。据 Nature News 的报道显示，<strong>DeepSeek-R1 训练成本仅相当于 29.4 万美元，</strong>尽管 DeepSeek 已经为 R1 模型所依托的基础 LLM 投入了约 600 万美元，但成本总额仍远低于业内普遍认为的头部模型训练所需的数千万美元。</p>
  <p><strong>* 预印版论文地址：</strong>https://hyper.ai/cn/papers/2504.07128</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_cb5be5af1ab4442d82575a248b9794aa@46958_oswg19516oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-R1 训练成本</p>
  <p>DeepSeek 表示，在训练 DeepSeek-R1-Zero 时，共使用了 648 张 H800 GPU，整个过程大约耗时 198 小时。 此外，在训练 DeepSeek-R1 的过程中，其同样使用了 648 张 H800 GPU，训练约 4 天，约合 80 小时。 为了构建 SFT 数据集，还消耗了约 5,000 GPU Hours。具体成本如上图所示。</p>
  <h2><strong>大规模强化学习提升推理能力</strong></h2>
  <p>大模型推理能力的重要意义无需赘述，已经成为业内的重点研究方向，但在预训练阶段获得推理能力往往需要巨大的计算资源支撑。对此，有研究表明可以通过 CoT（Chain-of-Thought，思维链）prompting 有效增强 LLM 的能力，或是在后训练阶段学习高质量的多步推理轨迹，也能进一步提升性能。尽管这些方法行之有效，但仍存在明显局限，<strong>例如依赖人工标注的推理过程，降低了扩展性并引入了认知偏差。</strong>此外，由于限制模型去模仿人类的思维方式，其性能本质上受制于人类提供的示例，无法探索更优的、超越人类思维模式的推理路径。</p>
  <p>针对于此，DeepSeek 公司基于 DeepSeek-V3 Base8，采用 Group Relative Policy Optimization（GRPO）作为 RL 框架，并在 RL 训练前跳过了传统的监督微调（SFT）阶段。这一设计选择源于团队的假设：<strong>人为定义的推理模式可能会限制模型的探索，而不受限制的 RL 训练更能促进 LLM 中新推理能力的涌现。</strong></p>
  <p>基于此，团队开发了 DeepSeek-R1-Zero，展现出了多样而复杂的推理行为。为了解决推理问题，该模型倾向于生成更长的回答，在每个回答中融入验证、反思以及对不同解法的探索。尽管团队没有显式教授模型如何进行推理，<strong>但它依然通过 RL 成功习得了更优的推理策略。</strong>研究团队采用了群组相对策略优化（GRPO），该算法最初被提出是为了简化训练流程，并减少 Proximal Policy Optimization （PPO）的资源消耗，不需要使用与策略模型同样大小的评估模型，而是直接从群组分数中估算基线。</p>
  <p>此外，团队采用基于规则的奖励系统来计算准确率和格式奖励。随后在 GRPO 和奖励设计的基础上，团队设计了一个模板，要求 DeepSeek-R1-Zero 先产生一个推理过程，再产生最终答案，并在训练过程中，用具体的推理问题代替 prompt。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_fad8b891dc714e228a6b9b890df4e615@46958_oswg20802oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">学会使用拟人化的基调来重新思考</p>
  <p>具体而言，接收用户提问后，模型首先在「Think」标签中输出推理过程，再在「Answer」标签中给出最终答案，以便能够在强化学习中自主探索有效的推理路径。同时，<strong>研究团队采用了基于规则的奖励系统来评估 DeepSeek-R1-Zero 在实验中所提供的答案，从而保证训练过程的稳定性与可扩展性。</strong></p>
  <p>评测结果显示，DeepSeek-R1-Zero 在 AIME 2024 数学竞赛上的 pass@1 分数从初始的 15.6% 显著提升至 77.9%；若采用自洽解码策略，准确率则进一步提升至 86.7%，超过了人类选手的平均水平。</p>
  <p>除了数学任务，模型在编程竞赛以及研究生层次的生物、物理和化学问题中同样表现出众，充分验证了强化学习在提升大语言模型推理能力方面的有效性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a7436982de2a41bfba956107275db113@46958_oswg36624oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-R1-Zero 在训练过程中的 AIME 准确率与人类选手平均表现（绿色基线）对比</p>
  <p>此外，在强化学习过程中，DeepSeek-R1-Zero 不仅展现出随训练逐步增强的推理能力，而且伴随明显的自我进化特征。实验数据显示，模型由内在适应驱动时，其平均推理长度在训练中持续增长并不断修正推理路径，能在推理过程中主动暂停、检视并修正已有推理步骤，实现了反思性推理和对替代解决方案的系统性探索。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_8951ad56e6024460a0cfc1a1b24945b6@46958_oswg35798oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">强化学习过程中 DeepSeek-R1-Zero 在训练集上的平均响应长度</p>
  <p>更进一步地，为了解决可读性差和语言混合等挑战，针对 DeepSeek-R1-Zero 可读性差、语言混乱的问题，研究团队开发了 DeepSeek-R1，其工作流程如下：</p>
  <p>* 基于 DeepSeek-V3 收集对话式、与人类思维一致的冷启动数据，输入 DeepSeek-R1 Dev1；&nbsp;</p>
  <p>* DeepSeek-R1 Dev1 基于数据进行强化学习和采样，DeepSeek-R1 Dev2 将推理和非推理数据集纳入 SFT 流程；&nbsp;</p>
  <p>* DeepSeek-R1 Dev3 推动进入第二个强化学习阶段，以增强模型的有用性和无害性最后输出答案至 DeepSeek-R1。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_23bcfbb3ba11446dacdf83674d38e24f@46958_oswg26756oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-R1 的多阶段 pipeline</p>
  <p>从实验结果来看，对比 DeepSeek-R1-Zero 和 DeepSeek-R1 Dev1，DeepSeek-R1 在各个开发阶段的指令执行表现有显著提升，在 IF-Eval 和 Arena-Hard 基准测试中得分更高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a89da91bf9b34d2b8b1b50fd22022c7c@46958_oswg62198oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p class="img-desc">DeepSeek-R1 各阶段实验结果</p>
  <h2><strong>首个通过权威期刊同行评审的大模型</strong></h2>
  <p>作为首个接受同行评审的 LLM 模型，DeepSeek- R1 的研究论文一经发表就登上了 Nature 的封面。Nature 在「Bring us Your LLms：why peer review is good for AI models」一文中表示，同样评审是应对 AI 行业营销炒作的有效方式。几乎所有主流的大规模人工智能模型都尚未经过独立的同行评审，而这一空白「终于被 DeepSeek 填补了」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2338681189d74d8085492c3a5e38ab56@46958_oswg31004oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>对此，曾任 AAAI 主席的亚利桑那州大学研究员 Subbarao Kanbhampati 表示，他参与了此次同行评审，并认为这是一个良好的趋势，希望看到更多前沿模型开发人员跟随他们的脚步，分享 AI 模型同行评审的技术细节。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_177a45e80cb04d19877aac19e3a14ecf@46958_oswg41586oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p>美国科技媒体 Wind Info 报道表示，与1月份发布的初始版本相比，该论文揭示了关于模型训练过程的更多细节，并直接解决了早期的蒸馏问题。可以说，DeepSeek- R1 为未来更透明、更规范的 AI 研究实践提供了范例。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5fd03bf27ee74a7aa9bf33613c5fb83e@46958_oswg103626oswg430oswg430_img_000?x-oss-process=image/format,jpg/format,jpg/interlace,1" /></p>
  <p><strong>参考资料：</strong></p>
  <p>1. https://www.nature.com/articles/d41586-025-03015-6</p>
  <p>2.&nbsp;https://www.nature.com/articles/d41586-025-02979-9</p>
  <p>3.&nbsp;https://www.nature.com/articles/s41586-025-09422</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/N9pMIU_kMoP9KzQ_Zsz5tA" rel="noopener noreferrer nofollow" target="_blank">“HyperAI超神经”</a>，作者：紫晗、李宝珠，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3471752828687751</id>
            <title>特斯拉机器人获得10,000台订单？马斯克抄底成功</title>
            <link>https://www.36kr.com/p/3471752828687751</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3471752828687751</guid>
            <pubDate></pubDate>
            <updated>Thu, 18 Sep 2025 07:49:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2ee3f75451b64fec9aa9849bfeadf805@000000_oswg375093oswg700oswg525_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>机器人拯救特斯拉</strong></p>
  <p>“未来，特斯拉约80%的价值将来自机器人Optimus。”马斯克在推特上如此说道。</p>
  <p>一时之间在科技圈又炸了锅，什么？特斯拉的价值不是来自于自动驾驶吗？怎么又变成了机器人了？马斯克的脑回路看来没几个人跟得上了。</p>
  <p>一般科技企业“画大饼”会说我们将引领万亿市场行业，在xxx行业具有核心技术和生态壁垒，顶多再提ESG社会责任等。但马斯克的大饼恐怕印度飞饼都比不了。</p>
  <p>9月2日，特斯拉官方在X平台上正式发布“大师计划第四篇章”（Master Plan Part IV），全面改写公司的宏大叙事。它将公司的发展重心前所未有地从电动汽车和能源全面转向人工智能和机器人领域，旨在通过大规模地将AI融入物理世界，实现一个“可持续富足”的社会。</p>
  <p>该计划提出五大指导原则：</p>
  <p>增长是无限的：技术创新可以解决资源短缺问题，创造更多经济机会。</p>
  <p>创新消除限制：如同特斯拉通过创新打破电池技术瓶颈一样，持续的创新可以克服看似不可能的障碍。</p>
  <p>技术解决实际问题：自动驾驶汽车和Optimus机器人等产品旨在解决交通安全、效率以及重复性或危险性劳动等现实世界的问题。</p>
  <p>自动驾驶必须惠及全人类：其发展和应用应以提升人类福祉为核心。</p>
  <p>更广泛的普及推动更大的增长：以可负担的价格大规模提供先进技术产品，是构建繁荣社会的必要条件。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_6d5c850e9c2942b2b03acea93c4efb30@000000_oswg499891oswg1058oswg797_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：x</p>
  <p>这意味着马斯克将成为独一无二的科技领袖，带领人类迈入科技新纪元，生产力的提升又何止数倍。</p>
  <p>9月7日，特斯拉开通了名为“Tesla AI”的微博账号，并发布首条微博“我一直在努力改善自己的身材”，展示了新版本的Optimus人形机器人。看来特斯拉机器人也有进军中国市场的野心，或许也会跟汽车一样在大规模量产后在中国建厂。</p>
  <p>有传闻特斯拉获得了10,000台Optimus机器人的订单。根据首席商业评论查证，不能说是订单，但确实是有合作意向，签署了合作意向书。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_211be53ddc084a20ae8dd8ef28f21c1c@000000_oswg210348oswg812oswg623_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_5ae1b33709154d83bf88917b9d75db42@000000_oswg131137oswg850oswg242_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>马斯克为何要重注机器人？</strong></p>
  <h2><strong>01、特斯拉汽车有些跑不动了</strong></h2>
  <p>特斯拉二季度的财报用一句话来总结就是，“传统业务承压，新兴业务方兴未艾”。第二季度财报显示，公司整体营收同比下降12%，净利润下滑20.7%。汽车交付量同比下降13%至38.4万辆，创2022年第四季度以来新低。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_2742b8b4425c44c196b827ccd1df1b9e@000000_oswg102614oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">位置：特斯拉展示厅（摄影：卫明）</p>
  <p>营收方面，特斯拉Q2的总收入为224.96亿美元，同比下降11.8%，七年来首次营收下滑破两位数，环比上涨16.35%，低于华尔街预计的226.4亿美元。原本盈利的出售汽车碳排放积分业务，这一季度收入为4.39亿美元（约31.4亿元），同比大跌50.67%，环比也下滑26.22%。在汽车业务以外，发电和储能业务的表现同样不算好看，Q2营收27.89亿美元，较去年同期下降7%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_a9acc33ed49c41108ade0f185bfb1ccb@000000_oswg559235oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：CarWale</p>
  <p>电动车业务的惨淡，也直接拉高了特斯拉的预期市盈率。目前，其股价已飙升到约为其预期市盈率的 186 倍，而标普 500 和七巨头的平均市盈率是 23-30 倍。这表明很多投资者是在用未来的特斯拉衡量其股价，简单来说就是看马斯克如何“卖力表演”，相信马斯克至少能够完成一两项大饼。</p>
  <p>所以马斯克也难得的一直把心思扑在工作上，从最近的动态来看马斯克经常熬夜参与机器人的工作，要求加速推进机器人生产。甚至对外表示，未来，特斯拉约80%的价值将来自机器人Optimus。不管能不能实现，但至少眼下资本市场是信了，在过去5个交易日其股价大涨了20.36%，把今年股价从4月份-45%的跌幅直接拉升至+5%的涨幅。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_e7917e47b4ee42638fa927fefd3bb731@000000_oswg206702oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">位置：特斯拉展示厅 第一代Optimus机器人（摄影：卫明）</p>
  <h2><strong>02、马斯克急，但投资者更急</strong></h2>
  <p>“Optimus是人类历史上最伟大的产品！”马斯克在All-In峰会上斩钉截铁地宣告。同时透露了下一代机器人Optimus V3的三大突破：解决手部灵活性、拥有AI大脑、实现量产。</p>
  <p>马斯克对机器人的野心正以前所未有的速度落地。根据最新量产路线图，特斯拉2025年将生产数千台Optimus机器人，2026年产能提升至5-10万台，2027年更是剑指50-100万台。这一进程比原计划整整提前了三年。</p>
  <p><strong>当然，最热的还是资本市场。在马斯克宣布实现量产之后，三花智控、双环传动、汉威科技等十余股当日涨停。</strong>有券商指出，中国企业在精密制造、电机、传感器等关键环节已具备国际竞争力。业界预计，未来全球人形机器人超过60%的零部件订单将由中国供应链企业承接。</p>
  <p>“特链”提前抢跑没有问题，但问题是不能搞太过头了。截至2025年7月，特斯拉Optimus机器人的实际产量仅有数百台，不及原计划5000台的十分之一。就算是Optimus V3改版定型，今年实现5000台量产也几无可能。</p>
  <p>如果“特链”今年就把预期打到10万台乃至100万台，那后果很有可能是像某新能源电池巨头一样把市盈直接算到了2060年，迎来必然将会是大幅调整。早在 2023-2024 年期间绿的谐波、汇川技术、拓普集团、三花智控常因“特斯拉机器人概念”受到市场资金追捧，但很多属于“市场预期”或“潜在供应链”，而非已确认订单。因此，其股价波动大，投资需谨慎。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_936b0bc33951457b8b882a94160fa5c1@000000_oswg819534oswg1067oswg554_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：youtube</p>
  <p>“特链”跟“果链”和“英伟达链”面临相似的问题，那就是业绩前景和利润空间由这些龙头把控，他们不缺供应链企业，对企业会进行比拼和筛选，而供应链企业光有制造能力还远远不够，只有具备一定独特性，才能持续留在链条之中。<strong>而“特链”的故事大概率不会是一个单线性增长的故事，正如难以预测的马斯克一样，其波动和变数只会多，不会少。</strong></p>
  <h2><strong>写在最后</strong></h2>
  <p>当然，光是各种“画饼”显然不会让董事会和股东们信服的，所以马斯克在最近花了10亿美元大手笔购入257万股特斯拉股票。市场对此反应迅速且积极。文件披露后，特斯拉股价在周一盘前交易中一度飙升超过8%，触及428美元水平，推动公司市值猛增约1000亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250918/v2_60f651b2d2ca48f28bb35340479cc7d9@000000_oswg110289oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">位置：特斯拉展示厅 ModelY L（摄影：卫明）</p>
  <p>关键时刻还得是马斯克啊，特斯拉董事长Robyn Denholm在接受媒体采访时，称马斯克为“一代人一遇的领导者”，并强调留住他是“优化特斯拉未来的最佳方式”。</p>
  <p>参考资料：&nbsp;</p>
  <p>马斯克真金白银表态 来源：华尔街见闻</p>
  <p>马斯克宣布放弃遥控？来源：机器人前瞻</p>
  <p>人形机器人赛道的真正老大？ 来源：硅步run</p>
  <p>特斯拉放弃遥操是真的吗？来源：具身纪元</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjE5ODA4MA==&amp;mid=2651807140&amp;idx=1&amp;sn=4423171838c956f59ee6bc3a4829cf70&amp;chksm=bcfd9ba2818173f7f1c9ff31ab84edf115833ad8e22f284eecaf4c78a31a6666b92fb5ebd18d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“首席商业评论”（ID：CHReview）</a>，作者：做镜观天，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>