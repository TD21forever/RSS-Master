<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3613514298770690</id>
            <title>孙正义女儿走到台前</title>
            <link>https://www.36kr.com/p/3613514298770690</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613514298770690</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 08:39:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>孙正义女儿意外爆红。</p>
  <p>本周，日本知名独角兽公司Spiber发布一份公告，让软银集团掌门人孙正义的女儿走到台前。</p>
  <p>川名麻耶，刚好出生于软银诞生那年，早年曾在高盛日本任职，也做过几年家庭主妇，但从未有过在软银任职的经历。她的父亲孙正义，全球创投圈都并不陌生，这几年经历大起大落，今年重回日本首富。</p>
  <p>虽然孙正义放话，软银的接班人不会由血缘来决定。但这次川名麻耶之所以引发轰动，或多或少是击中当下创投行业的交班话题。</p>
  <h2><strong>孙正义女儿现身创投圈</strong></h2>
  <p>根据公告，Spiber已与川名麻耶（Maya Kawana）签署业务支持相关协议。待协议生效前提条件满足后，川名麻耶将于2026上半年开展支持工作，发挥业务协同效应。</p>
  <p>交易方的履历赫然写着：<strong>川名麻耶是“孙正义的第一个孩子”（Born as the eldest child of Masayoshi Son）。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_64326e35aa2448ed9bfb323338cb9848@000000_oswg441254oswg1000oswg755_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>“我的参与不以IPO或并购为目标，而是要建立真正具有全球竞争力的生物科技企业。”川名麻耶在公告中表示。</p>
  <p>创立于2007年，Spiber利用蛛丝蛋白量产生物纤维，产品宣称可替代传统涤纶对石油的依赖。作为日本少数几家独角兽企业之一，当前估值超过12亿美元。</p>
  <p>川名麻耶指出，公司虽然拥有极高的技术开发能力，但在商业化与社会应用上仍面临挑战。她表示，未来将通过调整生产体制、优化经营资源分配及销售战略，帮助企业实现“具备经济可持续性的增长”。</p>
  <p>过去几十年里，孙正义几乎从不公开谈论家庭。但这次女儿的亮相引发不小的轰动。</p>
  <p>川名麻耶出生于1981年。彼时孙正义刚从美国回到日本，软银还只是一家刚起步的软件销售公司，与今天的投资帝国相距甚远。她的童年见证了父亲的白手起家。</p>
  <p>2000年，川名麻耶前往日本名校庆应义塾大学修习经济学，大学期间曾担任网球社团代表，性格开朗。毕业后加入高盛的投资银行部，负责企业融资和并购咨询。</p>
  <p>此后，川名麻耶有过一段长达数年的全职主妇生活。直至2019年，她设立品牌咨询公司BOLD株式会社，目标是“把时尚产业带入新的时代”。</p>
  <p>回顾过往履历，令人意外的一点是，川名麻耶并未在软银集团担任任何职位。</p>
  <h2><strong>孙正义重回日本首富</strong></h2>
  <p>孙正义，历来为人津津乐道。他所执掌的软银风投帝国打法激进，曾让对手无所适从。</p>
  <p>最为轰动的案例莫过于雅虎和阿里巴巴。1999年，孙正义在马云仅用6分钟的演示后，便拍板向当时尚无营收的阿里巴巴投资数千万美元，成为全球风投史上最成功的案例之一。</p>
  <p>然而，故事并非永远如此顺利。WeWork、OYO、Uber......一个个独角兽起高楼而后崩塌，给孙正义带来了一系列麻烦。犹记得2022年8月，软银录得公司成立以来的最大亏损，“上市股和未上市股接近全军覆没”。</p>
  <p>直到2023年，软银控股的芯片设计公司ARM在纳斯达克上市，市值一度涨至1900亿美元，成为软银重返巅峰的支点。此后软银调转船舵，2025—2026财年，愿景基金部门交出了一份漂亮的收益答卷。</p>
  <p>最新一幕是截止9月底的中期财报，软银净利润达到2.924万亿日元，同比激增2.9倍，创下日本企业史上最高半年度利润纪录；三季度愿景基金投资收益达3.5361万亿日元，上年同期仅为6103亿日元。</p>
  <p>其中，约三分之二的收益来自OpenAI。过去一年，孙正义已通过愿景基金2号向OpenAI投资了97亿美元，5000亿美元的“星际之门”（Stargate）计划也在筹备当中。</p>
  <p><strong>“我是哭着卖掉英伟达股票的。”</strong>孙正义曾如此表示。为了筹措资金加注OpenAI，软银在今年10月卖掉了约9000万股英伟达股份，套现约58亿美元。</p>
  <p>悄然间，“大魔王”又回来了。今年以来，软银集团市值多次刷新历史新高，一度达到约38万亿日元。在最新发布的彭博亿万富豪指数中，孙正义以551亿美元的净资产重回日本首富宝座。</p>
  <h2><strong>创投圈的交棒时刻</strong></h2>
  <p>女儿亮相，外界总容易联想到软银集团的接班问题。不过孙正义已多次强调：“软银不是家族企业，未来的继承由AI与专业经理人决定，而不是血缘。”</p>
  <p>不知不觉间，我们看到昔日指点江山的大佬们要开始面对交棒。</p>
  <p>今年5月，94岁的巴菲特在2025年股东大会上平静交棒，选择了历练25年的阿贝尔接班。放眼创投行业，接班传承历来备受瞩目——‌华平投资‌在2024年4月迎来‌Jeffrey Perlman‌作为第三代掌门人；Sequoia Capital（红杉资本）掌舵人经历更迭……</p>
  <p>我们把视野拉回到国内。一年前，启明创投内部制定一份“管理团队传承规划”：拟以未来十年之期，实现管理团队交接班。更早一些，创立真格基金的徐小平也逐渐淡出，方爱之走上台前。</p>
  <p>这一幕在本土创投机构同样迫切。</p>
  <p>上周深圳创投迎来25周年纪念日，当地本土创投掌门人几乎悉数到场。走过了四分之一个世纪，那些我们熟悉的创投大佬年纪渐长，交棒问题不得不摆到桌上。</p>
  <p>今年，一家头部本土VC合伙人在内部低调宣布退休，圈子里流传着其接下来的打算：“看书旅游，陪陪孩子，把时间花在自己感兴趣的事情上。”</p>
  <p><strong>创投圈基本没有“子承父业”一说</strong>，更多时候，创始人愿意花时间培养内部成长起来的合伙人。这几年，LP几乎都会聊起关于接班的担忧。因此，投资机构内部开始重视团队建设，着力培养年轻投资骨干。</p>
  <p>相比其他行业，创投更需要拥抱新生事物，永葆好奇心。</p>
  <p>退休切入渐进模式，正如一位创投大佬说，“我喜欢踢足球，年轻时踢前锋，现在踢中锋，未来会把机会留给年轻人。”</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247707757&amp;idx=1&amp;sn=fc5bc0226b14bd45f6a5e7a93c9efe8d&amp;chksm=edc9ee4089c28dd677d86f62cee0b0d56246aa483eea8271aa6065b9a4854027abba6218facb&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：余梦莹 杨文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613474751775750</id>
            <title>预估3万亿，特斯拉用AI攥住美股的话语权</title>
            <link>https://www.36kr.com/p/3613474751775750</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613474751775750</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 08:10:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当韦德布什分析师在2025年年末将特斯拉的牛市目标价推向3万亿美元市值的门槛时，华尔街的空气中弥漫着一种既贪婪又警惕的复杂气氛。这背后的逻辑不再是钢铁与电池的堆叠，而是硅基智能对传统制造业估值体系的绞杀。</p>
  <p>如果仅从汽车制造商的视角审视，特斯拉当下的市盈率不仅昂贵，简直到了荒谬的程度；但若将其置于“AI与机器人超级周期”的叙事框架中，那个看似遥不可及的“3万亿”数字，似乎又成了通往未来的入场券。</p>
  <p>这也正是马斯克最擅长的游戏，他成功地将一家年产数百万辆汽车的硬科技公司，通过FSD V13的迭代与Optimus机器人的量产预期，硬生生“格式化”为一家拥有物理实体的人工智能巨头。</p>
  <p><strong>华尔街为什么敢喊出“3万亿”？</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_b5938d65510d4f488c8c305fba4cde90@000000_oswg61676oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>要理解这3万亿美元的宏大叙事，首先必须拆解华尔街投行惯用的分类加总估值法模型。在摩根士丹利和Ark Invest的激进模型中，传统的汽车销售业务在总估值中的占比已经被压缩到了历史最低点，甚至不足30%。</p>
  <p>这个支撑特斯拉每日现金流的“现金牛”，在资本眼中已沦为一张单纯的入场券，其存在的意义仅仅是为那个庞大的AI训练集群提供源源不断的资金输血。为什么会发生这种视角的急剧转换？</p>
  <p>核心在于“边际成本”的魔法。传统汽车制造业的噩梦在于，每多卖出一辆车，随之而来的材料、物流、人工成本几乎是线性的，规模效应在达到一定体量后会遭遇剧烈的边际递减。即便是成本控制之王特斯拉，其汽车业务毛利率也一度在15%—18%的区间艰难博弈。</p>
  <p>然而，AI业务的逻辑截然不同。无论是FSD（完全自动驾驶）软件的订阅，还是未来Robotaxi（无人驾驶出租车）的调度网络，其复制成本几乎为零。一旦FSD跨越了L4级的技术奇点，特斯拉就不再是一家卖车的公司，而是一家卖“运力”和“时间”的SaaS平台。</p>
  <p>目前，FSD在北美和特定市场的渗透率虽然尚未达到爆发点，但其软件性质决定了高达80%的潜在毛利率。如果未来全球数千万辆特斯拉车队中有30%转化为FSD订阅用户，这将直接为财报注入数百亿美元的纯利润，且几乎不需要扩建新的冲压车间。</p>
  <p>其次是Robotaxi的平台经济学。在Ark Invest的模型中，Cybercab不仅仅是一款没有方向盘的车，它是切入这一市场的利刃。分析师们激进地预测，Robotaxi业务的每英里成本将低于0.2美元，远低于Uber或Lyft的运营成本。</p>
  <p>这种成本优势更将赋予特斯拉类似苹果App Store般的定价权，不仅赚取运费，还可能抽取平台佣金。</p>
  <p>而且在AI算力需求爆炸的2025年，数据中心对储能的需求呈指数级增长。特斯拉的Megapack业务在2025年Q3财报中表现出的惊人增速，让市场意识到这不仅是汽车的附属品，而是未来电力基建的核心拼图。</p>
  <p>但是这种估值逻辑的危险之处在于，它完全建立在“完美执行”的假设之上。它假设了端到端模型不会遇到无法逾越的数据墙，假设了监管机构会对取消方向盘的车辆大开绿灯。这是一场基于未来的透支，但对于渴望增长的美股市场而言，这种透支恰恰是最诱人的毒药。</p>
  <p><strong>FSD V13的算力“暴力美学”</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_8308742ca9ea490a98e5c4c7f3692ef7@000000_oswg104055oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果说估值模型是华尔街的数字游戏，那么FSD V13及其背后的算力军备竞赛，则是特斯拉在硅谷打响的一场硬核战争。2025年，当FSD V13.2正式向AI4硬件用户大规模推送时，行业内关于“规则代码”与“神经网络”的争论实际上已经结束了。</p>
  <p>特斯拉在FSD V12时期引入的“端到端”神经网络，彻底改变了自动驾驶的技术栈。在传统的自动驾驶开发中，感知、预测、规划、控制是分立的模块，由数十万行C++代码人为定义的规则串联。这种模式的弊端在于，工程师无法穷尽物理世界中所有的“长尾场景”。</p>
  <p>而特斯拉的“端到端”策略，将数百万个视频片段喂给巨大的Transformer模型，让AI直接学习人类司机的驾驶直觉。看到什么图像，输出什么转向和加速指令，中间不再有人类编写的“如果－那么”规则。</p>
  <p>到了V13版本，这种“暴力”被推向了新的高度。根据技术拆解，FSD V13的参数量和训练算力需求较V12呈现指数级跃升。这不仅仅是软件的胜利，更是硬件的碾压。</p>
  <p>特斯拉在得克萨斯州和纽约超级计算中心部署的Cortex集群，装备了数万颗H100/H200 GPU以及自研的Dojo芯片，将成为当今地球上最庞大的AI训练基础设施之一。</p>
  <p>这种“算力霸权”构建了两道极深的护城河。当Waymo还在为数千辆Robotaxi的运营区域精打细算时，特斯拉在全球奔跑的拥有FSD能力的车辆已超过600万辆。这600万个移动的数据采集节点，每天都在回传海量的边缘案例视频。</p>
  <p>这种量级的数据优势，使得特斯拉在训练端到端模型时，拥有了竞争对手无法企及的“教材”厚度。正如一位AI研究员所言：“在深度学习时代，数据就是新的石油，而特斯拉拥有最大的油田。”</p>
  <p>而且随着Hardware 4.0硬件的全面普及和对HW3.0算力瓶颈的逐渐显现，特斯拉展现出了科技公司特有的冷酷。尽管马斯克承诺会照顾老车主，但V13在AI4硬件上的表现显著优于AI3，这传递出一个明确信号。</p>
  <p>为了追求极致的AI性能，特斯拉愿意承受甚至牺牲一部分存量市场的体验。这种对算力摩尔定律的极致追逐，让传统车企望尘莫及，当大众和丰田还在为车机芯片的算力分配头疼时，特斯拉已经在思考如何将车载推理芯片与云端训练集群进行更高效的协同。</p>
  <p>然而，这种豪赌并非没有代价。端到端模型的“黑盒”特性是悬在特斯拉头顶的达摩克利斯之剑。与基于规则的系统不同，当端到端模型犯错时（例如在复杂的施工路段突然犹豫），工程师很难像修复Bug一样直接定位并修改某一行代码。</p>
  <p>他们必须通过针对性的数据清洗和重新训练来修正模型的权重。这意味着，解决一个Bug可能需要数周的算力燃烧。而且为了维持这种迭代速度，特斯拉必须持续投入数十亿美元购买GPU和扩建数据中心。</p>
  <p>这是一场没有终点的军备竞赛，只要资金链稍有断裂，或者模型收敛速度不如预期，整个“AI自动驾驶”的神话就可能瞬间崩塌。但在2025年的语境下，市场似乎更愿意相信算力能解决一切问题。</p>
  <p><strong>具身智能的终极战场</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_a6f8de15a21f49a29d8a561137eac8a6@000000_oswg180828oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果说FSD是特斯拉的软件灵魂，那么Optimus人形机器人和Cybercab Robotaxi就是特斯拉接管物理世界的躯壳。在2024年那场名为“We, Robot”的发布会上，马斯克展示的不仅仅是产品，更是一种通过AI重塑劳动力结构的野心。</p>
  <p>而且Optimus的进化速度确实令人咋舌。从最初步履蹒跚的原型机，到如今能够在工厂车间进行电池分拣，甚至完成精密装配任务的Gen 3版本，特斯拉向世界证明了FSD算法在机器人领域的复用性。</p>
  <p>这正是特斯拉最可怕的逻辑闭环。用来训练汽车自动驾驶的视觉网络，几乎可以无缝迁移到机器人的视觉导航中。虽然汽车是轮式机器人，Optimus是足式机器人，但是在底层AI逻辑上，它们是同构的。</p>
  <p>所以华尔街对此兴奋不已，全球劳动力市场规模远超数十万亿美元级别。如果Optimus能以2万美元的成本替代一名年薪5万美元的蓝领工人，其商业价值将远超汽车业务。高盛和摩根士丹利的分析师们已经在模型中为“机器人即服务”预留了巨大的增长空间。</p>
  <p>然而现实的物理屏障远比PPT上的曲线要坚硬得多。首先是监管对Robotaxi的“严防死守”。虽然技术上特斯拉可能已经准备好了。但法律并没有，在美国每一次涉及FSD的事故，都会引发监管机构的“釜底抽薪”式调查。</p>
  <p>加州DMV和公用事业委员会在批准无人驾驶商业化运营上的谨慎态度可以说是直接制约了Cybercab的落地速度。与此同时，在特斯拉寄予厚望的中国市场，虽然FSD入华的消息频传，但在数据出境、地图测绘资质以及高阶辅助驾驶的权责界定上，依然面临着复杂的合规博弈。</p>
  <p>更何况Optimus要实现马斯克所说的“数百万台”量产，其面临的制造难度不亚于重新发明一次汽车流水线。灵巧的执行器寿命、高密度电池的续航，以及在非结构化环境下的摔倒风险，每一个都是工程学上的大山。</p>
  <p>尽管特斯拉在努力压低执行器的成本，但要达到消费级电子产品的可靠性，仍尚需时日。而且中国在具身智能领域的爆发力开始显现。依托于强大的硬件供应链和快速迭代的创新生态，中国的机器人初创公司和科技巨头们正在以惊人的速度推出精品。</p>
  <p>无论是在四足机器人还是人形机器人领域，深圳和上海的实验室里正在发生的事情，让特斯拉不再是唯一的玩家。如果说在EV时代特斯拉是绝对的领跑者，那么在机器人时代，它面临的是一群同样饥渴且反应更快的狼群。</p>
  <p>尽管如此，特斯拉依然拥有一个杀手锏，将机器人视为一种“超复杂家电”进行大规模制造，恰好是特斯拉最擅长的领域。没有任何一家机器人公司拥有特斯拉这样大规模的超级工厂运作经验。</p>
  <p>这种“AI+制造”的双重基因，也是它在2025年依然能讲通“3万亿”故事的底气所在。马斯克在构建的不是一个个孤岛，是一个能源与信息的集合体。这一套连招，直接封死了后来者的路。</p>
  <p>亚马逊有云，但没有电。英伟达有卡，但没有网。只有特斯拉，把光子变成电子，把电子变成算力，最后把算力变成物理世界的动作。这个链条上的每一个环节，特斯拉都握着定价权。这就是为什么估值模型失效了。</p>
  <p>分析师试图用“市销率”去套，发现套不住。因为你没法给一个“能源+算力+制造+AI”的怪胎找对标。特斯拉是站在十字路口的那个唯一物种。3万亿？这可能只是起步价。拥有这三把钥匙的公司，实际上已经攥住了商业运作的操作系统。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI3MjExNTM5Mw==&amp;mid=2247502230&amp;idx=2&amp;sn=ae1fe8b3b75fd014a07e51acdd3469cb&amp;chksm=eaa9867428f091521bcab8152c76f5ba26c7ab59ff93608a128933855e7cf9931c5c8c9196d6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“道总有理”（ID：daotmt）</a>，作者：道总，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612160625001729</id>
            <title>如果不去爬雪山，你真的需要花2000块买「硬壳」吗？</title>
            <link>https://www.36kr.com/p/3612160625001729</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612160625001729</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 08:00:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果不去爬雪山，我们真的需要花2000块买一件专业级的硬壳冲锋衣吗？</p>
  <p>在当下的消费语境中，有一个常被忽视的误区。虽然大家习惯将“硬壳”和“软壳”统称为冲锋衣，但严格来说，只有具备全压胶工艺的“硬壳”，才能执行GB/T32614的国家标准。它们能上雪山、抗暴雨，但代价是面料硬、摩擦声响且透气性差。而主打日常通勤的“软壳”，也就是所谓的“城市款”，为了保证透气和柔软，工艺上本就没有执行这个严苛的国标，即便是几千元的国际大牌也不例外。</p>
  <p class="loading-entity">&amp;amp;nbsp;</p>
  <p>“城市冲锋衣面料会更好一点，但是做工会偏简单一点。户外冲锋衣做工更复杂，它需要一台价格上百万的流水线，再加上需要进行热封工艺，做工比较麻烦，这也是硬壳贵的原因。”做了这么多年冲锋衣，晋江“超斯特”工厂负责人王总很清楚其中的门道。</p>
  <p>作为源头工厂的经营者，他的店铺生产的200元热销款，单平台销量已达1.5万件。这类冲锋衣主要为城市需求服务，虽然舍弃了能防大到暴雨的全压胶工艺，但在面料投入上并未降级，甚至为了舒适度做了升级。按照这种标准，对于90%基本只在都市里待着的消费者来说，盲目追求硬壳，本质上是在为“性能过剩”和“品牌溢价”买单。</p>
  <p>既然明确了是“城市标准”，那么在200元的价格区间，到底能不能买到合格品质的软壳？</p>
  <p>对此，行业内至少有三个硬性指标可以参考：一是防水指数，建议达到5000mm以上，这样才能扛得住城市中的中雨；二是透湿指数，最好选5000g以上的，否则在早晚高峰挤地铁时，身体就像在“蒸桑拿”；三是面料支数，推荐75D以上的加密机织，唯有如此才能兼顾防风与耐磨。</p>
  <p>这些参数通常在商品详情页会有标注，如果没有，大家也可以直接询问客服。除了这些指标，王总还指出了一套源头工厂的肉眼鉴别法——</p>
  <p>首先看针脚密度，相比于市面上容易开线的大针脚“通货”，优质产品通常执行“3厘米16针”的严苛标准，以确保护具的耐用性与美观度；其次看品牌印记，为了方便下游商家随意贴牌，劣质通货通常会留白五金件和水洗标，而王总坚持在拉链、内标及背面反光条等细节处印制专属的品牌元素，以此与那些“万能公版货”划清界限。</p>
  <p>能够在200元的售价里堆足细节并保证利润，得益于晋江成熟的产业集群。在这里，所有的面料辅料都能在一小时车程内配齐。此外，30年坚持“按月结款、绝不拖欠”的商业信誉，也让超斯特能拿到原材料的最低采购价。</p>
  <p>有了优质产品和极致的生产成本，如何解决销售端的成本压力，也是价格控制的关键。</p>
  <p>王总坦言，他的运营策略就是尽可能利用平台政策叠加优惠。这背后，是拼多多“百亿减免”政策的直接托底。通过将技术服务费降至0.6%、退返推广费等措施，平台实打实地降低了商家的现金流支出，让运营成本不再转嫁给消费者。</p>
  <p>与此同时，拼多多的“千亿扶持”计划通过为“黑标”优质商品提供确定性的流量倾斜，帮助工厂实现了规模效应。淡季10万、旺季400万的订单量，意味着工厂设备可以满负荷运转，极大摊薄了折旧成本。这种“低经营门槛+高确定性销量”的模式，让工厂敢于在微利空间下，通过极致的周转效率换取利润，并将价格优势最终让利给消费者。</p>
  <p>翻看超斯特店铺数十万条评价，“实用”“耐磨”“口袋好装”成为高频词。这折射出当下消费者正变得愈发理性：在极端探险场景下，人们愿意支付技术溢价；但在日常通勤中，人们不再愿意为用不到的功能买单。</p>
  <p>清楚自己的需求，只为有效功能付费，毫无疑问，这已经是当下的消费共识。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613273664614914</id>
            <title>1400亿收编 Groq，英伟达的收购史，以及黄仁勋的并购逻辑</title>
            <link>https://www.36kr.com/p/3613273664614914</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613273664614914</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 07:53:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“英伟达史上最大金额收购”终究是一场乌龙。</p>
  <p>但是这场“乌龙”却不能全怪外界武断。说到底，英伟达斥巨资200亿美元，不仅获得了Groq的技术授权，还将其包括创始人在内的核心骨干招入麾下。</p>
  <p>Groq本体的确还在原地，但英伟达拿到了该拿到的一切。</p>
  <p><strong>英伟达强调这并不是一场“收购”，外界只是笑笑不语——谁不知道这话的核心受众是监管机构？</strong></p>
  <p>这种不是收购，却类似收购的交易，在如今的硅谷AI领域，在巨头与初创公司之间，已经是“基操”。</p>
  <p>而“花样收购之王”黄仁勋自然会迅速学以用之。</p>
  <p>回顾英伟达过去三十多年的收购路径可以发现，这家公司并非依赖高频并购扩张版图，而是始终将并购作为一种高度克制的战略工具。</p>
  <p>从2000年对3dfx的资产收购，到2019年并入Mellanox（英伟达历史上真正的最大收购），再到近年围绕 AI 软件、调度与基础设施的小规模并购，英伟达的每一次出手，几乎都发生在产业结构即将发生变化的关键节点。</p>
  <p>相比通过并购“做大规模”，英伟达更关心的是能否借此掌控技术演进中的关键环节——算力、互连、软件栈与生态入口。</p>
  <p>这种以补齐能力、锁定节点为核心的并购逻辑，使其收购数量并不显眼，却在长期中不断放大技术与平台优势。</p>
  <p><strong>近两年，英伟达明显加快了收购/类收购的步伐，但也完成了身份的转换：作为新晋巨头，必须开始小心行事了。</strong></p>
  <h2><strong>01</strong></h2>
  <p>英伟达对Groq发起的，并非正式的收购，却胜似收购。</p>
  <p>一切要从一个误会说起。</p>
  <p>多家媒体报道，英伟达同意斥200亿美元巨资，收购AI推理芯片初创公司Groq。</p>
  <p>这可是一件大事，以金额来看，一旦交易落定，那么这将是英伟达历史上最大的一笔收购，收购金额远高于英伟达之前创纪录的案例，即2019年69亿美元收购Mellanox。</p>
  <p>又因为Groq的创始人Jonathan Ross曾经是谷歌专有芯片TPU团队的成员，而谷歌TPU今年颇有瓜分英伟达GPU蛋糕的态势，因此这桩收购立刻引起广泛关注——看起来，黄仁勋面对谷歌的攻势坐不住了，要搞一笔大收购与之竞争。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_f02c9c78815a48af92008404f52cc8db@6119835_oswg96423oswg1015oswg541_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>但是，英伟达很快就出来澄清，中心思想就是强调——我们没有收购Groq，论技术，我们只是达成了非独家的授权协议而已。论人才，我们聘请了一些Groq的工程师加入我方。</strong></p>
  <p>但这件事颇值得玩味。</p>
  <p>英伟达只是否认了“收购”的定性，但是对于金额、聘请了Groq的什么人没有做出进一步否认。那么根据此前的广泛报道，Groq的创始人兼CEO Jonathan Ross、总裁Sunny Madra等核心高管及团队将加入英伟达，很有可能是事实。</p>
  <p>那么，即便定义上并非严格意义上的“收购”，甚至技术授权都是“非独家”的，但是Groq作为一家初创公司，失去了创始人及核心高管等骨干人员，技术也已经被行业老大哥拿到手，其命运也昭然若揭了——就算不会很快走向消亡，也不可能再以行业挑战者的姿态继续快速膨胀了。</p>
  <p>这家成立于2017年的芯片初创公司此前成长得很快，就在今年9月，还刚刚完成一轮7.2亿美元的融资，估值达到69亿美元。</p>
  <p><strong>换句话说，英伟达没有行收购之实，但是达到了收编Groq的目的。</strong></p>
  <p>而这样做的好处也不用多说，通过“变相收购”，既可以花更小的成本（不用将整个资产负债买过来），还能躲避反垄断的监管压力。</p>
  <p>这种做法，在如今的硅谷已经是巨头们心照不宣的招数。</p>
  <p>去年3月，微软就曾用极其相似的手法“掏空”AI初创公司Inflection AI，支付了6.5亿美元，拿到其技术授权，并且将其创始人苏莱曼（Mustafa Suleyman）和Karén Simonyan，以及该公司的大部分员工吸纳到微软。其中苏莱曼一去微软就坐上了AI首席执行官的位置，成为AI一把手，直接向微软CEO纳德拉（Satya Nadella）汇报。</p>
  <p>去年8月，谷歌以约25亿美元的价格拿到Character.AI的技术授权，并吸纳其包括创始人在内的核心团队，完成了一场“变相收购”。作为AI赛道曾经最受关注的独角兽之一，Character.AI就这样走到了尽头。</p>
  <p>今年6月，Meta豪掷149亿美元注资数据标注公司Scale AI，买下其49%股份，并将其联合创始人Alexandr Wang招入麾下，也成为了公司AI一把手，直接向扎克伯格（Mark Zuckerberg）汇报。</p>
  <p>这三个例子，与英伟达对Groq做的事如出一辙。</p>
  <p>英伟达也并非只对Groq这样做。就在几个月前，9月时，英伟达花9亿美金获得了初创公司Enfabrica公司的技术授权，并聘请了该公司的CEO及其他若干员工。</p>
  <p>“技术授权+团队加盟”的“类收购”，已经被英伟达熟练掌握。</p>
  <h2><strong>02</strong></h2>
  <p><strong>这两年，英伟达的投资步伐明显加快，其中不仅包括一般的投资，也包括收购与类收购。</strong></p>
  <p>金融时报就曾盘点，2024年全年投资总额达10亿美元，参与 50 轮融资和多起企业收购，显著高于 2023 年的 8.72 亿美元和 39 轮融资。</p>
  <p>而根据Crunchbase数据，截至2025年12月15日英伟达（包括直投+ NVentures）共计出手83次，涉及76家企业。</p>
  <p>如果再算上其对英特尔、Anthropic、OpenAI、xAI、CoreWeave等多笔“循环交易”，英伟达公开出手近90次，这个数字约是2024年的1.6倍。</p>
  <p>单就收购节奏来说，英伟达成立至今历史上的收购/类收购有30例左右，其中大部分年份这个数字都在3以下，少数年份如2020年达到4。但在2024年，英伟达一共有7例收购/类收购，2025年也已经多次出手。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_fe00a14f4fd247e6a9d2f1a0d6d141f8@6119835_oswg36234oswg1080oswg714_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>如果仔细看英伟达具体投了什么、收了什么，可以看到黄仁勋出手多而不乱。</strong></p>
  <p>据直面AI不完全统计，2025年英伟达至少有6起收购/类收购：</p>
  <p><strong>·</strong>&nbsp;3月，3.2亿美元收购Gretel Technologies，一家专注于AI数据生成的初创公司，以提升数据隐私和合成数据能力。</p>
  <p><strong>·</strong>&nbsp;4月，收购Lepton，一家AI初创企业，细节未披露，旨在扩展AI模型优化。</p>
  <p><strong>·</strong>&nbsp;6月，收购CentML，一家加拿大AI软件开发商，金额未披露，聚焦机器学习服务以加速AI工作流。</p>
  <p><strong>·</strong>&nbsp;9月，以9亿美元通过技术许可和招聘方式整合Enfabrica的AI网络芯片技术和团队。</p>
  <p><strong>·</strong>&nbsp;12月，收购SchedMD，该公司开发开源工作负载管理系统Slurm，优化高性能计算和AI训练。</p>
  <p><strong>·</strong>&nbsp;12月，约200亿美元通过技术许可和招聘方式整合Groq，强化AI推理芯片竞争力。</p>
  <p><strong>2025年英伟达的投资与收购呈现出一条清晰主线：AI。从硬件优势出发，持续向软件、调度和开发入口延伸，将GPU的竞争升级为平台生态的竞争。</strong></p>
  <p>无论是收购Slurm调度系统背后的SchedMD，还是并入CentML这样的效率优化团队，英伟达的目标都不是扩大产品线，而是控制算力体系中的关键节点。</p>
  <p>同时，通过NVentures的高频投资，英伟达在模型、互连和开发工具等方向提前卡位；而在监管敏感地带，则以Groq式的“技术授权+团队加盟”，低调完成能力整合。</p>
  <p><strong>我们仍旧以Groq和Enfabrica举例。</strong></p>
  <p>Enfabrica成立于2019年，本质上是一家做“AI 数据中心内部高速互连”的芯片公司。这一点公司的名称其实已经表现得非常生动，其中的“fabric”就是“织物”的意思。英伟达的GPU是一根根毛线的话，Enfabrica专攻的就是让毛线成为“织物”的技术。</p>
  <p>Enfabrica想做的是，当一堆GPU不再只是插在同一块主板上，而是分布在机架、机柜甚至多个机房时，如何让它们“像在同一块板子上一样协同工作”。</p>
  <p>如今单个数据中心的GPU数量从几百、几千已经膨胀到了几万，甚至几十万，这些巨量的GPU之间如何丝滑协同，对英伟达来说是很重要的。</p>
  <p>与Enfabrica相比，Groq所处的位置更加敏感。</p>
  <p>Groq 本身并不是一家 GPU 公司，而是一家主打确定性推理的AI芯片公司，其核心卖点在于通过高度专用化的架构，追求极低延迟和稳定吞吐。</p>
  <p>这条路线在技术上与英伟达并不完全重叠，但一旦规模化，理论上可能在特定推理场景中绕开 GPU 体系，对英伟达构成潜在替代。</p>
  <p>如果说Enfabrica是英伟达在“如何把GPU织成一张更大的网”上的提前布局，那么Groq更像是一种防御性整合：在新架构、新范式尚未成熟之前，先将其吸纳进既有算力秩序之中，确保未来的竞争仍然发生在自己设定的规则之内。</p>
  <p>从今年英伟达的收购/类收购可以看出，黄仁勋关心的是哪些环节一旦失守，整个算力体系就会松动。</p>
  <p>Enfabrica解决的是“GPU越来越多、越来越分散，怎么还能像一台机器一样工作”的问题；Groq则代表另一种风险——如果有人能绕开GPU，把推理重新做一遍，会不会改写规则。</p>
  <p><strong>英伟达对它们的处理方式不同，但逻辑一致：该收的收，该提前按住的先按住，不等威胁成型，就先把主动权握在手里。</strong></p>
  <h2><strong>03</strong></h2>
  <p>如果把视野拉远，在成立的32年中，收购/类收购约30例（注意，英伟达未对所有类似案例都做公开披露，因此该数字只是结合第三方机构报告等做出的估计），其数量并不算显著的“多”。</p>
  <p>与其将英伟达与谷歌、微软等平台型巨头对比，不如将其放回半导体同行的坐标系中。</p>
  <p>AMD和英特尔作为英伟达的直接竞对，历史收购案例数量分别约为15例左右，和100起左右。它们都有五十多年的历史。可以说，单纯从数量上来说，三家并没有拉开数量级的差异。</p>
  <p>有意思的是，英特尔虽然收购案例更多，但“留存率”偏低。</p>
  <p>最典型的例子，是英特尔在2010年以77亿美元的高价买下McAfee，但是因为实在是战略不协同，外界也对一家CPU公司买纯杀毒软件感到一头雾水。英特尔折腾了十年，最后终于在2021年以40亿美元的价格“贱卖”了McAfee。</p>
  <p>这些年英特尔干了不少这种事，很多并购当年都给出了理由，但后来不是被卖掉，就是边缘化，甚至直接放弃。</p>
  <p>对英特尔来说，并购更像是一种“试路”的方式——看到一个新方向，就先买进来试试，走不通再换一条路。</p>
  <p><strong>回头看英伟达过去三十多年的发展轨迹，很容易看出黄仁勋一以贯之的收购哲学：只收对的，不执着于数量，也不执着于形式上的“完整收购”。</strong></p>
  <p>对他来说，并购不是财务工程，也不是规模竞赛，而是一种工具——能不能拿到关键能力、关键人才，才是唯一标准。</p>
  <p><strong>黄仁勋始终非常清楚自己到底要什么。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_31f908fbf1474c8295c7957f1b03de93@6119835_oswg26079oswg533oswg400_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2000年对3dfx的“变相收购”，是最具代表性的案例。</p>
  <p>上世纪90年代末，3dfx曾站在整个3D图形产业的顶端，Voodoo显卡几乎是“高端显卡”的代名词。3dfx甚至曾有机会收购英伟达，却因为高管认定后者已经“气数尽了”而没有出手。但最终，英伟达后来居上，将3dfx按在地上摩擦。</p>
  <p>当3dfx运营崩溃，深陷财务危机时，英伟达并没有接盘整家公司，而是以约1亿美元买下其核心资产、专利和一百多名工程师。</p>
  <p>一年后，3dfx正式破产，债权人随即起诉英伟达，认为这是一笔不合理的低价交易。</p>
  <p>在庭审中，黄仁勋出庭作证，直言自己真正看重的并不是品牌或库存，而是工程师团队——在他的估算里，这些顶级人才的价值本就接近“每人一千万美元”。最终，法院判英伟达胜诉。</p>
  <p>这起案件也几乎是黄仁勋收购逻辑的注脚。公司的壳值不值钱不重要，关键的能力和人，才重要。</p>
  <p>在公司早期，这种克制的收购主要围绕3D图形与GPU 核心能力展开。2000年前后到2010 年之前，英伟达的收购对象多与图形渲染、图形软件栈和底层技术相关，目的非常明确：稳固自己在3D图形领域的领先地位，而不是横向扩张业务版图。</p>
  <p><strong>当然，英伟达也并非从未走过弯路。</strong></p>
  <p>最典型的一次，是对移动芯片领域的长期尝试。2003年，英伟达以约7000万美元收购 MediaQ，正式踏入移动芯片市场；随后十多年里，公司持续投入，并围绕移动SoC方向进行了一系列收购与技术整合。</p>
  <p>但直到2015年，英伟达才正式宣布退出手机芯片战场，承认这条路并不适合自己。</p>
  <p>但值得关注的是，相比于英特尔“不好用就丢掉”不同，黄仁勋非常善于“败中求胜”。</p>
  <p>移动时期积累的芯片设计、低功耗计算和系统集成经验，后来被顺势转移到汽车和机器人领域；Tegra芯片虽然在手机市场失利，却最终拿下了任天堂Switch的核心位置，甚至在某种意义上“挤掉”了曾经的老对手AMD。</p>
  <p>真正的战略转向，发生在2013年前后。随着深度学习浪潮逐渐显现，黄仁勋率先意识到 GPU在这一领域的潜力。</p>
  <p>到2016年，英伟达开始系统性地向数据中心和AI芯片倾斜资源，其收购与类收购的重心，也随之明显转向：不再围绕图形本身，而是集中在算力、软件栈、效率和生态入口。这条主线，一直延续到今天。</p>
  <h2><strong>04</strong></h2>
  <p><strong>英伟达的收购之路上，还有一个显著特点是，黄仁勋特别懂得“见好就收”“及时转舵”。</strong></p>
  <p>这还要从英伟达历史上第一大收购案例说起。</p>
  <p>如果说英伟达早期的收购更多是围绕主航道的耐心加固，那么2019年对 Mellanox 的 69 亿美元收购，则是一次毫不掩饰的大胆出手。</p>
  <p>这是英伟达历史上金额最大的一笔并购，当时也一度引发市场质疑：一家以GPU著称的公司，为什么要花如此高的代价去买一家做高速网络的公司？</p>
  <p>答案并不复杂。</p>
  <p>随着计算从单机走向数据中心，GPU的性能已经不再是唯一瓶颈，真正决定上限的是数据如何在成千上万颗芯片之间流动。</p>
  <p>没有高速、低延迟、可规模化的网络，GPU只是“孤岛算力”。</p>
  <p>Mellanox在InfiniBand和高速以太网领域的地位，正好补上了英伟达最关键，也最难自研的一块拼图。事后看，如果没有这笔收购，英伟达很难在随后的AI浪潮中，把GPU真正推成数据中心的基础设施，而不仅仅是一块性能突出的计算卡。</p>
  <p><strong>这种“大手笔”的思路，在次年得到了进一步延续——英伟达试图收购ARM。</strong></p>
  <p>彼时软银寻求退出，英伟达迅速出手，希望将这家掌握全球CPU架构命脉的公司收入囊中。一旦成功，英伟达将同时握住GPU、网络和CPU生态的关键入口，其野心不言而喻。</p>
  <p>但这一次，现实给了明确的反馈：交易在全球多个司法辖区遭遇强烈反垄断阻力，最终被迫放弃。ARM交易的失败，也让英伟达正式被各国监管机构“盯上”，成为反垄断审查中的重点对象之一。</p>
  <p><strong>从那之后，英伟达的收购节奏出现了明显转向。再也没有体量接近Mellanox或ARM的超级并购，取而代之的是一系列规模更小、目标更明确的出手，更多集中在软件、调度、效率工具和开发层面。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_1a03575f11684d40b500311bc87c9249@6119835_oswg16378oswg729oswg397_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>无论是直接收购，还是通过资产买断、团队并入、授权加人才引入等“类收购”方式，英伟达都在刻意降低交易的可见度和监管风险。</p>
  <p>黄仁勋并不需要通过并购来“证明存在感”，而是在监管压力下，及时转换思路，极其耐心地寻找那些刚好能补全英伟达拼图的初创公司。</p>
  <p>这些公司往往规模不大，但位置关键，名气不高，却卡在未来演进的关键节点上。</p>
  <p>相比一次性吞下整个公司，黄仁勋也更在意的是能否把能力、路线和人，精准地纳入自己的体系之中。</p>
  <p>Mellanox是一次必须赢的豪赌，ARM 是一次过于激进的尝试。而此后的英伟达，则明显更懂得在边界之内出手、在合适的时候见好就收。</p>
  <h2><strong>05</strong></h2>
  <p>盘到这里，再回头看眼下的Groq案例，就不难理解英伟达为什么会第一时间否认“收购”说法，并反复强调这只是非独家技术授权。</p>
  <p>在当前的监管环境下，任何一次涉及潜在竞争对手的并购传闻，都会被迅速放大。对英伟达而言，哪怕只是“看起来像收购”，都可能引发不必要的审查风险，因此在Groq这样的案例中，主动降调、切割，几乎是必然选择。</p>
  <p><strong>更大的背景是，英伟达所处的位置已经发生了根本变化。</strong></p>
  <p>2020年试图收购ARM时，英伟达的市值仍在3000亿美元规模。而如今，它已经迅速成长为市值超过4万亿美元的超级巨头。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_dc00d79b3bae4fb6b003ac0bae9f55cf@6119835_oswg59421oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在这样的体量下，英伟达几乎不可能再贸然抛出一笔“史上最大收购”。</p>
  <p>现实中的选择也印证了这一点：2025年以来，英伟达官宣的收购只有寥寥几例，清一色初创公司，具体交易金额大多未予披露。少数被媒体披露价格的案例中，较为典型的是对数据隐私初创公司 Gretel 的收购，交易金额约为 3.2 亿美元。</p>
  <p><strong>无论从规模还是影响力看，英伟达都刻意避开了“大型并购”的敏感区间。</strong></p>
  <p>但这并不意味着英伟达的监管压力正在减轻。</p>
  <p>傲人的市值、在AI芯片领域近乎垄断的地位，以及并未真正放缓的收购节奏，使反垄断的阴影始终悬在其头顶。即便英伟达已经明显转向小额、低可见度的收购与类收购，监管机构关注的重点，也早已不再只是交易金额本身，而是这些动作是否在持续巩固其生态控制力。</p>
  <p>前文提到的微软“掏空”Inflection AI的“变相收购”，美国监管部门已经在进行调查，而且开始对这类AI合作关系整体展开信息收集和评估；英国监管机构更是直接按并购审查框架立案评估，最终虽放行，但也算是为巨头敲了一记警钟。</p>
  <p>监管机构已经摆明态度——他们不再只盯着“有没有买下公司”，只要人才被整体带走、核心能力被转移、潜在竞争被削弱，即便名义上不是收购，也有可能会被按收购来审视。</p>
  <p><strong>英伟达已经今非昔比，它在短短几年间膨胀为了世界级巨头。黄仁勋面临着切实的难题。那就是事到如今，必须收编的，究竟该如何优雅收编？</strong></p>
  <p>英伟达一头扎进与监管机构的猫鼠游戏中。200亿美元的“非收购”之含金量，可以相信黄仁勋的判断力，但这是否会引来监管的审视，还是一个未知数。</p>
  <p><strong>参考资料：</strong></p>
  <p><strong>1、硅基研究室：《疯狂英伟达，疯狂撒钱》</strong></p>
  <p><strong>2、IT之家：《英伟达搅动AI风云：2024年参与50轮融资、投资总额达10亿美元，收购公司数量超过去4年总和》</strong></p>
  <p><strong>3、快科技：《Intel 40亿美元卖掉的杀软公司McAfee再次被卖：价值140亿美元》</strong></p>
  <p><strong>4、量子位：《Switch的救世主是老黄？》</strong></p>
  <p><strong>5、［美］金泰（Tae Kim）：《英伟达之道》</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/F288HIePrnSik5KJyhOzvg" rel="noopener noreferrer nofollow" target="_blank">“直面AI”</a>，作者：小金牙，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613263277868036</id>
            <title>AI大佬Karpathy焦虑了：作为程序员，我从未感到如此落后</title>
            <link>https://www.36kr.com/p/3613263277868036</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613263277868036</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 07:10:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>年末的假期，正是总结思考的时候。不过对于程序员来说，仔细这么一想可能会感觉有点不对劲。</p>
  <p>刚刚，Andrej Karpathy 在 X 上发的一条帖子，引发数万程序员和从业者强烈共鸣与热议。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_4c3240a4852c4fd680f937a14e1aca33@000000_oswg527774oswg1080oswg678_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Karpathy 坦言：「<strong>我从未像现在这样觉得自己作为一个程序员如此落后。</strong>」</p>
  <p>他指出，编程这个职业正在被彻底重构，程序员贡献的代码越来越少，而更多的是在各种工具之间串联。如果自己能正确利用过去一年左右出现的新东西，就能变得强大 10 倍，反之，不跟上就会陷入技能焦虑。</p>
  <p>现在有一个新的可编程抽象层需要掌握，包括 agents、subagents、提示词、上下文、内存、模式、权限、工具、插件、技能、钩子、MCP、LSP、斜杠命令、工作流、IDE 集成等。</p>
  <p>此外，还需要建立一个全方位的思维模型，来理解那些本质上是随机、易错、难以理解且不断变化的实体（指 AI 模型）的优缺点，而这些实体突然间与过去传统的优秀工程实践交织在一起。</p>
  <p>用 Karpathy 的比喻，<strong>这就像一个强大的外星工具被分发给大家，但没有说明书，每个人都得自己摸索怎么用，而这场变革给整个行业带来了「9 级大地震」般的冲击。</strong></p>
  <p>总而言之一句话，撸起袖子加油干，别掉队。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_2a53a598dade49979a630be8020c9cca@000000_oswg247397oswg1070oswg870_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此言一出，迅速获得超过 2.2 万点赞、3000 多次转发和 360 万浏览量。众多开发者在评论区表达了相似的感受。</p>
  <h2><strong>老手也在重新学习</strong></h2>
  <p>资深工程师 Boris Cherny 称，「我每周都有这种感觉，有时候开始手动处理一个问题，然后得提醒自己：Claude 应该能搞定这个。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_346c1c9544454ef8af48582514417e13@000000_oswg259271oswg1068oswg914_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他还举了一个具体例子。最近在调试 Claude Code 里的一个内存泄漏，他习惯性采用老办法：连接分析器、使用应用程序、暂停分析器，手动查看堆分配。</p>
  <p>而他的同事则直接让 Claude 生成一个堆转储文件（heap dump），然后让它读取该文件，查找那些本不该留存的对象。Claude 一次就搞定，直接提交了 PR。</p>
  <p>「这种事几乎每周都发生。」Boris 注意到一个有趣现象，某种程度上来说，<strong>新同事，尤其是应届毕业生，由于没有一大堆关于模型「能做什么、不能做什么」的先入之见，反而能最有效地使用模型。</strong></p>
  <p>他表示，每隔一两个月都需要投入大量心理努力来重新调整对模型能力的认知，因为模型在编码和工程方面不断进步。上个月，他作为工程师第一次完全没打开 IDE，全靠 Opus 4.5 写了约 200 个 PR，每行代码都是 AI 生成的。</p>
  <p>「软件工程正在发生根本性变革，即使对我们这些早期采用者和实践者来说，最难的部分仍然是不断重新调整自己的预期，而这还只是开始。」</p>
  <p>Karpathy 打了个比方来解释这种感觉，就像你拿着 AI 四处瞄准，它会发射弹丸，有时甚至会哑火，但偶尔当你握住它的角度恰到好处时，一道强大的激光束会突然爆发，瞬间帮你解决问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_65883e3dd14c4910b5ca12ee0f498a22@000000_oswg57493oswg1044oswg162_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>言外之意，AI 这个工具威力巨大，但不够稳定，不像传统编程那么可控，你得不停试错，大部分时间是小打小闹或翻车，但一旦找对方法，它就能带来指数级的生产力提升。</p>
  <p>X 联合创始人 Igor Babuschkin 在评论区点名表扬竞争对手 Claude Opus 4.5 表现出色，Karpathy 回应道，AI 进化太快了，过去 30 天没跟上的人，观点就已经过时了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_763e59de024f4ce5b0afa396bfe5de0b@000000_oswg105791oswg1070oswg548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>技术专家和风险投资家 David Galbraith 表示，「今年夏天花了三个月时间，通宵达旦地学习如何使用 AI 编码 Agent 来交付真正高质量的产品，而不是那种随性编码的垃圾货，这是我职业生涯做过的最棒的事。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_9d8d18a649f54d788923b1fbafb31094@000000_oswg54648oswg1056oswg242_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>X 博主 @omarsar0 持更乐观、放松的态度。他认为，代码越来越稀疏和 AI 进步飞速并不困扰他，因为他不把这当成「竞赛」。相反，现在领域完全开放，创意解决方案和工作流可以来自任何人、任何地方，这种变革不只限于编码，还发生在研究和其他知识密集型领域。他建议大家别焦虑，每天玩 2 小时工具、多实验、多分享、重点想怎么给 AI 喂好上下文，然后拼命 build 项目。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_0bad8eb3ce3b4b2b8cd8ab1adbc15dcb@000000_oswg462687oswg1066oswg1100_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>《Build a Large Language Model From Scratch》也挺看得开，大家现在普遍焦虑技能「落后」问题，通常来自于试图同时做太多事情，而不是在某些事情上深入钻研。比如，有些人学好几门编程语言，而不是专精 1-2 门。或者试图同时跟进多个领域 / 子领域的研究文献…… 这本身不是坏事，但确实会让人感到压力很大。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_2bc88b8b1a084d01bc446f22ee9fea42@000000_oswg78777oswg1068oswg416_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至 X 博主 @samswoora 发出了「软件工程师这个职业即将 over」的感慨。「可能是 5 年，也可能是 10 年，但我们都能感觉到，结束已经开始了。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_6f6de41574654b61867ccb6aa8a20547@000000_oswg81601oswg1062oswg418_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>知名博主 Yuchen Jin 则认为，人工智能并没有取代程序员，它取代的是编程语言。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_bcf5d3ec6201474683c0122245b13136@000000_oswg251217oswg1056oswg486_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>来自传统阵营的反对</strong></h2>
  <p>不过，也有人持反对态度，代表人物就是 Go 语言联合创始人、Unix 老兵、极简主义和高质量工程先驱 Rob Pike。</p>
  <p>Rob Pike 收到了一封由 Claude Opus 4.5 自动生成的节日感谢邮件，邮件里夸他推动了简约强大的软件设计、对 Go、Plan 9、UTF-8 和 Unix 的贡献影响深远。Rob 却被气炸了，直接在 X 上破口大骂：你们这些 AI 公司一边浪费巨资造有毒、不可回收的硬件，一边破坏社会，却还让机器假惺惺地感谢我追求简约软件？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_c8b4e1a1931b43508eb849727cbc25f0@000000_oswg809827oswg1080oswg1362_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Rob Pike 的愤怒戳中了很多程序员对 AI hype 的复杂情绪。</p>
  <p>有网友完全理解并支持 Rob 的态度，这种 AI 批量生成的劣质代码和垃圾邮件确实令人反感，尤其对像 Rob 这样追求极致简约、纯净工程的老派极客来说，简直是侮辱。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_1e3a855a7fa844ffab010c5114d2b52a@000000_oswg49268oswg1072oswg244_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>无论如何，我们都得承认，这两年 AI 的发展和进步速度惊人。虽然去年到今年，AI 专家对于 Scaling Laws（大模型扩展定律）终结的讨论喧嚣尘上，但是各家科技公司激烈的竞争，让 AI 技术的发展并不是减缓，反而是加快了。</p>
  <p>据 Epoch AI 的数据显示，Epoch Capabilities Index (ECI，一个衡量 AI 通用能力的综合指标) 在过去两年增长速度几乎是前两年的两倍，2024 年 4 月更是加速增长了 90%。</p>
  <p>实际的指数级增长甚至已经超过了原本预期，而且这种增长势头很可能会持续到 2026 年。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_bfc2db088ef9481cbf45b6a8107535d7@000000_oswg463561oswg905oswg988_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>很难想象 2026 年，AI 会发展到何种地步。你对 2026 年的 AI 发展有什么预测？欢迎在评论区分享你的看法。</p>
  <p>参考链接：</p>
  <p>https://x.com/karpathy/status/2004607146781278521?s=20</p>
  <p>https://x.com/bcherny/status/2004626064187031831</p>
  <p>https://x.com/daveg/status/2004661204296589480?s=20</p>
  <p>https://x.com/nixcraft/status/2004644277859889181?s=20</p>
  <p>https://epoch.ai/data-insights/ai-capabilities-progress-has-sped-up</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651009244&amp;idx=1&amp;sn=22c49a8d62096f94d8f587ba8068ac25&amp;chksm=8513f938129578074f33b6bbaef5aaf0a8ea0a8abb0963e8bafda36896e0c54e4e2e53838539&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：关注AI的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613319915193349</id>
            <title>一年两倍，千亿美金</title>
            <link>https://www.36kr.com/p/3613319915193349</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613319915193349</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 07:02:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>美光FY26Q1财报交出亮眼答卷：单季营收136.4亿美元，远超122-128亿美元指引区间，比市场预期多赚近7亿；调整后EPS4.78美元，大幅超越3.95美元的市场预期。</p>
  <p>公司更是加码押注，将FY26资本开支从180亿美元上调至200亿，FY27还将继续增加。另一边，韩国双雄来势汹汹，三星记忆体部门与SK海力士Q4毛利率预计达63%-67%，有望七年来首次超越台积电的60%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_bff99675735445e8b121bbcf189379f8@000000_oswg139210oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AI驱动下，存储行业强势复苏，HBM和数据中心SSD成增长核心。<strong>这场狂欢是短期炒作还是长期红利？全球半导体格局又将如何重塑？</strong></p>
  <h2><strong>业绩拆解：AI驱动的“量价齐升+利润爆炸”</strong></h2>
  <p>美光FY26Q1业绩全面超预期，营收到利润、产品结构到现金流，均彰显AI存储的火爆。</p>
  <p><strong>1.营收与盈利：碾压式超预期，现金流创纪录</strong></p>
  <p>单季营收136.4亿美元，同比大增57%，环比上涨21%，增速刷新近五年新高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_834c51f00470439cad5a2b0ae35fdd37@000000_oswg140128oswg1080oswg755_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>收入增长并非“以价换量”，主要由价格上涨驱动，比特出货量仅小幅增长。调整后EPS4.78美元，远超市场预期的3.95美元，较上一季度直接跳级。</p>
  <p>非GAAP毛利率飙升至56.8%，同比暴涨17.3个百分点，环比提升11.1个百分点，远超50.5%-52.5%的指引。要知道，存储行业低谷时毛利率曾跌破20%，如今已迈入AI催生的“暴利时代”。</p>
  <p>现金流表现亮眼，运营现金流84.1亿美元，远超59.4亿美元预期；调整后自由现金流39.1亿美元，创下历史纪录，自由现金流利润率接近30%。</p>
  <p><strong>2.产品结构：HBM+SSD成“印钞机”，DRAM稳坐头把交椅</strong></p>
  <p>DRAM业务是绝对主力，营收108亿美元，占总营收79%，环比增长20%。</p>
  <p>比特出货量环比仅小幅增长，但ASP（平均销售价格）环比暴涨约20%，完美体现“物以稀为贵”。NAND业务不甘示弱，营收27亿美元，占总营收20%，环比增长22%。</p>
  <p>比特出货量环比增长中高个位数，ASP同样实现中高个位数增长，呈现“量价齐升”态势。美光在QLC领域领先，还是首家供应合格Gen6SSD的公司，助力其在数据中心SSD市场份额持续提升。</p>
  <p>最耀眼的明星是HBM，作为AI服务器的“算力粮仓”，其火爆程度超出想象。美光2026年的HBM产能已全部售罄，且提前与客户敲定数量和价格。</p>
  <p>更值得期待的是，HBM4将于CY26Q2以高良率量产，良率提升速度预计快于HBM3E，后续盈利能力将再上台阶。<strong>预测显示，2025年HBM市场空间约350亿美元，2028年将飙升至1000亿美元，复合增长率约40%，堪称“黄金赛道”。</strong></p>
  <h2><strong>AI存储：不是短期炒作，而是五年新周期</strong></h2>
  <p>美光管理层在电话会议中反复强调“需求远超供给”，这并非短期现象，而是AI驱动的产业结构性变革。</p>
  <p><strong>与前两轮存储周期不同，本轮复苏不再依赖个人消费端需求，而是以企业级AI资本开支为核心，开启全新产业周期。</strong></p>
  <p><strong>1.需求端：AI“吞噬式需求”，全品类普涨</strong></p>
  <p>近十年存储行业经历三轮周期，驱动因素各不相同。2016-2019年是DDR4技术迭代叠加手机游戏需求爆发；2020-2023年是疫情催生的远程办公与数据中心需求先涨后跌。</p>
  <p>2024年至今，AI算力基建与HBM技术革命成为新引擎，直接改写传统周期逻辑。AI数据中心对存储的需求堪称“吞噬式”，不仅推动高端存储产品价格暴涨，还带动全品类同步上涨。</p>
  <p>HBM价格年内暴涨500%，DDR4价格涨幅超50%，从消费级NVMeSSD、DDR4内存条，到企业级存储系统与大容量HDD，无一例外都在涨价。</p>
  <p>这种全品类普涨态势在存储行业历史上极为罕见，充分体现AI需求的广度与深度。需求来源也呈现多元化特征。</p>
  <p>云端数据中心（亚马逊AWS、微软Azure等）扩建AI服务器，对HBM、高容量SSD需求旺盛；企业端（金融、制造、医疗）部署私有AI模型，带动中高端DRAM和NAND需求。</p>
  <p>汽车电子领域，自动驾驶、车载娱乐对存储的容量和性能要求不断提升，成为新的需求增长点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_9ae42f5110c24866a8a0c4962c6bf50f@000000_oswg150564oswg1080oswg929_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2.供给端：产能受限，供不应求将持续</strong></p>
  <p>与火爆需求形成鲜明对比的是，存储行业供给严重不足。预计CY26行业DRAM和NAND位出货量增长将受供应限制，均同比增长约20%，远低于需求增速。</p>
  <p>供不应求的紧张态势将持续到2026年及以后。更关键的是，存储晶圆厂生产不同产品的调整周期约为5个月以上（前端约3.5个月，后端6-8周），无法快速响应市场需求变化，进一步加剧供需失衡。</p>
  <p>产能分配也成为行业难题。美光需要在HBM和传统DRAM之间、不同终端市场（数据中心vs汽车/工业）之间进行平衡。</p>
  <p>公司策略是优先支持数据中心等战略客户和长期协议，同时维持业务多元化，确保对汽车、工业等关键任务应用客户的最低供应阈值，但整体供应依然紧张。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_9891bf17e0994ed99a653179a342c0a2@000000_oswg70581oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>未来展望：三大关键信号，决定增长成色</strong></h2>
  <p>美光的强势表现，让市场对存储行业的未来充满期待。据CFM闪存市场预测，2025年全球存储市场规模有望达到1932亿美元，创下历史最高记录。</p>
  <p>但要验证这场复苏的可持续性，未来1-2年需要关注三大关键信号。</p>
  <p><strong>1.FY26Q2业绩能否延续超预期</strong></p>
  <p>美光给出的FY26Q2业绩指引极为乐观：调整后营收183-191亿美元（中值约187亿美元），远超市场预期的143.8亿美元；非GAAPEPS8.42±0.2美元，大幅超越预期的4.71美元。</p>
  <p>非GAAP毛利率68%±1%，同样高于预期的55.7%。如果能够顺利完成这一目标，将进一步印证AI存储需求的强劲韧性，也将推动存储行业的估值进一步提升。</p>
  <p><strong>2.产能释放与技术爬坡进度</strong></p>
  <p>产能是制约存储行业增长的关键因素。美光新建工厂的产能贡献主要集中在2027年及以后，在此之前，现有工厂的效率提升和制程节点转换进度至关重要。</p>
  <p>DRAM的1-gamma节点和NAND的232层节点能否如期实现量产并提升良率，将直接影响公司的产能供给和盈利能力。HBM的进展更是重中之重。</p>
  <p>HBM4的良率提升速度、2026年产能的兑现情况，以及市场需求是否会持续超预期，都将决定美光在高端存储市场的竞争力。如果HBM业务能够持续爆发，将成为公司未来几年的核心增长引擎。</p>
  <p><strong>3.供需平衡与价格走势</strong></p>
  <p>短期来看，由AI需求和高附加值产品产能挤占带来的涨价动力依然强劲。但长期而言，行业最终会走向新的供需平衡。</p>
  <p>随着各大存储厂商加速扩产，2027年后行业供给将逐步增加，届时价格走势将取决于AI需求的持久力。如果AI需求能够持续增长，将消化新增产能，维持行业的高盈利水平；如果需求不及预期，可能会导致行业再次陷入调整。</p>
  <p>此外，地缘政治风险也不容忽视。全球半导体行业的供应链重构、贸易限制等因素，都可能对存储行业的产能分配、客户合作产生影响，需要持续关注。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkwNjQwODAxNA==&amp;mid=2247538079&amp;idx=1&amp;sn=0ded9e6f1eb6c606726c00c209f1ce84&amp;chksm=c1e534417916e18356495edbf3423a10e4f6ac08d5b9cdf55ffb45427df8ee6e30d482933524&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“格隆汇财经热点”（ID：glh_finance）</a>，作者：格隆汇小编，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613238548563208</id>
            <title>深度使用80天后，我已经离不开小米17 Pro Max的背屏了</title>
            <link>https://www.36kr.com/p/3613238548563208</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613238548563208</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 06:54:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <h2><strong>从噱头到实用</strong></h2>
  <p>有些东西，只有在失去之后，才真正意识到她的好。</p>
  <p>我说的不是爱情，而是我真正的日常伴侣，小米 17 Pro Max 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_cf2d6fd46d70496aaed901427fe9d035@000000_oswg43215oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果在两个月前，你问我怎么看小米 17 Pro Max 的背屏，我会毫不客气地用「电子盲肠」来形容它，那时的我，认为它不过是小米为了差异化而强行加戏的产物。</p>
  <p>但在深度使用了 80 天后，这台机器被同事拿去做测试，我改用 OPPO Find X9 标准版，一种随之而来的不适感让我意识到，我似乎有点离不开它了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_045b61f036ff437bba9a34722b5ef48c@000000_oswg60854oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>从 3 步到 1 步</strong></h2>
  <p>这种使用体验上的落差，藏在许多不起眼的生活细节里。</p>
  <p>在持有小米 17 Pro Max 的这两个多月里，我的清晨动线几乎一成不变：在出地铁口后，左手拉开咖啡店门，右手从口袋掏出手机，手腕自然一翻，背屏上常驻的取餐码就已经对准了扫描枪。「滴」的一声，取餐完成，转身离开。</p>
  <p>整个过程不需要点亮主屏，甚至不需要确认屏幕显示的内容，因为取餐码早已在下单时设定好，而背屏的位置也早已成为身体的条件反射。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_0080ba46cb404d9d8953aacaf3f77e37@000000_oswg92047oswg1080oswg1124_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不仅是取餐码，你可以把自己想要的任何东西贴在背屏上</p>
  <p><strong>这种流畅感在我换回直板旗舰后的第一天就戛然而止。</strong></p>
  <p>我下意识地把手机背面递出去，却只换来扫码枪的沉默和店员疑惑的眼神。我只好收回手机，双击唤醒、上滑解锁、点开灵动岛或桌面小组件，等待应用加载，最后才调出二维码。</p>
  <p>从物理时间上看，这大概只多了 3 到 4 秒。但在交互体验上，这是从「一步直达」到「三步跳转」的退化。</p>
  <p><strong>在早高峰这种高压、快节奏的特定场景下，这多出来的两步操作所带来的阻滞感被无限放大。</strong>它强迫我将注意力从「取咖啡」这件事本身，转移到「操作手机」这个工具上。</p>
  <h2><strong>新的解法</strong></h2>
  <p>在新能源汽车行业，评判一款新车的竞争力往往遵循这样的权重排序：</p>
  <p><strong>价格竞争力 &gt; 智能化水平 &gt; 高频核心功能 &gt; 设计审美（情绪价值） &gt; 低频特殊功能。</strong></p>
  <p>如果把这个逻辑套用到当下的智能手机市场，你会发现大体也适用。</p>
  <p>到了 2025 年，各家旗舰机的价格体系早已透明且固化，而在小米升级到澎湃 OS3，各家系统的使用体验拉不开质的差距后，竞争的决胜点自然下沉到了第三层级——高频使用功能的便利性。</p>
  <p>过去五年，手机厂商们对「高频」的理解几乎全部集中在影像领域。他们投入巨资打「军备竞赛」，更高像素、更大底传感器、外挂镜头……影像旗舰层出不穷。</p>
  <p>但边际效应正在显现。用户对画质从 98 分提升到 99 分的感知已极其微弱。为了一个使用频率并不高的影像系统，让手机变得厚重如砖，对大多数普通人来说，并不值得。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_01bc7b5aa65b411b83b86fc3b0968773@000000_oswg34249oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>没有了巨大的影像模组，握持手感好太多了</p>
  <p>而小米 17 系列的背屏，提供了一种截然不同的思路。</p>
  <p>背屏并非是小米的首创，从魅族 7 Pro 的「智窗」开始，到小米 11 Ultra，再到近两年各类的「小折叠」、「阔折叠」，厂商们已经做了很多尝试。</p>
  <p>但为什么最后只有小米 17 系列的这块背屏最后受到广泛好评，并成功带动了销量增长呢？</p>
  <p><strong>回顾过往的背屏产品，我们不难发现一个共性的交互陷阱：它们大多是在给用户提供「两条路」</strong>。</p>
  <p>背屏往往被设计成主屏的「缩水版」或「镜像版」，要么只能看时间、天气，要么就是和主屏别无二致，不仅可以用它自拍，也可以用它刷微博、回微信。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_44ba6654bc864f3196b02a5fe723a4e1@000000_oswg75510oswg1080oswg669_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>魅族 7 Pro 的「智窗」，只能看时间天气</p>
  <p>但此时我们就会面临选择，大脑需要花费 0.5 秒去思考「这事儿我是用正面做还是背面做」，<strong>一旦涉及选择，就会犹豫；一旦产生犹豫，体验就会断崖式下跌。</strong></p>
  <p>这种微小的犹豫感会在高频使用中被无限累积，最终演变成一种莫名的累赘感，我们在在两条路口前不仅没有感到自由，反而感到了困惑。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_63349e7f7d434f5db1e1cd1ecddc1e15@000000_oswg46478oswg1080oswg509_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>小米 Mix Flip 2，背屏功能和主屏几乎一致</p>
  <p>但小米 17 系列消灭了这种选择题。</p>
  <p>小米的产品经理非常克制地界定了两块屏幕的边界，你不能在背屏上刷短视频，也不能回微信，<strong>两者在功能定义上是各司其职、互不干扰的。</strong></p>
  <p>我尝试照 Github 大神分享的方案，在背屏上显示微信通知，但后来发现小米官方不做这个功能是有原因的，确实纯属「脱裤子放屁」。</p>
  <p>这种设计让「犹豫」的心理状态荡然无存。</p>
  <p>当我要进行深度的内容消费时，自然会点亮正面；而当我需要不中断当前物理世界活动（如走路、交谈、排队）的前提下，完成更轻量化的确认和交互（如取餐、看座位、控车）时，手腕会下意识地转向背面。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_567e90e5efcb4f25b3652289aaaa5df2@000000_oswg33060oswg1080oswg340_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种「零思考」的交互分工，才是双屏设计能够从「噱头」走向「好用」的关键分水岭。它没有增加用户的决策成本，而是通过物理形态的分流，让操作变得更加直觉化。</p>
  <h2><strong>「第三空间」</strong></h2>
  <p>更进一步，这块背屏不仅解决了效率问题，还意外填补了「审美」这一层的价值。</p>
  <p>在直板机上，手机背面除了品牌 Logo 和日益夸张的镜头模组，几乎是一片死寂的荒原。用户的个性表达，往往只能寄托于手机壳。</p>
  <p>而这块背屏的出现，让手机有了「自定义」的能力。</p>
  <p>它可以是心情的晴雨表，可以是宠物的电子相框，也可以是一块复古时钟。这种审美上的愉悦感，正如汽车内饰的氛围灯一样，它构成了产品质感的重要一环。</p>
  <p>当背屏的使用频率因为各种功能提升后，我们与其产生视觉接触的机会呈指数级增加。这种高频的视觉接触，让背屏承载的审美价值和情绪价值被成倍放大。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_71187a8af79348e3bc5520bcf88ce31f@000000_oswg193457oswg1080oswg765_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>各类「痛机」方案</p>
  <p>在这个维度上，小米其实是在为智能手机开辟「第三空间」。</p>
  <p>第一空间是锁屏和壁纸，用于阻挡和取悦自己；第二空间是主屏，用于沉浸式的内容消费和生产；而背屏既不像锁屏那样封闭，也不像主屏那样繁重，成为了一个介于二者之间的「轻交互空间」。</p>
  <p><strong>在这个空间内，我们拥有了更多的主动权。除了便利化功能之外，自拍、模拟游戏，彰显个性也成了相当广泛的用途。</strong></p>
  <p>甚至它还让我找回了一些类似在红米 2A 时代找各种 ROM 包刷机的「参与感」，在社群内，大家难得放下了争吵，转而开始分享各种「梗图」和搭配。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_9bd12f575f354ae7b30102f4f51e2c67@000000_oswg57875oswg1080oswg585_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我经常使用的一些背屏壁纸</p>
  <h2><strong>谦卑地服务于人</strong></h2>
  <p>在 2025 年的今天，我们评价一项技术是否是「好文明」，标准不再是它有多么科幻或酷炫，更多考虑它是否足够谦卑地服务于人。</p>
  <p>曾经，我们认为手机功能的增加必然伴随着操作复杂度的提升。但随着芯片性能的提升和 AI 技术的发展，手机操作系统终于具备了真正意义上的「感知」和「决策」能力。</p>
  <p>系统从被动等待指令的「执行者」，进化为了主动分发任务的「管理者」。 这种进步让信息显示和交互的位置不断前移——从 App 内部深处，移到通知栏，再移到锁屏，最后移到了像背屏这样的「零层级」的交互面上。</p>
  <p>从苹果的灵动岛到 OPPO 的流体云甚至 Nothing Phone（3）的 Glyph 2.0，整个行业都在朝这个方向狂奔。</p>
  <p>这些设计的本质逻辑是一致的：<strong>信息显示更提前，交互更智能，感知更无感</strong>。 它们都在试图打破 App 的孤岛，让高价值信息像水一样流淌出来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_8b32e317753a4438b844a569eb583ccd@000000_oswg38202oswg1080oswg554_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Nothing Phone（3）背后的灯带来通知后会亮起来</p>
  <p>而小米的背屏，只不过是这种理念目前最直观、承载信息量最丰富的一种物理形态。它不仅是一块屏幕，更是系统主动决策后的「信息出口」。</p>
  <p>它承认了这样一个事实——在很多时候，用户并不想「玩」手机，他们只想快速完成任务，然后把手机扔回口袋。</p>
  <p>从这个角度看，背屏的设计哲学与汽车上的实体按键复兴潮有着异曲同工之妙。在触控大屏统一度治车机的时代，能够盲操作的物理按键被证明是更安全、更高效的设计。</p>
  <p>小米的背屏，某种意义上就是智能手机时代的「超级实体键」。它用一块屏幕模拟了物理按键的直觉性，却又保留了数字化内容的灵活性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_fbf9ece6c09847389606725a67f72b12@000000_oswg39692oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当影像带来的边际效益日益稀薄，当系统的同质化竞争陷入胶着，小米通过一块背屏，在「高频场景便利性」和「情绪价值」这两块新大陆上插上了旗帜。</p>
  <p><strong>这种新时代的体验，一旦尝过，就再也回不去了。</strong></p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652437585&amp;idx=1&amp;sn=4e5eb6934e15c31656b3e202377f0283&amp;chksm=9a1da28f814e2a64275e081844dc94be31d292e3683e569fdb64607fccc52a4843694006ca0c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613193921475079</id>
            <title>1000人团队之外，再养700个Agent：Notion创始人讲透AI怎么改组织</title>
            <link>https://www.36kr.com/p/3613193921475079</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613193921475079</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 03:46:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025 年 12 月 23 日，Notion 联合创始人兼 CEO Ivan Zhao 发表文章《Steam, Steel, and Infinite Minds》（蒸汽、钢铁与无限心智），劈头就问了一句：</p>
  <blockquote>
   <p><strong>如果公司里突然多了几百个永不休息的员工，会发生什么？</strong></p>
  </blockquote>
  <p>他没讲概念，直接给出一组硬数字：</p>
  <p>Notion 目前约 1000 名员工，同时已有 700 多个 AI Agent 在处理实际工作。这些 Agent 不是功能栏里的助手，而是像团队成员一样并肩协作。</p>
  <p>那它们在干什么？</p>
  <p>为什么能落地？</p>
  <p>组织会因此变成什么样？</p>
  <p>Notion 在用实际行动回答：当 AI 真的变成员工，公司该怎么运转？</p>
  <h2><strong>第一节｜AI 落地靠的不是模型，是地基</strong></h2>
  <p>在过去一两年，AI Agent 多到让人眼花，但多数用了几周就被放弃。功能看起来强大，实际能持续运转的却寥寥无几。</p>
  <p>Ivan Zhao 认为：不是谁接入了大模型，谁就领先。</p>
  <p>Notion 之所以能让 700 个Agent 接手具体工作，不靠模型，而是靠早期就打好了底座。</p>
  <p>早在 AI 之前，Notion 就把自己做成了一座可以自由搭建的建筑。每个功能就像一块乐高积木，页面、表格、数据库，不是单独存在，而是能彼此连接、共享信息。这些看起来不那么惊艳的设计，现在成了AI发挥能力的关键支点。</p>
  <p>用 Ivan 的话说：别人是事后才考虑上下文，我们一开始就在构建上下文。</p>
  <p>什么意思？</p>
  <p>其他很多公司是先做出一个聊天机器人，再想办法接上公司资料。Notion 是先把所有信息（会议纪要、客户反馈、项目进度）沉淀在一个地方，再让 Agent读懂它、用它。</p>
  <p>AI 能不能帮上忙，不只在模型多强，更在于你有没有给它一个能读懂全貌的环境。</p>
  <p>Notion 的乐高式结构，恰好就是这个环境。</p>
  <p>这本质上不是在堆功能，而是在建平台。</p>
  <p>这个区别带来的结果是：一旦 AI 到来，Agent 不再只是点一下生成总结这种小帮手，而能真正参与任务流，处理复杂操作，减少组织摩擦。</p>
  <p>Notion 没有大张旗鼓搞 AI 战略发布。它只是一直在做自己的事，走到今天才发现：</p>
  <p>原来不是为 AI 做准备，而是 AI 最终来到了它准备好的地方。</p>
  <h2><strong>第二节｜为什么大多数公司做不到？</strong></h2>
  <p>第一节说了 Notion 提前打好了底座。</p>
  <p>但为什么有底座，AI Agent 就能真正工作？</p>
  <p>Ivan 给出的答案是：AI Agent 要落地，必须满足三个条件。而 Notion 的底座，恰恰提前满足了这三个条件。</p>
  <p><strong>1、信息集中，不跳来跳去</strong></p>
  <p>现实里，大多数知识工作都像是在翻抽屉找东西：聊天记录看一半，文档翻一半，表格打不开，邮件还没看完。</p>
  <p>AI 在这种场景下，就像被扔进一堆散落的碎片里，连任务从哪开始都摸不清，更别说帮你做完。</p>
  <p>Notion 的优势，是把这些信息本来就汇聚在一个地方。AI Agent 不用东翻西找，就能看到会议记录、项目进度、数据库、反馈表、用户评论，像是已经坐在办公室中心的一个新同事。</p>
  <p><strong>2、结果能被看出来</strong></p>
  <p>做软件，代码能不能跑通是结果；发票有没有出错是结果。</p>
  <p>但很多知识工作没有那么明确：一个汇报写得好不好？一个运营策略有没有用？都很难量化。</p>
  <p>Ivan 提出的做法，是让 Agent 接手那些有反馈闭环的任务：比如会议总结、客户答疑、项目状态报告。用户有没有点满意、有没有继续往下用，都是直接信号。</p>
  <p>只有这样，AI 才有进步空间，才能真正变强。</p>
  <p><strong>3、人给方向，AI 负责执行</strong></p>
  <p>这是 Ivan 强调最多的点。</p>
  <p>AI Agent &nbsp;不是自动运转的工具，而是需要人类来设定目标、验证结果、判断好坏。</p>
  <p>Notion 的 Agent 体系里，每个任务都有明确的反馈机制：</p>
  <p>Agent 生成会议纪要，PM 确认重点有没有遗漏&nbsp;</p>
  <p>Agent 整理客户反馈，产品经理判断优先级&nbsp;</p>
  <p>Agent 起草文档，负责人决定是否发出</p>
  <p>人不再是执行者，而是质量把关人。</p>
  <p>这也是为什么 Notion 的 Agent 能真正落地：不是让 AI 自主决策，而是让人类始终掌握方向。</p>
  <h2><strong>第三节｜700 个 Agent 接管了什么？</strong></h2>
  <p>很多人以为，AI Agent 是用来写文案、画图、脑暴创意的。</p>
  <p>在 Notion，Agent 做的是这些：新人入职答疑、客户问题匹配、项目进度同步、跨团队协调、文档变更通知。</p>
  <p>都不是核心业务，却最消耗组织精力。不是因为任务难，而是需要反复沟通、跟进、协调。</p>
  <p>这正是 Agent 最该接手的工作。</p>
  <p><strong>1、反复沟通和跟进，才是最大的内耗</strong></p>
  <p>开会没结论、每周写周报更新、客服转来转去、对接不上信息……</p>
  <p>这些在公司里天天发生，但没人觉得值钱。</p>
  <p>而正是这些场景，Notion 让 Agent 来接手了。</p>
  <p>不是因为这些事情技术含量低，而是因为它们需要大量人工沟通、整理、协调、提醒、重复确认。</p>
  <p>Ivan 的思路很清楚：不是为了做 AI 而做 AI，而是从组织最痛的地方开始。</p>
  <p><strong>2、Agent 不只是工具，是同事</strong></p>
  <p>更关键的是，这些 Agent 不止在执行任务，而是开始参与协作流程。</p>
  <p>它们有记忆，知道上次谁说过什么。有关联，能从多个页面中提取信息。 有表达，可以自动把结果反馈成页面、评论、文档，供人确认。</p>
  <p>Ivan 打了个比方：未来团队，就像你和 AI 共同组建一个小型战队，每个 Agent都能负责一块职能。</p>
  <p>你甚至可以像设定日程一样，设定一个同事，帮你盯进度、写文档、发通知、跟反馈。</p>
  <p>不是在用工具，而是在设计团队角色。</p>
  <p><strong>3、员工从“执行者”变成“流程设计师”</strong></p>
  <p>Agent 接管了执行工作后，员工的角色也在改变：</p>
  <p>过去是自己写报告，现在是让 Agent 生成初稿，然后判断哪些重点没抓住。</p>
  <p>过去是自己查每个报错，现在是看 Agent 的诊断结果，决定哪一步需要优化。</p>
  <p>过去是自己搬运信息，现在是设计 Agent 的工作流程，让它自动同步。</p>
  <p>会写文档的能力，没以前重要了。判断文档好坏、设计工作流程的能力，变得更稀缺。</p>
  <p>这是组织分工方式的根本改变。</p>
  <h2><strong>第四节｜组织不是剧组，是城市</strong></h2>
  <p>700 个 Agent 分担了具体工作。</p>
  <p>但这只是表面。</p>
  <p>真正在改变的，是组织本身的运作方式。过去几十年，组织是怎么搭起来的？</p>
  <blockquote>
   <p><strong>加人，设岗，开会，审批。一层层叠上去，靠流程和会议维持秩序。</strong></p>
  </blockquote>
  <p>当团队超过几十人时，信息开始堵塞；上百人，就要靠制度防止出错；到了几千人，组织的形态已经像老楼加盖到第十层，每上去一层，都要加固一次。</p>
  <p>Ivan Zhao 认为，AI 带来的最大变化，不是哪件事做得更快，而是<strong>组织本身可以被重新设计了。</strong></p>
  <p><strong>1、从木头砖块，到钢铁蒸汽</strong></p>
  <p>他说：我们从用木头、砖块建城市，进入了钢铁和蒸汽的时代。</p>
  <p>什么意思？</p>
  <p>木头建筑只能盖三层，钢铁结构才能撑起摩天楼；</p>
  <p>水车要靠河流，蒸汽机让工厂离开水源；</p>
  <p>人管人效率有限，Agent 可以全天候运转。</p>
  <p>AI 就是这个时代的新“建筑材料”。</p>
  <p>它不只让原来那栋楼装修得更好，而是可以重新规划城市格局。</p>
  <p><strong>2、Notion 在让组织像建筑一样被设计出来</strong></p>
  <p>Ivan 曾说，他想把公司当作一件有商业模式的艺术品来构建。</p>
  <p>从 Notion 的做法就能看出：</p>
  <p>原来用人来对接的事，开始交给 Agent；</p>
  <p>原来靠会议同步的环节，变成 Agent 异步汇总；</p>
  <p>原来靠记忆维持的职责，交给上下文统一的文档接力。</p>
  <p>组织像什么？</p>
  <p>过去组织像剧组：人一多，沟通成本暴涨。</p>
  <p>现在组织像城市：只要规划得好，道路畅通，信息流、任务流、反馈流，都能自然流转。</p>
  <p>Notion 已经不只是一个工具公司了。</p>
  <p>他们在回答一个更大的问题：<strong>AI 时代，组织能不能被重新设计？</strong></p>
  <h2><strong>结语｜Notion 正在做的事</strong></h2>
  <p>Notion 不是用 AI 装点工具栏，而是在重搭组织架构。</p>
  <p>1000 人团队之外，700 多个 Agent 已经接管了组织最耗人的事务。</p>
  <p>Ivan Zhao 在意的不是 AI 会取代谁，而是：</p>
  <blockquote>
   <p><strong>一个人加一个 Agent，到底能做多少人的事？</strong></p>
  </blockquote>
  <p>Notion 给出的答案是：像建城市一样，重新设计组织。</p>
  <p>这不是演示。</p>
  <p>这就是 Notion 正在做的事。</p>
  <p>📮 参考资料：</p>
  <p>https://www.youtube.com/watch?v=GkEhuPCmAtU&amp;t=744s</p>
  <p>https://x.com/ivanhzhao/status/2003192654545539400</p>
  <p>https://www.notion.com/releases</p>
  <p>https://releasebot.io/updates/notion</p>
  <p>https://x.com/NotionHQ/status/2003887924237025638?referrer=grok-com</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/AOeVxfzb3Wf-tmGc4mF4iQ" rel="noopener noreferrer nofollow" target="_blank">“AI 深度研究员”</a>，作者：AI深度研究员，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613119209210889</id>
            <title>英伟达1400亿“收购”，GPU拐点已现？</title>
            <link>https://www.36kr.com/p/3613119209210889</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613119209210889</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 03:36:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>12月25日凌晨，英伟达和Groq宣布达成“非排他性授权协议”，以200亿美元（约合1400亿元）现金价格购买一家“非GPU”架构企业的技术授权。</p>
  <p>这场交易是英伟达有史以来规模最大的一笔“投资”，该公司将现金和短期持有资本606亿美元的三分之一都给了这家公司，超出该公司此前估值的3倍，可见其必须拿下该项技术的决心。</p>
  <p>这一激进动作背后，与近期谷歌TPU等“非GPU架构”的风头正劲密切相关。英伟达收购的这家芯片公司Groq的创始人兼CEO，正是谷歌“TPU芯片”缔造者——乔纳森·罗斯（Jonathan Ross），收购后乔纳森及Groq的核心技术成员也将集体加盟英伟达。</p>
  <p>值得注意的是，Groq主攻的也并非谷歌TPU同款架构，而是独创的LPU——软件定义硬件的可重构数据流架构，消除了内存带宽的瓶颈。这种设计让LPU在处理大语言模型时，能实现每秒数百个Token的“瞬时”吐字，这是TPU和传统GPU无法企及的物理极限。这一技术也被业界及媒体誉为“高阶TPU”。甚至一些业内人士表示，对于推理环节而言，Groq的可重构数据流可能是最好的技术路径选择，没有之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_b1c910c00fbf45b2b598f817da0c4928@000000_oswg114991oswg1080oswg290_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达CEO黄仁勋（Jensen Huang）年初曾表示，他认为AI推理需求将增长百倍。而英伟达在岁末这个时点“强势收编”推理优化的低延迟芯片制造商Groq，或许已经承认了GPU并非AI推理工作的理想选择，更对外印证了非GPU架构在 AI 算力时代的重要性正日益凸显。</p>
  <p><strong>让模型性能暴涨40倍，新架构超越GPU</strong></p>
  <p>事实上，AI 大模型热潮引发了算力需求暴涨。从文本生成、AI 图像创作到 AI 视频合成，从大规模模型训练到高复杂度推理任务，大模型展现出令人惊叹的能力，这也让AI算力芯片在其中发挥关键作用。</p>
  <p>随着AI应用场景丰富、任务日趋复杂，AI 芯片赛道早已告别零散玩家试水的阶段，形成了两大泾渭分明的技术流派：一派是以 GPU 为代表的共享式集中计算派（简称 GPU 派）；另一派则是以ASIC（谷歌 TPU）、可重构数据流芯片（Groq LPU）为代表的非GPU派。</p>
  <p>在这个风云际会的AI芯片江湖中，两大技术流派如同武林界的泰山北斗——少林与武当。</p>
  <p>其中，谈到GPU派，门派宗师为芯片巨头英伟达。GPU架构就像精密的工业流水线，计算单元如同训练有素的工人，严格遵循CPU主管的指令，在冯·诺依曼架构的框架下高效运转。其最大优势在于数十年精心构筑的成熟软硬件生态，标准化程度高，用户几乎可以即插即用。然而，GPU架构芯片的性能提升越来越依赖于制程微缩的极限突破以及HBM带宽的艰难提升，如同攀登更加陡峭山峰。</p>
  <p>再来看非GPU派，包括ASIC（专用集成电路）和可重构数据流芯片，其中Groq LPU为可重构数据流领域的“得意门生”，其精髓在于硬件能够根据瞬息万变计算任务动态重组，构建出高效专用通道，使得AI芯片具备灵活性和专用集成电路高效性的优势。</p>
  <p>早在2015年，可重构计算就被国际半导体技术路线图（ITRS）预见为“未来最具前景的芯片架构”，被学术界和产业界视为继CPU、FPGA和GPU之外的第四类通用计算芯片。</p>
  <p>如今英伟达获得的Groq，并非基于GPU进行“小修小补”，而是直接融合已经被验证的强大的可重构数据流架构，从底层构建推理系统，旨在实现AI推理速度、规模、可靠性和成本效益。</p>
  <p>其中，被称为“高阶TPU”的Groq LPU采用软件定义硬件的数据流式并行架构，基于格罗方德（Global Foundries）的14nm工艺制造，芯片面积约为725平方毫米，不包含外部HBM存储，在处理过程中，权重、键值缓存 (KVCache) 和激活值等数据都保存在芯片内部，依赖于动态调度模式，可以让数百个核心同步激活张量模型，即可实现40倍于传统方案的推理性能，无需依赖先进制程即可突破能效瓶颈。</p>
  <p>2025年7月，Moonshot AI（月之暗面）对外发布开源文本大模型Kimi K2，一度在国际权威榜单LMArena上登顶全球最强开源模型，紧追闭源顶尖模型。而发布后短短72小时，Groq基于高阶TPU架构的AI云算力系统，将Kimi K2的性能提升40倍，能效比超过英伟达GPU。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_47fa194a88684ad187560d59724b1980@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在互联规模层面，得益于Groq Compiler和Groq RealScale芯片间互连技术，Groq芯片构建了一个共享的资源架构集群，能够在MoE（混合专家）万亿参数模型上高效运行，提供所需的规模和速度，以跟上不断变化的 AI 模型格局，而非出现输出速度瓶颈。而且，Groq针对近乎线性的扩展性进行了优化，相比于传统的GPU，14nm的Groq算力芯片可以从底层架构设计来应对 AI 工作负载扩展的挑战，能效比英伟达GPU最高可提升10倍。</p>
  <p>可靠性层面，根据开放式大模型评估框架OpenBench数据显示，Groq与基于英伟达GPU 的 API 提供商上Together AI 运行Kimi-K2-Instruct 模型的MMLU实例，结果表明，Groq的准确率更高，在STEM、Social Sciences等方面都比肩GPU AI Infra能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_603d549a055d46ae9cf193abbb840f76@000000_oswg160925oswg1080oswg674_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更为关键的是，制造成本层面，用于制造Groq芯片的晶圆成本可能低于每片6000美元，相比之下，英伟达的H100芯片采用台积电5nm工艺，其晶圆成本接近每片16000美元。最终，Groq芯片和单卡成本均低于英伟达H100，这对于重算力推理的客户来说性价比更高。</p>
  <p>以开源Mixtral 8x7b开源模型为例，Groq 的吞吐量最高可达其他推理服务的 4 倍，Tokens处理速度比GPU更快，而价格却不到Mistral本身的三分之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_cebe0c0c06fc4615bf4aa15584f9b3a9@000000_oswg39673oswg1080oswg590_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>总结来看，凭借“高阶 TPU”的可重构数据流架构，Groq在推理速度、吞吐效率、成本优化等核心维度形成综合优势，全面对英伟达 GPU 构成竞争压力。</p>
  <p>这或许也是英伟达着急收购Groq资产的核心原因。</p>
  <p>展望下一步，随着这桩200亿美元“非典型并购”交易落锤，乔纳森和其他高管将共同助力英伟达构建AI工厂。</p>
  <p>英伟达方面表示，Groq的低延迟芯片对输入的响应速度极快，将为英伟达的产品带来新的能力，帮助其开拓新的市场领域。“我们计划将Groq的低延迟处理器整合到英伟达的AI工厂架构中，以服务更广泛的AI推理和实时工作负载......虽然我们正在吸纳Groq的优秀人才并获得其知识产权许可，但我们并没有收购Groq公司。”英伟达CEO黄仁勋强调。</p>
  <p>黄仁勋曾称，未来AI软件将全面具备推理能力，这将改变AI系统处理方式，“我们具备大幅降低 AI 成本的能力，而这一价值已成为行业共识。一旦实现成本的显著优化，我们便能在推理领域开展更深度的探索与创新。”</p>
  <p><strong>非GPU时代已来</strong></p>
  <p>当前，英伟达这一AI芯片市场的“霸主”似乎正迎来些许动摇，市场对英伟达的未来投下了新的审视目光。</p>
  <p>据报道，英伟达的大客户Meta正考虑在其数据中心大规模采用谷歌自研的AI芯片——张量处理单元（TPU），并可能最早于明年开始租用。这一消息犹如一颗重磅炸弹，瞬间引爆市场。在11月25日交易中，英伟达股价一度暴跌6%，市值蒸发数千亿美元。</p>
  <p>实际上，随着AI大模型的重心从训练走向推理和Agentic AI，英伟达GPU的缺陷日益突出。</p>
  <p>首先，GPU并非为推理优化，它的设计初衷是高速并行计算，而不是以最低成本执行重复推理指令。</p>
  <p>其次，GPU的灵活性意味着其硬件资源在实际推理场景中可能并非最优配置，导致单位能耗的效率不如ASIC。</p>
  <p>最后，英伟达的定价权极高，云厂商往往需要以远高于制造成本的价格购入GPU，形成了强势垄断方案。</p>
  <p>因此，在上述诸多背景下，谷歌、Meta、Cerebras Systems等公司都在发力非GPU技术。而英伟达最后选择大规模收购Groq公司，以避免“高阶TPU”架构的领导者Groq，将与英伟达GPU共同“混战”的局面。</p>
  <p>早在2025年，谷歌推出第七代TPU Ironwood，不仅是TPU历史上第一款最强推理芯片，而且在架构、规模、可靠性、网络与软件系统上等AI基础设施技术层面都进行了重构，在多项关键指标上首次与英伟达Blackwell系列实现正面交锋。</p>
  <p>单芯片层面，Ironwood的FP8稠密算力达到4.6 petaFLOPS，略高于Nvidia B200的4.5 petaFLOPS，已跻身全球旗舰加速器第一梯队。更重要的是，一个Ironwood Pod可集成9216颗芯片，构成一个超节点，FP8峰值性能超过42.5 exaFLOPS，在特定FP8负载下，该Pod性能相当于最接近竞品系统的118倍。</p>
  <p>这不仅是单芯片差距，而且面对英伟达，谷歌TPU在系统架构、拓扑设计、集群扩展能力等层面获得碾压式胜利。</p>
  <p>知名投行花旗认为，英伟达短期地位稳固，但同时预测其AI芯片市场份额将从90%逐步下滑至2028年的81%。</p>
  <p>从投资视角来看，英伟达以 200 亿美元收购 Groq 的交易，不仅创下其自身史上规模最大的并购纪录，更堪称 AI 算力赛道的重磅布局。这笔交易的 “重量级” 显而易见：200 亿美元相当于英伟达手头近三分之一的资金储备，如此罕见的大手笔，也让市场戏称其是 “用巨额资金买下核心技术 IP”。</p>
  <p>这背后，恰恰印证了可重构数据流架构的巨大价值 —— “高阶TPU”技术不仅是 Groq 的核心竞争力，更是英伟达不惜重金补齐非 GPU 赛道短板、巩固算力领域主导地位的关键所在。</p>
  <p>据报道，另一家可重构芯片设计公司SambaNova也迎来与Groq一样的收购局面。据报道，英特尔正在就收购美国AI芯片独角兽SambaNova进行初步谈判，SambaNova公司估值达到50亿美元。</p>
  <p>展望未来，非GPU赛道前景广阔。</p>
  <p>据国际数据公司（IDC）的最新数据显示，预计2025年，AI算力芯片市场规模超过1285亿美元，同比增长47.1%，预计2030年AI芯片市场规模达4138亿美元，其中，非GPU架构芯片市场规模占比超过21%，而推理芯片占比提升至65%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_821c561bd7db44eb91ae0eb1890f1cc4@000000_oswg198898oswg1080oswg552_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>反观国内市场，IDC数据统计显示，2024年，中国加速服务器市场规模达到221亿美元，同比增长134%。其中，非GPU加速服务器高速增长，占比超过30%。IDC预测，到2029年，中国非GPU服务器市场规模占比将接近50%。其中国内ASIC以寒武纪、昆仑芯为代表，可重构数据流则是以清微智能作为这个赛道的标志性企业。</p>
  <p>2026，GPU，ASIC，可重构数据流，谁将撑起全球AI算力产业的半壁江山还是三分天下，我们拭目以待。</p>
  <p>*免责声明：本文由作者原创。文章内容系作者个人观点，半导体行业观察转载仅为了传达一种不同的观点，不代表半导体行业观察对该观点赞同或支持，如果有任何异议，欢迎联系半导体行业观察。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2NDgzNTQ4MA==&amp;mid=2247805830&amp;idx=2&amp;sn=774c2adf5e392d05dc77454b6f82df9a&amp;chksm=cffba8620038c29480e9bd62fd64adff6285a393e11cd1c436160dd2e09a85d4a969a9fdaf27&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体行业观察”（ID：icbank）</a>，作者：Jackson，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613193301328899</id>
            <title>马斯克圣诞礼物：X上所有图片都能一键AI改图了，全球画师暴怒</title>
            <link>https://www.36kr.com/p/3613193301328899</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613193301328899</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 03:34:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这可能是 AI 画图的分水岭事件。</p>
  <p>昨天，埃隆・马斯克端上了为大家准备的圣诞礼物：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_7b84570cb3454864999c775bbc68d43d@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这次更新的重点在于「全场域编辑能力」，<strong>X 平台上的所有图片现在都新增了「编辑图片」选项，接入了 Grok AI 模型</strong>。与传统的 AI 编辑工具（如 Photoshop 的 AI 填充）不同，现在你在推特上看到任何一张图（包括别人发的图片），直接原地输入你的想法，想怎么 P 就怎么 P。</p>
  <p>Grok 提供图转视频的能力，也可以把一个静态图转换成为 6-15 秒的视频。AI 会自动判断动作逻辑，如让人物眨眼、让背景的树叶摆动等等，并自动匹配音效。</p>
  <p><strong>该选项目前似乎适用于所有账号</strong>，也没有电影 IP 的限制。新的整活工具上线，大量用户立即开始了「创作」。比如这样的图片：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_3a4725bb6d9d465790ecde280d19f0bb@000000_oswg534888oswg874oswg811_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>底下的回复就是各种改图：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_17efe7d95705496f9ea7c6a28d3cb649@000000_oswg537593oswg879oswg782_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_10c3bd1243dd4279b31001c146c32f31@000000_oswg454285oswg886oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>大家玩得不亦乐乎，对于 P 图效果也多有称赞。</p>
  <p>Grok 这一系列能力的跃升，要仰赖 xAI 团队在今年的多模态模型技术进步。当然，十万卡 H100 GPU 的&nbsp;Colossus AI&nbsp;超算集群也功不可没，否则也供不起全网上亿的用户在线 P 图。这可能也标志着 X 平台从「内容分享平台」开始向「生成式创作平台」转型了。</p>
  <p>不过对于那些以作画为生的创作者来说，马斯克发布的新功能，就像一个噩耗。毕竟你辛苦画出来的作品，发到 X 上之后，底下可能就是一串 AI 改图的回应。这怎能不让人破防。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_966eff5cc06440b0b0833d4b343caa2a@000000_oswg561879oswg888oswg1305_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_2aa713b4e7ba43bfade164a1c7d557c8@000000_oswg461714oswg879oswg1221_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_e100cd54754e4c0d9529d816aac9178c@000000_oswg341140oswg875oswg969_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_8270f823de8c43ffacdf3fb004b39a96@000000_oswg129512oswg881oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>人们发现，使用 Grok 的 AI 功能修图，可以轻松地去除水印，删除作者签名，再重新发出来你就是「原作者」了。而且似乎没有让人可以禁用 AI 修图的设置选项。</p>
  <p>有人建议在 X 设置区的隐私选项里关闭 AI 权限，但这些建议都没有明确提及 AI 图像编辑。Grok 官方也表示，目前没有办法禁用这项新功能。</p>
  <p>新版 Grok 图像编辑功能推出后，X 平台已经更新了服务条款，其中有一项条款允许 X 和其他人使用发布到网站上的内容 —— 包括用于机器学习。</p>
  <p>抗议的人中也包括一些有名的画师，比如《石纪元》的作者 Boichi，他表示，虽然他很喜欢 X 平台，因为这个活跃的平台能让他与粉丝互动，但他不能在未经他同意或未获得报酬的情况下，将自己的作品发布到该平台上，并允许他人使用、学习或利用这些作品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_7d1683d427fc45239df6a4ba0a264d99@000000_oswg92281oswg885oswg705_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也有人建议，上传图片而使其不可编辑的一种方法是将其保存为 GIF 而不是 JPG，尽管这会导致图像质量下降。</p>
  <p>最后，有看热闹不嫌事大的人认为，X 选择在圣诞假期期间推出该功能，是为了在收到停止侵权通知函之前，先观察几天人们的使用情况。</p>
  <p>大型实验了属于是。</p>
  <p>马斯克这次整的大活会以什么样的形式收场？让我们拭目以待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2651009226&amp;idx=1&amp;sn=8ae0c0ecf664d6397b71419b2b0a49ca&amp;chksm=8545762ed565f51325b0007b06d74c64c6518172037d53170ea4de92c507de7a8740e1ee76df&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“机器之心”（ID：almosthuman2014）</a>，作者：关注AI应用的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613153571603461</id>
            <title>网易集团执行副总裁丁迎峰宣布退休，后续担任公司顾问</title>
            <link>https://www.36kr.com/p/3613153571603461</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613153571603461</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 03:03:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>文 | 果脯</p>
  <p>编辑 | 刘士武</p>
  <p>北京时间12月27日凌晨（美股交易日期间），网易集团发布公告，宣布<strong>网易集团执行副总裁、互动娱乐事业部负责人丁迎峰（丁丁）将于2025年12月31日正式退休。后续他将继续担任公司顾问一职。</strong></p>
  <p>公告中，网易CEO丁磊表示：“我们衷心感谢丁迎峰先生的奉献和贡献。他为公司旗舰游戏的成功做出了卓越贡献，并在公司研发和运营能力的建设中发挥了关键作用。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_162e270fad7e4c1e9bad8e7cb793964b@16519798_oswg169808oswg1036oswg1139_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="img-desc">网易集团公告</p>
  <p>丁迎峰于1998年进入游戏行业，曾担任过《古龙群侠传》的主策。之后他在2002年加入网易，参与集团多款标志性产品的设计与开发，而他参与的《大话西游 Online》也是网易旗下首款自研大型网游。</p>
  <p>在众多知名游戏IP当中，丁迎峰在职期间参与推出的《梦幻西游》于2003年正式上线运营，截至2025年底，该游戏及其衍生手游产品系列已持续运营超过22年，是网易网络游戏业务历史上运营时间最长、累计营收最高的产品系列之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_bfba19cd242a416fbe9891b0ee39c906@16519798_oswg103272oswg806oswg478_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="img-desc">丁迎峰简历介绍</p>
  <p>在担任互动娱乐事业群负责人期间，丁迎峰的管理范围覆盖了网易旗下包括《梦幻西游》《大话西游》等在内的多款产品，以及《燕云十六声》《第五人格》《明日之后》等来自不同品类的游戏产品。该事业群也是网易内部人员规模最大、产品数量最多的游戏研发与运营实体。</p>
  <p>据网易历年财报披露，以MMO为主体玩法的网络游戏服务收入长期占据游戏业务总收入的七成以上，而互娱事业群是贡献该收入的核心单元。</p>
  <p>网易集团内部与互娱事业群并行的重要游戏研发机构是雷火事业群。雷火事业群以研发《逆水寒》《永劫无间》等产品闻名，其风格侧重于高规格图形技术、开放世界与动作玩法。互娱和雷火两大事业群在MMO等核心赛道存在一定的业务差异化，这种结构被视为维持内部产品创新动力的机制之一。</p>
  <p>在丁迎峰退休前夕，网易集团发布了2025年第三季度财务报告。财报显示，该季度网易净收入为人民币284亿元，游戏及相关增值服务净收入为233亿元，较2024年同期增长11.8%，并占公司总营收比例达82%‌。增长部分主要得益于《燕云十六声》《破碎之地》等新游的上线贡献，以及《梦幻西游》系列、《蛋仔派对》等既有产品的收入稳定性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_270dd85c403e44cf834b5801a1e41bc9@16519798_oswg44524oswg1080oswg732_img_jpg?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="img-desc">丁迎峰</p>
  <p>而这份财报所反映的业务状况，是丁迎峰退休前参与交出的最后一份阶段性成绩单。</p>
  <p>丁迎峰退休后，网易官方暂未披露接任者信息以及关于此人事变动的更多细节。</p>
  <p>随着网易互娱事业部告别丁迎峰时代，其管理层的具体变动以及对网易游戏业务中长期战略与产品线规划的影响，将在2026年及之后逐步显现。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613125238506502</id>
            <title>美丽废物还是年轻人潮品？一款迷你AI手机靠情绪价值众筹千万｜焦点分析</title>
            <link>https://www.36kr.com/p/3613125238506502</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613125238506502</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 01:41:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者丨欧雪</p>
  <p>编辑丨袁斯来</p>
  <p>看上去，10年前，手机行业就对创业公司关上了大门。</p>
  <p>但2025年，一家来自香港、毫无名气的公司，做了款AI手机，在kickstarter上众筹突破1150万港元。</p>
  <p>它没有主流手机的大屏幕设计，反而采用了一块4.02英寸的正方形AMOLED显示屏，整体尺寸仅相当于传统手机的一半。此外，它的摄像头可以实现前后翻转，还能安装全键盘保护壳。</p>
  <p>显然，这是一款轻配置、重巧思的产品。</p>
  <p>IKKO的切入点，很符合当下的时代潮流——从做通用品转向挖掘利基用户。一些营销触觉敏锐的年轻团队，反而在点状爆发。</p>
  <p>在手机行业，AI虽然是智能手机的标配，但并没有坚实的落地场景。用户能体验的无非是语音助手、录音整理等功能。行业早期，大厂也没能建立起某种行业规则。</p>
  <p>这也是创业公司的机会。他们并不需要发布什么惊动世界的功能，而是找到某些细节做加成，就能拿下部分用户。</p>
  <p>当然，一家硬件公司要生存下去，需要接连不断推出爆品，并保证持续、稳定交付。IKKO轻巧迈出第一步，但用户消耗完最初的好奇后，取胜的永远是产品本身。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_693892eea5fd45318b83521d94be2e69@6221844_oswg4040oswg900oswg145_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h3><strong>更小更灵活的AI手机</strong></h3>
  <p>在业内很多人看来，iKKO Mind One Pro的出圈，是精准踩中了“情绪价值”的红利。</p>
  <p>在智能手机设计日趋同质化的当下，iKKO Mind One Pro以其独特的正方形卡片设计脱颖而出。</p>
  <p>这款设备尺寸仅为86×72×8.9毫米，配备4.02英寸方形AMOLED屏幕，体积约相当于传统智能手机的一半，挑战了大屏当道的行业共识。</p>
  <p>此外，它并不试图在4英寸屏幕上复制旗舰机功能，定位更像是“主力机的延伸与补位”。</p>
  <p>比较创新性的设计是，IKKO一颗5000万像素的180度翻转索尼主摄像头，同一枚镜头既当后摄，也可一键变为前摄，这意味着自拍也能用上主摄的全部实力。对于小尺寸设备来说，这可以弥补前摄体验弱的共性短板。</p>
  <p>系统方面，iKKO Mind One Pro采用了双系统设计——内置Android 15负责完整应用生态，iKKO AI OS则是一个更轻的“副系统”，用户可通过实体键快速切换。其中，AI OS主打专注模式，避免干扰，并内置翻译、语音转录、摘要等AI工具。</p>
  <p>这是很聪明的聚焦。</p>
  <p>目前主流AI手机的功能主要围绕影像增强、语音助手和系统优化三大领域展开。例如，OPPO的“一键闪记”可自动提取聊天关键信息并分类提醒；荣耀的YOYO主要面向生活场景，比如自动完成打车、领券等任务。</p>
  <p>相比之下，iKKO Mind One Pro的AI路径更为聚焦。其双系统设计让用户能在常规模式和专注模式间一键切换，后者会限制通知和社交应用，形成无干扰的工作环境，是个非常垂直的场景。</p>
  <p>在商业模式上，iKKO也展现出与主流厂商不同的灵活路径。目前安卓厂商除了硬件利润之外，主要靠应用市场抽成和周边硬件挣钱。iKKO延续类似思路，但更轻巧。它的Pro版本内置vSIM技术，在60多国提供专供AI功能使用的免费数据服务，实质上将网络成本纳入硬件售价，并为后续订阅服务预留了空间。</p>
  <p>整体来看，虽然“硬件免费、服务盈利”模式在手机行业整体难以走通，但针对iKKO这样的便携设备细分市场，软硬一体化的订阅制仍具想象空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_cab91479dc7646c3b5541528b81f29c2@6221844_oswg4703oswg900oswg145_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">&nbsp;</p>
  <h3><strong>时尚配件还是实用工具？</strong></h3>
  <p>IKKO Mind One Pro在引发业界好奇的同时，也面临着诸多质疑。</p>
  <p>“它更像是一个时尚配件而非实用工具。”这是许多网络用户对它的评价。</p>
  <p>在性能普遍过剩的当下，iKKO的配置落后了几代。其使用的联发科Helio G99处理器，还是2022年的产品，主要用在低端机上。而且，连千元机电池容量都到达6000毫安时，iKKO的电池不过2200毫安。这种配置，甚至无法作为日常主力机使用。</p>
  <p>不少消费者对iKKO宣传的“免费全球网络”也存有疑虑。细究众筹平台上的条款不难发现，这一服务仅限于AI功能使用，常规上网、视频流媒体等流量密集型应用仍需依赖传统SIM卡。</p>
  <p>而在AI功能的独特性方面，iKKO面临更大挑战。</p>
  <p>其主打的实时翻译、语音转写等功能，目前在主流品牌手机上均已实现，且体验不断优化。随着巨头们将AI能力作为底层基础设施深度融入系统，一个独立硬件品牌在AI应用层打造差异化优势的难度正变得越来越高。</p>
  <p>实际上，随着AI手机市场的不断成熟，分化已成为必然趋势。</p>
  <p>一方面，主流厂商将继续推动AI与系统的深度融合。荣耀的生态战略、OPPO的智能体框架，都指向同一个方向：让AI成为操作系统的底层能力，而非表层功能。</p>
  <p>另一方面，细分市场的创新不断涌现。iKKO代表的“智能伴侣”等方向，都会持续吸引小众玩家加入。</p>
  <p>在技术战场上与大厂正面对决，小众品牌难有胜算。真正的机会恰恰存在于技术之外——那些尚未被满足的外观设计与情感需求，正成为它们的突破口。</p>
  <p>未来几年，AI手机市场有望形成双层结构：顶层是苹果、三星与主流国产厂商的生态系统之争，底层则聚集了众多小众品牌的场景化创新。</p>
  <p>对iKKO这类品牌而言，核心挑战在于如何平衡创新与实用、小众与规模。在成功验证产品概念后，它们逃不开性能、续航与生态建设的试炼场。</p>
  <p>实际上，很多人认为，iKKO Mind One Pro让人们想起了早期的黑莓手机——虽不完美，但足够独特。这也表示，AI手机的未来，不只有更强大的芯片和更复杂的算法，还有对“设备如何真正融入生活”的重新思考。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3613096029422598</id>
            <title>“黑影石，200一条，接单速来”</title>
            <link>https://www.36kr.com/p/3613096029422598</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3613096029422598</guid>
            <pubDate></pubDate>
            <updated>Sat, 27 Dec 2025 01:30:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>「核心提示」</strong></p>
  <blockquote>
   <p>商业竞争正被AI水军们拖入一条危险“捷径”中，从比拼创新、技术、产品与服务的“明面”较量，滑向操控舆论、制造虚假信息的“暗面”博弈。&nbsp;</p>
  </blockquote>
  <p>2025年末，两条几乎同时出现的新闻，揭开了当前国内商业竞争深藏水下的残酷一面。</p>
  <p>在山东烟台，警方成功打掉一个利用AI技术批量生成文章、系统性诋毁多家新能源汽车品牌的网络水军团伙，关停账号8000多个。</p>
  <p>差不多同时，影像科技公司影石Insta360发布公告称，自旗下首款全景无人机新品影翎 Antigravity A1上市2周内，网络上集中涌现超过2500条虚假恶意内容，相关证据已固定并报案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_09c2ed19a43f43119b6a43c964a6c414@000000_oswg210456oswg1080oswg1330_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>从早已白热化的手机、新能源汽车，再到正寻求技术突破的影像硬件赛道，恶意舆论攻击的“战火”跨圈蔓延</strong>。这已不再是偶发的商业摩擦，而是进化为一种组织化、产业化且高度技术化的系统性侵蚀。攻击手段依托AI完成“迭代升级”，攻击目标随着创新风口同步“范围扩张”。</p>
  <p><strong>一场以操控舆论为核心、成本低廉却破坏力巨大的畸形商业暗战，浮出水面</strong>。它不仅扭曲了科技行业的竞争生态，也成为所有创新企业不得不面对的“成本黑洞”。</p>
  <h2><strong>狙击范围扩大：</strong></h2>
  <h2><strong>从手机、车圈到影像赛道</strong></h2>
  <p>“行业不是‘零和博弈’，应抵制水军、黑公关，把资源和精力集中到真正的科技创新上。”</p>
  <p>今年10月的2025世界智能网联汽车大会上，小米公司创始人雷军把矛头指向了行业内的恶性竞争。在他看来，SU7等车型发布后，小米成了全网被黑最惨的车企之一。</p>
  <p>无独有偶，今年理想发布的多款新车同样遭遇了网络暴力，水军大量分发关于理想汽车安全性能的不实信息，试图阻击i8等车型销量。为此，理想CEO李想罕见发视频称，已经知道幕后操控的品牌和水军机构，但“不想把自己黑化，去变成跟他们一样的人。如果我们变成跟他们一样的人，他们就彻底赢了。”</p>
  <p>从竞争激烈的手机圈，到飞速发展的新能源车，网络水军早已成为行业公害，如今，这股歪风也刮向了新兴的影像赛道。</p>
  <p>在一些社交平台上，近期密集出现大量关于影石新品影翎A1无人机的“差评”，称产品存在“信号差导致炸机”“拍摄画面模糊”“续航不足”等问题。<strong>如果是用户的正常吐槽，企业需要听劝，进而改进产品性能</strong>。<strong>但进入这些账号主页不难发现，事情并没有那么简单。</strong></p>
  <p>一方面，<strong>这些账号大多是0粉丝的“僵尸号”，出现了不少雷同的头像和评论</strong>。还有一些特征相似的账号，呈现出高度一致的发帖节奏，比如批量出现的宝妈号、追星号、种牙号等，上一篇帖子还在“不约而同”追星、种牙、美食探店，下一篇集体开始吐槽影石的产品性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_d025d9b0eba842febef6c148952ef8dd@000000_oswg103663oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一方面，<strong>同一MCN旗下的多个账号似乎在有意带节奏</strong>。在数码圈，通常采用横向对比的方式，用实拍效果去展示产品性能，而这些账号未经测评，仅靠淘宝店页面、评论区留言，便炮制出“深度对比”贴，主观得出影石产品性能不如大疆的结论，并在没有数据支撑的情况下，刻意夸大影石销量惨淡，拉踩目的明确。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_e7e56db570514b93a28c1637391f66c0@000000_oswg117382oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>面对网络暗战，影石不得不展开反击，法务部公开发帖征集线索，线索或证据一经采纳，每条奖励1千到1万元不等；若被公安机关采纳，每条奖励1万到10万元不等。</p>
  <p>实际上，影石无人机新品遭遇的超过2500条集中攻击，并非孤立事件，而是上述网络水军模式在新兴硬科技赛道的复刻。这表明，任何具备高成长性、可能撼动市场格局的创新领域，都可能迅速成为黑公关的下一个目标。</p>
  <h2><strong>黑公关进化：</strong></h2>
  <h2><strong>从“水军作坊”到“AI黑产”</strong></h2>
  <p>对于企业来说，每年投入几十亿、上百亿搞研发，其成果可能毁于每条成本仅几毛钱的恶意评论。更可怕的是，<strong>网络水军早已脱离“作坊式”发帖，在AI加持下进化成全链条的工业化“AI黑产”。</strong></p>
  <p>今年8月，网络上曝光一个“黑理想”兼职群，群消息明码标价：拍摄理想汽车负面视频每条8元，恶意评论每条1.5元，带图评论每条2元。</p>
  <p>网络水军给“黑影石”开出的价格更高：1000-10万粉以上的账号每发布一条负面评价，可获得200-2000元报酬。不到七天时间，就有接近1100名水军报名。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_524276557cec4ab3894edcc1e702a2c1@000000_oswg378617oswg610oswg1284_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些企业的遭遇体现了网络水军的两种操作套路。一种是<strong>“买大号”模式</strong>：不是简单转发，而是制作看似专业的评测视频或长文，刻意拉踩去引导舆论，危害在于隐蔽性和说服力。小米法务部就曾公布过一个案例，一位博主在碰撞测试前，掐断了汽车小电瓶电源，刻意营造出车辆因断电而导致车门无法开启的假象。</p>
  <p>另一种则是<strong>“以量取胜”模式</strong>，以海量虚假信息淹没真实声音，系统性制造“口碑差”的消费幻觉。</p>
  <p>随着AI时代的到来，黑水军已经形成“策划方下单-AI工厂生产黑稿-多账号分发-水军刷评论带节奏”的工业化造谣模式。</p>
  <p>黑水军可以用一套电脑，同时操控上百台手机自动生成文案、视频和评论，在目标产品的社交话题、电商评价区、短视频评论区进行饱和式攻击，一条信息的成本低至几毛钱。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251227/v2_1e587437fb8b415ba463e56f9e1d669c@000000_oswg853796oswg832oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：公安部网安局微信公众号</p>
  <p>例如，在影石影翎A1无人机发布两周后，网络上集中出现超2500条恶意虚假评论，既有数万粉丝的大V带节奏，又有AI生成多样化、个性化的负面评论，甚至模仿真实用户的语气和顾虑，让普通消费者更难辨别真伪。前者负责定性与深度穿透，后者负责定量和广度覆盖，低成本地制造出“口碑差”的假象，劝退潜在消费者，打击新品销量。</p>
  <p>随着AI技术的发展，<strong>水军的阵地正从传统的文字评论区，向更具冲击力和欺骗性的虚假视频领域系统性转移</strong>。</p>
  <p>此前网络上流传的两段新能源汽车起火视频，明显指向蔚来汽车。蔚来公共关系专家柳志卿在接受央视《经济半小时》采访时表示，这两段汽车撞击爆炸和自燃视频都是假的。其中第二条视频是AI合成的，画面下面甚至有一个AI软件的角标。</p>
  <p>视频的欺骗性远胜纯文字，而很多用户无法分辨这种AI合成视频进行的恶意抹黑。对企业来说，澄清一段虚假视频，更需要投入数倍的技术分析（如逐帧鉴定）、权威媒体背书和流量推广，且效果往往滞后，所谓“造谣动动嘴，辟谣跑断腿”在视频时代尤为凸显。</p>
  <p>柳志卿表示，蔚来每月监测到的网络黑贴超过1.5万条，造成的损失保守估计在28亿元以上。</p>
  <p>为了应对网络水军，企业不得不成立应急团队，涉及法务、舆情、公共关系等多部门，消耗巨量精力与成本。维权背后往往代价高昂，蔚来在一起胜诉案件中仅获赔60余万元，但其估算的实际损失在“10亿级”。</p>
  <h2><strong>被侵蚀的商业文明与竞争底线</strong></h2>
  <p>此次“被黑”后，影石法务团队进行调查取证，并报警处理。影石创始人刘靖康在转发法务部微博时，跟了一条帖：高调的人光明正大地阴阳，低调的人在隐秘的角落里捅刀子。</p>
  <p>言下之意，竞争应遵循商业文明的底线，而非不择手段。</p>
  <p>创新企业频频“被黑”的深层影响在于，当水军成为一门生意，商业竞争也被拖入一条危险的“捷径”，从比拼创新、技术、产品与服务的“明面”较量，滑向操控舆论、制造虚假信息的“暗面”博弈。</p>
  <p>水下的暗箱操作，背离基本商业伦理，却<strong>往往能“以小搏大”，产生不对称的破坏力，给行业生态带来系统性负面影响需要警惕</strong>。</p>
  <p>一方面，<strong>网络黑公关会迫使企业陷入巨大的资源内耗，</strong>甚至稀释其核心的创新动能。</p>
  <p>今年4月，公安部网安局公布的案例显示，捣毁的6个网络水军团伙总计23人，收缴作案手机、电脑6000余部，查获水军账号3万余个，涉案金额达2亿元。相比之下，一家企业可能拥有数千名工程师和一线销售人员，加上前期巨额的品牌投入，后期需要花更大代价去澄清舆论，一旦“被黑”，真实损失将远超攻击成本。</p>
  <p>面对无孔不入的舆论攻击，企业不得不组建跨部门的“反黑”团队，长期投入巨额的人力、财力与管理精力进行监测、取证、诉讼和公关应对。正如刘靖康所叹，研发团队会因心血之作被恶意诋毁而士气受挫，甚至质疑创新的意义。这种被迫进行的“防御战”，实质上是对企业研发资源与创新注意力的挤占。</p>
  <p>在法律的震慑下，部分水军删除了“黑帖”，但被黑企业却不得不付出额外的成本，原本这部分精力跟预算可以用于更关键的领域。</p>
  <p>另一方面，倘若纵容网络水军，很可能会<strong>造成劣币驱逐良币的效应</strong>。即好企业更容易受到攻击，而动歪脑筋的企业，却能从操纵舆论获取短期利益。为此，多个行业已经看到网络水军的危害，相继发起倡议，抵制黑公关。</p>
  <p>从“兵不厌诈”到“君子爱财，取之有道”，现代商业竞争伦理的演进表明，遵循法律与商业道义，已成为主流商业文明的核心共识。明面的竞争推动进步，暗处的攻击则侵蚀根基，纵容黑灰产和网络水军，无异于养虎为患。</p>
  <p>正如电影《绣春刀》中丁修的经典台词“得加钱”，黑灰产没有道义可言，只认钱，谁给钱就为谁办事。今天一家企业找网络水军抹黑别人，<strong>明天可能就搬起石头砸自己的脚。</strong>从这一点看，行业应形成共识，主动对网络水军说“不”，不仅是良性竞争的需要，也是在保护明天的自己。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI3OTEwMDQwNw==&amp;mid=2649967588&amp;idx=1&amp;sn=812fc1a3979e5ca8b7464cf6a5341212&amp;chksm=f2f3e8c070ba40caa90b1d44e48bca7125ce75d345ad771e12914173fb5550998c1dfe170a78&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“豹变”（ID：baobiannews）</a>，作者：陈法善，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612259589386755</id>
            <title>背叛初衷，“美国支付宝”要靠银行牌照续命了</title>
            <link>https://www.36kr.com/p/3612259589386755</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612259589386755</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:21:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>曾经的屠龙少年，到底是妥协了。</p>
  <p>当年，PayPal 以“颠覆者”之姿登上舞台，怀揣着颠覆传统银行金融体系的初心，立下了打造独立于银行体系之外的全球电子货币系统的雄心壮志。</p>
  <p>但事实上，公司的发展方向从来都不只是个体意志的选择，而是整体宏观环境和社会结构下，所做出的最现实抉择。</p>
  <p>曾经想颠覆银行的paypal开始努力成为银行。前不久，Paypal向监管提交申请，计划成立一家名为「PayPal Bank」的工业银行。</p>
  <p>之所以选择成为银行，是因为银行牌照是 PayPal 为数不多的救命稻草。</p>
  <p>PayPal 九成收入依赖支付业务，本质上是一家靠 “过路费” 生存的公司。但 PayPal 既无流量壁垒，也无政策保护，市场正被 Block、Apple Pay、Google Pay 蚕食，市占率三年内下滑了14.5个百分点。</p>
  <p>而手握银行牌照后，PayPal 将提升其各业务条线的竞争力。届时，其支付业务将拥有更多流量入口，信贷业务也将获得更低的资金成本。</p>
  <p>曾经，那个初生牛犊不怕虎的少年，终究是有了中年人对现实妥协的无奈。</p>
  <h2><strong>“过路费”越来越难收了</strong></h2>
  <p>正如中国没有沃尔玛，美国也出不了美团，企业出生地用户习惯、监管环境、区位特征等地缘因素的不同，会让出身相同的公司活成截然不同的两种物种。</p>
  <p>支付宝和Paypal就是最典型的案例。</p>
  <p>两者都是从电商支付起家，后逐渐形成了C 端钱包 + 日常/跨境支付的综合金融工具。虽然表面功能相似，但他们的商业模式却天差地别。</p>
  <p>和支付宝形成了支付、信贷、财富管理多元驱动的业务格局不同，Paypal收入集中在支付业务上，其支付收入占比在90%以上。</p>
  <p>Paypay的信贷、财管没有发展起来，既和监管环境有关也和竞争格局有关。</p>
  <p>美国对非银行机构的信贷、理财等金融业务监管极严。PayPal没有全功能银行牌照，没办法独立放贷，贷款业务需要合作银行提供资金，它只能赚技术服务费。同样，财富管理也只能做代销，难成核心收入。</p>
  <p>当然，对于规模庞大的信贷生意来说，就算只赚技术费，规模也可观。但问题是Paypal做信贷业务并无太大竞争力。</p>
  <p>Paypal的信贷产品包括“Pay in 4”（先买后付）、PayPal Credit（虚拟信用卡）以及PayPal Working Capital（商家贷款），但唯独缺少个人信贷。</p>
  <p>这是因为竞争环境不允许，个人信贷这门生意被互联网银行盯上了，典型如SoFi都把缺资产、缺数据的学生贷款利率压到了5.99%。而paypal从合作银行那拿到的资金成本就在4.5%至6%。用低利率服务优质客群的逻辑，在paypal这是很难成立的。</p>
  <p>虽然信贷跑不通，但好在美国的支付生意实在是太好赚钱了。</p>
  <p>PayPal 平均能从每笔交易中抽取1.7%-2.0%的费率。这个费率是其全业务的整体平均抽成率，包括不漏出品牌的技术服务，如果是商业交易或者跨境交易，实际费率会更高。</p>
  <p>对比之下，国内移动支付的费率大多在0.2%-1.2%。美国移动支付普及率不高，paypal的高费率出了不少力。</p>
  <p>但Paypal变现集中在支付，说明了它本质是靠收“过路费”活着的公司。过路费+高费率，意味着低壁垒，一旦竞对卷费率，Paypal的份额会掉的很厉害。</p>
  <p>这也是paypal现在最大的问题，亚马逊、苹果、谷歌等流量巨头持续拓展支付业务，以及Wise、Payoneer、Stripe等低费率的价格战竞争下，paypal市占率三年下降了14.5个百分点。</p>
  <p>市场份额流失也使paypal的用户增长出现瓶颈，2024年PayPal活跃用户数量较2022年减少100万。进入2025年后，paypal交易频次也出现下降，二季度交易笔数同比下降5%。业务不景气也让paypal的股价跌到了2017年的水平，这在美国科技股中很罕见。</p>
  <p>节节败退下，银行牌照是paypal为数不多的救命稻草。</p>
  <h2><strong>需要银行牌照提升竞争力</strong></h2>
  <p>12月15日，paypal延续了“跌跌不休”的趋势，但盘后转涨1.5%。</p>
  <p>“久旱逢甘霖“的导火索是paypal宣布：公司已向犹他州金融机构部和联邦存款保险公司（FDIC）提交申请，计划成立一家犹他州特许工业贷款公司（ILC），名为“PayPal银行”。</p>
  <p>银行牌照意味着更完整的金融闭环，如果拍照被批准，PayPal 将从“支付工具”向覆盖存、贷、支付的“综合金融平台”演进，并将提升其各个业务条线提升竞争力。</p>
  <p>例如，paypal的支付业务在白热化竞争中，不仅份额掉得快，盈利空间也被严重压缩，其支付业务毛利率从2019年的42%降至当下的35%。</p>
  <p>而申请银行牌照后，它不仅能靠存贷业务获得更多流量入口，还能提升支付业务利润率。</p>
  <p>在海外，paypal的支付流程：商家通过paypal向合作银行发收款指令-商家合作行联系VISA-VISA联系消费者发卡行-发卡行通过VISA向商家合作行付款。</p>
  <p>其中，每一环交易都要雁过拔毛的抽一笔“过路费”（手续费）。而paypay如果成为银行，可绕过其它银行直接接入卡组织网络，有机构预计其“通道费成本降低60%”。</p>
  <p>除了支付业务外，paypal也可以通过银行牌照提升信贷等业务的竞争力。</p>
  <p>上文已经提到，paypal的信贷业务受制于人，需要和银行合作，paypal不仅只能分技术费，甚至因为高资金成本缺乏个人贷款的竞争力。</p>
  <p>但有了银行就不一样了，PayPal称，获监管批准后，paypal银行计划向客户提供计息储蓄账户，且客户存款将有资格获得FDIC的保险保障。这意味着，其贷款资金来源将从高息、波动大的合作银行，转向成本更低的内部存款。</p>
  <p>而从过去看，银行牌照也往往能加速信贷业务的发展。2021年，Sofi通过收购Golden Pacific Bank获得全国性银行牌照后，用户数从185万飙升至1000万，总资产增长了4倍。</p>
  <p>如果把视角放开，透过Paypal申请银行牌照这件事不难发现，海外金融科技公司正试图摆脱“中间商”定位。</p>
  <h2><strong>美国金融科技公司开始摆脱Baas模式</strong></h2>
  <p>过去十几年，美国的科技巨头做金融都喜欢借用别人的牌照（BaaS模式）。</p>
  <p>典型如paypal给用户做分期、给商户放贷款都是靠合作银行WebBank“借牌”发放。前几年各个科技公司发的稳定币，也有不少是靠有相关牌照资质的“Paxos们”做合规。</p>
  <p>BaaS模式的优势有很多，例如轻资产、扩张快等等。但劣势也很明显，不仅利润要被分走一块，一旦竞争激烈，依靠BaaS模式的金融科技公司也难形成差异化优势。</p>
  <p>所以，新的趋势出现了，越来越多金融科技公司开始去拿相应的监管牌桌。例如，paypal的同行Block（前身为Square）已经获得了犹他州ILC牌照，加密资产新贵如Circle、Ripple最近也获得了初步的银行监管批准。</p>
  <p>金融科技公司们抢牌照既是为了提升竞争力，也是为了在链上金融的新叙事中获得合规壁垒。</p>
  <p>从竞争的角度看，随着存量时代到来，有中间商属性的生意，利润正变得越来越低。就比如，前文提到的paypal，因为本质上处在“收过路费”的中间商业环节，难以形成差异化壁垒，市占率、利润率持续走低。中间环节利润越来越低，中间商们必须要抢上游牌照了。</p>
  <p>而抛开竞争，银行牌照也能增加金融科技公司链上叙事的胜率。</p>
  <p>在链上叙事中，以稳定币为代表的链上金融解决了“货币数字化”的问题，其开展的链上金融革命有望从今传统金融格局。而从实际进展看，这种叙事已经到了必须要被重视的阶段。</p>
  <p>截止今年上半年，全球加密货币市值加起来到了3.3万亿美元，自2023年以来，上涨了快三倍。3.3万亿美元相当于全球GDP的3%。如果把整体加密资产，视作一个国家经济体，它已经击败法国位列全球第7。</p>
  <p>而对于一个冲击传统金融格局的新物种来说，始终绕不开监管法则，相关公司最稳妥的办法就是主动加入监管体系，而金融科技公司们拿下银行牌照，意味着数字资产将融入银行体系。他们也将真正成为受监管的银行机构，确定性和合规壁垒大幅提升了。</p>
  <p>可以说，以paypal为代表的金融科技公司们能不能摆脱“中间商”定位，将决定着他们最终的价值。这一点也适合绝大部分行业。</p>
  <p>免责声明:本文（报告）基于已公开的资料信息或受访人提供的信息撰写，但读懂财经及文章作者不保证该等信息资料的完整性、准确性。在任何情况下，本文（报告）中的信息或所表述的意见均不构成对任何人的投资建议。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/woMyX3GPCqoQGFuwWBAgAg" rel="noopener noreferrer nofollow" target="_blank">“读懂财经”</a>，作者：杨扬，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612251724956933</id>
            <title>机器人与时间赛跑：一场关于春晚、商业化、上市窗口的争夺赛</title>
            <link>https://www.36kr.com/p/3612251724956933</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612251724956933</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>编者按：</strong></p>
  <p><strong>岁末将至，站在2025年的时间节点回望，技术浪潮的奔涌、消费需求的变迁、商业模式的迭代，构成了全新的商业图景。连线Insight推出年终盘点专题系列，试图捕捉不同企业在这幅变局图景中，如何应对挑战、抓住机遇。本期为第二篇，关注具身智能行业。</strong></p>
  <p>时代变了，机器人也来抢春晚名额了。</p>
  <p>近期，一则消息在具身智能行业引发震动：智元机器人和宇树科技为争夺2026年总台马年春晚的最大赞助商资格，开价均达到数千万元级别。</p>
  <p>这天恰巧是CCTV总台《2026年春节联欢晚会》发布主题和主标识的日子。据36氪报道，知情人士称春晚成为具身智能需要抢占的高地，不少机器人公司都参与了竞标。<strong>其中智元机器人和宇树科技正在高价争夺春晚赞助席位，智元率先开价6000万元，宇树直接将报价拉升至1亿元。</strong></p>
  <p>截止发稿，智元机器人已回应称“不是真的”，而宇树科技并未回应。</p>
  <p>目前，关于春晚赞助商的具体名单尚未公布，只有《晚点 LatePost》报道了火山引擎将成为 2026 年中央广播电视总台春节联欢晚会独家AI云合作伙伴，字节跳动旗下的智能助手豆包也将配合上线多种互动玩法。</p>
  <p><strong>而机器人企业将以什么形式出现在春晚的舞台上，讨论依然在继续。</strong></p>
  <p>毕竟，宇树科技旗下的机器人，在2025年便已经在春晚舞台上亮相过，并成功获得了大面积的社会关注。</p>
  <p><strong>我们看到，人们看似在关注一场品牌营销的竞标，实则在关心整个机器人行业的走向：概念验证阶段即将结束，产业进入商业化落地的全新阶段。</strong></p>
  <p>当“春晚”成为机器人企业考虑的课题之一，竞争的本质已经改变。数年温和的技术迭代过程结束了，市场争夺成为重头戏。接下来，曝光、订单、融资、上市，每一个环节都成为机器人企业必争的高地。</p>
  <h2><strong>争夺春晚：机器人企业今年更需要被关注</strong></h2>
  <p>花上亿元赞助一台晚会，这笔账怎么算？</p>
  <p>春晚赞助从来不便宜。除去赞助费，技术团队驻场、备用方案准备、运营团队对接、反复彩排及配套宣传方案等隐形成本，往往让企业的实际投入在报价基础上翻倍。</p>
  <p><strong>但对如今的机器人企业来说，为春晚花钱确实有必要，即使最终没抢到赞助名额，能够争取上节目也是值得的。</strong></p>
  <p>2025年蛇年春晚，宇树科技16台H1人形机器人与16位舞蹈演员共同演绎了舞蹈《秧BOT》，机器人身着东北棉袄、灵巧舞动转帕，与舞者默契配合，让宇树从科技圈的明星企业一跃成为全民认可的国家科技力量代表。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ca1cbe25218248958348130023705ccd@000000_oswg92111oswg889oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇树科技机器人在2025年蛇年春晚，图源CCTV直播</p>
  <p>据央视网数据，2025年蛇年春晚全媒体累计触达168亿人次，直播总收视份额达78.88%，创下近12年来的收视新高。</p>
  <p><strong>除去流量效应，“登上春晚”本身也足以为品牌背书。官方背书和品质认证让宇树在与地方政府谈合作、与大型国企谈订单、获得政策支持等方面都占得先机。</strong></p>
  <p>春晚带来的效益，最先被下游感知。</p>
  <p>有媒体报道，宇树上完春晚后，需要租赁机器人的政府机关和企业都首选宇树，一位下游机器人租赁公司老板，一个多月靠出租机器人赚了十几万元。</p>
  <p><strong>2025年，机器人与春晚的联系绝非偶然。</strong></p>
  <p>首先是政策支持。2025年3月两会期间，具身智能首次被写入政府工作报告，标志着国家战略层面的明确支持。</p>
  <p>其次是技术发展逐渐成熟。据艾瑞咨询报告，具身智能的自主化程度已达到类似自动驾驶L2-L3的过渡阶段，质变的临界点就在眼前。未来2-3年内，模型能力很可能实现飞跃性突破。</p>
  <p><strong>机器人企业对春晚的关注背后，有一层紧迫的现实逻辑：商业化落地中，如果各家企业在技术上拉不开绝对差距，那么谁先抢占用户心智，谁就能在融资、招聘、合作生态等各方面占得先机。</strong></p>
  <p>无疑，在这个特殊的时间节点，春晚提供的曝光，既是向资本市场释放信心的信号弹，也是向潜在用户喊话的号角。</p>
  <h2><strong>具身智能企业们，量产与商业化进展如何？</strong></h2>
  <p>春晚之争只是一个缩影，2025年，机器人行业真正的战场在量产和商业化。在争夺战中，头部企业的进展最具代表性。它们的量产能力和商业化路径，很大程度上决定了整个行业的走向。</p>
  <p>宇树科技创始人王兴兴公开表示，2024年宇树营收已超过10亿元，并实现连续五年盈利。据高工机器人产业研究所数据，2024年宇树机器狗年销量高达2.37万台，约占全球市场69.75%的份额，人形机器人交付量突破1500台。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_3f4f79da571e4af187d71ba42f71c6c0@000000_oswg67716oswg1080oswg775_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇树科技创始人王兴兴，图源宇树科技官方微信公众号</p>
  <p>而据智元机器人披露，截至2025年12月初，智元三大产品线累计下线5000台通用具身机器人，其中灵犀X1／X2系列1846台，远征A1／A2系列1742台，精灵G1／G2系列1412台。</p>
  <p><strong>从生产能力与发展速度上，两家头部企业各有千秋。</strong></p>
  <p>起步于2016年的宇树，是相对“老牌”的机器人公司，在硬件能力上积累深厚。业内人士认为，宇树能够实现盈利的核心原因在于其成熟的硬件把控能力，其完成商业化的机器人不是通过堆料，而是在数个环节做到最合适、成本最优。</p>
  <p>一项可供参考的事实是，宇树科技新品人形机器人R1，AIR版售价仅2.99万元起，尽管当前宇树的主要收入来源仍然集中在四足机器人领域，但人形机器人成本的降低，无疑在应用场景、规模化上为其打开想象空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1db13cc1e0cb496a992819634abdbd9f@000000_oswg187924oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇树科技R1不同版价格及配置，图源宇树科技官网</p>
  <p>成立于2023年的智元机器人，发展时间虽短，但产品落地速度、资本背景都很强，其创始人彭志辉即为业内广受关注的“华为天才少年”稚晖君。据公开信息，两年时间里，智元已完成11轮、累计超50亿元融资，估值达150亿元人民币。</p>
  <p>据《财经》报道，智元的重心正在快速由研发转向商业化，多位核心人员离职，将研发部门分拆成独立的业务部门，为每条产品线设置自己的研发团队，通过内部赛马的方式快速迭代，核心目标是快速量产、抢占市场。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_32acef62939e4dc296b76965ba4fd7f1@000000_oswg68054oswg802oswg774_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">智元机器人联合创始人及CTO彭志辉，图源智元机器人官方微信公众号</p>
  <p>2025年，机器人在各个应用场景落地趋势明显，众多工商业订单也向国内头部厂商涌来。7月，智元与宇树共同中标中移（杭州）人形双足机器人代工服务采购项目，总标包金额1.24亿元；9月，优必选宣布获得2.5亿元人形机器人产品及解决方案采购合同。</p>
  <p><strong>据公开信息统计，国内企业公开订单总金额已突破46亿元，数量超2万台。</strong></p>
  <p><strong>从金额与数量，不难看出市场对机器人赛道的期望颇高。但针对当前的不少“亿元级订单”，业内也存在质疑的声音。</strong></p>
  <p>摩根士丹利报告指出，许多厂商高调宣布的“大额订单”中，相当一部分属于框架协议订单或意向订单，执行确定性较低。</p>
  <p>高盛今年11月对9家中国人形机器人供应链企业的调研显示，虽然供应商规划的年产能介于10万台到100万台之间，但没有一家公司确认收到大规模订单或明确的生产时间表。</p>
  <p><strong>或许，机器人真正的商业化瓶颈在于应用场景。</strong></p>
  <p>据艾瑞咨询的《2025商用具身智能白皮书》，具身智能商业化的突破点需要在续航、延迟、执行、可靠性与经济效益等五大维度均跨过可用门槛。当前最接近这个标准的，只有工业制造和物流仓储场景。</p>
  <p>尽管轮式机器人在续航、稳定性以及导航精度上，已能满足大部分工厂场景需求，但却很难深入到更复杂的场景中。</p>
  <p><strong>相比工业场景，家庭、养老等场景更少结构化，任务重复度更低，ROI更难计算。在更贴近这些场景的人形机器人上，仍有不少难题亟待解决。</strong></p>
  <p>宇树科技创始人王兴兴便曾坦言，当前开门、拖地等动作对人形机器人而言还很复杂，让机器人直接去家中干活不太现实。</p>
  <p>人形机器人技术瓶颈依然明显。例如，机器人的“一双手”作为核心部件，既要结构紧凑，又要保证敏捷性和可靠性，便衍生出“三难困境”。倘若无法完成这项突破，家庭场景的精细操作就无法实现。</p>
  <p>更深层的问题在于经济性。业内估计，一台足够成熟的人形机器人价格约在30万至50万元，唯有能在同一场景中承担约十类以上的任务，投入与产出相比才能算得上“划算”。</p>
  <p>如今，人形机器人的主要应用方向仍是表演和科研。据人形机器人场景应用联盟统计，截至2025年上半年，教育科研机构采购量占人形机器人总订单量的75%。</p>
  <h2><strong>趁着“概念热”，抢摊IPO是必然</strong></h2>
  <p>尽管商业化路径尚未完全跑通，但资本市场的热情已经沸腾。</p>
  <p>据华芯资本统计，2025年前七个月，具身智能行业一级市场融资总金额超过300亿元，而2024年上半年这个数字还只是75亿元。</p>
  <p>据IT桔子数据，2025年前11个月，中国机器人产业链相关投融资事件达557起，总融资额超过839亿元。</p>
  <p>今年融资额最高的20家AI相关创业公司中，有九家都是具身智能方向。</p>
  <p>二级市场同样火热。《证券时报》9月末统计，A股中110只人形机器人概念股年内平均上涨67.63%，有18只股票价格较去年末实现翻倍。</p>
  <p><strong>在热钱涌入的同时，机器人企业掀起了IPO热潮。</strong></p>
  <p>港交所18C条款的调整，为机器人企业打开了上市通道。市值门槛降至40亿港元，让更多处于早期阶段的企业看到了可能性。据公开信息，除了已经上市的越疆科技，仙工智能、斯坦德机器人、云迹科技、优艾智合等公司已经递表。</p>
  <p>宇树科技在2025年11月完成境内上市辅导，预计年内于A股主板递表。据公开信息，宇树C轮融资后估值为120亿元。乐聚机器人在今年9月完成股改后，10月拿到近15亿元Pre-IPO轮融资。</p>
  <p>与之对比，智元的路径更为迂回。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7769780595c24d3d9744e85b1e60f642@000000_oswg112000oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">智元远征A2机器人在上海武宁路桥</p>
  <p>今年10月，智元机器人通过旗下平台智元恒岳，成功收购科创板上市企业上纬新材，获得其63.62％股份。尽管智元多次否认“套壳上市”，这一操作仍被外界视为“曲线上市”。</p>
  <p><strong>为何头部企业都在抢摊IPO？</strong></p>
  <p>首先是资金需求。上市潮的背后，是一级市场融资空间的收窄。业内人士指出，尽管行业融资金额和频率仍在上升，但估值断层正在加剧。而机器人是资本密集型行业，需要持续投入研发、产能建设和市场拓展。从一级市场获得高估值融资的难度在增加，二级市场成为更现实的选择。</p>
  <p>其次是时机窗口。尽管行业存在“泡沫论”讨论，但投资市场依然对具身智能的故事保持兴趣。国家政策也在大力支持——“十五五”规划建议明确提及推动具身智能成为新的经济增长点，北京、上海、深圳等地相继出台专项扶持政策。</p>
  <p><strong>如果说当前“具身智能”概念仍处于高热阶段，那么没人能保证热度永远存在。一旦市场对“故事”失去耐心，估值压力将迅速传导，因此机器人企业必须抓住窗口期。</strong></p>
  <p>2025年11月27日，国家发改委政策研究室副主任李超公开表示，当前人形机器人技术路线、商业模式、应用场景尚未完全成熟，需要防范风险。</p>
  <p>金沙江创投主管合伙人朱啸虎今年3月公开表示正在“批量退出人形机器人公司”，直言行业“商业化路径不清晰”。也有行业投资人士认为，机器人领域泡沫很大，80％现存人形机器人公司未来可能会被淘汰。</p>
  <p><strong>对于初创公司，压力也源于跨界而来的大厂对手。</strong></p>
  <p>华为、小米、小鹏、奇瑞等硬件大厂纷纷入局，美团、阿里、京东等互联网巨头则大量投资机器人公司，不仅提供资金，还能提供场景和数据。11月5日，小鹏汽车发布了人形机器人“IRON”，计划2026年底量产。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8c3d62c4cdfb47088fe7f4d7ad211a52@000000_oswg18687oswg1080oswg534_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">小鹏汽车董事长及创始人何小鹏在发布会介绍人形机器人“IRON”，图源何小鹏官方视频号</p>
  <p>竞争格局在快速变化。大厂的加速介入，让创业公司的生存空间进一步收窄。</p>
  <p>在这种背景下，通过上市获得资金、提升品牌影响力，成为创业公司的战略选择。但上市不是终点，而是新阶段的起点。二级市场对业绩的要求更加严格，上市后如何持续增长，将是更大的考验。</p>
  <p><strong>争夺春晚曝光、争夺订单、争夺商业化落地、争夺上市窗口，一系列动作背后，是机器人企业对时间的焦虑。技术路线还在探索，商业化路径尚待跑通，但资本热潮已经推着企业向前冲刺。谁能真正在细分场景中扎下根、跑得通，谁就能率先“造血”，靠真实价值活下来。</strong></p>
  <p>无论最终是谁上春晚，当烟花散尽，如何让机器人从舞台走向嘈杂的工厂和千万的家庭，才是这场竞争的真正终局。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2MTc4Nzg5MQ==&amp;mid=2247554539&amp;idx=1&amp;sn=3b0acd2d7f687a9404c5283d0f9f347d&amp;chksm=cf887ffc7953f42e287cd6704c0c578df7726758f54cbb82976a040dd9215b9f5d6a5d64a85a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“连线insight”（ID：lxinsight）</a>，作者：熊逾格，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257750844681</id>
            <title>清华唐杰：领域大模型，伪命题</title>
            <link>https://www.36kr.com/p/3612257750844681</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257750844681</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:20:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>清华教授唐杰最新在微博发表了自己关于AI的一些感悟，非常值得一读～</p>
  <p><strong>共八个小点</strong>，不算长篇大论，但扎实有料：</p>
  <ul>
   <li>基座模型继续scaling仍然高效；</li>
   <li>真实使用体验想进一步上台阶，长尾能力的对齐和推理增强绕不过去；</li>
   <li>Agent代表模型开始进入环境、开始形成生产力；</li>
   <li>一旦模型进入持续交互的世界，记忆机制、在线学习、自我评估就会成为核心工程题，而不是可选项；</li>
   <li>AI终究要落到替人完成工作、创造增量价值上；</li>
   <li>领域大模型是个伪命题；</li>
   <li>……</li>
  </ul>
  <p>唐杰表示，发微博是想分享一下，希望对大家有用。</p>
  <p>兹以推文刊载，供大家广泛阅读、传播。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_5ede2ba69b994664bb573fdd2e28ab31@46958_oswg304697oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以下为其感悟原文：</p>
  <h2><strong>01，关于scaling基座模型</strong></h2>
  <p>预训练使得大模型已经掌握世界常识知识，并且具备简单推理能力。</p>
  <p><strong>更多数据、更大参数和更饱和的计算仍然是scaling基座模型最高效的办法。</strong></p>
  <h2><strong>02，关于激活对齐和增强推理能力</strong></h2>
  <p><strong>激活对齐和增强推理能力</strong>，尤其是激活更全面的长尾能力是保证模型效果的另一关键，通用benchmark的出现一方面评测了模型通用效果，但也可能使得很多模型过拟合。</p>
  <p>真实场景下是如何让模型更快、更好的对齐长尾的真实场景，增强实际体感。</p>
  <p>mid和post training使得更多场景的快速对齐和强推理能力成为可能。</p>
  <h2><strong>03，关于Agent</strong></h2>
  <p>agent是模型能力扩展的一个里程碑，也是体现ai模型进入人类真实（虚拟/物理）世界的关键。</p>
  <p>没有agent能力，大模型将停留在（理论学习）阶段，就类似一个人不断学习，哪怕学习到博士，也只是知识积累，还没有转化为生产力。</p>
  <p>原来的agent是通过模型应用来实现，现在模型已经可以直接将agent数据集成到训练过程，增强了模型的通用性，其实难题还是不同agent环境的泛化和迁移并不是那么容易，因此<strong>最简单办法也只有不断增加不同agent环境的数据和针对不同环境的强化学习。</strong></p>
  <h2><strong>04，关于模型记忆</strong></h2>
  <p><strong>实现模型记忆成为一个必须做的事情</strong>，这也是一个模型应用到真实环境必须有的能力。</p>
  <p>人类记忆分为短期（前额叶）、中期（海马体）、长期（分布式大脑皮层）、人类历史（wiki或史书）四个阶段。</p>
  <p>大模型如何实现不同阶段的记忆是个关键，context、rag、模型参数可能分别对应了人类的不同记忆阶段，但如何实现是个关键，一种办法是压缩记忆，简单存在context，如果大模型可以支持足够长的context，那基本有可能实现短中长期的记忆。</p>
  <p>但<strong>如何迭代模型知识，更改模型参数这还是个难题。</strong></p>
  <h2><strong>05，关于在线学习与自我评估</strong></h2>
  <p><strong>在线学习与自我评估。</strong></p>
  <p>有了记忆机理，在线学习成为一个重点，目前的大模型定时重新训练，这有几个问题：</p>
  <p>模型无法真正的自我迭代，但模型的自学习自迭代一定会是下一个阶段必然具有的能力；</p>
  <p>重新训练还比较浪费，同时也会丢掉很多交互数据。</p>
  <p>因此如何实现在线学习是个关键，自我评估是在线学习的一个关键点，要想模型自我学习，模型首先要知道自己对还是不对，如果知道了（哪怕概率知道）模型就知道了优化目标，能够自我改进。</p>
  <p>因此构建模型自我评价机制是个难题。</p>
  <p><strong>这也可能是下一个scaling范式。</strong></p>
  <p>continual learning/real time learning/online learning？</p>
  <h2><strong>06，关于模型研发和应用结合</strong></h2>
  <p>最后，大模型的发展越来越端到端，不可避免的要把模型研发和模型应用结合起来。</p>
  <p><strong>ai模型应用的第一性不应该是创造新的app</strong>，他的本质是agi替代人类工作，因此研发替代不同工种的ai是应用的关键。</p>
  <p>chat部分替代了搜索，部分其实融合了情感交互。</p>
  <p>明年将是ai替代不同工种的爆发年。</p>
  <h2><strong>07，关于多模态和具身</strong></h2>
  <p>写在最后的是多模态和具身。</p>
  <p>多模态肯定是个未来也很有前景，当下的问题是多模态不大能帮助到agi的智能上界，而通用agi的智能上界到底在哪儿还不知道。</p>
  <p><strong>可能最有效的方式还是分开发展，文本、多模态、多模态生成。</strong></p>
  <p>当然适度的探索这三者的结合肯定能发现一些很不一样的能力，这需要勇气和雄厚的资本支持。</p>
  <p>同理，如果看懂了agent就知道具身的痛在哪里了，太难通用了（也不一定），但至少少样本去激活通用具身能力基本不可能。</p>
  <p>那怎么办呢，采数据，或者合成数据，都不是那么容易，也贵。</p>
  <p>但反之一旦数据规模上去了，通用能力出来了自然会形成门槛。</p>
  <p>当然这只是智能方面的难题，对于具身，机器人本身也是个问题，不稳定，故障频繁都限制了具身智能的发展。</p>
  <p>2026年这些都将取得长足进步。</p>
  <h2><strong>08，关于领域大模型和大模型应用</strong></h2>
  <p>也讨论一下领域大模型和大模型应用。</p>
  <p><strong>我一直认为领域大模型就是个伪命题，都agi了哪有什么domain-specific agi……</strong></p>
  <p>但，agi还没实现，领域模型会长时间存在（多长，不好说，ai发展实在太快了）。</p>
  <p>领域模型的存在本质上是应用企业不愿意在ai企业面前认输，希望构建领域know how的护城河，不希望ai入侵，希望把ai驯化为工具。</p>
  <p>而ai的本质是海啸，走到哪里都将一切卷了进去，一定有一些领域公司走出护城河，自然就卷进了agi的世界。</p>
  <p>简而言之，领域的数据、流程、agent数据慢慢的都会进入主模型。</p>
  <p><strong>而大模型的应用也要回到第一性原理，ai不需要创建新的应用。</strong></p>
  <p>ai的本质是模拟人或者代替人或者帮助人实现人类的某些必须要做到事（某些工种）。</p>
  <p>可能就是两种，一种就是ai化以前的软件，原来需要人参与的改成ai，另一种就是创造对齐人类某个工种的ai软件，替代人类工作。</p>
  <p>所以大模型应用需要帮助到人、创造新的价值。</p>
  <p>如果做一个ai软件没人用，不能产生价值，那这个ai软件肯定没有生命力。</p>
  <p>参考链接：https://weibo.com/2126427211/5247011059141988</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/krtUS58RrBX4UHnMZLPy4w" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612255778206210</id>
            <title>2025年，AI在重复互联网打法</title>
            <link>https://www.36kr.com/p/3612255778206210</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612255778206210</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:19:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI亦难逃“流量魔咒”，市场正呈现与互联网时代惊人相似的推广逻辑。</p>
  <p>争夺春晚流量盛宴，就是最新具象的表现。作为年终最大的流量池，抢占春晚舞台，已经成为争抢超级市场应用的快速入口。此前，无论是微信摇一摇，“集五福”抢红包，甚至京东、抖快和B站，都曾站上春晚的舞台。</p>
  <p>而今年，这个位置，AI上桌了。12月24日，有报道表示，字节跳动旗下火山引擎将成为2026年中央广播电视总台春晚独家AI云合作伙伴，其智能助手豆包也将配合上线多种互动玩法。</p>
  <p>种种消息表明，豆包距离一款国民级应用的距离，越来越近。而凭借AI时代的超级入口，字节也正形成“流量—产品—流量”的闭环。</p>
  <p>实际上，不仅仅是字节，放眼过去，无论是OpenAI的GPT系列、谷歌的Gemini，还是DeepSeek以及其他AI应用，其市场策略无不遵循着“争夺流量入口”的原则。</p>
  <p>这一现象，在互联网大厂尤为明显。数据显示，2025年第一季度，全球前十大AI应用的用户获取成本中，流量渠道占比平均达到68%，而产品差异化功能投入仅占22%。这一比例与2015年移动互联网应用的投入结构几乎一致。</p>
  <p>更值得关注的是，产品“日活/月活”比值，也已成为衡量AI产品成功的关键，而这正是互联网产品常用的核心。</p>
  <p>一定程度上，尽管被誉为“第三次工业革命”，AI生态卡位战进攻的本质，仍是下一代流量分配权。</p>
  <h2><strong>-01- “得流量者得天下”？</strong></h2>
  <p>剥开技术炫酷的外衣，审视这场席卷全球的AI热潮，一个熟悉的市场逻辑正愈发清晰：得流量者得天下。</p>
  <p>巨头们倾尽资源，争夺入口、抢夺用户、构建生态闭环，其核心打法与二十年前互联网时代争夺门户、十年前移动互联网时代争夺超级App的逻辑，如出一辙。</p>
  <p>以字节跳动的豆包AI为例，这款产品通过抖音、今日头条等成熟流量池进行推广，用户在使用短视频和新闻资讯服务时频繁接触豆包AI的入口和提示，形成“流量—产品—流量”的闭环。最新数据显示，豆包的日均活跃用户数(DAU)突破1亿。</p>
  <p>在硬件端，豆包通过与手机厂商进行系统级合作，让AI助手获得直接调用App、完成跨应用任务的权限（如自动比价、行程规划），试图成为手机底层的新入口。</p>
  <p>另外，豆包明显延续了互联网时代的“产品思维”。</p>
  <p>有报道称，据业内人士透露，在豆包内部，判断标准也变得更加务实。一个新功能是否成立，不再看大厂员工的内测反馈，而是进行“盲测”，找10个完全不懂技术的普通老百姓，如果其中有 7 个人不仅愿意用，还产生了忍不住“剁手”分享的冲动，这才是一个合格的“Aha Moment”。</p>
  <p>同样，腾讯的混元大模型通过微信生态进行渗透，用户在使用微信聊天、朋友圈、小程序时都能感受到AI的无缝衔接。这种借助已有流量入口快速获取用户的方式，与当年微信通过QQ导流、淘宝通过阿里系产品导流的逻辑如出一辙。</p>
  <p>以腾讯元宝为例，依托微信这一无可比拟的社交与流量帝国，腾讯元宝将AI能力像水电煤一样，无感地融入视频号、企业微信、公众号等每一个场景，实现最自然的用户触达和转化。</p>
  <p>可以看到的现象是，在微信生态中，随时可调用的元宝，某种程度上，使得微信用户形成了对元宝的“依赖”。</p>
  <p>当然，阿里方面，不管是千问的加速迭代，还是灵光的推出，以及其他业务线下AI应用的快速跟进，无一不在彰显出其对AI赛道的志在必得。此外，阿里还通过千问，打通淘宝、高德、饿了么等核心业务的API，将AI能力具象化为可编排的“服务原子”，旨在成为阿里生态的智能总枢纽。</p>
  <p>毋庸置疑的是，2025年，AI应用已如空气般渗透进社会的毛细血管。</p>
  <p>中国互联网络信息中心发布的《生成式人工智能应用发展报告（2025）》（以下简称《报告》）显示，截至2025年8月，我国累计有538款生成式人工智能服务完成备案，263款生成式人工智能应用或功能完成登记。</p>
  <p>苹果应用商店中，甚至将AI应用单列为“日常好工具”，对此的介绍是“有了AI，面对各类场景与需求，满眼都是捷径”。</p>
  <p>这一定程度上也意味着，AI应用，不再是“高大上”的意识形态，已经成为一种“日常工具”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_4523f43ca023487aaf7dc135ca3d1b7d@5951134_oswg331223oswg1080oswg928_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：苹果App Store将AI应用单列为“日常好工具” &nbsp; 来源：App Store 《听筒Tech》截图</p>
  <p>尤其令人瞩目的是，随着“AI+”行动的推进，逐步发展成“国民应用”。一种乐观的表象便是，街头巷尾，各种年龄群体，对AI应用已经并不陌生。《报告》显示，截至2025年6月，我国生成式人工智能用户规模达5.15亿人，普及率为36.5%，移动端用户规模更达7.2亿。</p>
  <p>但能看到的是，进入下半年后，AI应用的推进速度更是明显加速。不管是阿里，还是字节、腾讯，抑或百度等其他，都在以抢跑的姿势快速迭代产品，并争夺流量卡位，早日拿到下一场工业革命的王牌。</p>
  <h2><strong>-02- 争夺下一代流量分配权</strong></h2>
  <p>在AI从业人员升哥看来，巨头之间争夺的本质，是下一代流量分配权。</p>
  <p>一个不容忽视的事实是，在这个AI应用爆发的时代，传统搜索引擎和App商店的中心化地位正在被撼动。</p>
  <p>“从年初的Deepseek开始，用户获取信息的起点，便逐步从‘搜索框’转向‘对话界面’。”在升哥看来，随着技术的快速迭代，一条日渐清晰的路径是，谁控制了对话的起点，谁就掌握了新时代的流量闸门。</p>
  <p>“因此，巨头们争夺的不仅是AI应用本身，更是成为用户与数字世界交互的首要智能代理（Agent） 。”升哥指出，本质上，这也是2025年国内互联网巨头为何始终在将关注点集中在“流量入口”的关键因素所在。</p>
  <p>在升哥看来，究其根源，最核心的因素，实际上来源于资本压力与商业化的迫切需求。</p>
  <p>“众所周知，AI基础建设，给企业带来的财务压力巨大。”升哥指出，资本急切需要看到商业回报，最直观的证明就是用户规模与市场份额。</p>
  <p>事实上，诚如升哥所言，目前，市场对“AI商业化能否形成可持续的盈利闭环”存在普遍担忧。</p>
  <p>在此背景下，快速获取海量用户，既能满足资本市场对增长故事的期待，也为未来的订阅、服务收费和生态盈利奠定基础。也正因此，从互联网时代继承而来的“规模至上”的估值逻辑，在AI时代被全盘沿用。</p>
  <p>另一方面，技术差距的缩小，也在倒逼巨头之间的竞争，从单纯的“技术跑分”转向“场景落地”和“用户体验”。</p>
  <p>升哥便直言，“当技术本身难以形成绝对壁垒时，生态和流量就成为关键的护城河。”</p>
  <p>更重要的是，AI尤其是大模型的进化，严重依赖“数据飞轮”：更多的用户产生更多的交互数据，数据用于训练和优化模型，更好的模型又吸引更多用户。要启动这个飞轮，必须有一个巨大的初始流量作为“第一推动力”。</p>
  <p>互联网大厂，则恰恰手握这把钥匙，AI竞赛重回流量逻辑，也是技术、资本、市场与人性在现阶段复杂交织的必然结果。</p>
  <p>当然，另一个事实是，整个行业正处在从“App时代”向“智能体时代”转型的3-5年混合期，用户如何与AI共处、依赖何种AI服务的习惯，正在形成。</p>
  <p>“时间窗口稍纵即逝。巨头们不惜代价地推广，目的就是为了在用户心智中刻下烙印，形成使用依赖和路径习惯，构建极高的迁移成本。”升哥解释。</p>
  <p>当然，拥有庞大的本土用户流量，就意味着拥有定义产品、培育产业链、制定行业标准的主动权。这也是典型的互联网“赢家通吃”思维在新时代的打法再现。</p>
  <p>不过，依赖流量和生态的“旧剧本”，虽然能快速催熟市场，但也可能导致重复投入、垄断固化。</p>
  <p>升哥认为，引领AI走向更可持续的未来，行业仍需要探索新的可能性。</p>
  <p>比如，流量垄断并非无懈可击。未来的竞争焦点，应从争夺用户停留时长，转向提升AI完成复杂、长链条真实任务的可靠性与效率上，“一个能自主完成从市场分析、代码编写、测试到部署的AI软件工程师，其价值远大于一个通用助手。”</p>
  <p>一定意义上，“得流量者得天下”，是技术爆发期与市场成熟度不匹配下的必然产物，也是商业力量驾轻就熟地运用历史经验的结果。</p>
  <p>不过，在更多的“升哥”看来，当行业的关注焦点从“用户量”变为“价值创造量”，AI的发展才能真正驶向属于智能时代的“新大陆”。</p>
  <p>（文中均为化名。）</p>
  <p>（头图由《听筒Tech》拍摄。）</p>
  <p>（声明：本文仅作为信息交流，不构成任何投资参考建议。）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/5_BxIH60Gd7A4BctKpoiVQ" rel="noopener noreferrer nofollow" target="_blank">“听筒Tech”</a>，作者：杨林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612227990995975</id>
            <title>Gemini 3预训练负责人警告：模型战已从算法转向工程化，合成数据成代际跃迁核心，谷歌碾压OpenAI、Meta的秘密武器曝光</title>
            <link>https://www.36kr.com/p/3612227990995975</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612227990995975</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:19:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_35cc8c4d6a2246728e07b2f8d81ecd9e@000000_oswg787472oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2025 年底，大模型行业的“年终决战”正式打响，各家纷纷亮出压箱底的杀手锏，就在这场激烈角逐中，Gemini 3 以绝对王者之姿强势突围，一登场就刷新了行业的认知边界。</p>
  <p>11 月 18 日，Gemini 3 直接“横扫”多项权威基准测试，以“世界最强多模态理解”“交互最深智能体”“推理怪兽”的姿态，强势碾压全球所有同类模型。谷歌 CEO 桑达尔·皮查伊亲自为其站台，直言这是“迄今为止最智能的模型”。消息一出，整个 AI 圈瞬间沸腾，所有人都在追问：Gemini 3 的强悍，到底藏着什么秘诀？</p>
  <p>答案在发布当天就有了初步线索。Google DeepMind 研究与深度学习副总裁 Oriol Vinyals 直接在推特上“剧透”：<strong>“Gemini 3 这么强，核心秘诀就两点：更好的预训练，更好的后训练。</strong>”这番直白的表态，让“预训练”与“后训练”瞬间成为行业热议的核心话题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_5bded75537d1424ba23f6bb83a15feb2@000000_oswg187866oswg513oswg919_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近日，<strong>Gemini 3 预训练负责人之一、开创性论文 RETRO 的合著者 Sebastian Borgeaud</strong>&nbsp;首次现身播客，深度拆解了这款顶级模型背后的实验室逻辑。在他看来，Gemini 3 的飞跃绝非单一环节的突破，而是无数细节持续优化的结果：“我们几乎每天都能找到让模型变更好的地方，整个团队都在加速前进。”</p>
  <p>更关键的是，Sebastian Borgeaud 点出了一个核心转变：<strong>谷歌已经不再是单纯“做模型”，而是转向“做系统”。</strong>&nbsp;这一观点恰好与 DeepMind 联合创始人兼 CEO 戴密斯·哈萨比斯不谋而合。哈萨比斯此前就公开表示，Gemini 3 的强大，根源在于“研究、工程和基础设施”的深度融合。</p>
  <p>Gemini 3 的秘诀，其实侧面反映了当下行业的深刻变革：<strong>AI 已经从“无限数据”的规模化时代，正式迈入“数据有限”的新阶段。</strong>&nbsp;这一趋势不可逆转，也倒逼整个行业重新思考创新方向。在 Sebastian Borgeaud 看来，合成数据、推理轨迹、长上下文、持续学习、端到端检索训练，再加上靠谱的评估体系，这些将共同构成 AI 行业未来的进化路径。</p>
  <p>其实早在经典的 Chinchilla 项目中，DeepMind 团队就已经摸到了关键规律：<strong>在训练计算量固定的前提下，与其盲目扩大模型规模，不如更快地扩展数据规模，这样能训练出更优的模型。</strong>&nbsp;这一结论放到现在依然极具现实意义，它直接决定了模型训练后的推理服务效率和使用成本，是企业落地 AI 的核心考量之一。</p>
  <p>作为从强化学习转向表征学习的资深研究者，Sebastian Borgeaud 的预训练功底堪称深厚：从 Transformer 架构，到 BERT、XLNet，再到 DeepMind 第一篇大语言模型论文 Gopher，丰富的研究经历让他形成了独特的“研究品味”，这也为 Gemini 3 的预训练突破埋下了伏笔。</p>
  <p>针对行业内&nbsp;<strong>“预训练 Scaling Law 已死”</strong>&nbsp;的争议，Sebastian Borgeaud 给出了明确回应：“规模依然重要，但架构创新和数据创新的权重已经显著提升，甚至变得更为关键。”</p>
  <p>那么，在数据受限的大背景下，如何实现更好的模型效果？<strong>合成数据</strong>成了行业追捧的热门方案，但 Sebastian Borgeaud 的态度却相当审慎：“这确实是个有意思的方向，但必须极度谨慎。”</p>
  <p>在他看来，合成数据的核心风险不是“没效果”，而是“用错了还浑然不觉”。一旦数据分布发生偏移，模型看似答题能力提升，但可能会陷入“自嗨”的闭环里。为此，他给出了一套稳妥方案：用强模型生成合成数据后，必须通过小规模的可控消融实验，验证其带来的收益和潜在副作用。</p>
  <p>但即便如此，一个核心疑问仍未解决：<strong>“用合成数据训练出的模型，能否超越它的‘老师’？”</strong></p>
  <p>值得一提的是，谷歌的模型训练一开始融合了多种来源的数据，这也为 Gemini 3 的多模态优势打下了基础。</p>
  <p>Sebastian Borgeaud 还透露，DeepMind 正在推进&nbsp;<strong>“后 Transformer 架构”</strong>&nbsp;的创新，同时十分看好&nbsp;<strong>“原生态模型”</strong>。尽管这种模型的研发成本高昂，但长期价值值得投入。此外，今年兴起的<strong>强化学习规模化趋势</strong>，他们也有丰厚的预训练阶的经验可以复用，形成了技术协同效应。</p>
  <p>在播客后半段，Sebastian Borgeaud 把话题转向<strong>下一轮预训练的热点</strong>。他认为，预训练不会再沿着“更大、更长、更贵”的单一路线走下去，重点会转向架构创新：</p>
  <p><strong>长上下文和注意力机制是其中的关键变量</strong>。如果上下文越长，模型推理时可携带的信息越多，模型能力边界也就越宽。</p>
  <p>更长期的方向，是把检索与搜索更深地融入训练，做端到端、可微的学习，让模型把“会检索”变成内生能力，而不是上线后再外挂工具。他判断，强化学习的规模化可能推动这一进程，但要沉淀为稳定的架构与训练范式，不是一时之功，还需要数年。</p>
  <p>另一条主线是<strong>持续学习</strong>。Sebastian Borgeaud 直言，基础模型一旦预训练结束，知识就基本定格：明天出了新论文、新发现，模型不会自己更新。眼下行业更可行的办法主要发生在产品推理侧——接入检索，把最新信息实时拉进上下文，再基于这些材料完成推理，从而避免频繁重训底座、缓解知识过期。</p>
  <p>这与他参与的&nbsp;<strong>RETRO 项目</strong>思路一致，将知识放在外部库，模型负责推理。他认为检索增强这套方法近年才走向成熟，未来几年有望更深地进入 Gemini 这类头部模型。更远的目标则是改变训练方式，让模型能在真实世界的数据流上持续训练，实现真正意义上的“持续更新”。</p>
  <p>Sebastian Borgeaud 还单独拎出来<strong>评估</strong>这件事，将其视为预训练阶段的核心难题。“如果评估体系跟不上，很容易陷入‘看似提升’的假象内耗，根本分不清是模型改对了，还是数据出了问题。”也正因为如此，谷歌内部搭建了专属的评估体系。毕竟外部基准很容易被污染，保留内部的评估阵地才是关键。</p>
  <p>他认为评估需要跨越两道鸿沟：一是在小模型上验证有效的改进，能否顺利迁移到大规模模型上；二是预训练阶段的优势，能否在后训练之后转化为真实可用的能力。</p>
  <p>最后，<strong>服务成本</strong>也是绕不开的现实约束。随着用户规模不断扩大，推理预算变得越来越敏感，预训练环节也必须为“上线落地”负责，在提升模型能力的同时，还要降低成本、节省资源。</p>
  <p>对于 Gemini 3 目前的表现，<strong>Sebastian Borgeaud 直言“超出预期”</strong>。他认为，模型是真的越来越聪明了，这种进步不仅体现在基准测试的屠榜成绩上，更反映在真实工作场景的使用体验中。</p>
  <p>展望未来，他预测 Gemini 将更好地服务于科学研究，甚至有可能凭借助力重大发现拿下诺贝尔奖；同时也会越来越深入地融入普通人的生活，解决各类实际问题。</p>
  <p><strong>“进步的脚步看不到尽头，至少未来一年，这种加速前进的势头不会放缓。”</strong>&nbsp;这正是他的对未来的预言。</p>
  <p><strong>播客里还分享了更多关于 Gemini 3 训练背后的细节和 Sebastian Borgeaud 的精彩观点，我们翻译了该内容，并在不改变原意基础上进行了删减和整理，以飨读者。</strong></p>
  <h2><strong>Gemini 3 强大的“秘方”：更好的预训练与后训练</strong></h2>
  <p>Matt Turck：我想从 Oriol Vinyals 的一条推文开始。Oriol 是 Google DeepMind 研究与深度学习副总裁，也是 Gemini 联合负责人。他在 Gemini 3 发布时说，模型背后的秘密非常简单：更好的预训练和更好的后训练。考虑到 Gemini 3 相比之前最先进水平的跃迁幅度，这听起来很朴素。你怎么看？在某种意义上，真的就是这么简单吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我不确定这算不算秘密。至少从我的角度看，这很正常。人们有时会期待从一个 Gemini 版本到下一个版本，会有某个重大变化并带来巨大差异。以我的经验，可能确实有一两件事带来的提升更大，但总体上是很多变化、很多来自一个非常大团队的工作累积起来，才让 Gemini 3 比之前几代好这么多。我想这会成为一个反复出现的主题：像 Gemini 3 这样的发布，是大团队共同促成的结果。</p>
  <p>Matt Turck：这对 AI 进展意味着什么？从外部看似乎只是调了一些“旋钮”就实现了跃迁。这对未来意味着什么？我们接下来可以期待什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：有两点。第一，以这种方式我们仍然能取得这么多进展，这仍然很了不起，而且进展并没有放缓。有很多“旋钮”、很多改进，我们几乎每天都能找到能让模型更好的东西。第二，我们不再是在构建一个模型，而是在构建一个系统。人们有时会觉得我们只是在训练一个神经网络架构，但我们实际上也在构建围绕网络的整个系统。</p>
  <p>Matt Turck：大家最关心的是：这对真正的智能进展意味着什么？我们不必深入讨论“AGI”，但我们该如何理解模型进展：它是通往智能的路径，还是只是为了在某个基准上表现更好？是什么让你相信核心模型在变得更聪明？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：基准表现确实在持续提高，而且前沿基准的设计正在变得越来越难。即使对我这样有计算机科学背景的人来说，模型能回答的一些问题也需要我花相当长时间才能答出来。这是基准视角。我们会频繁评估，也非常谨慎地保留测试集。但人们常担心对基准过拟合，或所谓 benchmaxing（刷榜 / 跑分）。我认为这些担忧并没有很充分的依据。</p>
  <p>另一个更让我有信心的方面是：内部人们使用模型来提升生产力的时间在不断增加。每一代新模型都很明显能做新的事情，并且在研究与日常工程工作中比上一代提供更大的帮助。这也说明模型在变得更有能力，并在做非常有用的事情。</p>
  <p>Matt Turck：如果把视角拉远，你还会对现状感到惊讶吗？从你的角度看，我们相比几年前你的预期是领先、按计划，还是落后？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：事后说“按计划”很容易。如果我诚实面对自己，我觉得我们领先于我原本以为能达到的位置。2019 或 2020 年开始做大语言模型工作时，很难相信我们现在所做一切的规模，以及模型如今的能力。当时如果看 Scaling Law ，它们确实指向这个方向，也有一些人非常相信这些。但我不确定当时我是否会重注押它一定会实现并达到今天的状态。</p>
  <p>一个随之而来的问题是：如果未来还能保持过去五年的同类进展，这会把我们带到哪里？我认为未来几年会发生非常酷的事情。</p>
  <p>Matt Turck：你认为短期两到三年会走向哪里？AI 会提出新的科学发现、获得诺贝尔奖吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这是其中一部分。在科学方面，DeepMind 历史上做了很多工作，也有大量工作继续朝这个方向推进。我认为未来几年会有一些重大的科学发现。</p>
  <p>另一方面，在我日常的研究和工程工作中，我也很期待我们如何用这些模型推动更多进展，同时更好地理解我们正在构建的系统，并进一步发展我们自己的理解和研究。</p>
  <p>Matt Turck：行业里有一个重要主题：自动化 AI 研究与工程。如果外推，会通向类似“AI 2027”的情景，出现某种断点。从务实角度，你今天在工作中使用 AI 是什么样？你觉得几年后会意味着什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我认为与其说是自动化，不如说是让我们更快，让我们把更多时间投入到更高层次的研究部分。语言模型研究的日常工作中，我们要处理基础设施层面非常复杂、非常大的系统，所以相当多时间用在跑实验、盯实验、分析数据、收集结果。真正有意思的部分是形成假设并设计新实验。我认为后两部分仍将主要由我们来做。第一部分，尤其在接下来一年，随着更多能动式（agentic）工作流被启用，会越来越能够加速我们的工作。</p>
  <p>Matt Turck：你认为各个前沿 AI 实验室基本都在朝同一个方向做同样的事情吗？几乎每周或每月都有新模型，我们已经被“惯坏了”。Gemini 3 刚发布时，几乎就在我们录制前两小时，GPT 5.2 也发布了。你怎么看？未来会怎样？会有人脱颖而出吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：不同实验室的工作确实有相似之处，底层技术也相似。如果大家都在训练类似 Transformer 的模型架构，我不会惊讶。但在其之上，确实存在专业化：研究树上不同分支会被不同公司探索与利用。例如，DeepMind 在视觉与多模态方面一直很强，这一点今天仍然成立，也体现在使用方式与基准表现中。推理方面，OpenAI 提出了第一个模型，但我们也有相关研究脉络。所以有相似之处，但并不完全相同。</p>
  <p>至于未来是否会有人脱颖而出，我不确定。有一点很清楚：今天要在 Gemini 这样的模型上继续取得进展，确实需要很大的团队和大量资源。但这并不意味着今天的方式就是最优的。颠覆性研究可能出现，使得更小团队在某种形式上实现超越。这也是我喜欢在 Google 的原因之一：Google 有做更探索性研究的历史，研究覆盖面很广，而且这些研究很多时候与 Gemini 并行推进，我们也能利用其中一些进展并将其带入 Gemini。</p>
  <p>Matt Turck：在 DeepMind 或行业其他地方，是否有团队在半秘密或完全秘密地研究“后 Transformer”架构？有一天会突然出现让大家惊讶的成果吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我相信有。Google 和 DeepMind 内部确实有团队在模型架构方面做研究。至于这些研究是否会成功，很难说，因为研究想法真正能奏效的很少。在此期间，一家公司相对另一家的核心优势，可能就是人才质量。</p>
  <p>Matt Turck：我提到的那条 Oriol 的推文，被 Demis Hassabis 引用转推。他说真正的秘密是研究、工程和基础设施的结合。这是 Google 的“秘方”吗？你们做了垂直整合（端到端整合）？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这确实有帮助，是重要的一部分。研究与工程的界限也很有意思。我认为随着时间推移，这条界限变得模糊：在这些很大的系统上工作时，研究看起来像工程，工程也反过来像研究。这种思维方式在 DeepMind 过去几年发生了变化：以前可能更偏传统研究心态，但现在做 Gemini 更像研究工程。</p>
  <p>基础设施也非常重要。我们在构建超级复杂的系统，因此拥有可靠、可用、可扩展的基础设施，是不让研究工程被拖慢的关键。Gemini 3 是在 TPU 上训练的，不是在英伟达芯片上训练的，这体现了端到端整合。</p>
  <h2><strong>Sebastian 的工作内容与研究品味的养成</strong></h2>
  <p>Matt Turck：你是 Gemini 3 的预训练负责人之一。这具体意味着什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这项工作包含几部分。第一部分是研究：让模型变得更好。但现在不太是我亲自跑实验，而是帮助设计实验，并与团队成员一起审查结果。</p>
  <p>第二部分是协调与集成。团队规模很大，在预训练侧包含数据、模型、基础设施、演进等，日常参与的人可能有 150 到 200 人。把所有人的工作协调成一个能共同构建的整体很复杂，也需要时间。对我来说这很重要，因为能把每个人的进步释放出来，才是我们取得最大进展的关键，而不是让少数人短期跑在前面。短期可能有效，但长期真正成功的是能整合很多人的工作。</p>
  <p>Matt Turck：你在哪里长大？你是如何成为今天的你？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我在欧洲多个地方长大，搬家比较多。我出生在荷兰，7 岁时搬到瑞士。父亲来自瑞士，母亲来自德国。我大部分学校教育以及高中开始阶段在瑞士完成，主要使用法语，也有德语部分。15 岁时我搬到意大利，在那里完成高中，大概到 19 岁。那时我原本打算去苏黎世联邦理工学院学习，但某天早上查排名时看到剑桥排在前面，就决定申请。几个月后收到录取，于是搬到剑桥，在计算机实验室完成本科和硕士。</p>
  <p>Matt Turck：你成长过程中是数学很强、偏理工、偏计算机的孩子吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我父亲有技术背景。我大概 10 或 11 岁开始和他一起写程序学习，一直很喜欢。我在学校的数学和科学一直比较轻松，数学考试几乎不需要复习也能考得很好。这在大学里明显改变，但那就是我的高中经历。</p>
  <p>Matt Turck：你从学校到现在的路径是什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这也比较幸运。硕士期间有一门课的授课人也是 DeepMind 的研究员。最后一节课结束后，我去问他能否给我内推。他让我发简历给他看看能做什么，我由此获得了 DeepMind 面试机会。那是 2018 年。我大学毕业后以研究工程师身份加入 DeepMind（当时还不是 Google DeepMind）。</p>
  <p>Matt Turck：你最开始做什么？后来如何发展到成为 Gemini 3 的预训练负责人之一？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我最开始做强化学习方向：训练无监督网络，在 Atari 环境中学习关键点，尝试让智能体玩 Atari。我做了大约 6 个月，但不太喜欢这种偏合成的部分。我更想做真实世界数据，产生更直接的真实世界影响。我总体更喜欢做“能用起来的东西”，不太喜欢纯粹学术式研究。</p>
  <p>这促使我转向表征学习：构建或训练能形成良好表征、可用于不同任务的神经网络。我参与的第一个项目叫“从真实世界数据中学习表征”。当时我们不得不把“真实世界数据”写进项目名里，因为否则大家会默认是合成环境或合成数据；这一点后来完全改变。</p>
  <p>之后在大语言模型与 Transformer 方面，我们研究 Transformer 架构，以及 BERT、XLNet 这类模型，学习这些表征并尝试改进。</p>
  <p>Matt Turck：你做过 RETRO，对吗？能谈谈吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：之后我们开始做大规模化大语言模型。首先是 Gopher，我认为那是 DeepMind 发表的第一篇大语言模型论文。那时团队大概 10 到 12 人，已经很清楚这类研究无法靠个人完成。</p>
  <p>这也是我开始做预训练、做大规模预训练的阶段。我形成了自己的研究取向，也很享受这项工作。我们训练了一个密集 Transformer 模型，参数规模约 2800 亿，数据约 3000 亿 token。现在我们不会再用当时那样的方式做事，但那是一次很棒的学习经历。</p>
  <p>之后出现了两个项目：Chinchilla 与 RETRO。Chinchilla 重新审视模型规模与数据规模如何扩展，尤其从训练计算量最优的角度：训练计算量固定时，如何训练出最好的模型？应该增加模型规模还是增加数据规模？我们重新审视了 OpenAI 的相关工作，发现相较于扩展模型规模，更应该更快扩展数据规模。这在今天仍然很相关，因为它影响训练后推理服务成本以及使用成本。</p>
  <p>RETRO 更偏架构创新：研究如何通过给模型加入从大规模文本语料库检索的能力来改进模型。与其让模型把所有知识都存进参数里，我们让模型在训练和推理时都能查找特定内容。</p>
  <p>Matt Turck：你提到“research taste”。这是什么意思？对研究者有多重要？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这很重要，也难量化。第一，研究不是孤立的；你的改进必须能与其他人的研究整合。假设你让模型变好，但让其他人使用模型难度增加 5%，这不是好权衡，因为会拖慢其他人的研究，累积下来会拖慢长期进展。</p>
  <p>第二，要对复杂性敏感。复杂性具有主观性，但我们有复杂性预算，也有研究风险累积的上限。意识到并管理它很重要。很多时候我们不一定用性能最强的版本，而是愿意牺牲一些性能，选择更低复杂度的版本，因为这能支持未来取得更多进展。</p>
  <p>Matt Turck：这也包括对什么可能有效的直觉判断吗？毕竟算力有限。&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：是的。有些人这方面更强，经验也很重要。研究侧确实受算力瓶颈限制；如果算力更多，会更快取得更多进展。你需要判断研究树上哪些方向值得探索、做哪些实验。大多数研究想法都会失败，你需要判断何时该转向别的方向，何时该继续推进。深度学习里，负面结果并不一定意味着方法不行，往往只是还没把它做成，意识到这一点也很难。</p>
  <p>Matt Turck：你们如何平衡短期与长期？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：总有关键路径事项需要做：某部分需要改进，或已知某部分不够好。我们会投入很多精力去修复这些问题。原因之一是它们能确定性地让模型变好，是较安全的投入；原因之二是那些不够好、不够完美的地方，往往在扩大规模或模型更强时暴露问题，所以需要认真解决。</p>
  <p>另一部分是探索性研究：可能进入下一版或再下一版 Gemini 的想法，潜在收益更大，但尚未完全验证。如何平衡没有明确答案，也有周期性：做 scale-up 时探索性研究更多；临近扩大新架构或新模型规模时，会更偏执行导向，重点在去风险、补齐最后不确定因素。</p>
  <h2><strong>预训练 Scaling Law 已死？从无限数据向有限数据的深层转变</strong></h2>
  <p>Matt Turck：研究与产品之间的张力如何？会不会因为与其他实验室竞赛而有压力，比如为了某些基准目标？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我认为在 Google 这类压力很少，因为领导层有研究背景。他们知道可以强推某些基准或目标，但最终重要的是研究进展与把研究做成。我个人日常几乎不感受到这种压力。</p>
  <p>Matt Turck：DeepMind 的团队如何组织？预训练有几百人？是否有后训练、对齐团队？大家如何协作？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我们有预训练团队、后训练团队。预训练侧有人做模型、数据、基础设施，也有评估（eval）。很多人低估了评估研究的重要性，但它很难做好。也有大型团队做基础设施和上线服务。</p>
  <p>Matt Turck：Gemini 3 用起来和 2.5 很不同。是否有一个关键架构决策解释差异？你会怎么描述架构？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：从高层看，架构与上一代相比变化不大，更像是多个因素叠加带来的大幅改进。它是基于 Transformer 的混合专家（MoE）架构。粗略看，你仍能在其中辨认出原始 Transformer 论文里的很多组件。</p>
  <p>Matt Turck：能用科普方式解释 MoE 吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：Transformer 大体有两块：注意力模块负责在不同 token 之间混合信息；前馈模块更多提供模型推断所需的“记忆”和计算能力，它对单个 token 计算，因此可以并行。在原始 Transformer 中，这部分是一个密集计算的隐藏层：输入线性变换到隐藏维度，经过激活函数，再线性变换回输出。</p>
  <p>混合专家的核心想法是把“使用的计算量”和“参数规模”解耦，通过动态路由，把计算分配到某些“专家”上执行，而不是把计算量与参数规模完全绑定。</p>
  <p>Matt Turck：Gemini 原生多模态。从实际角度看，这意味着什么？是否会更贵？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：原生多模态意味着不分别训练图像模型、音频模型、文本模型，而是同一个模型、同一个神经网络共同处理不同模态。</p>
  <p>成本大致有两类。第一是复杂性成本：做的事情更多，不同模态会相互作用，与研究中的不同部分产生交互，因此需要花时间处理复杂性。第二是计算成本：图像输入通常比纯文本大，朴素处理会更贵，但也有很多研究在提升效率。我认为收益总体上远大于成本，这也是我们训练这些模型的原因。</p>
  <p>Matt Turck：2025 年很多人讨论“预训练 Scaling Law 已死”。Gemini 3 是否证明 Scaling Law 仍在继续？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这些讨论对我来说有点奇怪，因为我的经验不匹配。规模在预训练中很重要，是让模型变好的关键方面，但人们高估了它：它重要，但不是唯一因素。规模带来的好处相对可预测，这就是 Scaling Law 告诉我们的。但这只是其中一部分；架构创新与数据创新同样重要，甚至今天可能比纯扩规模更重要。不过规模仍然重要。</p>
  <p>Matt Turck：今年后训练出现了强化学习规模化、测试时计算规模化。预训练这边是否也在继续加速？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：更合适的说法是这些因素会叠加。规模是一条轴，模型与数据也会提升性能。有时创新带来的收益超过继续扩规模；有时纯扩规模才是正确答案。强化学习规模化也出现了类似现象；因为我们有预训练经验，很多经验教训可以复用到强化学习规模化上。</p>
  <p>Matt Turck：Gemini 3 的预训练数据混合是什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：数据从一开始就是原生多模态的，包含许多不同来源。</p>
  <p>Matt Turck：我们会不会用完数据？合成数据今年使用增加。合成数据在哪里有帮助，哪里没有？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：合成数据很有意思，但必须非常谨慎，因为很容易用错。常见做法是用强模型生成合成数据，再用更小规模消融实验验证其效果。一个关键问题是：能否用合成数据训练未来的模型，并让这个模型比生成合成数据的模型更强？我们为此花了很多时间思考并做研究。</p>
  <p>至于是否用完数据，我不这么认为。我们也在这方面做工作。但更可能发生的是范式转变：从数据无限环境转向数据受限环境，这会改变研究方式与问题思路。一个类比是，大语言模型之前，很多人在 ImageNet 等基准上工作，也处在很数据受限的环境；那个时期的一些技术因此又变得有意思。</p>
  <p>Matt Turck：行业里还有“推理轨迹（reasoning traces）训练”的概念：让模型展示推理过程，用来训练下一代模型。你怎么看？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我不能评论具体细节。泛泛来说，这与合成数据问题相关，我们的思路类似。另一个关键主题是：模型如何用更少的数据学习。</p>
  <p>我这里的“数据受限”不一定指数据更少，而是指数据是有限的，范式从“无限”转为“有限”。</p>
  <p>从另一个角度，架构改进的含义之一是：用同样数据训练能得到更好结果；等价地，也可以用更少数据达到旧模型的同等结果。但就今天所需的数据量而言，我们仍比人类可用的数据量高出好几个数量级。人类还有进化过程等因素，这类高层换算需要很多假设，但一阶近似下，我们确实用得更多</p>
  <h2><strong>长上下文、注意力机制：未来预训练的重要方向</strong></h2>
  <p>Matt Turck：你对预训练进展的哪些方向感到兴奋&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：Gemini 1.5 在长上下文能力上有很大跃迁，这使模型与智能体能处理更长的上下文，例如在代码库上做大量工作时上下文会不断增长。未来一年左右，这方面会有更多创新：让长上下文更高效，也让模型支持更长上下文。</p>
  <p>对我们来说，注意力机制方面最近也有一些有意思的发现，会影响未来几个月的研究，我对此非常兴奋。</p>
  <p>我也想强调：进展往往来自许多因素累积。我们已经看到很多小到中等规模的改进：修复某个问题、修复某个 bug、某项研究显示出前景。这些叠加会推动大量进展。</p>
  <p>Matt Turck：RETRO 强调效率，小模型做更多；而 Gemini 3 是海量数据与长上下文。长上下文是否会让 RAG/ 搜索不再需要，一切被折叠进模型？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：RETRO 的核心是检索信息而不是存储信息，不一定是为了让模型更小。它更像是让模型在预训练意义上做更多推理，而不是只存知识。这一点今天仍然重要。</p>
  <p>直到最近，预训练的迭代周期通常比后训练慢很多，因此预训练侧做大改动风险高、耗时长。RAG 或搜索可以在后训练中做，迭代更快，也能提供很强性能。</p>
  <p>但从根本上说，我相信长期答案是以端到端、可微的方式学会这些能力：在预训练（或未来某种训练形式）中，把检索作为训练的一部分，把搜索作为训练的重要部分。我认为强化学习规模化可能开启了这个过程，但架构侧仍有很多工作。这会在未来几年出现，而不是立刻。</p>
  <p>我还想强调：让预训练更好的不只有架构，还有基础设施、数据与评估。评估非常难，在预训练中更难，因为要跨两个差距：一是小模型评估要能预测大模型 scale-up 后的方向；二是预训练评估还要能代理后训练之后的效果。评估上的进展非常重要，也很难，它帮助我们判断模型侧或数据侧的改动是否是真实改进。</p>
  <p>Matt Turck：你们内部会自己建立一套评估体系，对吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：是的，而且越来越是这样。外部基准可以用一段时间，但很快会被污染：它们会以不同形式出现在论坛或网络各处。如果训练数据覆盖到这些内容，就很难检测评估泄漏。要防止自欺、避免误以为自己更强，唯一办法是创建内部留出的评估集，并真正把它们留出。</p>
  <p>Matt Turck：对齐在预训练层面重要吗，还是主要在后训练？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：主要是后训练，但确实有一些部分与预训练相关，我们也会考虑。我不能讲太多细节。</p>
  <p>Matt Turck：如果核心数据来自互联网，而互联网有很多糟糕内容，对齐的最基础做法是否就是把某些内容从模型中排除？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我没有明确结论。但你不希望模型去做那些糟糕事情。从根本层面，模型需要知道那些事情是什么，因此至少要训练一部分内容，让它知道并学会避开；否则用户提到糟糕内容时，模型可能连在说什么都不知道，也就无法判断“这是糟糕的事情”。</p>
  <p>持续学习很重要&nbsp;</p>
  <p>Matt Turck：Deep Think 是不同模型，还是同一模型的一部分？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我不能评论太多。</p>
  <p>Matt Turck：模型“思考”10 秒、20 秒时幕后发生什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：核心是生成“思考”。不只是在模型深度方向做计算，也在序列长度方向做计算，让模型在序列上进行更多推理。模型会形成假设、检验假设、调用工具验证、进行搜索调用等，最后可能查看思考过程并给用户确定答案。</p>
  <p>Matt Turck：智能体部分，以及 Google 的 antigravity 项目，你觉得哪里有意思？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我们日常很多工作偏执行，例如盯实验。我认为智能体在这里影响最大。</p>
  <p>从预训练角度看，感知与视觉很重要，因为模型需要与电脑屏幕交互；屏幕理解做得好非常关键。</p>
  <p>Matt Turck：vibe coding（氛围编程）是预训练带来的还是后训练带来的？如何把“氛围”做进模型？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：你问五个研究者会得到五种答案。也有人谈“大模型气场”，认为更大模型可能“感觉”不同。我不会用这些词来表述，但我认为模型“氛围 / 感觉”更多来自预训练，而非后训练。至于 vibe coding 本身，我认为更偏强化学习规模化与后训练：可以获得大量数据，把模型训练到在这方面做得很好。</p>
  <p>Matt Turck：什么是持续学习？它会如何影响重训？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：持续学习是让模型随着新知识出现而更新。例如明天出现新科学突破，我们昨天训练的基础模型在预训练阶段并不知道它。</p>
  <p>过去几年这方面进展很大，主要在后训练：使用搜索工具并进行搜索调用，模型在某种意义上能访问新信息。这也类似 RETRO 的思路：通过检索，把知识语料与推理部分外化。</p>
  <p>预训练侧也有关联：如果能持续扩展用户上下文，模型在上下文中获得越来越多信息，在某种程度上就具备持续学习成分。</p>
  <p>更范式性的变化是：是否能改变训练算法，使模型可以在来自现实世界的数据流上持续训练。</p>
  <p>最值得关注的研究热点&nbsp;</p>
  <p>Matt Turck：持续学习之外，你觉得今天哪些研究方向最值得关注？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：很多小改动仍在累积，这是历史上推动进步的主要方式，我不认为它会停止。长上下文架构与研究是一个方面；注意力机制是一个方面；从无限数据转向有限数据的范式转变也会带来很多变化与有趣研究。</p>
  <p>另一个重要方面是：使用模型的人增长很快，因此预训练侧也越来越要考虑上线服务成本。预训练侧能做什么，让模型质量更好、服务更便宜，并在推理时消耗更少资源。</p>
  <p>Matt Turck：给想成为你这样的学生或博士生一些建议：几年尺度应该聚焦什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：越来越重要的是：能做研究，同时理解系统层面。我们在构建复杂系统，能理解从 TPU 到研究的整套堆栈，是一种优势：能发现不同层之间的空白，也能把研究想法一路推演到 TPU 堆栈层面的影响。能做到这一点的人会产生很大影响。应关注研究、工程与系统结合，而不仅是纯架构研究。</p>
  <p>我也对 RETRO 那类检索研究很感兴趣。我认为它直到现在才接近成熟，但情况在变化。未来几年，让类似方法对 Gemini 这类领先模型变得可行，并非不合理。</p>
  <p>Matt Turck：为什么以前不成熟，为什么可能改变？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：与复杂性有关，也与这样一个事实有关：它带来的能力可以在后训练中更快迭代。用搜索与后训练数据，可以用更简单方式给模型提供相似能力。随着后训练与强化学习规模化发展，重心可能再次向预训练侧转移。</p>
  <p>Matt Turck：你认为 AI 领域有哪些方向被过度投资？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：情况已经好很多。两年前我看到人们还在做专门模型来解决一些任务，而这些任务可能在半年到一年内就会被通用模型覆盖。现在大家更相信：对不需要极度专门化的任务，用通用模型更合理，即使不是当前版本，下一版本可能就能做到。这意味着如何使用模型、以及 harness 等研究变得越来越重要；也包括如何让模型与这些 harness 更稳健、能从错误中恢复。</p>
  <p>Matt Turck：对创业公司有什么建议？基础模型越来越强，似乎缩小了创业空间。&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：可以比较一年前或一年半前模型能做什么，再看今天能做什么，然后外推。模型正在改进的领域会继续改进；也可能有一些领域进展不大，那些可能更值得研究。我没有具体例子，这是总体建议。</p>
  <p>Matt Turck：从你个人经历的角度，你对未来一年到两年有什么期待？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我很喜欢日常工作中的一点：与很多人一起工作，并向许多研究人员学习。这在很大程度上驱动着我。每天我来上班都会与非常聪明的人交流，他们会教我以前不知道的东西，我很喜欢这部分。</p>
  <p>我已经多次提到：有太多因素会叠加，很多方面仍有改进空间。我非常好奇，因为我看不到这类工作继续带来进步的尽头。能够见证并看到这能把我们带到多远，非常有意思。至少在接下来一年左右，我看不到它会放缓。</p>
  <p><strong>参考链接：</strong></p>
  <p>https://www.youtube.com/watch?v=cNGDAqFXvew&amp;t=442s</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247652167&amp;idx=1&amp;sn=b5242de056a538ecc5b49fc57a615232&amp;chksm=fa1f2ffdee820996bd2b3bc1f51ef568c2a7b53997bd5a96190501ef6cb4807143a19fd18f4f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID：ai-front）</a>，作者：高允毅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612229188715522</id>
            <title>百度等巨头、A股公司齐入局，2025年具身智能CVC投资力度全揭秘</title>
            <link>https://www.36kr.com/p/3612229188715522</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612229188715522</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:19:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着人工智能从“感知智能”向“具身智能”跃迁，机器人技术正加速实现从虚拟交互到物理执行的突破。具身智能不仅成为通向通用智能的关键路径，更被视作新一轮产业变革的核心引擎。&nbsp;</p>
  <p>在此背景下，资本市场对具身智能赛道的关注度持续飙升。&nbsp;</p>
  <p>据IT桔子数据，截至2025年12月21日，今年中国具身智能赛道的融资事件有超305起，较去年增长了近2倍；总融资额估算超过了380亿元。&nbsp;</p>
  <p>数据背后，是超过600多家投资方的“真金”加码助力。其中百度、阿里、美团等大厂及各类产业资本组成的CVC力量，凭借资本与场景的双重优势，成为推动赛道发展的核心动能。&nbsp;</p>
  <p>今年产业资本对具身智能创业企业的投资力度究竟如何？还有哪些CVC产业方比较活跃？&nbsp;</p>
  <h2><strong>&nbsp;一、核心力量：互联网/科技/AI巨头的投资布局与战略解读</strong></h2>
  <p>互联网、科技及AI巨头凭借技术积淀、场景资源与资本实力，在具身智能投资领域展现出高度的战略自觉性，其布局并非盲目撒网，而是紧密围绕自身核心业务生态，形成了差异化且精准的投资逻辑，具体投资数据如下表所示：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_763ea77f12a04679b0f20a1e4cd6bda0@000000_oswg336649oswg1080oswg918_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据IT桔子据，大厂巨头在具身智能赛道的投资呈现出“高频次、强聚焦”的特征：8家核心大厂全年投资次数合计达62次，其中百度风投以13次投资位居首位，联想创投/联想之星以11次紧随其后，国香资本（商汤）与蚂蚁集团均以8次投资并列第三，形成第一投资梯队。&nbsp;</p>
  <p>投资力度上，8家大厂全年估算投资总额区间达14.5-34亿元，除科大讯飞单家投资金额或少于1亿元外，百度风投、联想创投/联想之星、蚂蚁集团、美团/美团龙珠、京东等均有2-5亿元的大额布局，彰显出大厂对赛道的坚定信心。&nbsp;</p>
  <p>基于上述投资数据，大厂的战略逻辑可归纳为三大核心方向：&nbsp;</p>
  <p><strong>其一，技术基座卡位。</strong></p>
  <p>以百度风投为代表，聚焦具身智能大脑这一核心技术领域，通过投资星海图等企业，强化在大模型与机器人融合技术上的布局，构建“云端训练+边缘计算+终端执行”的技术闭环。&nbsp;</p>
  <p>阿里巴巴则依托通义千问大模型优势，投资原力灵机等企业，推动多模态模型在具身智能硬件中的落地，夯实技术基座。&nbsp;</p>
  <p><strong>其二，场景协同赋能。</strong></p>
  <p>美团的投资紧密围绕“科技+零售”战略，布局具身智能大脑与机器人本体，旨在通过无人配送、智能履约等机器人应用，降低服务成本、提升服务密度，与自身本地生活服务生态形成深度协同。&nbsp;</p>
  <p>京东则聚焦电商零售场景，通过投资智元机器人等企业，推动具身智能机器人在仓储、物流、居家服务等场景的应用，构建“硬件+软件+服务”的生态闭环。&nbsp;</p>
  <p><strong>其三，生态圈层构建。</strong></p>
  <p>大厂普遍摒弃粗放式投资，转而追求商业生态互补与技术协同，通过投资覆盖机器人本体、算法、零部件等关键环节，形成完整的产业生态链。例如，联想创投聚焦机器人应用场景，蚂蚁集团侧重AI算法，讯飞创投今年侧重投资机器人零部件及应用领域，均是通过精准投资完善自身生态的关键拼图。&nbsp;</p>
  <p>更多可参见：美团对机器人的投资布局，京东对机器人的投资布局&nbsp;</p>
  <h2><strong>二、生态补位：传统企业CVC的跨界布局</strong></h2>
  <p>除科技巨头外，传统企业尤其是A股上市公司旗下CVC成为2025年具身智能投资的重要补充力量，其凭借产业资源优势，以跨界投资的方式切入赛道，寻求产业升级与新增长曲线，具体投资情况如下表：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_89ff7e0342344e17b49a1364dbd79729@000000_oswg302462oswg1080oswg934_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>根据IT桔子统计，8家核心传统企业CVC全年对具身智能创业企业的投资次数合计达43次，投资力度估算总额超5亿元。&nbsp;</p>
  <p>其中首程资本以10次投资成为传统企业CVC中的投资频次冠军，其投资金额或达2-6亿元，与科技大厂的大额布局不相上下；多家传媒上市公司投资的GP央视融媒体产业投资基金以6次投资位居第二，东方精工虽投资次数仅3次，但凭借数亿元+的投资力度展现出强劲的布局决心。&nbsp;</p>
  <p>数据显示，部分新能源车企和制造类企业CVC的投资呈现出鲜明的产业协同属性：&nbsp;</p>
  <p>典型CVC如上汽（尚颀资本）、歌尔股份（同歌创投）、龙旗科技聚焦机器人本体制造与硬件环节，与自身制造优势形成互补。&nbsp;</p>
  <p>其中，尚颀资本作为上汽集团旗下私募股权投资平台，通过投资逐际动力，并推动其与上汽集团在具身智能领域展开深度合作，合作核心是双方联合研发适用于汽车生产流水线的工业具身机器人。&nbsp;</p>
  <p>据悉，2025年7月份，<strong>上汽集团与逐际动力</strong>LimX Dynamics在北京正式签署战略合作备忘录，宣布建立长期战略合作伙伴关系，并成立具身智能联合实验室，携手推动具身智能在汽车产业链的技术创新、研发协同和人才培养。&nbsp;</p>
  <p>另外，A股上市公司龙旗科技今年3月参与智元机器人的B轮数亿元投资，半年后就促成了相关的战略合作落地。&nbsp;</p>
  <p>10月，<strong>智元机器人与龙旗科技</strong>签署战略合作协议，龙旗科技下达‌数亿元规模的框架订单‌，采购智元精灵G2机器人，预计部署‌近千台‌，这是国内工业具身智能领域的重要订单。&nbsp;</p>
  <p>该合作方案以消费电子制造为切入点，聚焦验证具身智能在‌柔性生产‌和‌质量控制‌中的价值，为工业巡检等垂类场景提供可复制模式，推动制造业运营效率提升。‌&nbsp;</p>
  <p>另外一些CVC则呈现了不同的投资路径，比如平台型企业如中国移动（中移创新产业基金）则通过投资机器人本体企业，探索智能硬件与通信服务的融合场景。首程资本、央视融媒体产业投资基金等则采取全面覆盖策略，广泛布局赛道关键环节，抢占未来产业变革先机。&nbsp;</p>
  <h2><strong>&nbsp;三、新生势力：新兴机器人公司的投资入局</strong></h2>
  <p>值得关注的是，除传统大厂与传统企业外，作为新兴机器人创业公司，他们左手从上市公司、巨头和大厂手里融资拿钱，右手开始积极通过投资参与具身智能生态的构建，具体投资数据如下表：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_530f060758364c1a9a52fc70a52f32d9@000000_oswg160740oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据IT桔子数据，3家新兴机器人公司全年对具身智能企业的投资次数合计达16次。&nbsp;</p>
  <p>其中智元机器人以9次投资成为该阵营的核心力量，投资频次非常高，但作为独角兽公司，其投资金额力度相比上市公司和科技大厂要少很多，单笔投资主要在数百万元及数千万元级别，鲜少过亿元。&nbsp;</p>
  <p>银河通用机器人以4次投资紧随其后，乐聚机器人以3次投资完成初步布局，整体呈现出“高频次、精准化”的投资特征。&nbsp;</p>
  <p>这类新兴企业的投资逻辑主要基于技术协同与生态互补，共同推动具身智能产业的技术迭代与生态完善。&nbsp;</p>
  <p>比如，今年8月，智元机器人正式入股深圳玉树智能机器人。玉树智能背靠A股环卫上市公司，是玉禾田集团旗下孙公司。&nbsp;</p>
  <p>早在6月，双方就宣布签署战略合作协议，成立“<strong>深圳玉树具身机器人智创中心</strong>”，专注于<strong>具身机器人的数据采集与技术创新</strong>，重点为机器人通用智能应用打基础，解决行业长期依赖仿真数据的局限性。&nbsp;</p>
  <p>智元机器人一边与上市公司合作拿下订单，推进商业化；另一边通过生态式投资，不仅强化了自身在赛道中的生态话语权，也为行业培育了更多技术创新力量。&nbsp;</p>
  <p>总结来说，2025年具身智能赛道的CVC投资呈现出“科技巨头引领、传统企业补位、新兴企业协同”的多元格局，资本流向与投资布局均围绕技术突破与场景落地展开，彰显了赛道从概念炒作向价值落地的转型趋势。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjQ2NzA2Mg==&amp;mid=2649626450&amp;idx=1&amp;sn=a6c3fdf1499b7f404fd8d4af58b8bf73&amp;chksm=bfbe275eafab56ba3284cfa18c65998801b0d069d1df4cf6de93fa6685941b6cc6e0268828f6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT桔子”（ID：itjuzi521）</a>，作者：吴梅梅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612280889558025</id>
            <title>算法算不到的意外：Waymo无人车，成了临时产房</title>
            <link>https://www.36kr.com/p/3612280889558025</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612280889558025</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:51:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】又一个生命在Waymo后座里降临！科技追求可控，但生命偏要在最意外的时刻闯进来。当自动驾驶撞上人类最混乱的瞬间，硅谷才真正意识到：世界不会按算法的节奏运行。</strong></p>
  <p>旧金山的深夜，一辆Waymo无人车行驶在去往UCSF医院的路上。</p>
  <p>激光雷达、摄像头、毫米波雷达把整座城市扫描得一清二楚，连夜间几厘米的障碍物都能识别。</p>
  <p>可在车内，是另一幅完全失控的画面<strong>：</strong>&nbsp;孕妇痛得呼吸紊乱，紧紧握着座椅边缘，完全无法预测下一秒会发生什么。</p>
  <p>Waymo的远程团队首先察觉到异样。系统监测到「乘客坐姿变化剧烈、肢体动作不规律」，声音检测更是发现了高强度波动。</p>
  <p>系统随即启动了自动报警流程，向911发出求助。</p>
  <p>无人车调整了路线和车速，最终，孩子还是抢在到达医院之前降生了。</p>
  <p>Waymo事后给媒体的回应，倒是保持了硅谷式的幽默：</p>
  <blockquote>
   <p>有些新乘客，就是等不及体验人生第一程ride。</p>
  </blockquote>
  <p>而这项婴儿无需送往医院的「光荣传统」，也被延续了下来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_43fde52378ec42f1b018eb59eabef9e7@46958_oswg513071oswg870oswg672_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>最意外，也是最古老的「产房」</strong></h2>
  <p>如果你以为，这只是无人车时代才有的新鲜事，那可就大错特错了。</p>
  <p>「后座分娩」，算得上是人类延续了几十年的「光荣传统」。</p>
  <p>医学上，产妇从出现剧烈宫缩到生产，可能只有几十分钟。</p>
  <p>而在城市里，救护车的平均等待时间往往比人们想象得更长。</p>
  <p>当交通拥堵、救护车延迟、产程突然加速，这些条件叠在一起，就极有可能导致「来不及去医院」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_891a264b1abc48acad0dd2721e21941b@46958_oswg314013oswg672oswg423_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但是无论时代背景如何变迁，这种「生命加速」的瞬间从未缺席。</p>
  <p>早在2015年，一位印度德里妈妈因为救护车一直没来，只能叫Uber，最终她在出租车后座诞下了孩子。</p>
  <p>事后，这对夫妇给孩子起名为Uber。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7e30785aad4e46d48579a5ac0a043483@46958_oswg158851oswg600oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在英国伦敦，有乘客在Uber上提前临盆，司机和家人在狭窄的后座上帮忙接生。</p>
  <p>事后大家还笑谈要给孩子起个特别的名字。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b908a6d57c7341a88f743250a13e0e8e@46958_oswg53684oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">伦敦乘客在Uber后座提前临盆，司机和家人合力接生</p>
  <p>在美国纽约，也有出租车司机见证过这样的突发状况。</p>
  <p>司机一边打电话一边指导乘客呼吸，沉着地稳定局面。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_74f11479ce0f41cf8711c1e3d77c1909@46958_oswg119578oswg1024oswg682_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Luis Leonardo和他的丰田汉兰达SUV</p>
  <p>无论是伦敦黑出租、纽约黄出租，还是Uber网约车，后座的空间比方向盘更接近生命的诞生。</p>
  <p>正因如此，才会出现伦敦、纽约、印度、加州这些看似分散，却有共同逻辑的故事。</p>
  <p>Waymo只是把这个混乱又惊喜的「后座分娩传统」，带入了硅谷的自动驾驶时代。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8aef724a95754fdd872344e09b2251c0@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p class="img-desc">Waymo官方发布的传感器可视化画面（彩色点云 / 物体框选）</p>
  <p>当然，形式变了。但那种突如其来的惊喜和无可避免的混乱感，跟老出租车时代，也没太大区别。</p>
  <h2><strong>当自动驾驶遇上生命的失控</strong></h2>
  <p>自动驾驶，从诞生起就在追求一种极致的「可控」。</p>
  <p>路线可控、速度可控、行为可控，甚至连紧急状况都被写进了标准操作程序（SOP）。</p>
  <p>Waymo的代码里密密麻麻都是交通规则、优先级、避障逻辑……但唯独没有一条，是写给人类的身体节奏的。</p>
  <p>生命不会等系统加载完毕，更不会遵守「最佳路径规划」。</p>
  <p>它总是突兀、混乱、不讲逻辑，是算法里最难处理的非线性变量。</p>
  <p>如果无人车遇到非交通类紧急情况，比如乘客突发抽搐、孕妇临盆、儿童窒息......车应该怎么做？它会自动报警吗？会绕开红灯吗？有权利「擅自加速」吗？</p>
  <p>乘客的身体数据是否应该被系统监测？监测到什么程度算越界？又是谁来定义「危险」？</p>
  <p>Waymo远程团队这次能及时发现异常，是因为系统检测到了「姿态剧烈变化」。</p>
  <p>但如果乘客是独自坐车并昏迷呢？如果穿着厚衣服遮挡了动作呢？这些都没有真正的答案。</p>
  <p>自动驾驶正在把「非交通事件」推入一个灰色地带，而无人车的责任边界、能力边界、伦理边界，都还远未厘清。</p>
  <p>生命也再次证明了，人类的节奏，永远不会向技术的节奏低头。</p>
  <p>Waymo可以提前预测拥堵、自动避开施工、计算出最快路线，但它永远预测不了一个孩子什么时候降生。</p>
  <p>这就是自动驾驶无法修复的最温柔的「Bug」。</p>
  <h2><strong>自动驾驶时代的荒诞图鉴</strong></h2>
  <p>Waymo车里的这一幕，其实反映了一个更大的问题：</p>
  <p>我们把世界交给AI，它总会被「人类的混乱」打个措手不及。</p>
  <p>旧金山街头，孩子直接骑到了外卖机器人身上，而机器人只能继续按程序移动，完全不知道自己已经成了人类的玩具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_04bf658cec334452ae88b57c69b896ed@46958_oswg222641oswg1024oswg951_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>算法在预测情绪时经常失灵。人们随便一句无伤大雅的抱怨，也能让AI误判为严重的心理危机。</p>
  <p>而像「机器人接生」这种桥段，更是完全不在任何硅谷PR手册的FAQ列表里。</p>
  <p>事实上，无人车遇到的离谱状况，远比Waymo的官方案例多得多。</p>
  <p>在酒驾执法行动中，警方曾经试图把无人车当成「可能的醉驾对象」拦下，结果发现根本没人坐在里面，只能报警联系公司。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2698972c862c4373a3f3e2ed0703d4a9@46958_oswg85404oswg1024oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">圣布鲁诺警察局的警员发现这辆无人驾驶汽车在红绿灯处当着警察的面非法掉头</p>
  <p>有路人看到一群Waymo停在路中央，实际上是软件更新导致短暂同步卡顿；</p>
  <p>还有人在深夜把无人车当成移动KTV，整个车厢被音响震得像夜店。</p>
  <p>科技在努力把世界压缩成一条清晰、线性、可预测的曲线。</p>
  <p>但人类的故事，本来就是跳跃式的、情绪化的、充满失控味道的。</p>
  <p>AI越进步，越容易无意间撞上这些「计划外的瞬间」<strong>。</strong>&nbsp;代码里也没有定义的温柔、荒诞和意外。</p>
  <p>AI的时间是平滑的、数学化的，是可优化的曲线。</p>
  <p>而人类的时间却是突然的，是跳跃的，是会被情绪、疼痛、天气、交通堵塞随时打断的。</p>
  <p>技术想让世界越来越可靠、越来越稳定，可生活的本质，从来不是稳定，而是突如其来的改变。</p>
  <p>自动驾驶会越来越聪明，但人类的混乱与温度，也会一直存在。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8c5037eb9b8642f997a21e1986e5e377@46958_oswg81833oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Waymo的后座成了临时产房，硅谷所有的算法、传感器、路线规划都静静退到了一边。</p>
  <p>科技能把道路铺得笔直，却永远预测不了生命什么时候降临。</p>
  <p>无人车可以自动驾驶，但人类的故事，从来不是自动的。</p>
  <p>它带着意外、带着疼痛，也带着一种无法被简化成流程的温度。</p>
  <p>也许未来某一天，Waymo真的会把「突发分娩应急流程」写进产品文档里。</p>
  <p>可生命的节奏和力量，永远不会因为一段代码而改变。</p>
  <p>参考资料：https://x.com/TechCrunch/status/1998978439110603018&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/kJf786Nf_Ei0SGyvUeU2SQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：倾倾&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257529218308</id>
            <title>超越GPT-5、Gemini Deep Research，人大高瓴AI金融分析师，查数据、画图表、写研报样样精通</title>
            <link>https://www.36kr.com/p/3612257529218308</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257529218308</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:50:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>能自动查数据、写分析、画专业金融图表的AI金融分析师来了！</p>
  <p>最近，中国人民大学高瓴人工智能学院提出了一个面向真实金融投研场景的多模态研报生成系统——<strong>玉兰·融观</strong>（Yulan-FinSight）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7bfea04bb94847c69da4961a2825bbcb@46958_oswg446663oswg1080oswg535_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>面对用户的研究需求，FinSight能够自动拆解任务，从互联网和金融数据库中搜集包括股价、财报、新闻在内的<strong>多源异构数据</strong>，并生成包含“发展历程”、“核心业务架构”、“竞争格局”等章节的<strong>万字图文报告</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_33659d329ba645fdbc45562d1f53b36e@46958_oswg181916oswg1080oswg574_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>该系统也在<strong>AFAC 2025 金融智能创新大赛挑战组</strong>的1289支队伍中夺冠，并在多项评测中超越了GPT-5 w/Search、OpenAI Deep Research与Gemini-2.5-Pro Deep Research，展现出接近人类专家的金融分析与写作能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a0fa9a2298cd478986af65efa07d2f15@46958_oswg46846oswg1080oswg361_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>下面来看详细内容。</p>
  <h2><strong>为什么通用AI做不好金融研报？</strong></h2>
  <p>在研究者看来，问题的关键并不在于模型“不会写字”，而在于金融行业的研究报告本身是一项<strong>高度结构化、强逻辑、强可视化</strong>的专家级工作，涉及多个流程。</p>
  <p>相比通用问答、检索或文本生成任务，金融投研对数据整合能力、分析深度以及表达形式均提出了更高要求。</p>
  <p>具体而言，现有通用AI系统主要面临三方面挑战：</p>
  <p><strong>1、领域知识与数据割裂：</strong></p>
  <p>通用搜索系统难以有效整合股价、财务报表等结构化金融数据与新闻、公告等非结构化信息。由于缺乏统一的数据表示与多智能体协作分析机制，系统往往只能对单一信息源进行浅层处理，难以形成系统性的金融洞察。</p>
  <p><strong>2、专业级可视化能力缺失：</strong></p>
  <p>金融研报高度依赖图表来传递高密度信息，但现有模型多只能生成静态图片或简单折线图，难以支持多维对比、事件标注等专业金融可视化需求，图文之间也缺乏严格的数据一致性约束，例如，图文无关或图文信息矛盾与冲突。</p>
  <p><strong>3、缺乏“迭代式研究”能力：</strong></p>
  <p>绝大多数系统仍采用固定的“先检索—后生成”流程，研究路径一旦确定便难以调整。</p>
  <p>相比之下，人类分析师往往会根据中间发现不断修正研究重点，而这种基于中间结果的动态策略调整能力，正是现有通用AI系统普遍欠缺的部分。</p>
  <h2><strong>FinSight的核心思路：像金融分析师一样工作</strong></h2>
  <p>为突破上述限制，FinSight并未简单地“堆模型”，而是从认知流程入手，模拟人类金融专家的工作方式，并提出了三项关键技术创新。</p>
  <h3><strong>核心架构：代码驱动的可变内存智能体架构</strong></h3>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b63682d7329b4ebb993012325bce847f@46958_oswg359272oswg1080oswg611_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>FinSight的底层采用了一种全新的、名为<strong>Code-Driven Variable-Memory</strong>（CAVM）的多智能体架构。</p>
  <p>如图所示，现有Agent 架构本质上仍受限于对话式记忆范式，即以消息或任务进度等历史作为状态载体。这一范式在任务复杂度与流程长度增长时，容易暴露出表达能力与可控性的结构性瓶颈。</p>
  <p>CAVM将这一范式重构为代码驱动的变量记忆空间。系统不再以自然语言对话作为协作媒介，而是将数据、工具与中间推理结果统一映射为可读写的程序变量，由多个<strong>Code Agent</strong>通过共享变量空间完成协同推理。</p>
  <p>通过将“记忆”从消息序列提升为可操作的变量结构，CAVM 使复杂任务得以被显式建模、持续修正与模块化组合，为<strong>长时程、多流程</strong>的专家级推理提供了必要的结构支撑。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_dcff242f7e39449d9ff4b5d567fbc429@46958_oswg185178oswg846oswg632_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>在这一设计中，数据、工具和智能体被统一抽象为可编程变量空间：</p>
  <p>财务报表、行情数据、新闻文本作为数据变量</p>
  <p>搜索、分析、绘图等能力作为工具变量</p>
  <p>不同功能的Agent通过Python代码进行调度与协作</p>
  <p>这种“以代码为中枢”的设计，使系统能够高效处理大规模异构金融数据，并支持复杂的多流程任务协作。&nbsp;</p>
  <h3><strong>视觉突破：迭代式视觉增强机制</strong></h3>
  <p>针对金融图表生成中普遍存在的专业性与可信度问题，研究者们提出了<strong>Iterative Vision-Enhanced Mechanism</strong>，将绘图过程建模为一个可迭代优化的视觉生成问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b890901e59734d91a36304e6ca3fde3e@46958_oswg130918oswg1080oswg462_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>该机制采用了<strong>Actor–Critic 协作范式</strong>：</p>
  <p>文本大模型作为<strong>Actor</strong>，负责生成可编译、可执行的绘图代码，充分发挥其在代码生成与逻辑控制上的优势；而视觉语言模型则作为<strong>Critic</strong>，直接对图像进行视觉层面的审视，从数完整性与整体美观性等维度提供反馈。</p>
  <p>这一设计的关键在于<strong>优势互补</strong>：语言模型擅长编码与思考，却难以获取真实的视觉反馈；视觉模型具备强大的感知与判别能力，但在复杂代码生成上能力受限。</p>
  <p>通过将二者解耦并置于闭环中，系统在<strong>test time</strong>通过多轮“生成—评估—修正”实现持续优化，使绘图质量随迭代次数自然提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_cf8bae62349343718f1e33201615fd82@46958_oswg165534oswg705oswg512_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>最终，系统能够稳定生成包含双轴对齐、事件标注以及复杂结构的专业金融图表，如图所示，将原本一次性生成的静态结果，转化为一种<strong>test-time scaling</strong>的过程。</p>
  <h3><strong>两阶段写作框架：先分析，再成文</strong></h3>
  <p>在写作层面，FinSight并不试图一次性生成完整的长篇研报，而是将研报写作重构为<strong>“分析—整合”</strong>的两阶段过程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_0503fb07a6464e02beccb44b951002aa@46958_oswg119272oswg784oswg648_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>首先，系统生成一组<strong>“分析链”</strong>（Chain-of-Analysis，CoA）：每条分析链对应一个明确的子任务（如公司历程、财务分析、竞争对手分析、风险因素等），在局部范围内完成证据收集、关键判断与核心结论提炼。</p>
  <p>之所以需要这一步，是因为一份研究报告往往由多个子问题耦合构成，若直接端到端生成长文，很难兼顾所有的分析准确性和深度。</p>
  <p>随后，系统以这些CoA作为“骨架”，将分散的洞察在全局层面进行组织与编排，生成大纲并分章节逐步写作：在保证章节结构与论证链条连贯的同时，把文本叙述、数据引用与图表呈现进行对齐，最终合成为一份逻辑自洽的长篇报告。</p>
  <p>这种<strong>“先分析、后写作”</strong>的策略有效避免了长文常见的逻辑松散问题，使报告在篇幅超过2万字时仍保持结构清晰、论证深入。</p>
  <p>为了进一步保证长篇研报中的事实准确性与图文一致性，作者在写作阶段还引入了一种<strong>生成式检索</strong>（Generative Retrieval）&nbsp;机制。</p>
  <p>不同于传统“先检索、后生成”的后处理做法，该方法将检索过程嵌入写作本身：模型在生成具体段落时，会根据当前的分析链与写作上下文，动态生成数据和图片的索引标识符，再通过后处理统一嵌入。</p>
  <p>这样一来，引用准确性和图文一致性得到了最大的保证。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_9553889edba64471b75d606a95366c6f@46958_oswg780249oswg1080oswg1083_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>通过这种方式，FinSight能够在长篇写作过程中持续对齐文本叙述、数据来源与可视化结果，避免常见的事实错配与图文脱节问题，从而在报告篇幅不断扩展的情况下，依然保持整体逻辑与证据链的稳定性与一致性。</p>
  <h2><strong>实验结果：全面超越现有Deep Research系统</strong></h2>
  <p>作者们在涵盖公司研究与行业研究的高质量基准测试上，对FinSight进行了系统评估。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7289b76c9d9541ce9ebb92a9df876807@46958_oswg257358oswg1080oswg440_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>结果显示，FinSight在事实准确性、分析深度与呈现质量三项核心指标上均显著优于Gemini-2.5-Pro Deep Research与OpenAI Deep Research，综合评分达到<strong>8.09</strong>。</p>
  <p>在可视化维度上，得益于迭代式视觉增强机制，FinSight获得<strong>9.00</strong>的评分，明显领先对比系统，体现出对专业金融图表生成能力的有效提升。</p>
  <p>而迭代式绘图的效果分析同样惊艳：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_e9929d477a324dd3a207e22e7d9c9dea@46958_oswg169246oswg1080oswg371_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在长文本生成场景中，系统生成的研报平均长度超过20000字，包含50余张图表与结构化数据引用，且随着篇幅增长，报告质量保持稳定，未出现显著退化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1a804390e3f0425c8afac96546732344@46958_oswg276565oswg1080oswg541_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，在AFAC 2025金融智能创新大赛中，FinSight在来自企业与高校的1289支参赛队伍中<strong>排名第一</strong>，获得挑战组赛题四冠军，进一步验证了其在真实场景中的实用性与鲁棒性。</p>
  <p>研究者认为，FinSight并非仅是一个金融工具，而是展示了Agent架构在高复杂度垂直领域的潜力。</p>
  <p>通过统一数据、工具与智能体，并引入视觉与写作的多阶段闭环，AI系统<strong>首次</strong>在金融投研这一“专家密集型”场景中，展现出接近人类分析师的工作能力。</p>
  <p>这一范式的意义不止于金融。</p>
  <p>它表明，在那些高度依赖专业知识、长时程推理与多模态表达的“专家密集型”场景中，AI 系统不再只是信息汇总器，而开始承担起类似人类专家的工作方式：</p>
  <p>分解问题、验证假设、修正结论，并最终形成可被审阅与追溯的完整成果。</p>
  <p>从这个角度看，<strong>FinSight更像是一个起点</strong>。</p>
  <p>随着Agent架构不断成熟，未来的科研分析、法律研判、医疗决策等复杂领域，或将逐步迎来以专家级AI Agent为核心的新一代生产力形态。</p>
  <p>论文及项目作者：中国人民大学高瓴人工智能学院：金佳杰、张宇尧、许一孟、钱泓锦、朱余韬、窦志成</p>
  <p>论文链接：https://arxiv.org/abs/2510.16844</p>
  <p>代码链接：https://github.com/RUC-NLPIR/FinSight</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/F7l6bVXzhe7Ihc7ThM47sQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：FinSight团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257612006403</id>
            <title>第一批拿12.8万月薪的实习生已经出现，AI人才抢夺战真的好激烈</title>
            <link>https://www.36kr.com/p/3612257612006403</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257612006403</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:49:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好震惊，好意外，现在一份4–6个月的AI相关实习，月薪已经接近14万人民币了！</p>
  <p>而且<strong>这个价格不是个例</strong>——</p>
  <p>OpenAI、Anthropic、Meta、Google DeepMind等巨头，都为实习、Fellowship、Residency这类短期岗位，开出足以对标全职研究员的价格。</p>
  <p>Business Insider最新披露的一组数据显示，目前AI相关实习和研究型短期项目的月薪，已经普遍来到7000–18000美元区间，折合人民币约4.9-12.6万元。</p>
  <p>换算成年薪水平，是不是<strong>已经明显超出大多数行业对“实习生”这一角色的传统认知</strong>……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b1209f9a6ea04639984f1c41be558495@46958_oswg99889oswg232oswg224_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>真·AI人才的生活，我的梦（没错已经开始白日做梦了）。</p>
  <p>书归正传。</p>
  <p>继大厂、巨头为成熟的AI人才大动干戈，甚至扎克伯格为了挖OpenAI的人亲自洗手作羹汤端到想挖的人嘴边过后，<strong>这场纷争终于开始波及那些还没有正式毕业、甚至刚刚进入研究路径不久的人。</strong></p>
  <h2><strong>水涨船高的AI实习工资</strong></h2>
  <p>在薪酬层面，实习生、学生研究员、驻留项目，已经可以和全职研究岗站在同一水平线上。</p>
  <p>我们先展开来看看硅谷那边的具体情况。</p>
  <h3><strong>OpenAI</strong></h3>
  <p>OpenAI发起了一个<strong>周期为6个月的驻留计划</strong>。</p>
  <p>参与者以全职员工身份加入研究团队，直接参与前沿模型和系统研究。</p>
  <p>公开信息显示，该项目工作地点在旧金山，月薪约为18300美元（约合12.8万）。</p>
  <p>最重要的是，项目结束后，计划参与者有可能转正。</p>
  <p>不管是工作强度还是薪酬，都已经可以和OpenAI本身的正式岗位媲美，只不过有一个“6个月”的期限罢了。</p>
  <h3><strong>Anthropic</strong></h3>
  <p>Anthropic的<strong>AI Safety Fellow项目</strong>有异曲同工之妙。</p>
  <p>这个为期4个月的全职研究型人才计划在伯克利或伦敦办公，核心目标是推动AI安全方向的公开研究产出。</p>
  <p>Anthropic披露，往届的AI Safety Fellow项目中，有超过80%的成员产出了论文，有的成果还以其它形式公开。</p>
  <p>参与者不仅可以获得每周3850美元（约合2.7万元）的津贴，还能按月使用约15000美元（约合10.5万）的算力支持。</p>
  <p>从投入成本来看，这个补贴已经不能算是传统意义上的实习补贴了，其实就是专项经费的old school说法。</p>
  <h3><strong>谷歌</strong></h3>
  <p>谷歌的<strong>Student Researcher项目</strong>则覆盖了更大范围的博士生群体。</p>
  <p>这个项目采用年薪制，根据地区和经验不同，基础薪酬在11.3万到15万美元之间，也就是79万到105万左右。</p>
  <p>谷歌方面表示，这个项目主要是为了给Google Research和Google DeepMind等团队补充新鲜血液，</p>
  <p>发现了吧……</p>
  <p>虽然项目形式上仍然被定义为“学生研究员”，但从工作内容和薪酬水平来看，这项目已经很难再与普通学生兼职或短期实习划等号了。</p>
  <h3><strong>Meta</strong></h3>
  <p>上述趋势同样体现在Meta的<strong>Research Scientist Intern项目</strong>中。</p>
  <p>Research Scientist Intern是一个12周到24周的研究型实习，研究方向覆盖NLP、生成模型、CV等核心领域，月薪大概在7650美元到12000美元之间，据说还有更高的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_c05aa32a2fcc4c63bcd8a0f9963cfc25@46958_oswg32641oswg168oswg126_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>是所有AI实习生项目都提升了吗？我们不得而知。</p>
  <p>但根据已经有的信息来看，顶尖实习生的薪酬已经又攀爬了（不只）一个台阶。</p>
  <p>Anyway，对于有明确研究背景的候选人来说，不管从薪酬来看还是从倾斜的资源来看，以上这类项目都绝对足以等同于和一份AI领域的正式工作。</p>
  <h2><strong>这种情况不只发生在国外</strong></h2>
  <p>这种变化并非只存在于海外巨头之间。</p>
  <p>虽然公开披露的数据相对有限，但<strong>国内市场上也显现出隐隐抬头的趋势</strong>。</p>
  <p>就拿最近的一则新闻来说——</p>
  <p>最近，<strong>字节</strong>给20位博士颁发了2025年字节跳动奖学金，这些人覆盖大模型、机器学习、多模态、AlInfra、机器人、Alfor Science、硬件等多个研究领域。</p>
  <p>相比往届，这一次的获奖名额增加了，奖学金还比以前翻了一倍（为10万现金+10万专项学术资金补贴），又还给每位获奖同学的导师提供10万元奖励。</p>
  <p>奖学金获得者清华计算机科学与技术系的张金涛在小红书称赞“字节大气”，还透露出一点额外的消息：</p>
  <blockquote>
   <p>字节报销了他从伯克利Sky Lab往返北京的差旅费。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_d40905a5d9ff4de592a57c1b3f7d68c7@46958_oswg444428oswg1080oswg776_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不光是字节这么大手笔，近几年，阿里云、腾讯、百度等在实习生和学生研究员层面的项目规模持续扩张，覆盖方向也从传统工程岗位，逐渐延伸到基础模型、系统架构、算法研究等更偏研究型的领域。</p>
  <p>以<strong>腾讯</strong>为例。</p>
  <p>今年4月，腾讯宣布启动史上最大规模的就业计划，三年内将新增 28000 个实习岗位，并同步提高实习转正比例。</p>
  <p>仅在今年一年内，腾讯就计划接收10000名实习生，其中六成为技术类岗位。</p>
  <p>（2025年就要过去了，也不知道腾讯的计划落实得怎么样了）</p>
  <p>腾讯方面的解释很直接：一切都基于大模型加速落地这一背景。</p>
  <p>变化不是只有亿点点。</p>
  <p><strong>阿里云</strong>给出的信号同样明确。</p>
  <p>上半年2026届实习招聘启动后，公司明确表示这是近年来规模最大的一次AI人才校园招聘，其中AI相关岗位占比超过80%，覆盖大语言模型、多模态理解与生成、模型应用以及 AI Infra 等方向。</p>
  <p>这种集中度本身已与传统“多业务平均分配”的实习模式拉开了距离。</p>
  <p><strong>百度</strong>这边，早在今年3月就向在校生开放了3000多个暑期实习岗位，其中87%与AI相关。</p>
  <p>综合上述信息可以发现，虽然国内大厂付给实习生方的具体薪资水平并未披露，但在岗位占比、技术集中度以及长期转化预期上，国内市场也开始向同一个方向靠拢。</p>
  <h2><strong>巨头在“买”什么样的实习生？</strong></h2>
  <p>当短期项目的成本被不断推高，一个绕不开的问题是，这些公司究竟在寻找什么样的人？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_395426013ac8408c84f345ea0ba1f1b4@46958_oswg64804oswg218oswg222_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从各类项目的申请要求和历史参与者背景来看，<strong>最核心的能力是可验证的研究产出能力</strong>。</p>
  <p>这种能力通常体现在论文、方法论创新、或在复杂问题上的系统性推进经验上。</p>
  <p>很多项目<strong>明确强调，希望候选人能够在项目周期内完成具有公开价值的研究成果</strong>。</p>
  <p>同时，这些公司也在寻找能够独立推进长期、复杂问题的人。</p>
  <p>无论是模型架构、安全性研究，还是系统层面的优化，这些问题更依赖研究者自身的判断和持续投入。</p>
  <p>上述的短期项目们，不少被设计为全职强度——很大程度上，一大部分原因是为了观察候选人在这种环境下的表现。</p>
  <p><strong>更长远的考量，则在于潜力</strong>。</p>
  <p>我们可以在许多项目在描述中看到，诸如“希望参与者未来能够成长为核心研究员或技术方向负责人”这种话术。</p>
  <p>说白了，这类实习岗位虽然周期还是短，但它就不是传统意义上的实习，也就是补充人力或承担基础任务的那种。</p>
  <p>公司对这些实习生的定位也和常规实习生不同。</p>
  <p>背后真实目的是经过系统性筛选，考核这群人对问题的理解深度、研究品味以及长期投入某一方向的意愿，然后<strong>提前开始培养和绑定AI技术人才</strong>。</p>
  <p><strong>短期研究项目，正在成为企业提前下注人才的一种方式，同时也是一套隐形的精英筛选机制</strong>。</p>
  <p>这种方式比直接高价挖成熟人才风险更低，也比单纯依赖简历和面试更加可靠。</p>
  <p>在这样的逻辑下，实习生被当作“顶尖期货”来对待，也就不难理解了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b798f782cdf64a9ca009906ae21e97b8@46958_oswg39194oswg182oswg122_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过AI人才的培养和筛选路径明显前移这个趋势，对资源和资金没那么宽裕的初创公司就不那么友好了。</p>
  <p>他们获取顶尖人才的难度开始上升——而且可能是只是刚刚开始。</p>
  <p>大厂砸钱砸资源，岂是一般初创公司能够与之相抗衡的呢？</p>
  <p>参考链接：</p>
  <p>[1]https://www.businessinsider.com/top-paying-ai-internships-fellowships-residencies-openai-anthropic-meta-google-2025-12</p>
  <p>[2]https://www.xiaohongshu.com/explore/6927412f000000001902688c?app_platform=ios&amp;app_version=9.14.2&amp;share_from_user_hidden=true&amp;xsec_source=app_share&amp;type=normal&amp;xsec_token=CBoPjgHC6p1qNs6Sqx0OQ6V4QZkPpFIpH9gQdgKyh3f84=&amp;author_share=1&amp;xhsshare=WeixinSession&amp;shareRedId=NzxHOEQ6OTw6Pjw3Sj81SD1HQUk5R0lK&amp;apptime=1766715420&amp;share_id=3af983a0c03a440a9c3e2f72094e59c5&amp;wechatWid=9c1aa40191ada137b15ba1a8b9204956&amp;wechatOrigin=menu</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/E13AuvGTCFQwfADfenJKFA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：衡宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257575470339</id>
            <title>英伟达成美国大模型开源标杆：Nemotron 3连训练配方都公开，10万亿token数据全放出</title>
            <link>https://www.36kr.com/p/3612257575470339</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257575470339</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:49:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英伟达在开源模型上玩的很激进：</p>
  <p>“最高效的开放模型家族”Nemotron 3，混合Mamba-Transformer MoE架构、NVFP4低精度训练全用上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_cfb0745865424db4ae6405af2120e17a@46958_oswg445342oswg720oswg900_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且开放得很彻底：</p>
  <p>不仅开放模型权重，还要把超过10万亿token的训练数据、预训练和后训练软件、训练配方全部公开。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8bbc0a7f504c4c7f937c0a2fdc969329@46958_oswg44843oswg1080oswg314_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与其他开源模型相比性能有竞争力，且速度快1.5-3.3倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_75140db87e844e06a9a33736dded2ded@46958_oswg99627oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>把Mamba和Transformer混着用</strong></h2>
  <p>Nemotron 3在架构层面追求推理效率的最大化。</p>
  <p>传统Transformer的自注意力机制需要对不断增长的KV Cache做线性扫描，序列越长，计算开销越大。</p>
  <p>英伟达的解决方案是大量使用Mamba-2层替代自注意力层——Mamba层在生成时只需要存储固定大小的状态，不受序列长度影响。</p>
  <p>以Nano型号为例，整个模型主要由交替堆叠的Mamba-2层和MoE层构成，自注意力层只保留了少数几个。</p>
  <p>论文给出的层排布模式是：5个Mamba-2+MoE的重复单元，接3个同样结构的单元，再来1个包含注意力层的单元，最后是4个Mamba-2+MoE单元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a7170bbc299a472aa074cc3c0d603faa@46958_oswg110094oswg1080oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在8k输入、16k输出的典型推理场景下，Nemotron 3 Nano 30B-A3B的吞吐量是Qwen3-30B-A3B的3.3倍。序列越长，优势越明显。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_c6fe663ab3ba43f8ad4fa6d2755bd8ca@46958_oswg84148oswg1080oswg416_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与此同时，模型在长上下文任务上的表现并没有打折扣。</p>
  <p>论文展示了一组RULER基准测试的结果：在100万token输入长度下，Nemotron 3 Nano基座模型拿到了68.2分，而在同样条件下训练的Nemotron 2 Nano 12B只有23.43分，出现了断崖式下跌。MoE混合架构在长度外推上的鲁棒性明显更好。</p>
  <h2><strong>LatentMoE：在潜空间里做专家路由</strong></h2>
  <p>针对Super和Ultra这两个更大的模型，英伟达提出了LatentMoE架构，在潜在空间中进行专家计算。</p>
  <p>MoE层在实际部署时会遇到两类瓶颈：</p>
  <p>低延迟场景下，每次只处理几十到几百个token，此时从显存读取专家权重成为主要开销。</p>
  <p>高吞吐场景下，一次处理数千token，此时专家间的all-to-all通信成为瓶颈。两种情况下，开销都与隐藏维度d线性相关。</p>
  <p>LatentMoE的做法是：先把token从原始隐藏维度d投影到一个更小的潜在维度ℓ（通常是d的四分之一），在这个低维空间里完成专家路由和计算，最后再投影回原始维度。</p>
  <p>这样一来，每个专家的权重加载量和通信量都降低了d/ℓ倍。省下来的计算预算被用于增加专家数量和每个token激活的专家数。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_71b718346772464cb0d7f122c84dfb6b@46958_oswg173033oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>标准MoE用128个专家、激活6个；LatentMoE用512个专家、激活22个。</p>
  <p>两者的总参数量和激活参数量几乎相同（都是8B激活、73B总参），但LatentMoE在所有下游任务上都取得了更好的成绩——MMLU-Pro从48.30提升到52.87，代码任务从51.95提升到55.14，数学任务从78.32提升到80.19。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_970b977841cc4b5ca159ca8d6541f587@46958_oswg50034oswg1080oswg384_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>需要注意的是，路由门控网络、共享专家计算以及非专家层仍然保留在原始维度，因为这些部分对瓶颈的贡献很小。</p>
  <h2><strong>用NVFP4训练250亿token</strong></h2>
  <p>Super和Ultra还采用了NVFP4格式进行训练，这是英伟达在低精度训练上的又一次探索。</p>
  <p>NVFP4是一种4位浮点格式，采用E2M1的元素格式（2位指数、1位尾数），配合16元素的微块缩放和E4M3格式的块缩放因子。在GB300上，FP4的峰值吞吐量是FP8的3倍。</p>
  <p>论文显示，团队已经用NVFP4格式稳定训练了高达25万亿token。与BF16训练相比，Nano模型的损失差距控制在1%以内，8B激活参数的更大模型差距进一步缩小到0.6%以内。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2776ac307b0140a99cda5bffbc1a532b@46958_oswg139016oswg1080oswg391_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在MMLU、GSM8K、HumanEval等下游任务上，NVFP4训练的模型与BF16版本的准确率曲线几乎完全重合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_74938f43584d408d8dbe38e237d3512c@46958_oswg174134oswg1080oswg549_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过并非所有层都适合量化到NVFP4。团队发现Mamba输出投影层在量化后会出现高达40%的flush-to-zero现象，因此保留在MXFP8精度；QKV投影和注意力投影保留在BF16以维持少量注意力层的保真度；网络最后15%的层也保持高精度以确保稳定性。MTP层和潜在投影由于对推理时间影响很小，同样保留在BF16。</p>
  <h2><strong>多环境强化学习一把训到底</strong></h2>
  <p>Nemotron 3的后训练采用了多环境强化学习，覆盖数学推理、竞赛编程、指令遵循、软件工程、搜索、对话、通用工具使用、长上下文等多种任务。</p>
  <p>与之前分阶段训练不同能力的做法不同，这次英伟达选择同时训练所有任务。</p>
  <p>论文指出，这种同步训练方式更稳定，更不容易出现reward hacking，也避免了分阶段训练常见的能力退化问题。</p>
  <p>AIME25数学分数从80提升到90，LiveCodeBench从65提升到72，τ²-Bench工具使用从40提升到50左右，全程呈稳定上升趋势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_4fe407b2e0644e028a470b70e88b5053@46958_oswg199909oswg1080oswg441_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>高效的推理吞吐量在这里发挥了重要作用。</p>
  <p>大规模RL需要生成海量rollout样本，Nemotron 3的混合架构相比其他开源模型有显著优势。</p>
  <p>团队还采用了异步RL架构来解耦训练和推理，并利用多token预测加速rollout生成。训练算法方面使用GRPO配合masked importance sampling来处理训练策略和rollout策略之间的差异。</p>
  <p>整个后训练软件栈以Apache 2.0协议开源，包括NeMo-RL（可扩展RL训练）和NeMo-Gym（RL环境集合）两个仓库。</p>
  <p>此外，Nemotron 3还支持推理时的思维预算控制。</p>
  <p>用户可以指定思维链的最大token数，当模型达到预算时，追加一个标记即可让模型基于部分思维链生成最终回答。</p>
  <p>论文给出了准确率与平均生成token数之间的权衡曲线，这为实际部署中的效率-精度平衡提供了细粒度控制。</p>
  <p>论文地址：https://arxiv.org/abs/2512.20856</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/OEtDlmYgkD37DzAEdtR5nQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：梦晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612292341449730</id>
            <title>2025年，这十个科技突破再次革新我们对世界的认知</title>
            <link>https://www.36kr.com/p/3612292341449730</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612292341449730</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:49:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_58904d08801148e28a7220bea7e8bedd@46958_oswg37573oswg640oswg364_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：界面图库</p>
  <p>2025年，是联合国教科文组织定义的“国际量子科学与技术年”，也是我国“十五五”规划承前启后的时段。</p>
  <p>在这一年，计算范式更迭。“DeepSeek时刻”带来的“Aha Moment”让我们反思算力，量子计算的技术突破层出不穷；从诺贝尔物理学奖到硬科技的产业界，这个世界似乎正在挥别那个堆砌晶体管数量的时代。</p>
  <p>材料不断翻新，继而重塑着我们对于物质世界的感知：脑机芯片滑入大脑皮层，空芯光纤刷新长距离通信，金属材料挤压至埃米级的“二维”世界，μ子的理论模型与现实世界精确耦合，抽象的物质极限正被技术一一兑现。</p>
  <p>人类生存的图景也随之摇身一变。这一年，钢材首度达到“近零排放”阈值，中国“人造太阳”得以预演核聚变堆运行的未来，贝努小行星的样本则直指地球的过去，人类文明的生存坐标正被重新校准。</p>
  <p><strong>以下是界面新闻盘点的2025年度十大科学技术突破。</strong></p>
  <h2><strong>DeepSeek-R1：大模型的“中国方案”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_cd7e9e38f15047b2966f29674529f111@46958_oswg20769oswg580oswg330_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>深度求索（DeepSeek）在2025年1月20日发布的DeepSeek-R1模型，基于Deep Seek-V3的基础模型，以强化学习为核心驱动训练推理能力，并免费开源。</p>
  <p>该模型在o1类推理模型的基础上，更多地依赖“强化学习”，模型使用为自己创建和调整的奖励系统，从自身行动中获得反馈。在Math-500等基准测试中，R1以极低的算力成本实现了媲美OpenAI o1的推理能力。Nature杂志将DeepSeek创始人梁文锋列为2025年度十大人物，评价其“让复杂的逻辑推理变得触手可及”。</p>
  <h2><strong>超导量子电路与宏观量子隧穿：确证量子科技基石</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a96d41f125b94295b77e55bfe48cf3ec@46958_oswg443767oswg566oswg566_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>10月，诺贝尔物理学奖花落量子科技，表彰了超导量子电路技术为现代计算变革奠定的宏观基石。John Clarke、Michel H. Devoret与John M. Martinis因在上世纪80年代利用含约瑟夫森结的电路，首次观测到宏观量子隧穿与能级离散而获此殊荣。</p>
  <p>这一发现打破了经典与量子世界的传统界限，证明了由数亿原子组成的宏观电路系统也能像微观粒子一样被精确操控。该突破催生了“人造原子”与超导量子比特（Qubit），构成了今日谷歌、IBM等科技巨头构建量子计算的物理学原点。</p>
  <h2><strong>通用量子计算机Helios：高精度量子计算叩响商用大门</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_326b736f645e4fd79cf617f60fba94be@46958_oswg62460oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为量子计算领域离子阱路线的领军企业，Quantinuum于11月5日发布了第三代量子计算机Helios。Helios包含98个物理量子比特，单量子比特门操作的保真度达到 99.9975%，双量子比特门操作的保真度在所有量子比特对之间平均为99.921%，并能提供48个经过纠错的逻辑量子比特，是目前全球精度最高的通用商用量子计算机。</p>
  <p>Helios实现了接近2：1的物理-逻辑比特转换率（远高于行业平均的几十甚至上百比一）被加州大学洛杉矶分校教授Prineha Narang评价为“独特且令人印象深刻”。 配合其研发的Guppy编程语言，Helios的问世或标志着量子计算开始真正具备解决商业问题的能力。</p>
  <h2><strong>超薄高带宽脑机接口BISC芯片：给大脑植入“无线宽带”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ff0f3b9d5be243ef976549671aa470fa@46958_oswg155723oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>哥伦比亚大学联合斯坦福等团队于12月8日发布的BISC芯片，为人类大脑植入了前所未有的“无线数字宽带”。该成果发布于国际权威期刊Nature Electronics，通过将65536个电极、电源及射频模块极致集成于一枚厚度仅50µm、体积3mm³的柔性CMOS芯片上，彻底颠覆了传统脑机接口的物理形态。</p>
  <p>该芯片能如贴纸般滑入大脑皮层表面，并通过体外中继站建立UWB链路，实现高达100Mbps的数据吞吐量。这一飞跃不仅解决了高分辨率信号无法实时传输的痛点，更将海量神经数据直接送入AI模型，为全植入式癫痫监测、高自由度神经假肢及双向脑机交互提供了核心数据通道。</p>
  <h2><strong>新型空芯光纤：刷新信号传输损耗纪录</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_aae6b92bb1474460a84218f7769841fe@46958_oswg247759oswg1080oswg401_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由微软支持的Lumenisity研究团队宣布其发现了一种具备前所未有的传输带宽和超低衰减性能的微结构光波导。成果于9月1日发布在国际权威学术期刊Nature Photonics上，这种新型空芯光纤在1550nm波长（通信常用波段）下的实测损耗仅为0.091dB/km，且在长达66THz的频宽窗口内，损耗均保持在 0.2 dB/km 以下。</p>
  <p>与传统的实心玻璃纤芯不同，这种创新光纤采用“空气纤芯”，通过周围精心设计的玻璃微结构来引导光线传输。此外，该技术在理论上仍有进一步降低损耗的空间，并支持在拥有更宽带放大器的波段下工作，标志着长距离通信及高能激光远程传输领域有望迎来一个新的时代。</p>
  <h2><strong>“埃米级”二维金属制备术：对金属原子的“降维打击”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ba125dd9545e48469b05792fa2c5e941@46958_oswg188083oswg1080oswg257_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>3月，中国科学院物理研究所张广宇团队发表在国际权威期刊Nature上的论文显示，其开发了一种“原子制造的范德华挤压法”，将金属材料厚度推向了埃米（Å）级极限，约为头发丝直径的二十万分之一。针对单层铋（Bi）的输运和拉曼测量显示，其具有优异的物理性能，例如全新的声子模式、增强的电导率、显著的场效应以及巨大的非线性霍尔电导率。</p>
  <p>原子级薄的二维金属曾长期被学界认为是“不可能完成的任务”，这一工作为实现二维金属、合金以及其他二维非范德华材料建立了一条有效途径，为广泛的新兴量子器件、电子器件和光子器件提供应用前景。</p>
  <h2><strong>μ子g-2实验高精度结果：标准模型暂时屹立不倒</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1faa0b75d6234c8a93ea6b224a9f6e84@46958_oswg200187oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>6月，备受期待的费米国家加速器实验室（FNAL） μ 子 g-2 实验最终结果公布，其测得的 μ 子异常磁矩与修正后的理论预测完全吻合。最新的测量结果与2021年及2023年发布的结果高度一致，更将测量精度提升至前所未有的127ppb（一千万分之一点二七），超越实验最初设定的目标（一千万分之一点四），给出了当前最精确的μ子反常磁矩测量结果。</p>
  <p>尽管理论计算的最新结果削弱了μ子反常磁矩中可能存在的“新迹象”，但此次实验的高精度结果可为未来标准模型的扩展提供基准；标准模型又挺过了一项挑战。</p>
  <h2><strong>近零碳排放绿色钢铁 SSAB Zero™：更可持续的能源经济先声</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_d69d6bcb1e9f492a8527caa20f704199@46958_oswg147422oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>9月23日，瑞典钢铁巨头SSAB宣布其SSAB Zero™钢材成为首个达到国际能源署（IEA）近零排放阈值并满足“先行者联盟”（FMC）采购标准的产品。依托美国爱荷华工厂，该产品融合无化石电力、生物质能源与HYBRIT®技术路线的氢还原铁，从化学反应根源斩断了碳排放。</p>
  <p>GE Vernova（通用电气能源业务分拆后成立的独立公司）当日宣布将其即刻引入陆上风电塔筒供应链，这标志着“绿氢+绿电”冶炼模式已正式跨越概念验证鸿沟，为全球能源基建提供了首个可规模化复制、具有清晰减排路径的绿色范本。</p>
  <h2><strong>中国“人造太阳”EAST：创造“亿度千秒”世界纪录</strong></h2>
  <p>1月20日，位于安徽合肥的全超导托卡马克核聚变实验装置（EAST）首次实现1亿摄氏度1066秒稳态长脉冲高约束模等离子体运行，再次创造了托卡马克装置稳态高约束模运行新的世界纪录。</p>
  <p>千秒量级是聚变反应实现稳定的重要基础。但运行时间越长，约束等离子体的难度就越高。此次实验超越千秒，意味着人类首次在实验装置上模拟出未来聚变堆运行所需的条件，验证了聚变的工程可行性。</p>
  <h2><strong>小行星贝努含有生命物质：探秘前生命时期的地球</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_f51745480c2e46e1874a6837bf8bb66d@46958_oswg100721oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此前，Nature与Nature Astronomy刊登的多项重磅研究揭晓了NASA OSIRIS-REx任务带回的贝努（Bennu）小行星样本的深度分析结果。科学家在其中检测到了构建生命所需的14种氨基酸、核碱基及含钠磷酸盐。</p>
  <p>日本东北大学发布于权威期刊Nature Geoscience 12月的最新研究显示，在OSIRIS-REx 航天器采集的贝努样本的提取物中鉴定出多种生物必需的糖类，包括核糖（RNA 的糖组分）和葡萄糖（代谢底物）。这些糖类的发现补全了生命关键成分的清单，表明包含生命所需全部三大组分的物质，可能已经被散播到了前生命时期的地球及其他内太阳系行星上。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_ofr6n0e5QmfkceHVM07UQ" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，作者：周末&nbsp;林鑫龙，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257773487113</id>
            <title>训练时间爆砍80%，港大快手联合打造了一个AI炼金师：专挑“有营养”数据，20%数据达成50%效果</title>
            <link>https://www.36kr.com/p/3612257773487113</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257773487113</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:48:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>想象一下，如果让一个大厨用发霉的食材、过期的调料来做菜，即使厨艺再高超，也做不出美味佳肴。AI训练也是同样的道理。</p>
  <h2><strong>一、数据就像食材，质量决定成品</strong></h2>
  <p>现在的AI图像生成模型，如Stable Diffusion、FLUX等，需要从网络上爬取数百万张图片来学习。但这些图片质量参差不齐：有些模糊不清，有些内容重复，有些甚至只是广告背景图。用这些“食材”训练出来的AI，自然效果不佳。</p>
  <p>由香港大学丁凯欣领导，联合华南理工大学周洋以及快手科技Kling团队共同完成的这项研究，开发出了一个名为“炼金师”（Alchemist）的AI系统。它就像一位挑剔的大厨，能从海量图片数据中精准挑选出最有价值的一半。</p>
  <p><strong>更让人惊喜的是：</strong></p>
  <ul>
   <li>用这一半精选数据训练出的模型，竟然比用全部数据训练的表现还要好</li>
   <li>训练速度快了 <strong>5倍</strong></li>
   <li>只用20%的精选数据，就能达到50%随机数据的效果</li>
  </ul>
  <h2><strong>二、让AI学会“自我评判”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2a8f2af8d49649d6a50e35a2ef94a99c@46958_oswg220281oswg830oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>2.1 传统方法的局限</strong></h3>
  <p>传统的数据筛选方法就像用筛子筛米粒，只能按照单一标准过滤：</p>
  <ul>
   <li>只看图片清晰度</li>
   <li>只看文字匹配度</li>
   <li>只看美学评分</li>
  </ul>
  <p>这些方法的问题在于：<strong>它们不知道哪些数据真正有助于AI学习</strong>。</p>
  <h3><strong>2.2 炼金师的智慧</strong></h3>
  <p>“炼金师”更像是一位经验丰富的美食评委，它能同时考虑多个维度：</p>
  <ul>
   <li>不仅看“菜品”的卖相</li>
   <li>还要品尝口感</li>
   <li>甚至考虑营养搭配</li>
  </ul>
  <p>核心思想：让AI学会观察自己的学习过程</p>
  <p>炼金师训练了一个专门的<strong>评分员模型</strong>，这个评分员就像资深的艺术老师，能够判断每张图片对整个学习过程的价值。</p>
  <p><strong>评判标准：</strong></p>
  <p>✅如果一张图片能让AI模型学到新知识并快速改进→<strong>好数据</strong></p>
  <p>❌如果一张图片让模型学了半天也没什么进步→<strong>无用数据</strong></p>
  <p>这就像观察学生做习题时的表情和进步速度，来判断这道题是否适合他们。</p>
  <h2><strong>三、最简单的不一定最好</strong></h2>
  <h3><strong>3.1 意外的真相</strong></h3>
  <p>研究团队发现了一个<strong>违反直觉</strong>的现象：</p>
  <p><strong>那些看起来最“简单”的图片，比如纯白背景的产品图：</strong></p>
  <ul>
   <li>虽然能让AI快速收敛</li>
   <li>但对提升模型能力帮助不大</li>
   <li>就像一直做最简单的加法题，虽然不会出错，但对提升数学能力没有帮助</li>
  </ul>
  <p><strong>相反，内容丰富、稍有挑战性的图片，才是真正的“营养品”</strong></p>
  <h3><strong>3.2 科学验证</strong></h3>
  <p>研究团队追踪了不同评分区间图片的训练动态：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_0435cbd5d9b240e4a770009171340872@46958_oswg56688oswg876oswg224_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_15ac75eef80541ed97fb0e2411909bde@46958_oswg179651oswg830oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>四、技术亮点：偏移高斯采样策略</strong></h2>
  <p>基于上述发现，团队提出了“偏移高斯采样”（Shift-Gsample）策略。</p>
  <h3><strong>4.1 传统方法vs炼金师</strong></h3>
  <p><strong>传统Top-K方法：</strong></p>
  <ul>
   <li>简单选择评分最高的数据</li>
   <li>❌但这些数据往往过于简单，缺乏营养</li>
  </ul>
  <p><strong>炼金师策略：</strong></p>
  <ul>
   <li>✅避开评分过高的“简单”数据</li>
   <li>✅重点选择中等偏上评分的“有营养”数据</li>
   <li>✅保留少量简单和困难样本，维持数据多样性</li>
  </ul>
  <p>这就像制定健身计划：</p>
  <ul>
   <li>❌不选择过于轻松的运动 （没有锻炼效果）</li>
   <li>❌不选择过于困难的运动 （容易受伤）</li>
  </ul>
  <h3><strong>4.2 多粒度感知机制</strong></h3>
  <p>为了更好地评估数据质量，炼金师还设计了<strong>“多粒度感知”</strong>机制：</p>
  <ul>
   <li><strong>个体层面：评估单张图片的质量</strong></li>
   <li><strong>群体层面：考虑整批数据的搭配</strong></li>
  </ul>
  <p>就像营养师不仅关注单个食材的营养价值，还要考虑整餐的营养搭配。</p>
  <h2><strong>五、实验结果：数据说话</strong></h2>
  <h3><strong>5.1 主要成果对比</strong></h3>
  <p><strong>在LAION-30M数据集上：</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_068baadd81454c29b0e23ca8d0ce0c56@46958_oswg73006oswg870oswg266_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p><strong>关键发现：</strong></p>
  <ul>
   <li>用50%精选数据超越100%全量数据</li>
   <li>用20%精选数据达到50%随机数据效果</li>
   <li>训练速度提升 <strong>5倍</strong></li>
  </ul>
  <h3><strong>5.2 跨模型通用性</strong></h3>
  <p>炼金师在不同规模、不同架构的模型上都有效：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2e804e85a21940ddbaa51ee0265f5acd@46958_oswg209753oswg625oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>5.3 跨数据集适应性</strong></h3>
  <p>在不同类型数据集上的表现：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_e4adbe9df18d4b208db9742bc4f527d6@46958_oswg131914oswg621oswg331_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>HPDv3-2M数据集</strong>（真实+合成混合）：</p>
  <ul>
   <li>20%保留率：FID从35.55→ <strong>32.27</strong> ✅</li>
   <li>50%保留率：FID从20.21→ <strong>18.15</strong> ✅</li>
  </ul>
  <p><strong>Flux-reason-6M数据集</strong>（纯合成推理数据）：</p>
  <ul>
   <li>20%保留率：FID从23.66→ <strong>22.78</strong> ✅</li>
   <li>50%保留率：FID从19.35→ <strong>18.59</strong> ✅</li>
  </ul>
  <h2><strong>六、可视化分析：眼见为实</strong></h2>
  <h3><strong>6.1 数据分布特征</strong></h3>
  <p>研究团队对筛选后的数据进行了可视化分析：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_939932f1543e4c5ca595899ca21c7657@46958_oswg444323oswg647oswg361_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>0-20%高分区域</strong>（简单但营养不足）：</p>
  <ul>
   <li>白色或纯色背景</li>
   <li>简洁的产品图</li>
   <li>视觉干净但信息量有限</li>
  </ul>
  <p><strong>30-80%中分区域</strong>（最有价值的“金中间”）：</p>
  <ul>
   <li>内容丰富</li>
   <li>主题明确</li>
   <li>动作清晰</li>
   <li><strong>炼金师重点选择区域</strong>⭐</li>
  </ul>
  <p><strong>80-100%低分区域</strong>（过于混乱）：</p>
  <ul>
   <li>噪声图片</li>
   <li>多对象混乱场景</li>
   <li>视觉密集区域</li>
   <li>内容不清晰</li>
  </ul>
  <h3><strong>6.2 训练动态对比</strong></h3>
  <p><strong>训练稳定性对比：</strong></p>
  <p>炼金师选择的数据展现出：</p>
  <p>✅稳定持续的性能提升</p>
  <p>✅更快的收敛速度</p>
  <p>✅更少的训练波动</p>
  <p>随机选择的数据则表现出：</p>
  <p>❌早期训练波动大</p>
  <p>❌性能提升缓慢</p>
  <p>❌需要更多epochs才能收敛</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7921a2288bd841a594411ce3661c20b6@46958_oswg229315oswg366oswg840_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>七、技术深度：元梯度优化框架</strong></h2>
  <h3><strong>7.1 双层优化问题</strong></h3>
  <p>炼金师的核心是一个<strong>双层优化框架</strong></p>
  <p><strong>外层优化</strong>：学习如何评分</p>
  <ul>
   <li>目标：找到最优的评分策略</li>
   <li>评判标准：验证集上的性能</li>
  </ul>
  <p><strong>内层优化</strong>：训练代理模型</p>
  <ul>
   <li>目标：用加权数据训练模型</li>
   <li>权重由评分器决定</li>
  </ul>
  <h3><strong>7.2 元梯度更新机制</strong></h3>
  <ul>
   <li>系统通过观察两个模型的表现差异来更新评分：</li>
   <li>评分更新∝代理模型的验证集损失</li>
  </ul>
  <p><strong>核心思想：</strong></p>
  <p>如果一个样本让验证性能提升→提高其评分</p>
  <p>如果一个样本只降低训练损失但不提升验证性能→降低其评分</p>
  <h2><strong>八、Q&amp;A环节</strong></h2>
  <h3><strong>Q1：炼金师如何判断哪些图片数据更有价值?</strong></h3>
  <p><strong>A：</strong>炼金师通过观察AI模型在学习过程中的“反应”来判断数据价值：</p>
  <p>✅好数据：能让模型学到新知识并快速改进</p>
  <p>❌差数据：让模型学了半天也没进步</p>
  <p>这就像观察学生做题时的表情和进步速度，来判断题目是否合适。</p>
  <p><strong>技术细节</strong>：</p>
  <ul>
   <li>监控训练损失变化</li>
   <li>追踪梯度动态</li>
   <li>对比验证集性能提升</li>
  </ul>
  <h3><strong>Q2： 为什么用一半数据训练出的模型比用全部数据还要好?</strong></h3>
  <p><strong>A：</strong>因为<strong>并非所有数据都有价值</strong>，关键在于质量而非数量。</p>
  <p><strong>类比说明：</strong></p>
  <ul>
   <li>教孩子画画时，精选5000张优质作品</li>
   <li>比给他看10000张杂乱涂鸦更有效</li>
  </ul>
  <p><strong>科学原理：</strong></p>
  <p><strong>1.冗余数据消耗资源但不提升性能</strong>：如重复的简单样本、模糊不清的噪声图片</p>
  <p><strong>2. 有营养的数据促进真实学习</strong>：如内容丰富的中等难度样本、多样化的场景和对象</p>
  <p><strong>3. 避免过拟合</strong>：若只用简单数据会导致模型“死记硬背”，还应使用适当难度的数据培养泛化能力</p>
  <h3><strong>Q3： 炼金师的数据筛选方法能在其他AI模型上使用吗?</strong></h3>
  <p><strong>A：</strong>可以！研究显示这种方法具有<strong>良好的通用性和跨模型适用性</strong>。</p>
  <p><strong>验证范围：</strong></p>
  <p>✅不同数据类型：</p>
  <ul>
   <li>网络爬取数据 （LAION）</li>
   <li>高质量合成数据 （Flux-reason）</li>
   <li>人类偏好标注数据 （HPDv3）</li>
  </ul>
  <p>✅不同模型架构：</p>
  <ul>
   <li>STAR系列 （40M→0.9B参数）</li>
   <li>FLUX系列 （3B参数）</li>
   <li>从头训练 vs LoRA微调</li>
  </ul>
  <p>✅不同模型规模：</p>
  <ul>
   <li>用小模型 （0.3B） 筛选数据</li>
   <li>成功提升大模型 （0.9B） 性能</li>
   <li>评分成本可忽略不计</li>
  </ul>
  <p><strong>原理：</strong></p>
  <p>数据质量是本质属性，不依赖特定模型</p>
  <p>就像好食材适合各种烹饪方法</p>
  <p>经验丰富的教练选择的训练方法，既适合业余选手也适合专业选手&nbsp;</p>
  <p><strong>Project Page：</strong>https://kxding.github.io/project/Alchemist/</p>
  <p><strong>Github：</strong>https://github.com/KlingTeam/Alchemist/</p>
  <p><strong>arXiv：</strong>https://arxiv.org/abs/2512.16905</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/vMhEjEXbX9PTtziGumP_AQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：Alchemist团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612177250660866</id>
            <title>宁德时代再签大单，32只锂电概念股“蠢蠢欲动”</title>
            <link>https://www.36kr.com/p/3612177250660866</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612177250660866</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:54:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，锂电池板块热度持续攀升。</p>
  <p>消息面上，宁德时代与韩国电解液制造商Enchem签订5年大单，合同规模约达1.5万亿韩元，约合72.68亿元人民币，是Enchem成立以来最大规模的单一客户订单。</p>
  <p>12月26日早盘，碳酸锂主力合约盘中强势突破13万关口，一度涨超8%，创2023年11月以来新高。</p>
  <h2><strong>头部厂商持续斩获大单</strong></h2>
  <p>随着全球能源转型加速，锂电池产业正经历从规模扩张到质量提升的关键转折期。</p>
  <p>行业层面，截至2025年，全球已有超过130个国家提出碳中和目标，动力电池作为交通电动化核心，储能电池作为可再生能源规模化利用关键，迎来确定性增长。国际能源署（IEA）预测，到2030年全球电动汽车保有量将突破3亿辆，配套动力电池需求将超过3,000GWh，年均复合增长率保持在25%以上。</p>
  <p>技术层面，过去十年，锂电池成本下降近90%，能量密度提升超三倍。行业共识认为，2026-2030年锂电池成本仍有20%-30%下降空间，主要通过材料创新、工艺优化和规模效应实现。同时，钠离子电池、固态电池等下一代技术将在2027年后逐步进入商业化导入期，开启新一轮技术竞赛。</p>
  <p>中研普华产业研究院报告显示，2025年全球锂电池市场规模预计超过1.2万亿元人民币，其中动力电池占比约70%，储能电池占比快速提升至20%以上。</p>
  <p>从整体电池产业来看，国金证券认为，锂电供给确立穿越过剩周期，库存周期结束两年去库阶段，正式转入“主动补库”的繁荣期，基本面呈现2024年触底、2026年有望明显复苏。随着头部企业稼动率打满，行业由“内卷价格战”转向“联合挺价”，推动价格触底回升，产业链利润分配正向具备高壁垒、高集中度的上游“硬瓶颈”材料环节转移，最终实现全行业的量利双升。</p>
  <p>今年以来，锂电产业链大单呈爆发状态。以宁德时代为例，公开数据显示，公司年内已拿下300GWh以上储能订单，相比2024年93GWh的储能系统出货量，已翻至少3番。2021-2024年，宁德时代已连续4年储能电池出货量位居全球第一。</p>
  <p>市场最新消息显示，宁德时代旗下的江西枧下窝锂矿将在2026年2月农历新年后全面恢复运营。宜春市作为“亚洲锂都”，拥有丰富的锂云母资源。枧下窝矿区的供应能力直接关系到宁德时代乃至全球新能源汽车的供应链稳定。</p>
  <p>其他锂电池巨头如亿纬锂能、国轩高科、中创新航等相继披露了大额采购协议，涵盖磷酸铁锂、正负极材料、电解液、铜箔、隔膜等关键环节，这些订单动辄数十亿甚至数百亿元，协议期限多为3至5年。</p>
  <p>11月底，龙蟠科技与楚能新能源签署补充协议，约定2025年至2030年采购130万吨正极材料，以当时市场价估算合同总金额高达450亿元。</p>
  <h2><strong>年内已诞生6只翻倍股</strong></h2>
  <p>同花顺数据显示，根据申万三级行业分类，A股锂电池板块一共有31家上市公司。</p>
  <p>从地域分布看，广东省11家，占比35.5%；江苏省4家，占比12.9%；浙江省 3家，占比9.7%；安徽省、湖北省、江西省各有2家；福建省、湖南省、吉林省、辽宁省、上海市、四川省、重庆市各有1家。</p>
  <p>从业绩表现看，2025年前三季度，上述31家上市公司营收合计为5168.87亿元，同比增长14.24%；净利润合计为592.81亿元，同比增长39.23%。其中，有28家公司的净利润为正，占比90.3%；有26家公司营收同比增长，占比为83.9%。</p>
  <p>其中，宁德时代的营收和净利润在31家公司中均稳居第一。前三季度，宁德时代实现营收2830.72亿元，同比增加9.28%；归属于上市公司股东的净利润490.34亿元，同比增加36.20%。</p>
  <p>从二级市场表现看，截至12月25日收盘，今年以来，一共29家上市公司年内股价实现上涨。其中，涨幅超过50%的有15家公司。</p>
  <p>铜冠铜箔（301217.SZ）、德福科技（301511.SZ）、嘉元科技（688388.SH）、震裕科技（300953.SZ）、天宏锂电（920252.BJ）、鹏辉能源（300438.SZ）6家公司年内股价已经成功实现翻倍。</p>
  <p>12月23日，震裕科技公告称，公司拟向不特定对象发行可转换公司债券，募集资金总额不超过18.8亿元，用于锂电池精密结构件扩产项目、人形机器人精密模组及零部件产业化项目（一期）、电机铁芯扩产项目（一期）以及补充流动资金。其中，锂电池精密结构件扩产项目计划总投资10.38亿元，拟使用募集资金7.52亿元。</p>
  <p>公开资料显示，震裕科技主营业务涵盖精密级进冲压模具、电机铁芯、锂电池精密结构件等，产品广泛应用于家电、新能源锂电池、汽车等领域，合作客户包含多个行业头部企业。2025年前三季度，公司锂电池结构件实现收入超过42亿元，同比增长接近50%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1963b794ed41491a9665a05aed98c8ab@5727534_oswg104958oswg617oswg729_img_jpg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号“览富财经网”，作者：览富财经网，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612218491438088</id>
            <title>金属暴涨潮下投资众生相：有人惊险解套、有人暴赚200%，牛市还能追吗？</title>
            <link>https://www.36kr.com/p/3612218491438088</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612218491438088</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:53:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“金价还在涨，我真的看不懂了。”电话那头，黄金投资者徐雨的声音带着一丝困惑与庆幸。今年10月入场的她，刚刚经历了从亏损到回本、再到小赚1000元的过山车行情。</p>
  <p>12月25日圣诞节，全球贵金属市场休市。就在前一日，现货黄金价格首次突破每盎司4500美元大关，盘中最高触及4525.83美元/盎司。至此，黄金年内涨幅已超过70%。</p>
  <p>这不是黄金的独角戏，一场全面而猛烈的贵金属牛市正以雷霆之势席卷全球。白银、铂金、钯金同步狂飙，年内涨幅均超100%。</p>
  <p>12月24日，白银首次站上72美元/盎司，铂金突破2377美元/盎司，钯金逼近1960美元/盎司，最高纪录不断被改写。Wind数据显示，按当天最高价计算，年内白银、铂金、钯金的涨幅分别高达惊人的151.61%、163.05%和115.72%。</p>
  <p>南开大学金融发展研究院院长田利辉对时代周报记者分析称，本轮贵金属集体走强，核心在于“三重共振”：一是美联储降息周期开启，美元指数回落，美元资产吸引力下降；二是地缘政治风险持续发酵，中东局势、俄乌冲突等导致避险需求激增；三是全球去美元化加速，多国央行持续购金，中国、印度等国央行购金量创历史新高。</p>
  <p>然而，面对历史高位，投资者心态分化：有人回本后选择观望，有人坚定长持不动，也有人凭借杠杆实现翻倍收益。盛宴之下，是继续追高，还是落袋为安？</p>
  <h2><strong>金价“狂飙”，投资者心态分化</strong></h2>
  <p>12月24日，现货黄金在创下4525.83美元/盎司新高后回落，收盘报4479.42美元/盎司。COMEX黄金期货亦在触及4555.10美元/盎司后收于4505.40美元/盎司。</p>
  <p>中信期货分析指出，金价冲高回落受美国超预期GDP数据带动美元反弹影响，但地缘风险、央行购金及降息预期将持续支撑，下行空间有限。</p>
  <p>机构对前景颇为乐观。高盛预计，到2026年12月金价将涨至4900美元/盎司；摩根大通则认为，中国保险巨头的新需求可能推动金价在2026年底触及5055美元/盎司。</p>
  <p>国内金饰价格随之水涨船高，周大福、周生生等品牌足金饰品报价一度突破1400元/克。</p>
  <p>12月25日，周大福、周生生等多家品牌金饰价格回落至1395-1398元/克左右，较前一日单克价下滑约12-16元。其中周大福、六福珠宝、老凤祥、潮宏基、谢瑞麟、金至尊等品牌足金金饰价格报1398元/克，周生生、老庙黄金报1397元/克，周六福报1395元/克，菜百首饰报1360元/克，中国黄金报1300元/克。</p>
  <p>临近年末，时代周报记者注意到，在北京朝阳合生汇，周六福、周大福、菜百首饰、周生生、中国黄金、老庙黄金、潮宏基等品牌推出克减130元的活动，部分货品低至5折。</p>
  <p>不同商场门店优惠力度也不同，中国黄金通州万达门店销售人员告诉时代周报记者：“目前正在做圣诞和元旦的活动，优惠力度是克减120元，一口价商品打八折，老顾客可以打七五折。”此外，中国黄金华贸门店销售人员告诉时代周报记者，当前该门店的优惠力度是克减150元。</p>
  <p>面对一路高涨的黄金饰品价格，大多数消费者望而却步。与此相比，黄金投资者的心态却呈现出较大分化。</p>
  <p>“从今年10月开始投资黄金，正赶上黄金牛市”。北京00后徐雨告诉时代周报记者，她主要购买黄金ETF，“因为买入方便，可以每天看到收益损失”。</p>
  <p>十月初入市的她，刚进场就经历了市场剧烈波动，“之前投了2万，因为10月底开始的波动亏损后撤出了一部分，现在只剩1万多。黄金最近大涨，我刚回本，还赚了1000块”。面对金价新高，徐雨选择暂停投入，保持观望，“波动太大，不落袋为安也不敢说真赚了”。</p>
  <p>与徐雨不同，魏灵的投资策略则显得更为稳健。她自2022年起为抵御通胀开始购金，主要投资实物金条与首饰。“2024年买的100克，成本约每克680元，现在已经赚了3万元左右。”魏灵表示。</p>
  <p>目前，魏灵在黄金投资方面已投入约20万元，占其总资产20%。尽管10月份时以每克979元购入的50克一度亏损，但近期大涨已让其回本。“选择持有，不关注短期因素。黄金的货币属性决定其长期（以十年计）总是上涨的。”她表示。</p>
  <p>李娜的投资组合更为多元，包括积存金、首饰和投资金条。“从前年开始投资，最初开始买黄金是因为喜欢戴黄金首饰”。目前，她总共投入约10万元，占个人总资产的40%左右。</p>
  <p>“其实不应该占比这么高，风险太大了。”李娜表示，目前的收益率约40%，都卖出去的话，能赚四万元左右。</p>
  <p>面对高位，她采取“部分获利了结+持有底仓+回调加仓”的灵活策略。“已将短期获利部分约30%仓位减仓锁定收益；保留70%底仓长期持有”。李娜设置了明确的加仓区间，她表示，“若金价回调至4250-4300美元/盎司，会用积存金分批补仓”。</p>
  <h2><strong>白银、铂金、钯金涨超100%，有投资者暴赚200%</strong></h2>
  <p>在黄金闪耀之际，白银、铂金、钯金的表现更为凶猛。</p>
  <p>截至12月24日收盘，现货白银报71.87美元/盎司，盘中曾涨至72.70美元/盎司，创历史新高。COMEX白银期货报71.875美元/盎司，也在盘中刷新历史高位，至72.750美元/盎司。若按当日最高价计算，年内现货白银、COMEX白银期货分别涨151.61%、135.56%。</p>
  <p>“直接投资白银期货，交易灵活，杠杆能放大收益。”在北京从事金融工作的路鸣，道出了专业玩家的路径。2024年，他开始关注贵金属，2025年8月察觉到白银“逼仓”等增量逻辑后，便将重心从黄金转向白银。路鸣将个人账户20%-30%的期货仓位配置于白银，目前累计投入约100万元左右，盈利超过200%。</p>
  <p>然而，即便经验丰富，面对巨大涨幅也要保持警惕。“近期计划逐步减仓”，路鸣判断，白银可能还有逼仓行情，因此选择部分获利了结，剩余仓位继续持有。路鸣表示，“未来仍关注贵金属大周期下不同品种机会。后续降息逻辑可能使黄金更强，铂金、钯金也值得关注”。</p>
  <p>事实上，钯金、铂金近期表现同样优秀。截至12月24日收盘，现货铂金报2256.73美元/盎司，盘中曾涨至2381.53美元/盎司，突破2008年所创历史最高位2300美元/盎司；现货钯金报1726.84美元/盎司，盘中最高触及1959.68美元/盎司，创下历史新高。按当日最高价计，年内现货铂金、现货钯金已分别上涨163.05%、115.72%。</p>
  <p>紫金天风期货贵金属研究员刘诗瑶对时代周报记者表示，本轮贵金属集体走强主要基于三重逻辑驱动：一是美联储降息预期持续构成直接利好；二是市场对美联储在数据缺失时降息的决策独立性产生担忧，强化避险需求；三是提前定价2026年美国中期选举年可能出现的财政扩张与债务风险。</p>
  <p>“从品种表现看，白银、铂金等涨幅显著超越其工业属性范畴，主要跟随黄金的金融逻辑波动，呈现出贵金属普涨格局，其中白银因历史弹性特征涨幅尤为突出。”刘诗瑶指出。</p>
  <p>面对创纪录的价格，投资者追高进场风险几何？田利辉建议，普通投资者应避免追高，贵金属波动剧烈，杠杆交易风险极高。应慎重控制贵金属在投资组合中的比重，作为避险资产而非核心配置，关注白银工业需求变化，如光伏用银需求因价格高企可能受到抑制。投资需理性，切忌被“翻倍”诱惑冲昏头脑。</p>
  <p>（徐雨、魏灵、李娜、路鸣等为化名。）</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653339044&amp;idx=4&amp;sn=70594f7b58c237a520b01a7e3f5db515&amp;chksm=bc76c64c23b329e35e558d4b1bc55d1889d677156406714eca5e45b0c10ac9da7d28e7a90198&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：王苗苗，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612186689270531</id>
            <title>2025年A股IPO收官：111家企业募资1253亿元，近半投向科创领域</title>
            <link>https://www.36kr.com/p/3612186689270531</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612186689270531</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:53:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年即将收官，A股IPO（首次公开募股）格局初定。</p>
  <p>截至12月26日，2025年A股发行上市家数共计111家，同比增长11%；首发募资总额达到1253.24亿元，同比增长86.07%。募资增速远超数量增速，反映出今年IPO市场“少而精”的特征。</p>
  <p>业内人士表示，纵观过去五年，A股IPO市场已完成从“规模扩张”向“质量优先”的转型。在经历2021年高位运行后，市场通过阶段性调整实现了结构优化，标志着已进入一个更加成熟的发展阶段。</p>
  <h2><strong>全年111家企业IPO募资1253亿元</strong></h2>
  <p>2025年，A股IPO市场在稳监管与优结构背景下实现温和增长。截至12月26日，A股共有111家企业首发上市，募资总额为1253.24亿元。</p>
  <p>2025年，A股IPO平均募资额相较于2024年增加4.55亿元，同比增长67.51%。IPO企业募资规模主要集中在10亿元以下的区间，其中募资金额在5亿元以下的企业有42家，募资金额在5亿元至10亿元的企业有40家，募资金额在10亿元至30亿元的企业有21家。此外，募资金额在30亿元至50亿元、50亿元至100亿元、100亿元以上的企业分别为6家、1家、1家。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b152b1afc2e646cd9e55697be74d901e@5727534_oswg19314oswg705oswg422_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2025年，A股十大IPO共募集资金561.65亿元，占全年募资总额的44.82%，募资额同比增长197.52%。这一显著增长主要源于下半年超大型项目的落地，其中华电新能（600930.SH）于7月上市，以181.71亿元的募资额领跑，直接拉高了前十大IPO的整体募资规模。</p>
  <p>紧随其后的是摩尔线程（688795.SH）和西安奕材（688783.SH），分别以80.00亿元和46.36亿元的募资额位列第二和第三位。其中，摩尔线程是国内稀缺的全功能GPU研发企业，其募资主要投向新一代自主可控AI训推一体芯片等硬科技研发项目；西安奕材则专注于12英寸硅片研发生产，产品覆盖AI芯片、存储等领域，两者均体现了资本市场对高科技及战略性新兴产业的重点支持。</p>
  <p>从整体市场特征来看，2025年A股IPO呈现“少而精”的特点，超大型项目密集落地，成为募资规模大幅增长的核心动力，这与A股从“规模扩张”向“质量优先”的转型方向高度契合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_86f193520b1a47dd9ea4995672ef3782@5727534_oswg288284oswg1344oswg670_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得关注的是，年内IPO终止审查企业共计99家，同比减少335家，降幅达到77.19%。终止数量的大幅回落，反映出监管审核标准趋严，企业申报更加审慎，“带病申报”现象减少，同时也体现出市场生态持续优化。</p>
  <h2><strong>近五成IPO募资投向科创领域</strong></h2>
  <p>在板块分布上，科创板上市企业共有18家，合计募资353.05亿元；创业板上市企业有32家，合计募资245.05亿元，北交所上市企业有25家，合计募资72.04亿元；沪市主板上市企业有23家，合计募资432.28亿元；深市主板上市企业有13家，合计募资150.82亿元。</p>
  <p>从科创属性维度来看，创业板与科创板合计上市企业50家，合计募资598.1亿元，分别占全年上市数量和募资总额的45.05%、47.72%。接近五成的募资投向科创领域，展现出资本市场服务科技创新的核心定位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_3623ac4417ca4475a642bb4dbd72b2b3@5727534_oswg102142oswg1146oswg708_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在行业分布上，电子行业成为今年IPO的“双料冠军”，共有19家企业上市，合计募资337.44亿元，分别占全年上市数量和募资总额的17.12%、26.93%。从募资额TOP5行业来看，电子（337.44亿元）、汽车（229.25亿元）、公用事业（181.71亿元）、电力设备（118.56亿元）、医药生物（90.66亿元），占全年募资总额的76.41%。这一分布特征与国家战略导向高度契合，工业、科技类行业成为IPO市场主力，彰显资本市场对新质生产力发展的支撑作用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ca205b3403494a898e554e18c143cc2d@5727534_oswg91811oswg554oswg414_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体来看，今年IPO企业主要集中在电子、电力设备、汽车、机械设备、医药生物、基础化工等行业，分别有19家、18家、16家、13家、10家、10家。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b4593f2ecf7443cd9c0ce569d2d819dd@5727534_oswg31141oswg725oswg468_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>A股打新收益创三年新高</strong></h2>
  <p>从首日涨幅来看，今年IPO新股上市首日平均涨幅达到256.77%，为近三年来最佳表现。中签投资者在股票上市首日，回报率超发行价两倍半。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_01d171646fce45fe80da01487709344f@5727534_oswg452260oswg1138oswg3144_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体来看，上市首日涨幅在300%以上的个股共有34只，其中大鹏工业（920091.BJ）首日涨幅达到1211.11%，排名榜首，三协电机（920100.BJ）、沐曦股份（688802.SH）紧随其后，首日涨幅分别达到785.62%、692.95%。此外，江南新材（603124.SH）首日涨幅606.83%，广信科技（920037.BJ）首日涨幅500%，分别位居第四和第五位。</p>
  <p>值得关注的是，随着沐曦股份的上市，再度刷新了年内A股IPO单签赚钱纪录。若以收盘价计算，投资者中一签盈利高达36.26万元，超过了摩尔线程（24.31万元），成为A股全面注册制以来最赚钱新股，也是近十年最赚钱新股。</p>
  <p>业内人士表示，“肉签”股多为市场热门的概念股，其频繁出现的原因是今年新股普遍具备强科创属性，被市场寄予厚望。此外，发行价控制相对合理，为股价上涨预留了空间。</p>
  <p>本文来自微信公众号“览富财经网”，作者：览富财经网，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612182446097409</id>
            <title>全员涨薪潮</title>
            <link>https://www.36kr.com/p/3612182446097409</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612182446097409</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:52:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是喜闻乐见的一幕。</p>
  <p>昨天（12月25日），京东发布2025年终奖公告：京东全集团92%的员工拿满甚至拿到超额年终奖，年终奖总投入同比增幅超过70%，京东采销更是“<strong>上不封顶</strong>”。</p>
  <p>不久前，字节跳动也宣布2025年奖金投入提升35%，调薪投入上涨1.5倍。几乎同一时间，比亚迪、宁德时代等超级巨头纷纷开始给员工涨薪。</p>
  <p>想起不久前，中央经济工作会议列出了明年经济工作的重点任务，第一条就提出——制定实施城乡居民增收计划。无疑，企业主动给员工涨工资、发奖金，立竿见影。</p>
  <p>“希望这股涨薪的风，也能早点吹到我这儿。”临近年底，打工人们有了新盼头。</p>
  <h2><strong>京东字节宣布：涨工资！</strong></h2>
  <p>大厂们开始卷工资了。</p>
  <p>从京东说起。其实早在去年9月，京东就发布了20薪升级计划，宣布自2024年10月1日起京东零售集团和职能体系将用两年时间实现20薪，其他部门也将随后陆续启动加薪。</p>
  <p>根据该加薪计划，今年京东年终奖继续大幅上涨，已升级部门今年实现19薪，同时更有业务单元提前实现20薪。此外，一线员工年终奖仍将在年前发放。</p>
  <p>整体上，<strong>京东2025年的年终奖总投入同比增幅超过70%，预计将创下行业今年最大涨幅</strong>。具体来看——</p>
  <p>今年升级为19薪的部门内：</p>
  <p>年度绩效A+的员工将获得10倍月薪年终奖，即全年22薪；</p>
  <p>年度绩效A的员工将获得9倍月薪年终奖，即全年21薪；</p>
  <p>年度绩效B+的员工将获得7倍月薪年终奖，即全年19薪。</p>
  <p>今年提前实现20薪的部门内：</p>
  <p>年度绩效B+的员工即可拿满8倍月薪年终奖，即全年20薪；</p>
  <p>年度绩效A+将直接获得12倍年终奖，全年24薪。</p>
  <p>更让人羡慕的是，京东采销今年将实现平均25薪，并且“上不封顶”。</p>
  <p>这已是京东过去一年多第七次提高员工薪酬激励。值得一提的是，京东今年布局外卖业务时，率先给全职骑手缴纳社保，推动行业迈进“五险一金时代”。</p>
  <p>字节也放大招。12月19日，字节跳动发布全员信宣布：增加奖金（含绩效期权）投入，2025全年绩效评估周期相比上个周期提升35%；大幅增加调薪投入，较上个周期提升1.5倍；提高所有职级薪酬总包的下限（起薪）和上限（天花板）。</p>
  <p>对此，字节跳动在邮件中解释称，行业正面临新的机遇和挑战，公司希望更好地激励和保留优秀人才，同时也更好地吸引全球优秀人才加入公司，<strong>做到“什么时候加入都不晚”。</strong></p>
  <p>纵观互联网大厂圈，字节的薪资一向诱人。根据其在社交平台发布的多个热招岗位，如“海外商业化-算法专家”月薪最高可达8万元，“智能编辑技术专家”月薪最高7万元，校招大模型算法工程师岗位的月薪达到6万元，相当霸气。</p>
  <p>当然，这背后是一场硝烟四起的人才争夺战。并且，火药味已经越来越浓了。</p>
  <h2><strong>涨薪潮来了</strong></h2>
  <p>这股风还吹到了智能制造领域。</p>
  <p>先是宁德时代。一份宁德时代发布的《2026年1—6级员工薪资调整通知》显示，宁德时代决定自2026年1月1日起，对1-6职级员工——也就是<strong>生产线操作工、技术员等一线基层员工的基本工资上调150元</strong>，其他薪资结构保持不变。</p>
  <p>消息一出便迅速冲上热搜，有网友调侃“杯水车薪”，但也有网友认为“蚂蚱腿再少也是肉，总比没有强”。</p>
  <p>除涨薪外，宁德时代还发布春节坚守岗位奖励计划：2026年春节期间，出勤满足条件即可获得额外奖励至少3200元，适用范围包括宁德时代及国内独资分、子公司电池、材料制造基地下沉十大部门、中心MEVEOPNJG1-10级员工。</p>
  <p>市值1.7万亿元，宁德时代赚钱能力惊人。单看2025第三季度，其营收1041.85亿元增长12.90%，净利润185.49亿元增长41.21%。<strong>粗略计算，“宁王”日赚约2亿元</strong>。</p>
  <p>比亚迪也来了。最近，互联网社交平台流传着比亚迪对技术研发人员实施涨薪的消息——调薪幅度500元至3000元不等，最高涨薪4500元。对此，比亚迪方面回应称“涨薪属实”，但并未透露涨薪幅度以及涉及人员数量。</p>
  <p>还有市值超2700亿的药明康德。据业内流传，药明康德2025年已完成两次调薪：4月按个人绩效实施差异化年度加薪，11月底落地化学业务平台特殊调薪，覆盖90%正式员工，平均调薪比例超12%。</p>
  <p>羡煞打工人的是，昨天药明康德发放了2025年“阳光普照奖”——<strong>每人2500元，全员覆盖、不问岗位、不谈绩效</strong>。据说，这是这家生物医药巨头的老传统，今年比往年还多了500元。</p>
  <p>如此来看，从科技、制造到新能源、医药，巨头们不约而同地表态涨薪，信号隐隐约约。</p>
  <h2><strong>涨薪背后：鼓励大力消费</strong></h2>
  <p>风向标早已出现。</p>
  <p>这里先提一提大背景。长期以来，我国居民收入占比GDP的比例相对偏低，只有40%左右，而发达国家在70%左右，全球平均水平也有60%左右。再来看消费水平，2025年前三季度最终消费支出对经济增长贡献率达53.5%，虽较往年有所提升，但与发达国家仍有差距。</p>
  <p>扩大内需消费，成为一场至关重要的战役。</p>
  <p>今年12月11日落幕的中央经济工作会议，明确提出“制定实施城乡居民增收计划”。细细读下来，这次的表述与往年相比有着明显不同，一方面今年不再只是中低收入群体，几乎覆盖了所有人群。另一方面，相较于去年提出的“推动”，今年则是“制定实施”，这意味着将从方案制定走向具体落实。</p>
  <p>数日后，《求是》发表了《坚定实施扩大内需战略》，对于居民增收计划提出了更具体的表述，“实施城乡居民增收计划，<strong>提高居民收入在国民收入分配中的比重，提高劳动报酬在初次分配中的比重。”</strong></p>
  <p>显然，增加居民收入，最直接、最有效的办法就是涨工资。以此，进一步释放中国居民的消费潜力，让大家更富裕，更敢消费，从而形成内外需更加均衡的增长动力。</p>
  <p>做好、做大“蛋糕”的同时，也要进一步分好“蛋糕”。根据人社部数据，2025年以来已有20多个省份上调最低工资标准：第一档月最低工资标准均超过了2000元。其中，上海以2740元领跑全国。同时，超过2500元的还有北京、天津和广东，深圳最低工资标准单列公布，为2520元。</p>
  <p>另一边，以京东、字节、宁德时代、比亚迪等为代表的超级巨头，已率先开了个好头。毕竟，居民富裕了，消费能力上去了，才能拉动了内需。</p>
  <p>一切才刚刚开始。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247707663&amp;idx=1&amp;sn=33da16864879a5986f74678e70135dfa&amp;chksm=edfdcce3946ae507869a4aed332f533eda91f682fad64c8f801b35eedc547336ae427e0c3e1c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：周佳丽，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612182536930311</id>
            <title>12个月，他们投向医疗30亿</title>
            <link>https://www.36kr.com/p/3612182536930311</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612182536930311</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:52:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年已近尾声，若要回顾今年创投圈的关键时刻，创新药高涨一幕无法略过。</p>
  <p>回想前两年，医疗行业经历估值回调，医疗投资一度趋于沉寂。市场情绪悲观之际，启明创投主管合伙人胡旭波却和团队做出重要决策——继续重点投资创新药和器械领域，尤其是有重大临床突破潜力的领域。</p>
  <p>现在回头看，当初的决定看起来是个正确的选择：今年，创新药板块成为明星，港股盛况更是历历在目——IPO钟声不断，十倍股频现，指数一度飙升逾100%。甚至有投资人将2025年称为“医药翻身之年”。</p>
  <p>“这只是开始。”行至年终，胡旭波与投资界聊起中国医疗创新的起起伏伏。他相信，中国创新已迈入关键节点，正从局部单点突破向大规模全面突破迈进。以年初DeepSeek出圈为代表，中国创新历经了从跟进到自我革新的阶段，未来工程化能力还将持续提升；创新药领域正从部分技术平台、产品线的突破，向整个体系突破迈进，医疗器械领域的创新企业则凭借突破性的临床设计和显著供应链优势稳步开始全球化发展。未来5-10年，更多具有高度原创性的研发成果有望在中国的实验室诞生，并为全球医药创新做出贡献。</p>
  <h2><strong>出手医疗创新最重VC</strong></h2>
  <p>回顾2025年，启明创投在医疗创新领域投资了超30个项目，出资超30亿元，其中部分投资是2024年下半年决策——启明创投的医疗投资历来是一张晴雨表。</p>
  <p>印象深刻的包括康诺思腾。这是一家诞生于中国香港的创新型手术机器人独角兽企业，创始人欧国威曾在香港中文大学任教，后于2019年创办康诺思腾（Cornerstone Robotics），专注于研发能够对标进口品牌的新一代国产腹腔镜手术机器人。</p>
  <p>带着做中国手术机器人的创业抱负，欧国威率队的康诺思腾于2024年开始步入商业化，完全掌握机械架构、电气架构、软件架构、复杂算法以及视觉影像等核心技术，自主搭建手术机器人底层技术平台。一路走来，其身后也集结了一众VC/PE，融资超30亿元。当中，启明创投是最早一批投资康诺思腾的投资人。</p>
  <p>那是2020年，一通在酒店大堂的远程电话让胡旭波坚定了投资的决心。欧国威对手术机器人领域的深入理解及其“改变全球手术机器人格局”的愿景，与启明创投对市场前景的判断相契合——无论是国内尚未饱和的需求，还是国际新兴市场的潜力，都预示着广阔的空间。就这样，启明创投于2020年坚定出手，并一路陪伴至今。</p>
  <p>今年11月，康诺思腾完成约2亿美元的超募融资，吸引了包括港投公司、全球战略投资者及主权基金在内的多方参与，老股东启明创投等继续加持。这已经是启明创投连续五轮投资康诺思腾。</p>
  <p>几天后，启明创投还将迎来一个重要IPO——英矽智能，一家总部在香港、研发中心在上海的AI新药研发企业。启明创投是英矽智能的早期投资人之一，并在后续多轮融资中持续加注。英矽智能发展早期，启明投资团队就开始协助支持公司建立起新药研发领导团队，并让AIDD的AI能力和药物研发能力真正开始有机融合。</p>
  <p>手握全球进展最快AI药物——Rentosertib（ISM001-055），英矽智能即将于今年12月30日在港交所IPO上市，有望成为今年港股最大的Biotech IPO。按照每股24.05港元的发行价计算，英矽智能将通过本次IPO募集至多约23亿港元，IPO市值超130亿港元。</p>
  <p>这也意味着，启明创投医疗版图又将落袋一个百亿IPO。</p>
  <h2><strong>越是市场悲观，越是笃定出手</strong></h2>
  <p>久违地，医疗行业热闹了起来。</p>
  <p>回想2021年，中国医药行业在一场狂欢后急转直下，此后便是漫长的冬天。期间，一级市场大多数投资机构将重心转移到其他领域，出手医疗极其谨慎，甚至是避而不投。在部分投资机构内部，医疗投资人也一度处于相对边缘的位置。</p>
  <p>“那时候，我们始终告诉自己，要深入到第一线，积极与企业家和创业公司沟通交流，验证我们所关注的创新的实际价值。”行业最低谷时，启明创投医疗创新投资团队并未停下脚步，反而保持了密切的行业接触，几乎覆盖了中国95%以上的创新公司。</p>
  <p>直到2024年上半年，胡旭波的判断逐渐清晰：启明创投所坚持的——<strong>推动中国创新服务于全球市场——是可行且值得投入的</strong>。尽管当时医疗投资依旧冷清，启明创投看到的是中国创新被低估的历史性机会，胡旭波也在内部多次强调，必须把握时间窗口，果断投资那些产品与团队都令人信服的企业。</p>
  <p>在这样“非共识”的决策下，启明创投成为那段时期在医疗领域投资最为活跃的VC之一，在创新药和医疗器械领域投入了大量资金，自2024年5月至2025年5月的<strong>12个月内投入近40亿元人民币，可能是当时全球医疗基金里投资金额最大的中国VC基金</strong>。</p>
  <p>今年以来，随着全球资本对中国创新资产进行重新评估，加之企业自身通过产品成果、授权合作与全球布局释放积极信号，行业整体呈现回暖态势。“我们还是有点幸运，我们坚持的投资理念和方向在一个合适的时间点得到了初步的确认。”胡旭波感慨道。</p>
  <p>回顾今年以来，A股与港股市场中市值达到千亿规模的创新药企已增至近10家。此间，港股创新药板块表现尤为突出，成为上涨集中的领域，相关指数一度累计涨幅超过100%，十倍股集中涌现。赚钱效应传导，港交所门口排满了等待上市的创新药企，仅11月就有近10家公司递交上市申请。截至当前，2025年成功在港股IPO的生物科技公司数量已较去年翻了一倍。</p>
  <p>这当中，国际投资人的态度转变尤为关键，此前主战场在纳斯达克的机构，2025年开始重新配置中国创新药资产。背后原因在于，<strong>中国创新药企业的产品开始真正意义上被业界尤其是全球制药创新体系认可。</strong></p>
  <p>“尤其是去年下半年开始，有一批中国创新药企业的临床数据很惊艳。业界发现，原来中国公司能做得这么好，海外药企龙头纷纷开始跟中国创新药企业合作。”胡旭波分析本轮回暖时指出。</p>
  <p>他认为，如果有更多大型国际投资机构和专业投资人将资金配置于中国的创新药企业，先进入港股，未来或许进一步扩展至A股，这将有助于构建一个更加健康、可持续的生物医药产业生态。</p>
  <h2><strong>穿越周期，中国医疗创新永不落幕</strong></h2>
  <p>医疗投资下一阶段的叙事是什么？</p>
  <p>据最新数据，2025年全球大型药企通过许可引进（license-in）的新药项目中，大概率有40%左右来自中国的优秀生物医药创业公司。而2019年，这一数字是0。</p>
  <p>这里有一个背景，即全球最大的跨国药企，有一部分新药通过内部研发获得，另外很大一部分新药是通过外部的协作，包括从中小生物研发机构、生物研发企业购买专利。过去中国是license-in，是海外先进医药的主要承接国。但现在情况变了，<strong>中国已经成为license-out（对外授权）的主要发源地。</strong></p>
  <p>行至当下，中国医疗创新的全球影响力正在提升，密集发生的超级BD交易是最好的印证。在胡旭波看来，BD不仅带来现金流，也证明中国创新企业具备与全球头部药企合作的能力，更向市场证明了中国创新药的价值。BD交易构建了全球化创新生态——<strong>中国提供优质资产，国际药企提供商业化渠道，形成双赢格局。</strong></p>
  <p>在此过程中，中国正在形成独特的创新双循环：一方面用工程化创新快速降低新药可及性门槛，另一方面用源头创新构建长期技术壁垒。</p>
  <p>因此，持续布局中国药企出海，早已成为启明创投的核心投资主题之一。团队也从数年前开始，有意识地帮助被投企业构建全球化的能力，包括定期与海外大公司保持交流，连续四年组织启明创投医疗创新合作伙伴开放日（Partnering Day）活动，为启明创投投资企业和全球头部药企搭建交流合作平台，帮助了超百家（次）全球头部药企和投资企业开展了数百场1对1会议。</p>
  <p>除此之外，启明创投内部也设立专门的团队，协助投资企业了解全球医疗注册体系和出海规则等，帮助企业走向全球。投资界拿到一组数据——截至2025年10月，<strong>启明创投投资企业已签署30项与跨国药企及海外生物科技公司的BD交易，可披露交易总额197亿美元。</strong></p>
  <p>“很多企业已经发展到能在全球市场上与最优秀的公司同台竞争的水平。”谈及中国药企的未来，胡旭波表示，“10年前，我还不敢说很多中国公司能走向全球，但现在可以了，只不过要求更高了。”</p>
  <p>他也指出，许多中国公司规模仍较小，要参与海外市场，将面临诸多挑战——包括文化适应、对全规则的了解、组织结构的支撑，以及资金实力等。“并非所有企业都能走到那一步，前方的道路必然充满挑战。”</p>
  <p>起起伏伏，中国医疗投资市场经历了过去一个周期的寒冬，今年终于有了暖意，正如大家普遍感受到医疗行业拐点的到来。走出低谷，这一波行情将持续多久？</p>
  <p>胡旭波的心态是谨慎乐观：“未来的路还很长，我们当前始终保持着兢兢业业的状态，深入调研每一家企业。启明创投所投的医疗公司，我们都希望它具有全球影响力——<strong>无论是新药还是器械，都不应仅局限于中国市场，而应能在海外创造价值</strong>。当然，这也绝非易事。”</p>
  <p>医疗创新历来被喻为一场耗资巨大、周期漫长的马拉松。于医疗投资人而言，这无疑也是一场漫长的修行。或许正如胡旭波所说，一切才刚刚开始。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247707663&amp;idx=2&amp;sn=a4f3afe57bf60db7f3a9225b8e0bfe2f&amp;chksm=ed9fc39352976d2189126a621fd638972974b8ca6ee475237b7efa9d1d03c4ad3de38751f438&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：周佳丽，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>