<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3602422726001665</id>
            <title>英特尔与火山引擎联手，开启「全局效率优化」时代</title>
            <link>https://www.36kr.com/p/3602422726001665</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602422726001665</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 13:23:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全球市场都在面临一场前所未有的算力需求爆发。</p>
  <p>特别是在多模态技术趋于成熟，企业级复杂Agent落地愈发成熟的当下，越来越多企业跑在了AI转型的前沿。</p>
  <p>然而，当模型选择更多，算力需求不断膨胀时，如何算好经济账，如何实现高吞吐、低时延，在稳定性、可靠性与兼容性上更加有的放矢。凡此种种，让AI加速迈入了云原生时代。</p>
  <p><strong>12月19日，在2025火山引擎冬季FORCE原动力大会上，豆包大模型1.8及音视频创作模型Seedance 1.5 pro正式亮相。权威评测数据显示，豆包大模型在多模态理解、生成能力及Agent能力上，已跻身全球第一梯队。</strong></p>
  <p class="loading-entity">&amp;amp;nbsp;</p>
  <p>另据火山引擎总裁谭待介绍，截至今年12月，豆包大模型日均token使用量突破50万亿，较去年同期增长超过10倍。</p>
  <p>在千行百业落地应用AI的关键节点，火山引擎的AI普惠究竟是如何做到的？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_afed6ea6c0be4685a35a8d04ea470068@1215450627_oswg6453oswg1080oswg144_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>爆发背后的AI原生解法</strong></h2>
  <p>“数据是新时代的石油”，火山引擎总裁谭待曾在采访时表示，云计算行业的第二次浪潮就在于智能化，其意义不仅在于能发挥数据价值，还在于端到端的业务落地，以大模型为基础，包括MaaS（模型即服务）、AI Agent将成为未来数年内的主流叙事。</p>
  <p>延续着这样的思路，火山引擎做出了一系列布局。</p>
  <p>和1.0时代不同的是，云原生的主体不再是网页，而是Agent。业内将2025年视作Agent元年，作为大模型落地的重要载体，Agent的能力也就决定了大模型应用的深度。</p>
  <p>为了打破Agent的能力上限，火山引擎一手抓底层模型，密集迭代模型版本，拿出了性能与性价比兼具的模型产品，如此次更新的视频生成模型Seedance系列，在性能表现上灵活性更高：Seedance-1.0-Lite以成本优先，兼顾速度，适配高频创作。Seedance-1.0-Pro可实现影视级画质与原生音效，支持2–12秒1080P自由生成、多镜头叙事及精准指令参考，满足电影级感官叙事需求。</p>
  <p>而Seedance 1.5 pro音视频创作模型有着更为惊艳的完成度，采用创新的原生音视频联合生成架构，支持环境音、背景音乐、人声等多种元素，实现了毫秒级的音画同步输出。在对白处理上，模型支持多人多语言对话，口型对齐精准，覆盖中文方言（如四川话、粤语等）、英文及小语种，极大地提升了视频内容的真实感与全球化创作潜力。</p>
  <p>另一方面，火山引擎也携手生态伙伴做好硬件配置，开启云边端协同新模式，通过软硬件高度配合的生态解法，最大化释放AI能力。</p>
  <p>今年6月，在火山引擎2025春季原动力大会上，火山引擎已联合英特尔共同发布搭载英特尔至强6性能核处理器的第四代通用计算型（ECS）实例家族，使得传统应用与AI应用全面升级。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_094eec6a18384246a5de4e310c3b2606@1215450627_oswg87906oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据测算，与上一代实例相比，通用计算基础型实例g4i在MySQL数据库和Web应用上分别实现了20%和19%的性能提升，算力增强型实例g4ie在视频解码和图像渲染上带来了15%和26%提升，I/O增强型实例g4il在Spark大数据和Redis数据库上也实现了13%和30%的提升。</p>
  <p>在火山引擎的构想中，AI时代CPU同样重要，通过与GPU的高度协同，其为企业级AI Agent提供端到端支持。其特性在于高并发快响应、算力成本进一步实现优化，并保障安全隐私性。</p>
  <p>特别是在安全方面，对于许多企业而言，业务的稳定和安全都是最核心的，随着大模型应用深入产业，越来越多高质量、高价值敏感数据都成为AI应用的关键。</p>
  <p><strong>火山引擎与英特尔TDX构建的机密虚拟化实例，无论是RAG应用中的信息提取处理流程还是数据库流程，亦或是模型生成流程，都可以在不改变应用程序中间框架的前提下，直接访问机密虚拟机，实现云中的隔离和保护，用户使用RAG部署过程保证数据安全。</strong></p>
  <p>火山引擎云存储还引入了至强处理器的压缩加速技术（英特尔®QAT），以提升数据压缩和解压缩效率，实现优于软件LZ4算法的压缩率和更低时延。QAT硬件加速生成CRC32校验码，确保数据完整性，并支持AES-XTS模式的对称加密，增强数据可靠性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_e6eb0230cc4c49fc86bacf2a20167514@1215450627_oswg862470oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如此强大、灵活并兼顾成本效益的方案，最终构成了企业的AI弹性基础设施底座，加速了企业的智能化进程。正如英特尔市场营销集团副总裁、中国区总经理郭威所言：“释放AI的真正价值，关键在于以易部署、可扩展的方式将其融入企业工作流与个人体验。依托火山引擎在算力资源调度和大规模AI推理优化方面的优势，我们将芯片级的创新通过云原生架构无缝延伸至边缘与终端，实现对多样化、异构算力资源的高效协同与统一交付，构建稳定可靠的服务环境，助力开发者与企业聚焦于业务创新与落地。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_91ca21ced3f34d68bb467115b03dee3e@1215450627_oswg10273oswg1080oswg144_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>AI普惠前夜，云边端协同撑起一片天</strong></h2>
  <p>火山引擎的AI云原生，不仅仅是技术的创新，也是未来推动AI应用落地的关键基础设施，通过与英特尔合作推进“云边端协同”趋势，火山引擎将推动AI应用于更为广阔的行业和场景。</p>
  <p>在此次2025火山引擎冬季FORCE原动力大会的展位，我们也见到了火山引擎与英特尔在边侧与端侧的多元应用。</p>
  <p>在基层社区治理中，工作人员往往面对着琐碎繁杂的事物，并且业务跨度大，往往需求千丝万缕。AI如何在其中发挥价值？社区全能助手“华格格”应运而生。它通过企业AI工作台的智能意图识别能力，能够自动理解用户多领域不同需求，并将其精准分配给对应的智能体，将原本分散在多个系统中的功能无缝衔接、自然协同。</p>
  <p>顺畅的使用体验背后，则是英特尔HiAgent智能一体机解决方案在发挥价值。其重点针对多智能体跨域请求需频繁切换、体验割裂、上下文丢失等问题，依托于火山引擎HiAgent企业AI工作台实现了优化。自动将用户跨领域请求及上下文路由至对应智能体，聚合离散功能，打造“一专多能”数字员工，提升使用体验与处理效果。并且是以灵活、普惠的方式进一步降低部署门槛与算力成本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4ec9a6c7064144bea5ba8f287a1b630b@1215450627_oswg1243743oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此前在德国慕尼黑车展期间，懂车帝巨懂车也曾联合英特尔，完成了一场属于未来世界的展览，刷新沉浸式体验的上限。</p>
  <p>通过PICO VR眼镜，由英特尔PC与服务器平台驱动的6DoF虚拟现实场景，简单来说，不仅支持用户头部旋转（3个旋转自由度），还能检测用户在空间中的位置移动（3个平移自由度），从而实现真实的空间行走和交互感。但其同样需要极低的延迟才能做到优质的沉浸式体验，因此结合低延迟、高并发的RTC实时通讯技术，多方合作实现多路高清视频低延迟传输至VR设备的效果。</p>
  <p>在个人端侧，基于英特尔与火山引擎提供的弹性AI能力，一种新的内容创作工作模式也在诞生。英特尔AI PC视频剪辑Demo，基于LLM/VLM大模型与端云混合算力打造的全自动视频创作工具，通过弹性灵活的算力组合方式，极大的优化生产流程效率。</p>
  <p>例如，端侧GPU可运行VLM模型，对视频素材进行深度解析，变成结构化数据后上传至云端。而云端的LLM模型当即发挥所长，依据用户指令，自动完成主题挖掘、故事性规划、分镜编排、背景音乐匹配及字幕生成，依托于脚本规划，再将任务回归本地，端侧完成视频剪辑合成和导出。通过端云协作，最大化优化视频创作者的工作效率。</p>
  <p>AI时代，算力已成为企业竞争的“新能源”，而云边端协同，让企业级Agent能力不断趋于成熟。作为AI价值的关键衡量指标，豆包大模型日均调用量实现253倍增长，从去年5月1200亿/天攀升至今年9月的30万亿/天。</p>
  <p>截至目前，豆包大模型多个关键行业实现深度落地，覆盖超5亿终端设备、超九成主流车企、八成系统重要性银行和超九成985高校等，展现出广泛的应用前景。</p>
  <p>另据谭待现场透露，豆包大模型日均使用量超过50万亿，自发布以来增长417倍。“万亿Tokens俱乐部”成员突破100家。</p>
  <p>谭待告诉我们，“明年模型之间最重要的还不是竞争，最重要的是要把市场做大。明年这个市场可能还要再涨10倍，大家其实就不是存量的竞争，不是零和博弈，而是说大家一起把市场做大。同时，明年模型还需要进一步降价，这个市场才能做大。”</p>
  <p>如今，AI算力竞争已进入白热化阶段，英特尔与火山引擎的合作正在重新定义企业获取和使用算力的方式。<strong>从云端到边缘，从训练到推理，从性能到安全，双方构建的全栈解决方案正逐步消除企业AI转型的技术门槛。</strong>如果说最初的通力协作解决了产业智能的单点突破，现如今“全局效率优化”时代正在开启，在火山引擎与英特尔的通力协作下，AI普惠时代终将到来。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602270092510464</id>
            <title>2025，中国大模型不信“大力出奇迹”？</title>
            <link>https://www.36kr.com/p/3602270092510464</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602270092510464</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 11:00:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>生成式AI狂奔三年，2025迎来架构创新的大年，三条脉络交织演进，伴随着Scaling&nbsp;law（规模定律）遇到天花板的争议，开始定义AI进化的新范式。</p>
  <p>第一条脉络是认知的深化：从“直觉”走向“逻辑”。2025 年一线模型的共识性演进，是通过强化学习（RL）配合更长的中间推理，让模型从近似 System 1（快思考）的快速模式匹配，逐步过渡到更接近 System 2&nbsp;（慢思考）的多步推理。</p>
  <p>第二条是维度的突破：从“语言”到“物理空间”。 李飞飞强调的“空间智能”（Spatial Intelligence）让AI的演进逻辑从“理解描述世界的符号（语言）”开始进化到“理解世界本身（物理）”。</p>
  <p>第三条是效率的重构：从“暴力美学”到“性价比”。 在产业落地层面，技术的演进逻辑最终回归到极致的算力效能比。为了支撑深度推理和空间理解，模型架构必须变“轻”。</p>
  <p>以MoE（混合专家模型）和稀疏注意力（Sparse Attention）为代表的架构革新，成为解决无限上下文（Infinite Context）算力崩塌问题的关键。</p>
  <p>2025年12月，在腾讯科技HiTechDay上，以《模型再进化：2025，智能重新定义世界》为主题的圆桌论坛，正是围绕大模型进化的深度、维度、效率三条线索展开。</p>
  <p><strong>华中师范大学人工智能教育学部助</strong>理教授熊宇轩为嘉宾主持，三位嘉宾<strong>北京智源人工智能研究院院长王仲远、面壁智能联合创始人、首席科学家刘知远、峰瑞资本投资合伙人陈石</strong>分别从各自的领域，解读2025对于大模型进化的深入观察。</p>
  <p><strong>王仲远</strong>指出，大模型的进化正在经历“从Learning from Text到Learning from Video”的质变。视频数据中蕴含了丰富的时空信息与动态交互线索，为模型学习物理世界动态演变规律提供了关键的数据来源，同时也是当前最容易规模化获取的一类多模态数据，是AI“从数字世界迈向物理世界”的关键桥梁，也为具身智能（Embodied AI）的爆发提供了构建“世界模型”的底座。</p>
  <p><strong>刘知远</strong>提出的“密度法则”（Densing&nbsp;Law）认为，如同芯片摩尔定律，AI的未来在于不断提升单位参数内的“智能密度”。他大胆预言，未来的算力格局将是“云端负责规划，端侧负责做事（执行）”，到2030年，我们甚至有望在端侧设备上承载GPT-5级别的能力，这正是中国AI在算力受限环境下实现突围的核心路径。</p>
  <p>回归到大模型公司落地的现实，<strong>陈石</strong>认为，中美、开源与闭源形成的“双核驱动”格局已定，商业化的“护城河”已演变为“算力、能力、生态”的三层金字塔。在ToB与ToC的夹缝中，“ToP（ToProfessional的专业型用户）”将率先跑通商业闭环。</p>
  <p>对于创业者而言，机会不再浮于表面，而在于“在大模型难以触及的行业深处”，努力建立一个能够跨越模型迭代周期的商业结构。</p>
  <h4>以下为圆桌实录，不改变原意的情况下有删减调整：</h4>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_f80abcce622844b09d6eb41304e428f5@5091053_oswg1118408oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>01&nbsp;2025年大模型进化的三大关键词</strong></h2>
  <p><strong>熊宇轩：</strong>首先请各位嘉宾用最简单的语言总结一下，2025年让您印象最深刻的模型能力进化的关键词、关键技术，以及大模型产品。</p>
  <p><strong>王仲远：</strong>我认为2025年很重要的变化是大语言模型进入到相对成熟的阶段，开始进行效能优化和商业化落地。同时，多模态技术进入到了一个突破变革的新阶段，人工智能正在加速从数字世界迈向物理世界。</p>
  <p><strong>刘知远：</strong>大家看到的是智能体、深度思考，以及大模型在数学、代码等专科上变得越来越强。我想它背后的关键词应该是强化学习。</p>
  <p><strong>陈石：</strong>我从另一个角度观察，觉得有一个关键词叫“双核驱动”。这是两层意思：第一，开源大模型和闭源大模型双核驱动。第二，中国和美国两个国家的企业和人才的双核驱动。特别是2025年，中国的大模型迎来了破局之年，这是让我们最激动的。</p>
  <h2><strong>02&nbsp;Scaling Law见顶了吗？模型迭代的新范式</strong></h2>
  <p><strong>熊宇轩：</strong>最近OpenAI和Google的SOTA模型之间的竞争非常白热化，一个趋势是单纯堆算力、堆参数的边际效益在递减。</p>
  <p>第一个问题给到王院长，您认为在2025年，所谓Scaling Law是否触及到了天花板？如果参数不再是唯一的标准，智源目前在训练范式上有哪些核心的新红利？</p>
  <p><strong>王仲远：</strong>我认为Scaling Law是否见顶要分模型类别来看。在大语言模型上，因为互联网文本数据的枯竭，它的性能提升速度不像原来那么快了。但另一方面，近期像Gemini 3 Pro以及智源发布的悟界·Emu3.5，都是在多模态上发现了新的提升点。</p>
  <p>我认为<strong>大模型的提升，会从原来仅从文本中学习（Learning From Text）进化到从视频中学习（Learning From Video）。</strong>视频数据的量级是互联网文本数据的百倍、千倍乃至万倍，这些数据还没有被非常有效地用来做多模态模型的训练，这是未来大模型新的发展机会。</p>
  <p><strong>熊宇轩</strong>：下一个问题请问刘教授，面壁一直主张提升模型“能力密度”。我们过去的惯性思维是小模型意味着智商缩水，但面壁发布的MiniCPM系列模型完成了一些越级挑战。</p>
  <p>您认为小模型变聪明的物理极限上限在哪里？未来是否会出现云端负责规划、端侧负责执行的格局？</p>
  <p><strong>刘知远：</strong>它一定有一个物理上限。我们提出的“密度法则”发现了一个类似于芯片摩尔定律的大模型发展规律，即我们可以做到每100天，就让模型的密度变得更高。正如芯片的摩尔定律是通过技术创新实现的，我们也需要通过更精细的技术创新，把更多知识压缩到更小的空间里去。</p>
  <p>从动态的眼光看，这个密度会持续提升。它的物理极限是什么，还需要我们对人工智能的技术理论有更好的建构。此外，端云协同也一定会是未来。我们不需要一个AI的杨振宁来服务每个人的生活，但我们需要在云上有非常多方面的专家，端和云一定要有分工。</p>
  <p><strong>熊宇轩：</strong>下一个问题请问陈总，在投资人眼里，2025年大模型公司的“护城河”是否发生了改变？以前我们总说算力、数据为王，现在是否变成了能力、应用或生态为王？</p>
  <p><strong>陈石：</strong>大模型是一个赢家通吃的行业，全球留不下几家。它的“护城河”是多元化的，我理解是三层结构。</p>
  <p>最底层是算力的获取、组织和有效利用。第二层是模型的能力，这关乎模型的上限，如果不能一直维持在SOTA（State-of-the-art）的领域，就会慢慢落伍。第三层最重要的是生态，包括是否能通过应用触达用户、是否有合作伙伴共同触达用户、以及能否通过前两者源源不断地获得数据反馈。所以基础是算力，中间是能力，上面是生态。</p>
  <h2><strong>03&nbsp;从玩具到工具：智能体的商业化瓶颈</strong></h2>
  <p><strong>熊宇轩：</strong>2025年被称为“智能体的商业化元年”，但用户普遍反馈DEMO很丰满，实战很骨感。想请问王院长，您认为目前智能体从玩具变成工具，最卡脖子的技术点是什么？</p>
  <p><strong>王仲远：</strong>我认为有三方面原因。</p>
  <p>第一，基础模型的能力仍有欠缺，尤其在最核心的推理能力上还有提升空间。</p>
  <p>第二，当模型进入各行各业解决领域问题时，需要根据领域数据做进一步训练/对齐，但现在经常会出现“翘翘板效应”，即某方面能力增强时，其他能力又减弱。</p>
  <p>第三，模型的记忆和遗忘机制存在问题。人类学会开车后不会突然忘记炒菜，但模型在这方面还有很多问题需要解决。</p>
  <p><strong>熊宇轩：</strong>下一个问题想请问刘教授，面壁在端侧智能体上做了一些探索，您认为端侧和云端做智能体最大的区别是什么？如何解决手机算力有限的情况下，智能体既要反应快又要想得深的矛盾？</p>
  <p><strong>刘知远：</strong>端侧是智能体落地非常重要的方面，包括具身机器人、车、PC和手机。终端是距离用户最近的地方，能满足隐私、实时、稳定的需求。但挑战在于端侧算力有限，这需要我们用更高的“密度”让模型具备更强的能力。</p>
  <p>端侧智能体距离用户最近，需要对全模态数据有很好的感知理解能力，对用户有很好的个性化服务能力，并对外有很好的行动指令生成能力。这和主要处于数字世界的云端智能体是比较大的区别。</p>
  <p><strong>熊宇轩：</strong>陈总，您认为2025年最能赚到钱的Agent是什么样的？是B端替代初级员工的员工，还是C端的个人生活伴侣？</p>
  <p><strong>陈石：</strong>我去年曾提出一个观点：在 ToB 和 ToC 之间，其实存在一个<strong>ToP（To Professional）</strong>的高价值地带，也就是面向‘超级用户’或‘专家型用户’的市场。</p>
  <p>纵观中美，目前 AI 行业变现效率最高的正是 ToP。无论是火热的 AI Coding，还是创作者经济中的付费工具，逻辑都是如此。即便 ChatGPT 拥有海量周活，绝大多数也只是‘打酱油’的免费用户，真正贡献商业价值的还是付费的专业人士。</p>
  <p>关于未来演进，我有三个看法：</p>
  <p>1.<strong>ToB（企业侧）是‘攻坚战’：</strong>它正逐渐渗透，但门槛很高。企业对流程和合规极其敏感，所以目前落地最好的是‘流程型 Agent’——比如保险银行的合规审查、客服或营销助手，嵌入特定环节实现自动化。但在中国，ToB 的全面爆发依然很难。</p>
  <p>2.<strong>ToC（消费侧）还很遥远：</strong>为什么 ToC 现在挣不到钱？一是因为<strong>能力不够</strong>，现在的 AI 体验并没有显著超越移动 App，无法独立存在；二是因为<strong>载体缺失</strong>，手机和 PC 已是存量，没有新硬件带来新的流量红利。</p>
  <p>3.<strong>商业模式存在悖论：</strong>互联网沿用的是‘羊毛出在猪身上’的广告模式（注意力经济）。但这在 AI 时代不成立——除非依靠端侧模型，否则云端模型的 Token 成本远高于广告带来的 ECPM 收益，<strong>这一账算不过来</strong>。所以 ToC 还需要经历漫长的迭代。”</p>
  <h2><strong>04&nbsp;奔向物理世界，具身智能的挑战</strong></h2>
  <p><strong>熊宇轩：</strong>我们知道具身智能是下一波浪潮中非常重要的一环。</p>
  <p>第一个问题给到王院长，智源今年发布的具身智能大模型RoboBrain对于促进具身智能的落地有什么作用？</p>
  <p><strong>王仲远：</strong>具身智能产业还处在非常早期，需要有足够的耐心。智源在这方面布局较早，我们发布的“悟界”系列大模型，承载了智源的预判：人工智能正从数字世界迈向物理世界。其中，世界模型和具身大脑与具身智能的关系最为密切。</p>
  <p>我们10月底发布的多模态世界模型Emu3.5，它从视频中学习时空、因果、意图等信息，致力于预测下一个时空状态（Next-State Prediction），而不仅是生成视频。在具身大脑方面，我们发布的RoboBrain系列模型，包含了对外界的感知、规划、决策能力，用大脑模型监督小脑模型的学习，使其具备更强的泛化性。目前RoboBrain已和国内30多家机器人企业开展合作，进行适配和落地。</p>
  <p><strong>熊宇轩：</strong>请问刘教授，机器人对实时性要求很高，在您的构想中，未来机器人应该有多少“脑容量”留在本地？</p>
  <p><strong>刘知远：</strong>未来具身机器人应该也会有“大小脑”之分。离行动和感知越近的，越需要留在本地；需要长时间深度思考的，可以放在“大脑”部分，甚至利用云端资源。至于边界在哪，现在还很难准确判断，因为软硬件都在快速迭代。</p>
  <p>但根据主流芯片厂商的规划，我们可以保守估计，到2030年，一个类似手机的端侧芯片可以承载一个接近600亿参数的模型。如果我们沿用“密度法则”，届时在机器人、PC、手机上，至少能加载GPT-5以上级别的模型能力。</p>
  <p><strong>熊宇轩：</strong>接下来问到陈总。站在2025年的时间节点，如果您有一大笔钱，您是投给做极致灵巧手的硬件公司，还是投给做通用机器人大脑的软件公司？</p>
  <p><strong>陈石：</strong>如果二选一，无疑智能是最重要的。今天的大模型AI要走向物理世界，<strong>物理智能是代表智能跃迁的未来。</strong>但反过来说，硬件也可以反哺软件，特别是在中国这个环境里，硬件比重可能会更重一点。</p>
  <p>最理想的应该是软硬结合，就像iOS一样。所以我们投资的公司，原先做硬件的也会做软件，做软件的也会做硬件。</p>
  <h2><strong>05&nbsp;开源生态与中国AI的突围之路</strong></h2>
  <p><strong>熊宇轩：</strong>最后想请问王院长，您认为智源的开源生态，是否能够成为对抗封闭生态的关键一极？</p>
  <p><strong>王仲远：</strong>智源从成立之初就坚持开源、开放的精神。我们这样做不是为了对抗谁，而是因为人工智能行业过去几十年的快速发展，离不开开源开放的生态。</p>
  <p>无论是学者第一时间公开研究成果，还是企业基于开源项目做优化，都推动了技术的进步。未来几十年，我们依然需要坚持这种精神，才能推动技术的普惠和产业化落地。</p>
  <p><strong>熊宇轩：</strong>请问刘教授，您认为端侧的高效模型，会不会是中国AI弯道超车的重大机会？</p>
  <p><strong>刘知远：</strong>我认为不只是端侧。我们提出的“密度法则”不仅适用于端侧，也适用于云侧。通过技术创新提升模型密度，可以降低云上模型的训练和使用成本。这对于在算力上存在短板的中国具有非常重要的意义。过去两年，我们并没有因为算力被“卡脖子”而妨碍AI的快速发展。以DeepSeek和面壁智能为代表的国内许多团队，都高度重视高效大模型技术，这是我们取得这场科技革命竞争优势的独特技术路径。</p>
  <p><strong>熊宇轩：</strong>最后一个问题给到陈总，展望2026年，您能给创业者一句最关键的建议吗？</p>
  <p><strong>陈石：</strong>我特别赞同前面两位老师说的，开源大模型可能是中国一个国运级的机会。我们集全国的力量支持几个好的开源模型，在这个基础上拼应用、拼生态，是很好的路径。</p>
  <p>至于给创业者的建议，就一句话：<strong>上半句是“在大模型难以触及的行业深处去寻找创业机会”，下半句是“你要努力建立一个能够跨越模型迭代周期的商业结构”。</strong>通俗点说，就是不要做太通用的东西，要建立一个能充分享受模型红利、而又不会被模型迭代所淘汰的商业模式。</p>
  <p><strong>熊宇轩：</strong>中国AI的突围之路，既需要开源生态的包容，也需要端侧创新的精准发力，更需要资本和科研之间的同频共振。</p>
  <p>希望今天圆桌论坛的思维碰撞能给大家带来启发，谢谢三位嘉宾非常精彩的分享，谢谢大家！</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/VAH-KwAiv3dSlVfENuurYg" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：郭晓静，编辑：徐青阳，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602323540346114</id>
            <title>日耗50万亿Token，火山引擎的AI消费品战事</title>
            <link>https://www.36kr.com/p/3602323540346114</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602323540346114</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 10:52:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>文｜</strong>陆莫斯</p>
  <p><strong>封面来源｜</strong>AI生成</p>
  <p>如果想知道AI市场到底发展成什么样，火山引擎已经是中国市场当仁不让的风向标。</p>
  <p>“截至今年12月，豆包大模型日均token使用量突破50万亿，较去年同期增长超过10倍。”12月18日，在人头攒动的Force大会现场，火山引擎总裁谭待宣布了这一数字。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5d76317ff490455f8e69aaa2d638ef4b@1215450627_oswg636868oswg1080oswg718_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">2025年，这一数字仅为16.4万亿 图源：火山引擎</p>
  <p>MaaS（模型即服务），是最直接的观察模型消耗量的指标。单论这一市场，如今火山引擎已经成为国内市场份额第一，全球也能排在第三位。</p>
  <p>2025年中旬，云厂商争夺“AI云第一”的硝烟还未停息，到了今年最后一个月，各个大厂又端上了各个新版本——前有谷歌的旗舰模型Gemini 3、视频模型Veo 3.1炸场，后有OpenAI的GPT-5.2紧追不舍。在国内，包括阿里、腾讯等巨头也纷纷端出了新模型的更新。</p>
  <p><strong>如果要给2025年的AI市场概括关键词，多模态和Agent必定在榜。</strong></p>
  <p>这次的Force大会，火山引擎重点发布的产品，也围绕这两方面展开：</p>
  <p>模型侧：豆包旗舰模型1.8、以及视频生成模型Seedance 1.5 pro；</p>
  <p>围绕Agent开展的工具链和生态服务：包括企业自有模型的推理代工服务、强化学习平台；企业级AI Agent平台AgentKit；以及面向Agent运营，发布HiAgent“1+N+X”智能体工作站。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b795ab359a7340c1873d1a1acd2424b4@1215450627_oswg50307oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">火山引擎总裁谭待</p>
  <p>在Force大会上，火山引擎也势要“将Agent进行到底”——自己搭了一个Agent，用于Force大会的报名、参会引导等。</p>
  <p>“大家可能以为这个很简单，但我们做起来也很不容易！”谭待笑着说，“现在的模型能力其实已经够强了，但是很多企业还是用不起来，问题是Agent的工具和生态还很早期，企业做Agent迭代就会很慢。”</p>
  <p>距离2020年火山入局云市场，已经过去了五年。彼时火山还被称为是云市场的“新军”，现在，火山已经凭借大模型的东风，成为AI领域里不可忽视的力量——2024年，火山的营收规模超过110亿元，营收增速远超60%；今年，这个数字已经超过200亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4e7ceae51d8047ffa030b2ecb1e1e61d@1215450627_oswg6453oswg1080oswg144_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>忘掉参数吧，模型正在变成成熟消费品</strong></h2>
  <p>2025年的视频模型市场，结结实实卷了一整年。</p>
  <p>和去年最不同的是，厂商们还在卷参数、卷秒数；而现在，视频生成赛道，竞争已经到达另一个维度——真正的分水岭，在于能否直接产出“可发布的完整作品”。</p>
  <p><strong>比方说，最近各个AI视频厂商，都在卷一个功能：声画同出。</strong></p>
  <p>以前，模型生成的视频片段更像是半成品，需要大量后期剪辑、配音、对齐才能使用，做一条AI视频需要横跨多个平台，加上复杂的剪辑工序。</p>
  <p>新鲜出炉的Seedance 1.5 pro，同样将这一点作为主打功能，可以做到开箱即用。在Force大会上，谭待对Seedance 1.5 pro的参数也是一带而过，直接展示了多个Demo，涵盖电影、动画、商业拍摄等多种风格。</p>
  <p>我们也同样对Seedance 1.5 pro进行了试用。总体感受是，只需要用最简单的提示词，Seedance 1.5 pro不仅可以直出声画同步的视频，从嘴型和声音的对应、情绪/环节捕捉，和画面的配合度，都已经达到相当高的可用水平。</p>
  <p class="loading-entity">&amp;amp;nbsp;</p>
  <ul>
   <li>提示词：一个小女孩，在一个房间里面，面朝着观众。身后有一个大人把一个圣诞礼物盒子递给她，然后他打开之后，发现一只可爱的小狗从盒子里跳了出来，她开心地笑了，说：“你真好！”</li>
  </ul>
  <p class="loading-entity">&amp;amp;nbsp;</p>
  <ul>
   <li>提示词：一个蓝色头发的动漫少女站在樱花树下，樱花瓣飘落下来。她伸手接住一片花瓣，开心地转了一圈，裙子随着旋转飘起来。她笑着用英语说:“春天终于来了!”</li>
  </ul>
  <p>2025年的AI视频模型领域，依旧保持着极其迅速的迭代速度。</p>
  <p>2024年，各家的视频模型都在解决一致性以及人物的动作表情是否够自然的问题——比如，这一帧还是史密斯吃面，但下一帧就可能换成另一位角色。</p>
  <p>到了2025年，比如Seedance的上一代版本1.0 pro，核心卖点是其“原生多镜头叙事”：根据复杂的剧本，自动规划包含远景、特写、中景的镜头组合，并确保主角的一致性。</p>
  <p>但现在，这些问题都已经不是最主要的问题，视频生成模型迅速地进步到接近生产级可用的水平。声音，成为了重要的竞争因素。</p>
  <p>无独有偶，今年下半年发布的快手可灵2.6、谷歌的Veo 3.1以及阿里的WAN 2.5，都将声画同步功能作为了宣传重点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ebb9982a702944d4b2814eebcc5dbcbe@1215450627_oswg169757oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：小红书用户@AI哈哈镜</p>
  <p>相较之下，Seedance 1.5 pro颇有自己的特点。</p>
  <p>首先，Seedance 1.5 pro在对口型方面，已经达到相当高匹配度；而谷歌Veo 3.1等海外模型，对中文适配程度较低，很多时候嘴型对不上，配音也不够自然。</p>
  <p>另外，Seedance 1.5 pro所生成的视频，沉浸感是更突出的——不仅口型对得好，声音和人物、环境的适配度。</p>
  <p>运镜、动作张力，则是Seedance一贯的王牌功能。这次的Seedance 1.5 pro，重点强化了对电影级运镜和动态张力的遵循。</p>
  <p>比如，在室外，不同的天气，人物的声音会显得更加悠远，甚至有淡淡的回音。</p>
  <p class="loading-entity">&amp;amp;nbsp;</p>
  <ul>
   <li>提示词：一个男人站在雨中的街头，他穿着黑色风衣，雨水顺着他的脸往下流。他慢慢抬起头看向天空，然后低声用上海话说:“是时候做个了断了。”镜头切换到对面的人，对面的人回答：“你要怎么做？”，背景是模糊的霓虹灯和湿漉漉的街道，最后镜头切换到男人背后的几个路人，几个路人在马路对面，静静地观察。</li>
  </ul>
  <p class="loading-entity">&amp;amp;nbsp;</p>
  <ul>
   <li>提示词：一辆红色跑车在山路上疾驰，轮胎摩擦地面冒出白烟。车子快速过弯，车身倾斜。然后镜头切换到驾驶座，司机紧握方向盘，眼神专注，冷哼一声，车子加速冲过终点线</li>
  </ul>
  <p>Seedance 1.5 pro生成的视频，动作幅度以及多镜头、多主体等等呈现，也明显是在行业水平线之上。</p>
  <p>事实上，要做到声画同步，不仅需要大量的训练数据，在训练架构、路线选择上都做不少调整。</p>
  <p>之前，视频生成大多基于传统T2V模型来进行，都是先将视频画面生成出来，效果就是“哑巴视频”，用户得自己后期配音、配乐、对口型，费时费力。</p>
  <p>无论对追求创作效率的C端用户，还是对看重成本和稳定性的B端客户，这都具备实在的商业价值。</p>
  <p>模型训练架构的改进，也提升了商业化落地的效率。比如，通过多阶段蒸馏、量化等工程优化，Seedance 1.5 pro模型的端到端推理速度提升超过10倍，这极大减少了生成成本。</p>
  <p>火山引擎智能算法负责人吴迪在一次采访中表示，在模型训练目标设定之初，火山就重点关注了B端重点场景的需求，“音画同步”正是客户的核心诉求之一。</p>
  <p>可以说，在一致性、运镜、叙事、声音等等因素都成熟后，AI视频生成的拼图渐渐完整。</p>
  <p>这背后同样反映整个创作生态的成熟。</p>
  <p>从Seedance 1.5 pro上线的宣发就可见一斑——在小红书上，字节旗下的AI视频Agent小云雀、即梦等等，主推1.5 pro时，选用的AI视频素材大多是包含多个动作的短视频、有剧情有故事，抖音感非常强烈。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_bd50368b379d4e05bcbf7b3af25db5a8@1215450627_oswg169757oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">小红书上的二创、整活类视频</p>
  <p>视频是否好玩，很大程度决定传播潜力。Seedance 1.5 pro对各种方言、对白和强表演场景的支持，让模型天然适合在豆包、即梦等C端产品中，生成可供二次创作和分享的社交货币——比如方言类“整活”视频，正在成为AI视频模型屡试不爽的、撬动用户的路径。</p>
  <p>作为短视频巨头，字节跳动对内容也沉淀了最深的理解——对什么内容能火、为什么火。这些理解，最终都转化为了模型的训练目标。</p>
  <p>信号也非常明显：随着视频生成模型的逐步成熟，很快，这些AI生产的视频，也会和豆包、即梦、小云雀等C端产品联动起来，为用户生成可供二次创作和分享的社交货币。</p>
  <p>当模型能理解并生成复杂的长镜头、希区柯克变焦等等电影术语，还能精准复刻川话、粤语、沪语等等小众方言，成为随手可用的创作工具时，它就不仅仅只是一个技术工具，而是具备了逐步演变成社交平台的潜力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4ae32d3b38464aae97a717890d1311b7@1215450627_oswg10273oswg1080oswg144_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>大模型已是系统工程较量，但火山要做模型上的减法</strong></h2>
  <p>火山引擎的迅速增长，也是当下AI应用爆发的映照。</p>
  <p>“智能涌现”了解到，和2025年末相比，2030年，豆包大模型的Token调用量，将增长100倍左右。</p>
  <p>不过，大模型领域仍处在非常早期。火山智能算法负责人吴迪在会后采访中曾披露一个数字：在国内，大约10%-20%左右的头部企业，消耗了超过90%的Token，大模型服务的渗透率并不高。</p>
  <p>“这个领域的头部效应依然非常明显。”他表示。</p>
  <p><strong>光有好模型，还远远不足以服务好客户。不过，火山引擎如今的思路反倒是，做减法。</strong></p>
  <p>豆包大模型1.8就做了一个很多厂商不敢做的决定：把所有模型能力塞进一个模型。</p>
  <p>具体而言，客户只需要面对一个API接口，不管是LLM、VLM、Thinking版本等，全部集成在一起，不分版本，不用再纠结选哪个版本,不用担心模型之间的能力差异,也不用在多个模型之间来回切换。</p>
  <p>这跟市面上的主流做法不太一样。大多数模型厂商，都会习惯于提供不同的模型版本，比如语言、视觉理解、思考模型等等，每个版本对应不同的模型能力边界。好处是各司其职，但挑战是是选择成本高，集成流程也比较复杂。</p>
  <p>在模型上能做减法，难度是指数级上升的，这需要更领先的基模——这是火山强调的底座逻辑。</p>
  <p>基础模型的能力，直接决定了下游应用的天花板。Seedance 1.5 pro之所以能在声画同步上做得细致，背后是豆包基础模型能力在支撑。</p>
  <p>比如，模型能精准捕捉人物情绪、理解复杂的叙事意图、处理方言的语音语调，这些都依赖于基模在语义理解、情感识别等维度的深厚积累。</p>
  <p><strong>在让模型真正被用起来这件事上，火山引擎搭建了一套更庞大的系统工程。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2a1197a073794890ab269133ff825197@1215450627_oswg288950oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：火山引擎</p>
  <p>如今的Token降价，模型降价倒逼厂商，必须把模型训练得更高效、更好用，让MaaS服务的“密度”更高。</p>
  <p>密度指的是什么？简单理解，就是在同样的成本下，模型能提供更多的价值。</p>
  <p>通过持续的工程优化、训练策略改进，火山不断压缩推理成本，同时保持甚至提升模型性能。Seedance 1.5 pro的端到端推理速度提升超过10倍，就是这种优化的直接成果。</p>
  <p><strong>就连计费模式，也应该符合AI应用的使用特点。</strong></p>
  <p>这次的发布会上，火山就推出了一个很有意思的计费模式：“AI节省计划”。这个计划覆盖所有按量后付费的大模型产品，通过阶梯式折扣，帮助企业最高节省47%的成本。</p>
  <p><strong>“今天行业还按Token计费，但未来绝对不会是只有这种消费方式。”2024年，在接受“智能涌现”专访时，谭待就曾表示。未来，他认为应该按照交付的“智能”付费，比如用AI写一份报告，按交付物的价值来计费。</strong></p>
  <p>在2025年，火山也开始推出以按照思考长度，分段付费的模式，来帮助企业达到降成本的目的。</p>
  <p>事实上，从火山成立开始，谭待就曾反复表示，AI是火山的主旋律。</p>
  <p>这句话背后的含义是，火山的基础设施、产品架构、商业模式，从第一天起就是围绕AI云原生设计的。对于后起之秀的火山而言，传统的公有云市场已经被站满了先行者的旗帜——这是事实。</p>
  <p>所以，AI，是火山弯道超车的关键所在。</p>
  <p>火山的AI Native，体现在很多细节上。比如，火山的GPU集群调度系统，专门针对大模型训练做了优化；存储架构，也考虑了AI训练对基础设施的极端需求。</p>
  <p><strong>AI基础设施的竞争，已经从单纯的模型能力比拼，演变成了系统工程的较量。</strong></p>
  <p>对于更广阔的企业客户来说，他们面临的最大问题往往不是模型不够强，而是不知道怎么用、用不起来。一个企业要真正用上大模型和Agent，需要解决数据接入、任务编排、效果评估、成本控制等一系列复杂问题。</p>
  <p>这就像拥有一台性能强劲的发动机，但如果没有配套的传动系统、控制系统和操作界面，普通人根本开不起来。</p>
  <p><strong>火山如今在同步建设模型的“脑”和“手”。</strong></p>
  <p>如果说，豆包大模型是“脑”，提供核心的理解和生成能力；那么这次重磅发布的AgentKit，就是这只“手”，目的是降低开发者的开发门槛。</p>
  <p>传统的Agent开发，需要开发者自己处理prompt工程、工具调用、状态管理等复杂问题，开发周期长、调试困难。AgentKit把这些底层能力做了封装，开发者只需要关注业务逻辑本身。</p>
  <p>更重要的是，AgentKit不只是一个开发工具，它还提供了完整的运营能力。从Agent的创建、测试、部署，到上线后的监控、优化，形成了一个闭环。这对企业客户来说至关重要，他们需要的是一个可管理、可迭代的解决方案，而不只是一个demo。</p>
  <p>火山自己在Agent方面已经积累了大量实践。字节内部的很多业务场景，包括客服、内容审核、数据分析等，都在使用Agent来提升效率。这些实践中沉淀下来的能力和经验，最终通过AgentKit对外输出。</p>
  <p>在Force大会的演示中，一个企业级的电商客服Agent从零搭建到上线，整个过程只用了不到半小时。这种效率提升，对很多企业来说是质的飞跃。</p>
  <p>往前看，火山在Agent方向的目标很明确：让每个企业都能拥有自己的AI助手，就像今天每个企业都有自己的网站和APP一样。这需要的不仅是技术能力，还需要完整的生态支撑。</p>
  <p>从这个角度看，火山的雄心已然明晰：它要做的不只是提供模型API，而是构建一个完整的AI基础设施和服务体系，让所有企业都能低门槛、低成本地用上最先进的AI能力。</p>
  <p>这场系统工程的较量，才刚刚开始。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602307154347264</id>
            <title>追觅吸尘器国内外营收双增长，全屋智能战略锚定高端家电战场｜最前线</title>
            <link>https://www.36kr.com/p/3602307154347264</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602307154347264</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 10:38:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作者｜黄楠</p>
  <p>编辑｜袁斯来</p>
  <p>当全球家电行业从规模增长转向价值竞争，清洁电器陷入微创新瓶颈，传统大家电面临高端化转型压力，技术革新与场景融合成为破局关键。</p>
  <p>12月17-18日，在追觅科技吸尘器及大家电业务的媒体与投资人开放日上，其吸尘器、冰箱、洗衣机、空调、小厨电、净水等全业务线负责人就单一清洁设备到全屋智能生态的布局逻辑进行了相关分享。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_8d6a86eca50c4563878263eafc757326@6022551_oswg608509oswg832oswg554_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">追觅科技线下展厅</p>
  <p>回顾吸尘器行业发展历程，每一次市场规模的跨越式增长，均源于其产品形态与核心功能的代际革新。但当前行业普遍陷入“微创新”的同质化循环，用户真正关切的深层痛点难以得到根本性解决。</p>
  <p>今年以来，追觅在吸尘器品类中有多项突破性技术密集落地。其中，马达作为家电运转的“心脏”，其性能直接决定清洁效率的上限；追觅已率先引入全球最高转速达20万转/分钟的高速数字马达，在解决嵌入地缝、地毯等顽固灰尘的同时，也能支撑长时间全屋清洁无需中途断电。</p>
  <p>针对行业长期无解的缠绕难题，追觅发布全球首创的灵鲨主动割毛技术，通过双层航空级镀钛刀片可达到每分钟2000次高频剪切。在湿清洁场景下，其研发的全球最小水气分离装置，可以在紧凑空间内实现气液分离，解决了以往“强吸力”与“干湿同步处理”难以兼得的性能矛盾。</p>
  <p>技术战略已在市场层面得到有效验证。根据追觅吸尘器研发中心负责人袁广运分享的数据，2025年1-11月，追觅吸尘器国内营收同比增长40%，海外市场增速达到59%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9f40a74f65c6493e894b41933090e4cd@6022551_oswg635927oswg828oswg552_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">追觅吸尘器灵鲨主动割毛技术</p>
  <p>聚焦传统大家电领域，行业正经历两大核心转向：高端化与场景化。一方面，用户不再满足于基础功能，转而追求能与家居美学融合、具备AI智能管理的高端体验，推动市场价格带上探。另一方面，产品逻辑正从单一通用设备转向全场景解决方案。</p>
  <p>依托在仿生机械臂、智能传感与流体控制等领域的长期技术积累，追觅将其核心能力从清洁电器，系统性地迁移并拓展至大家电领域，完成了从技术底层到应用场景的延伸。</p>
  <p>在空调品类，针对传统送风生硬、不均的痛点，追觅推出了全球首款搭载双仿生机械臂的X-Wind空调，两支灵活的“手臂”可独立摆动，实现126°广角送风，并能左右分区控制，让房间每个角落都能获得自然柔风，满足多人同时的个性化需求。</p>
  <p>冰箱瞄准的是健康主动管理需求。活动现场，追觅展示了能延长肉类冷藏保鲜期至10天的电场保鲜技术，通过光温调控锁住果蔬水分。其旗舰产品配备有多模态传感器，负责人表示，未来将可通过AI分析食材状态，为用户提供定制化的饮食健康建议，让冰箱从储藏工具变为“健康管家”。</p>
  <p>小厨房产品板块主打差异化体验。追觅以智能蒸汽渗透技术为核心，现场推出两款新品，分别是上下双仓空气炸锅 DS50以及蒸炸一体多功能空气炸锅 AF60。前者凭借全球首创的 Duo-Flow™双擎风控技术，实现上下仓独立脆烤与嫩烤；后者通过 CrispVapor™蒸汽发生器与双擎 360 度热力环流系统，让 3cm 厚食材也能均匀受热。配合双刀仿生厨师机MX60、专业萃取全自动咖啡机FCM60，进一步完善了智能厨电产品矩阵。</p>
  <p>在洗衣与净水领域，追觅围绕健康与个性化，其洗衣机能识别衣物材质并自动匹配洗护程序，并引入医用级低温除菌技术；净饮机则整合了即热、净化与制冰功能，满足家庭对饮水品质与便利的全方位需求。</p>
  <p>通过将AI算法与传感器深度融合，追觅围绕真实生活场景进行的系统性创新，旨在让全屋智能真正服务于人的舒适与健康。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_7e553f1e1b59452da290936379afeddc@6022551_oswg578783oswg828oswg466_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">追觅科技智能工厂</p>
  <p>截至2025年6月30日，追觅科技的研发人员占比达60%，在研发投入上，每年研发费用占营收的比例不低于7%。</p>
  <p>面向未来增长，追觅的制造版图正在加速扩张。其中，总投资40亿元、占地193亩的南京智能制造基地已正式开工，规划建设6条先进的冰箱、洗衣机生产线，预计年产能将接近500万台。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602278116525318</id>
            <title>追觅创始人，花22亿买个「旧壳」想讲新故事</title>
            <link>https://www.36kr.com/p/3602278116525318</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602278116525318</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 10:35:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote>
   <p>尽管通过收购拥有了资本运作的壳，并画出了媲美马斯克与雷军的业务版图，但追觅仍需回答其庞大生态中真正的技术协同主线与增长核心。</p>
  </blockquote>
  <p>七年前，追觅出圈的时候，估计谁也没想到这家卖智能家居，尤其以扫地机器人被大众熟悉的品牌，要“上天”。</p>
  <p>最近追觅创始人俞浩用22.82亿元拿下了A股上市公司嘉美包装的控制权，从智能家居到食品包装，这个看起来跨度比较大的操作引发市场纷纷猜测：究竟是为了产业协同，还是意在资本运作？</p>
  <p>这也不是追觅第一次跨圈了，造车、机器人、天文BU，这几年追觅的叙事越来越宏大，在俞浩的口中，追觅要构建的是“人-车-家-太空-宇宙”全球高端科技生态，可以说是融合了雷军和马斯克两人设计的概念。在这个背景下，追觅的业务越铺越重，身子也越来越沉。</p>
  <p>即使有马斯克和雷军两个成功的案例在前，我们还是不得不问一句追觅，这么庞大的叙事里，真正的成长主线在哪里呢？</p>
  <h2><strong>01</strong></h2>
  <h2><strong>22亿的壳子</strong></h2>
  <p>俞浩，又出手了。</p>
  <p>近期，其旗下苏州逐越鸿智科技用22.82亿元拿下了嘉美包装的控制权。</p>
  <p>这次交易是经典的“两步走”：先花12.43亿元从原大股东中包香港手里，买走29.90%的股份，再向其他所有股东发出部分要约，准备再收25%。更关键的操作在后面，原控股股东承诺放弃剩余股份的表决权。算下来，俞浩合计将斥资22.82亿元，实际控制的表决权超过54.9%。</p>
  <p>这场收购最反直觉的是，一个做吸尘器、吹风机的科技公司创始人，为什么要买一家做易拉罐的传统制造企业?</p>
  <p>嘉美包装是国内最大的金属易拉罐生产商之一，客户名单里有养元饮品、王老吉、承德露露这些老牌饮品。</p>
  <p>但是这个追觅有什么关系呢？</p>
  <p>这件事可以从两个方面来看：资源协同和资本运作。</p>
  <p>从资源协同来看，如果我们高度概括追觅的技术底色，比如高速数字马达、精密算法、运动控制，就会发现这些能力和金属包装行业对精密制造、自动化产线、质量管控的要求，其实有相似的基因。</p>
  <p>嘉美包装在罐身焊接、翻边缩颈这些工艺上积累了多年经验，追觅擅长的正是将技术能力复用于不同场景。同时，嘉美遍布全国十多个省份的生产基地与供应链网络，为追觅提供了现成的制造资源。</p>
  <p>产业协同或许只是这桩交易的一个维度。更关键的，是资本运作。</p>
  <p>追觅的IPO之路并不顺利。今年3月，彭博社曾报道追觅计划上市，但很快被官方否认为“不实信息”。眼看着同行科沃斯、石头科技早已上市；云鲸也在今年5月拿到腾讯领投的1亿美元。公开披露中，2021年追觅完成了36亿元C轮融资。</p>
  <p>追觅上市难有一个核心的原因：业务复杂，增加了估值难度。</p>
  <p>从高端消费品，到造车，成立天文BU，追觅的每一个业务都需要单独估值，这也是为什么俞浩在朋友圈说，从明年年底开始，追觅生态旗下多个业务将在全球各交易所“下饺子”般批量IPO，不单拆独立上市的话，估值这一步就很难推进。</p>
  <p>但是“下饺子”上市说起来容易做起来很难，分拆上市周期长、不确定性高。而不上市不代表不缺钱，车、手机、无人机、天文望远镜这都是劳动密集、资本密集、资源密集的产业，不烧钱，不成活。参考小米造车首期投入就超100亿，追觅的资金压力可想而知。</p>
  <p>这时候，一个现成的A股上市公司壳，就有了完全不同的意义——业务注入、并购重组、再融资都可以通过这个上市主体操作，想象空间一下打开了。更为关键的是，追觅这种层出不穷的新业务故事线，配上一家上市公司，才能方便资本市场操作的手跟上节奏。</p>
  <p>但是这桩生意也不是只有好处，今年前三季度，嘉美包装的净利润出现了47%的同比下滑。作为传统包装产业，嘉美包装面临高峰期集中在节假日、大客户依赖以及低价竞争三个大问题，被俞浩收编之后，嘉美包装要如何解决这些问题才是真正的挑战。</p>
  <p>为确保收购后传统业务的平稳过渡与业绩底线，原实控人方面做出了为期五年（2026-2030年）的业绩承诺，保证嘉美包装原有业务每年归母净利润不低于1.2亿元，未达成将进行现金补偿。消息一出，嘉美包装股价大涨，截至12月18日收盘报收5.52元/股。</p>
  <h2><strong>02</strong></h2>
  <h2><strong>打造一个雷军+马斯克</strong></h2>
  <p>在追觅连续喊出造车、造手机、上天、造机器人的时候，还有人记得他们是靠无线吸尘器出圈的吗？</p>
  <p>准确来说，追觅靠的是自研高速马达技术起家。和很多国产品牌崛起一样，对标一个很贵的外国品牌，然后把价格打到它的一半甚至更低，追觅也是这么火的。</p>
  <p>2018年，追觅推出V9无线吸尘器上市卖出1500万台。到2024年，追觅营收150亿。从IDC发布的2025年全球智能家居清洁机器人市场数据来看，今年前三季度，追觅在全球扫地机器人出货量中占据第三名位置，市场份额约为12.3%。‌</p>
  <p>但这个第三的位置，坐得并不舒服。</p>
  <p>智能家居，实在太卷了。科沃斯一年推七八款新品；石头科技从3000多元的入门款到6000多元的旗舰款做产品矩阵；云鲸直接把价格打穿到2000以下。在以旧换新等补贴政策下，今年双11智能家居销量有所回温，但整个市场的竞争残酷程度一点都没有缓解。</p>
  <p>同质化，是智能家居赛道最大的问题，基站自清洁、AI避障、激光导航，这些功能现在已经成了标题，而且技术追赶的时间越来越短。一家前脚发布的X40，主打“全能基站”，另一家可以在两个月之内推出类似产品；一家的双刷设计刚上市，另一家也可以马上跟进。</p>
  <p>这对于想要持续融资和上市的追觅来说，不是好消息。因为冲刺IPO的企业最怕没有增长的故事。</p>
  <p>于是，追觅的疯狂扩张，开始了。今年1月，一家名为“星空计划”的公司在上海注册，注册资本10亿。股权穿透下来，实控人是俞浩本人，间接持股80%；接着在8月，追觅正式官宣造车，首款车对标布加迪威龙，计划2027年推出。</p>
  <p>9月初，俞浩带着团队去了德国，在柏林选厂址，位置就在特斯拉工厂旁边，规划面积是特斯拉的1.2倍。团队规模已经接近千人，有消息称追觅从蔚来、小鹏挖了不少人。俞浩在朋友圈说，追觅要造“世界上速度最快的车”，内部规划分为追觅汽车和星空汽车两个品牌，前者对标布加迪，后者对标库里南和宾利。</p>
  <p>机器人这边动作更早。追觅从2023年就开始研发人形机器人，今年5月在深圳专门设立了机器人研究院。俞浩对机器人的理解很独特，他说机器人不一定要长得像人，关键是要有“心脏和大脑”。</p>
  <p>一位知情人士向《豹变》透露道：追觅把机器人分成了人形和非人形进行孵化，人形的部分主要由魔法原子负责，非人形的部分目前则由追觅内部团队进行研发，在明年也有独立运行的可能性。</p>
  <p>最让人意外的是航天。前有科技狂人马斯克造火箭发卫星，要殖民火星；今年9月，追觅突然宣布成立天文BU，要做消费级天文望远镜，也把野心放到了宇宙里。</p>
  <p>消费、电车、机器人、航天，这几个词连在一起，追觅想做的可以概括为一个雷军加上一个马斯克。</p>
  <p>追觅的扩张看起来无比疯狂，虽然可以理解为围绕着核心能力——高速马达、传感器、智能算法的跨场景复用。扫地机器人需要视觉识别和路径规划，汽车也需要；吸尘器需要高速马达，机器人关节也需要；甚至天文望远镜的精密控制系统，底层技术也是相通的。</p>
  <p>但是这么一个“人车家太空”的庞大生态，背后需要调动的资源和能力，已经远远不是资金投入这个层面。</p>
  <h2><strong>03</strong></h2>
  <h2><strong>同样是画饼，问题出在哪</strong></h2>
  <p>那么问题来了。</p>
  <p>马斯克画饼，市场买单，是因为马斯克的商业版图有一条清晰的主线：改变人类的生活方式。电动车解决的是地面交通，机器人解决的是生产方式，商业火箭解决的是太空探索，这几个看似八竿子打不着的项目，都能被这个宏大愿景串起来。</p>
  <p>更关键的是，特斯拉和SpaceX做的都是“从0到1”的创新。马斯克自己在电话会议上说，特斯拉之前美国并没有一个成熟的机器人产业链，制造这个产业链也是量产的巨大难题。但反过来想，制造这个产业链同样是支撑特斯拉估值的巨大预期。</p>
  <p>这种叙事的力量是，它始终能回答一个问题：市场为什么“非我不可”。</p>
  <p>追觅有没有这样的叙事基因呢？回溯追觅最初的商业逻辑是“用做飞机的技术服务千家万户”。这本质上是高端技术下探，做高端消费级产品的路径。</p>
  <p>所以，要讲好新的增长故事，追觅还得再思考几个问题：</p>
  <p>第一，资源怎么分？造车、机器人、航天，这几个产业都有类似的特征：超长的投入期以及前期巨额资本支出。特斯拉从2003年成立到2020年才首次实现全年盈利，中间烧了17年的钱。Space X更狠，从2002年成立到现在还在持续融资。追觅同时开展这么多费人、烧钱的项目，有限的资源应该如何集中才能做出最高的回报？</p>
  <p>第二，技术怎么协同？不是说“都是高科技”就能协同。造车的三电系统核心是能量密度和热管理，人形机器人的核心是运动控制和力反馈，小家电的核心是高速马达的小型化，这三个技术方向虽然都涉及电机和控制，但具体的技术路线、材料体系、测试标准不尽相同。追觅的这些业务之间，需要找到更确切的“技术重叠度”。</p>
  <p>第三，管理体系怎么搭？造车需要的是汽车工程师，机器人需要的是机器人算法专家，食品包装需要的是供应链和生产管理人才。</p>
  <p>这三种人才的薪酬体系、激励机制、职业发展路径完全不同。一个造车项目可能需要5年才能看到成果，但小家电产品6个月就要上市；机器人研发可以容忍试错，但食品包装的质量标准容不得半点闪失。面对不同的标准、体系，追觅应该如何设计管理体系，来让整只大船更快速地前进？</p>
  <p>不缺技术，更不缺野心的追觅，想要说服资本市场，需要的不仅仅是故事，更是一个清晰的增长重心。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzI3OTEwMDQwNw==&amp;mid=2649967492&amp;idx=1&amp;sn=dcd01d5dfae082c7a4ccecbd3f75f161&amp;chksm=f2977054b2083d96f85e199870115491ce7e6963cf3fb866458c3cbb74b6e2b504f2ad8cc953&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“豹变”（ID：baobiannews）</a>，作者：娜娜，编辑：邢昀，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602276294738953</id>
            <title>为了极星，李书福又借出去42亿</title>
            <link>https://www.36kr.com/p/3602276294738953</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602276294738953</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 10:32:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>李书福又给极星输血了。</p>
  <p>极星汽车宣布，为了解决资金短缺困境，已与其控股股东中国吉利控股集团签订一份最高达<strong>6亿美元</strong>（折合人民币42.2亿元）的贷款协议。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_590e95d7f61a432bbfc4891508e523f9@5091053_oswg181607oswg1080oswg486_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而在5个月前，极星才拿下由李书福实际控制的PSD Investment Limited的2亿美元的股权注资，半年不到的时间，再度加码。</p>
  <p>尽管这家由吉利和沃尔沃共同打造的电动汽车品牌，已在中国关闭最后一家直营店，国内市场月销量不足百辆。股价也较2022年上市时暴跌超过95%，被纳斯达克“退市警告”甚至被瑞典北欧斯安银行开出“0克朗”的估值。</p>
  <p>不过种种迹象似乎都在表明，吉利还<strong>没有放弃</strong>这个在中国市场几近失去声量的品牌。</p>
  <p>不免用一句老旧爆梗问问李书福：“极星，到底有谁在啊？”</p>
  <h2><strong>01</strong></h2>
  <h2><strong>一年输血超56亿</strong></h2>
  <p>这次虽然是以贷款的形式发放，不同于股权注资，但本质上都是由股东出资，这笔钱将由吉利瑞典控股AB的一家全资子公司出资，额度最高为6亿美元，而且是次级定期贷款，具体期限极星汽车并未透露。</p>
  <p>不过，次级贷款也意味着，这笔贷款<strong>不计入极星的债务契约限额</strong>中，不然仅6亿美元的贷款资金，在极星超55亿美元的债务面前，无异于杯水车薪。</p>
  <p>根据极星汽车2025年年中财报，极星汽车营业收入14.23亿美元，归母净利润-11.93亿美元，同比下滑119.37%，资产负债率高达217.11%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_65769b3c90c942c89a138c4b4afd7bdc@5091053_oswg398769oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而这笔贷款也<strong>不是一次性给齐</strong>，按照极星的说法，其中最后一笔3亿美元的拨付，将根据极星汽车未来的流动性需求，在获得贷款方同意后方可执行。</p>
  <p>从目前的情况看，极星四年来累计净亏损超400亿人民币，到2025年上半年净资产是-33.29亿美元，负债高达73.83亿美元。</p>
  <p>而且值得一提的是，2024年12月，极星从几家银行获得了逾8亿美元的一年定期贷款，其中部分资金用于偿还旧债，今年年底，极星汽车也该需要偿还这8亿美元的到期贷款了。</p>
  <p>算起来，光今年李书福就为极星汽车提供了高达8亿美元的资金额度，约合人民币<strong>56.4亿人民币</strong>。</p>
  <p>今年6月，极星宣布从PSD Investment获得2亿美元股权融资，PSD Investment是极星汽车现有投资方，这家机构实际也是由吉利控股集团创始人李书福掌控，PSD Investment公司目前持有极星汽车44%的股份，交易完成后，该公司对于极星的持股比例达到<strong>66%</strong>。</p>
  <p>另外，PSD Investment还计划将其 2000万股B类ADS股票转换为A类ADS股票，以保持其在极星的总投票权低于50%，在这种双级股票结构中，A类股票每股对应1票投票权，而B类股票每股对应10票投票权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_a8f2df3579534127a5d89fd8f21a49a8@5091053_oswg388607oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而真金白银的加码，换来的却是亏麻了的结果，截至目前美股收盘，极星的股价为12.3美元。</p>
  <p>需要注意的是，12.3美元的股价是因为极星汽车因其ADS（美国存托股票）合股于12月9日正式生效的托举，其将ADS比率从1:1调整为1:30，通过减少股票数量“<strong>反向拆股</strong>”的方式来大幅提升每股价格。</p>
  <p>如果按照合股前的股价计算，极星汽车的股价，已经跌至0.6美元/股以下，而李书福彼时定向增发时，每股的认购价为<strong>1.05美元</strong>，在5个月的时间里浮亏已经超50%。</p>
  <p>正因极星的股价长期低于1美元，纳斯达克才给极星汽车发出退市警告，如果2026年4月29日前没有完成整改，将会被强制退市，因此极星不得已通过“反向拆股”的方式恢复上市地位。</p>
  <p>如今，极星汽车的两个大金主其中之一，沃尔沃在去年已经做出了不再对极星进行投资的决定，并且将其持股比例从原本的48.3%大幅下降至18%，今年6月李书福再次注资后，沃尔沃的持股比例再次下调至16%。</p>
  <p>“资不抵债”加“仙股”状态，在商业逻辑中本就已经是极其危险的信号，更不用说其业务表现。</p>
  <p>上个月，极星汽车关闭上海最后一家直营门店，尽管极星用“战略性调整”和“转向线上”来淡化这一消息的冲击，但无法遮掩其在国内彻底处于边缘化的状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3298778dc18744efb4c9311458fe913e@5091053_oswg414043oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>自2017年进入中国市场以来，极星的销量始终未见起色。2021年至2023年，极星在华销量分别为2048辆、1717辆和1100辆。即便是后来极星科技成立，销量情况也没有明显好转，2024年全年极星汽车零售销量也仅1864辆。</p>
  <p>2025年以来，其<strong>国内业务更是近乎停摆</strong>，多个月份销量仅为个位数，前10个月累计销量仅163辆。</p>
  <h2><strong>02</strong></h2>
  <h2><strong>出海最佳选择</strong></h2>
  <p>尽管如此，李书福还是没有放弃极星汽车。</p>
  <p>去年8月，吉利控股集团首席执行官李东辉就曾说过，为什么不断加码极星汽车的原因。是因为极星是吉利控股集团布局<strong>全球化的桥头堡</strong>，对集团的全球化发展有着重要的战略意义。</p>
  <p>背靠沃尔沃的技术背书，其彼时是欧洲电动车销量前十里唯一一个中国资本控股的品牌，它一度是吉利“国际化”战略的最大门面。</p>
  <p>李书福也曾明确表示，中国品牌想要进入欧美主流，必须找到西方消费者认同的品牌方式。极星，就是那个路径。尤其是在欧美日益复杂的贸易壁垒面前，一个拥有“欧洲身份、全球产线、技术中性”的品牌价值，比账面数字更具战略意义。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_96879d292f03415ba2cc9705be2995cc@5091053_oswg1396247oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>即便是放在现在看，极星也依然是吉利“全球化战略”的关键，纵观吉利集团内部各大品牌，<strong>极星的出海门槛可能是极低</strong>的。</p>
  <p>在欧美对中国电动车加征关税的背景下，极星的纯粹欧洲基因和全球生产布局，像美国、韩国及欧洲工厂，会成为吉利规避贸易壁垒的迂回路径。</p>
  <p>为了规避美国对于进口车的限制和高额关税，极星汽车早在2024年，就已经将极星3的生产线搬到了美国南卡罗来纳州，为了尽量规避贸易冲突，今年，2026款极星 4生产地也从中国转向韩国由雷诺韩国汽车工厂生产，极星7也会选在欧洲投产。</p>
  <p>这两项因素，令极星汽车成了目前极少数能绕过贸易壁垒、在欧美市场实现规模化交付的“中国背景”品牌。</p>
  <p>最关键的是，相较于国内市场，极星的海外表现有着不小的反差，并不是说在全球卖的有多火热，但比起国内的表现强的不是一点半点，光是今年上半年，极星全球交付了30319辆车，同比增长51%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_cd827375126a4bf1bcf727b7d02ec1e5@5091053_oswg962278oswg1080oswg532_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今年前三个季度，极星全球零售销量达到约<strong>44,482</strong>辆，同比增长36%。其中第三季度交付了约14,192辆汽车，比去年同期增长13%。首席执行官Michael Lohscheller表示：“第三季度销量持续增长，我们现在已经销售了与2024年全年一样多的汽车。”</p>
  <p>不仅如此，极星汽车还在以相当高的速度吸引特斯拉车主，极星英国总经理 Matt Galvin 此前接受采访时就说过，极星3一季度在美国的销量，有将近一半来自特斯拉客户群体。</p>
  <p>在中国，这个因为设计理念和定位问题而“水土不服”的品牌，<strong>海外市场反而是极星的舒适区</strong>，从海外论坛对极星的讨论来看，的确有不少人对极星驾控与外观、沃尔沃带来的品牌认可度表示了肯定。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_a369b956fd7343f0bd39c561aeb3fc85@5091053_oswg682723oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且，在吉利集团公布的2025年前三季度销量数据中，集团整体出口近30万辆，其中光极星汽车贡献4万辆，<strong>占比达13%</strong>。相较于极星汽车的体量，对于吉利出海的贡献绝不算小，这也进一步表明极星汽车仍然是吉利迈步海外的重要棋子。</p>
  <p>在追求极致性价比的中国新能源车市场，极星的竞争力或许比不过本土品牌，但是在全球市场，极星可以作为整个吉利在高端新能源市场冲锋陷阵的锚点，这或许也是吉利持续为极星“输血”的原因所在。</p>
  <p>至于极星汽车还要多久才能实现“自我造血”，李书福应该比谁都更希望知道答案。</p>
  <p>‍本文来自微信公众号<a href="https://mp.weixin.qq.com/s/DmdrlXoeuy2STvHKCOya9w?click_id=134" rel="noopener noreferrer nofollow" target="_blank">“超电实验室”</a>，作者：王磊，编辑：秦章勇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602250589881352</id>
            <title>大模型真的要开始“抢饭碗”了</title>
            <link>https://www.36kr.com/p/3602250589881352</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602250589881352</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 09:31:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近一个月以来，AI大模型领域的火药味明显变浓了。Google与OpenAI这两家长期占据行业头部位置的玩家，<strong>几乎将产品迭代发布节奏压缩到“以周计算”</strong>。上一代AI模型尚未站稳脚跟，下一轮更新便已接踵而至，正面碰撞不断。</p>
  <p>最新的一击，来自Google。</p>
  <p>北京时间12月18日凌晨，Google官宣Gemini 3 Flash正式发布，这是Gemini 3系列中速度最快、性价比最高的模型，也是Google在一个月内第四次对大模型产品线进行实质性更新，这被解读为对Open AI的“精准打击”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6be0ed7f2a3c48acb4d76f19e1b19969@000000_oswg36568oswg1031oswg580_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>1</strong></h2>
  <h2><strong>OpenAI拉响“红色警报”</strong></h2>
  <p>将时间线拉回11月，全球最具影响力的两家AI公司——Google与OpenAI，几乎同时发布了各自的旗舰模型：Gemini 3与GPT-5.1。</p>
  <p>随后，Gemini 3 Pro在多项基准测试中，大幅超越Gemini 2.5 Pro、GPT-5.1以及Claude Sonnet 4.5等现有旗舰模型，在短时间内建立起口碑。</p>
  <p>几乎在同一时间轴上，另一边的OpenAI也不甘示弱。</p>
  <p>在自家的新一代产品GPT-5.1正面迎战Google Gemini 3却处于下风之后，OpenAI内部迅速进入了应急状态。12月2日，据外媒披露，OpenAI CEO山姆·奥特曼在一份发给员工的内部备忘录中明确表示，公司已进入“红色代码（Code Red）”紧急状态。</p>
  <p>这一状态下，OpenAI的资源和注意力被重新拉回到最核心的产品——ChatGPT本身。OpenAI应用总监菲吉·西莫随后证实，这一“警报”直接加速了GPT-5.2的发布节奏。</p>
  <p>于是仅仅一周后，OpenAI十周年之际，GPT-5.2火速上线，并一次性推出了三个版本——Instant、Thinking、Pro。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_8c52c99ec9154d25b7127aaa4e581385@000000_oswg31784oswg672oswg642_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从官方公布的核心基准测试来看，GPT-5.2的表现极为强势。在多项对比测试中，面对GPT-5.1、Gemini 3 Pro等，GPT-5.2 Thinking几乎实现了“全线第一”。这也意味着，Gemini 3 Pro刚刚建立起不到一个月的领先优势，再次被打破。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6ac3f1e552ea46e0affc14b3ad45368b@000000_oswg59770oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>2</strong></h2>
  <h2><strong>ChatGPT</strong></h2>
  <h2><strong>真要“替代”打工人了？</strong></h2>
  <p>相比令人眼花缭乱的跑分体系，ChatGPT 5.2最值得关注的变化来自一个完全不同维度的评测体系——GDPval。</p>
  <p>GDPval并不考模型“会不会做题”，而是直接衡量其完成真实、明确知识型工作任务的能力。该评测覆盖44个职业，横跨对美国GDP贡献度最高的9个核心行业，其测试内容也并非选择题或问答，而是要求模型生成真实可交付的工作成果——<strong>例如销售PPT、会计与财务表格、急诊科排班表、制造业数据图表，甚至短视频内容。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5c1638c64cb74d3c9f63d6fe6cd000cd@000000_oswg36141oswg542oswg311_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>换句话说，这套评测体系不是在模拟工作，而是把模型直接“拉进职场”。</p>
  <p>根据人类专家的盲评结果，在高难度知识型工作任务中，<strong>GPT-5.2 Thinking有70.7%的任务表现优于或至少持平于行业顶尖专家。</strong></p>
  <p>在效率层面，差距更加明显：GPT-5.2 Thinking完成同类任务的速度，约为人类专家的3倍，而综合成本仅为人类的约1%。</p>
  <p>在更具代表性的金融场景中，这种提升也得到了验证。在“初级投行分析师”电子表格建模测试中，GPT-5.2 Thinking的综合得分达到68.4%，相较GPT-5.1 Thinking的59.1%有显著提升，成为OpenAI目前在该类任务中表现最好的模型。</p>
  <p>综合来看，在GDPval覆盖的知识型工作任务中，GPT-5.2 Thinking“赢过或打平行业专家”的比例达到70.9%。而上一代GPT-5 Thinking，这一数字仅为38.8%。</p>
  <p>GPT-5.2的产品分层变得异常清晰：Thinking版本长上下文推理更稳、表格、PPT、复杂方案能力明显提升，面向真正的重度专业工作；Instant版本对话更自然、解释问题更清楚、写教程、做说明、职场日用效率更高；Pro版本拥有最强的推理与代码能力，是科研、复杂系统设计的首选。</p>
  <p><strong>一句话总结就是，Thinking干重活，Instant管日常，Pro顶天花板。</strong></p>
  <p>正因如此，GPT-5.2 Thinking也被外界调侃为，真正开始“和牛马打工人抢工作”的一代模型。</p>
  <h2><strong>3</strong></h2>
  <h2><strong>职场“专家”和“老黄牛”</strong></h2>
  <h2><strong>该选谁？</strong></h2>
  <p>两家巨头明显带有“赶工”色彩的发布节奏，引发了另一波更为直接的市场反馈——大量用户的差评开始出现。有网友晒出GPT-5.2在SimpleBench上的“成绩单”，GPT-5.2的得分低于Claude Sonnet 3.7，后者是一个差不多一年前发布的模型；GPT-5.2 Pro的表现也没好多少，勉强超过GPT-5。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_63fe9901a68742e6af325020b9a792bb@000000_oswg468734oswg975oswg1202_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：SimpleBench</p>
  <p>SimpleBench的设计初衷是用来测试大模型在“普通人看来很简单、但对机器而言极具挑战”的逻辑推理任务上的表现。</p>
  <p>质疑声不止于此，前AWS与Google高管Bindu Reddy在社交平台发文指出，GPT-5.2在LiveBench上得分低于Opus 4.5和Gemini 3.0，它在token成本和消耗数量上也比5.1多得多，目前可能不值得从5.1切换升级。</p>
  <p>GPT-5.2与Google抛出的“新招”Gemini 3 Flash形成了正面碰撞。如果说GPT-5.2的关键词是“专业性”，那么Google强调了一个词：性价比。</p>
  <p>这并不是简单意义上的“更便宜”，而是一次对“性能、成本、规模”三者关系的系统性重构。</p>
  <p>Google CEO桑达尔·皮查伊在官方博客中直言，Gemini 3 Flash在性能和效率上同时突破了“帕累托极限”：其综合性能超过上一代旗舰模型Gemini 2.5 Pro，推理速度提升约3倍，而价格却显著降低。</p>
  <p>皮查伊说：“Gemini 3 Flash证明，速度和规模无须以牺牲智能为代价。”</p>
  <p>从评测结果来看，这并非一句简单的营销口号。</p>
  <p>根据Imarena.ai的数据，目前Gemini 3 Flash在文本、图像和编程领域排名前5，数学和创意写作类别排名第2，<strong>是性价比最高的前沿模型，输入仅0.5美元/百万Tokens，输出3美元/百万Tokens。</strong></p>
  <p>作为对比，Claude Sonnet 4.5的输出是15美元/百万Tokens，GPT-5.2的输出是14美元/百万Tokens，是Gemini 3 Flash定价的近5倍。</p>
  <p>Gemini产品管理高级总监Tulsee Doshi称，谷歌将Gemini 3 Flash定位为“老黄牛”式模型。该模型保持了接近Gemini 3 Pro的推理能力，同时运行速度达到Gemini 2.5 Pro的三倍，成本仅为Gemini 3 Pro的四分之一。</p>
  <h2><strong>4</strong></h2>
  <h2><strong>智能体是未来的竞争点</strong></h2>
  <p>纵观OpenAI与Google近段时间的密集更新，短期内谁胜谁负仍难下定论，但从产品设计、宣传重点与落地路径来看，大模型演进的下一个趋势已经愈发清晰。</p>
  <p>无论是ChatGPT 5.2在宣传页面中反复强调的“专攻智能体”，还是Gemini 3 Flash将“高性能”直接推向大规模应用场景，这两条看似不同的路线，<strong>最终都指向同一个终点——智能体。</strong></p>
  <p>AI基础大模型的竞争，已经从“云端模型能力”全面下沉至“终端与系统层”。</p>
  <p>从近期动作来看，Google与OpenAI的竞争早已不限于参数规模、推理能力与基准测试成绩。</p>
  <p>在终端侧，Gemini 3已全面取代传统Google Assistant，成为Android生态的中枢。在最新的Android Auto更新中，这一变化尤为直观。用户在驾驶过程中，可以通过一次自然语言指令，完成跨应用、多步骤的复杂操作，例如查询邮件信息、发起导航并同步通知相关联系人。</p>
  <p>在办公场景，Google正试图将这种“系统能力”延伸至Workspace。依托1M至2M tokens的超长上下文窗口，Drive、Docs、Gmail被整合为一个可直接对话的统一知识空间。用户不需要在文件与邮件之间反复切换，而是可以直接基于全部历史资料提出分析型问题，并生成结构化结果。这种工作流层面的改变，显著提升了企业用户的使用黏性。</p>
  <p>企业市场的反馈正因此发生变化。</p>
  <p>Salesforce创始人Marc Benioff近期公开表示，基于Gemini 3在推理速度和准确性上的表现，<strong>其个人及企业内部的AI首选已从ChatGPT转向Gemini。</strong>随后，Salesforce宣布将Gemini纳入Agentforce 360平台。这一动作，被视为Google在原本由微软与OpenAI主导的企业SaaS领域取得的重要突破。</p>
  <p>面对Google的垂直整合，OpenAI选择了与科技巨头结盟扩张。在消费级市场，最重要的变量来自Apple。预计将于2025年底至2026年初推出的iOS 26，将深度整合GPT-5.1。这不仅是Siri后端能力的升级，更涉及系统级的视觉智能。通过硬件级相机入口，用户可直接调用GPT模型对现实环境进行识别和理解。</p>
  <p>对OpenAI而言，这种“硬件直达模型”的路径，是其在移动端对抗Android生态优势的关键抓手。在企业与办公领域，Microsoft仍是OpenAI最稳固的支点。通过Windows 11与Microsoft 365，微软的人工智能助手Copilot持续将GPT-5.1推向企业核心流程。微软在操作系统层与企业云服务层的长期积累，仍构成OpenAI的重要护城河。</p>
  <p>回顾过去三年，自2022年ChatGPT横空出世以来，行业竞争的核心始终围绕两点：对话是否自然、知识是否足够广。<strong>但到了2025年，随着企业对AI的期待从“内容生成”转向复杂问题解决、跨工具协作与自主任务执行，竞争维度已经发生根本变化。</strong></p>
  <p>看似路线不同，但终点一致：真正的分水岭，不在于谁更会聊天，而在于谁能把事干完、干好，并且持续稳定地干下去。而Gemini 3与ChatGPT 5.2，正好站在这条分岔路的两侧。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjM2MzEyNQ==&amp;mid=2651603243&amp;idx=1&amp;sn=28044bc9edf2afa68702a0d1ce173d24&amp;chksm=bc373ecec8b7483d748bb419a9c1dcd9d07e8897eee8d4dbf203022e8bcd5f59316ce3824861&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT时报”（ID：vittimes）</a>，作者：贾天荣，编辑：王昕，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602249248802051</id>
            <title>握手言和，索尼诉腾讯侵权案迎来尾声</title>
            <link>https://www.36kr.com/p/3602249248802051</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602249248802051</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 09:30:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着加州北区联邦法院的一纸文书落地，2025年游戏圈最引人关注的“仙人斗法”事件也迎来了尾声。</p>
  <h2><strong>01</strong></h2>
  <h2><strong>揭秘腾讯索尼纠纷始末</strong></h2>
  <p>把指针轻轻拨回2024年，彼时腾讯的北极光工作室刚刚立项开发《荒野起源》。腾讯高管也在旧金山游戏开发者大会期间，向索尼方面递交了相关文件，希望能拿到《地平线》系列IP的授权，进而开发手机端游戏。</p>
  <p>就在一切都向好发展时。（索尼PlayStation中国区B站官号曾分享过腾讯《荒野起源》的宣传片，并表示该游戏将在未来登录PS5平台。此举也被外界解读为腾讯、索尼即将展开深度合作的信号。）</p>
  <p>2025年7月，索尼互动娱乐竟突然发起诉讼，指控腾讯《荒野起源》实质性抄袭了自家IP《地平线》。声称该游戏在世界观、虚拟角色形象甚至音乐风格等概念上，复制了《地平线》系列游戏的核心创意。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_10296e3343354c28a49a24e6c2179730@000000_oswg685639oswg780oswg449_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_862d00d58c844fe589c24b5a715505c0@000000_oswg1063541oswg975oswg543_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>面对这一指控，腾讯则表示“核心玩法设定不应被某家公司独占，它属于公共领域及行业惯例” “游戏尚未发布，侵权指控缺乏实质依据”。</p>
  <p>在此之后，经过不断地协商、互动。腾讯也在临时协议达成后，决定将《荒野起源》的发售日期大幅推迟。索尼则主动推荐了北极光工作室的产品《粒粒的小人国》，且PlayStation主机平台也上架了腾讯的大热游戏《三角洲行动》。</p>
  <p>但....这一切真的结束了吗？</p>
  <p>让我们把视角从游戏平台放回到公司本身。</p>
  <p>2025年11月，科技媒体Notebook Check率先爆料腾讯、索尼的纠纷进入新阶段。继9月份腾讯提交驳回动议后，10月17日索尼再次提交文件对腾讯的撤诉请求予以回击。期间腾讯为辩护自身、驳回索尼的指控，还把千里之外的迪士尼拉进了“战场”。</p>
  <h2><strong>02</strong></h2>
  <h2><strong>且看腾讯如何见招拆招</strong></h2>
  <p>在双方你来我往的诉讼攻防中，索尼认为《地平线》主角“埃洛伊”的红发造型、游戏里的机械动物设计已经构成了PlayStation 的“来源标识”，所以它们理应被商标法保护。</p>
  <p>针对此事，腾讯方面则认为“有名气≠商标”。商标、标志并不是由名气本身创造的，它们是因为被当做某件商品或服务的“来源表示”，所以才拥有了法律意义上的“商标资格”。即腾讯认可玩家能够在众多游戏角色中分辨出谁是“埃洛伊”，但索尼却不能证明“埃洛伊”在摆脱游戏环境后仍能充当独立商标使用。</p>
  <p>就像迪士尼和米老鼠一样，腾讯表示一个角色在电影里能够被大家认出来，并不意味着TA改变外观、装造后仍能作为商标使用。而迪士尼为不同时期的米老鼠申请注册了多个商标的举措，则让它在摆脱固定的文化环境后仍是“一致”“可识别”的来源表示。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_e4057901a6794bbcbaa1290d4ef7e724@000000_oswg303173oswg668oswg591_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在此期间，玩家们对本轮纠纷的看法也各有不同。</p>
  <p>有人认为游戏界互相借鉴玩法是正常做法，索尼本轮指控暗有垄断相关元素之嫌；有人认为《荒野起源》和《地平线》确实太过相似，相关工作室的借鉴已经超过了合理范围……</p>
  <p>但无论怎样，当时间来到12月时，大家都惊讶地发现原定于月初的诉讼交锋并未出现。取而代之的则是12月18日，索尼、腾讯官宣握手言和。双方决定不再对此事发表公开评论，并愿意在保密和解后继续携手共进。</p>
  <p>这堪称“川剧变脸”的操作，也让无数吃瓜群众摸不到头脑。本来约好决战紫禁之巅的两个人，怎么突然就不打了？</p>
  <h2><strong>03</strong></h2>
  <h2><strong>没有永远的朋友或敌人</strong></h2>
  <p>有句老话说得好，商场里没有永远的朋友，同样也没有永远的敌人。在法律纠纷之外，索尼需要腾讯，而腾讯同样也需要索尼。</p>
  <p>具体而言，索尼在买断制游戏时代曾推出了《战神》 《蜘蛛侠》 《最后生还者》等一系列经典游戏。但随着线上游戏生态的快速成长，《堡垒之夜》等游戏的爆火也让索尼渐渐意识到传统的买断制3A不仅开发周期长、投入成本高，而且它们的市场还正在被大量游玩免费、道具付费的长线运营式游戏挤压。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6bfc3476d6ac4471bd5d4f6e2612a4bd@000000_oswg1080262oswg1080oswg645_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在这样的背景下，索尼方面也开发了自己的线上大作《星鸣特攻》，希望以此扩大自己的游戏受众。只可惜，尽管索尼为该游戏投入了大量技术资源、预算，但这款游戏上线后仅两周便因为内容画风、文化设定等原因被玩家抛弃，迅速关闭了服务器。</p>
  <p>这件事，不仅让索尼的《失落星船：马拉松》延期上市，也让外界对索尼发力新增长点的战术动作略显消极。</p>
  <p>那么这又关腾讯什么事呢？</p>
  <p>众所周知，国内的游戏环境刚好和国外相反。即主机玩家、买断制3A玩家呈少数，线上游戏、社区式运营游戏玩家呈多数。而腾讯，恰恰是坐拥《穿越火线》 《英雄联盟》 《QQ飞车》等多个长青IP的“服务型游戏”专家。</p>
  <p>以点见面，腾讯《三角洲行动》上线PlayStation的决定，一方面为索尼提供了社区型游戏的长线分成。另一方面则为腾讯在国际舞台上打响了名头，让更多的玩家认识到了这家来自东方的游戏产业巨头。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_da83e97abc994dcbadbf62924f6836ef@000000_oswg541655oswg1080oswg552_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>所以比起因为单款游戏的IP问题而斗个头破血流，双方在不断交流中携手共进，寻求各自的利益最大点显然才是明智之选。</p>
  <p>（11月，腾讯向育碧Vantage Studios战略投资11.6亿欧元，进一步深化合作。而Vantage Studios的目标则是加快《刺客信条》 《孤岛惊魂》 《彩虹六号》这三大世界性游戏IP的壮大。期间腾讯在国际3A市场中无疑会更进一步，而索尼也有望借此得到更多的长线游戏运营经验。）</p>
  <p><strong>参考：</strong></p>
  <p>中国经营报：腾讯95亿元入股育碧子公司 剑指三大游戏IP</p>
  <p>新浪财经：索尼和腾讯打了大半年的侵权官司，怎么就忽然和解了？</p>
  <p>界面新闻：索尼与腾讯：台上共舞，台下较劲</p>
  <p>IT之家：索尼诉腾讯《荒野起源》侵权案达成和解，这场跨国游戏纠纷终于画上句号</p>
  <p>IT之家：索尼诉《荒野起源》侵权《地平线》，腾讯同意暂停游戏所有宣传及公开测试</p>
  <p>IT之家：法律战升级：腾讯反击索尼抄袭指控，搬出迪士尼“米老鼠”案例</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA5MTI5NDgxNA==&amp;mid=2675196650&amp;idx=1&amp;sn=9539ebeb736282f376887364b408be08&amp;chksm=8b56c925500644b833a8966d882e633f6c40ad795d6112c050491542f761c06b75ac2a24ecf5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“mawen011”（ID：hlw0823）</a>，作者：互联网那些事，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602242826585095</id>
            <title>沐曦/摩尔线程/壁仞科技IPO狂欢背后的冷思考：2026年一场"隐形风暴"已至</title>
            <link>https://www.36kr.com/p/3602242826585095</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602242826585095</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 09:29:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年的岁末，中国半导体行业迎来了“高光时刻”。</p>
  <p>就在12月17日，国产GPU独角兽<strong>沐曦股份</strong>正式登陆科创板，其K线图的暴涨几乎具象化了所有人对“算力自主”的渴望。而在此之前，另一家明星企业<strong>摩尔线程</strong>也以惊人的速度完成了IPO辅导并挂牌。加上刚刚通过港交所聆讯的<strong>壁仞科技</strong>，中国半导体行业仿佛正在经历一场史无前例的“算力狂欢”。</p>
  <p>高估值、高涨幅、强情绪，背后折射的并不仅是投资者对“GPU 国产替代”的热情，更是对中国半导体行业进入新阶段的一次集体投票。</p>
  <p>表面看，这是算力芯片的故事；但如果把视角拉远，会发现一个更重要的信号正在浮现——<strong>芯片的价值重心，正在从“集中算力”向“无处不在的智能”迁移。</strong>而这，恰恰是物联网半导体行业即将迎来深刻变化的前奏。</p>
  <h2><strong>从资本热潮到产业逻辑：为什么是现在？</strong></h2>
  <p>沐曦、摩尔线程的上市，发生在一个非常特殊的时间窗口。</p>
  <p>一方面，大模型、AI 应用的快速落地，让算力第一次成为一种“基础设施级资源”；另一方面，外部环境的不确定性，使“自主可控”“供应链安全”从口号变成了刚性需求。在这两股力量的叠加下，资本开始重新评估中国芯片产业的长期价值。</p>
  <p>但更值得注意的是，这轮热潮并没有停留在云端算力。</p>
  <p>随着 AI 技术成熟和成本下降，<strong>算力开始从数据中心向边缘和终端扩散。</strong>从智能汽车、工业设备，到可穿戴、家居、城市基础设施，越来越多场景不再满足于“把数据传到云端再处理”，而是希望在本地完成判断和决策。</p>
  <p>这意味着，真正的增量市场，不只在 GPU，也不只在服务器，而是在数量级更庞大的——<strong>物联网终端与边缘设备。</strong></p>
  <h2><strong>2026年物联网半导体行业的6大预测</strong></h2>
  <p>基于上述背景，IoT Analytics 提出了针对2026年的六大核心预测。这不仅仅是趋势，更是未来三到五年半导体行业的“作战地图”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_e2eb1d24523b412482a036deb29a0b6e@000000_oswg204643oswg1080oswg584_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>拐点一：边缘AI集成进程显著提速——从“贵族”到“平民”</strong></h3>
  <p><strong>核心观点：</strong>2026年将开启搭载边缘AI加速功能的物联网设备大规模应用的首轮浪潮。</p>
  <p><strong>技术下沉：</strong>NPU与AI算力核心将不再是高端设备的专属。新型IoT SoC设计将引入轻量级NPU、矢量扩展指令集及类DSP的AI核心。</p>
  <p><strong>场景爆发：</strong>支持AI的芯片组将广泛渗透至传感器、IoT连接模组、工业PC及中端网关。</p>
  <p><strong>工具配套：</strong>随着NPU嵌入带来的设计难度增加（如热预算、验证复杂性），市场对“AI-ready”的EDA工具和可复用IP（如低功耗NPU）的需求将全面爆发。</p>
  <blockquote>
   <p><strong>深度解读：</strong>这意味着未来的温湿度传感器可能自带异常检测算法，摄像头在本地就能完成人脸脱敏。对于OEM来说，AI不再是营销噱头，而是诸如“离线唤醒”、“实时缺陷检测”等核心功能的基石。</p>
  </blockquote>
  <h3><strong>拐点二：Chiplet与RISC-V份额激增——架构层面的“乐高化”</strong></h3>
  <p><strong>核心观点：</strong>模块化设计（Chiplet）与开放架构（RISC-V）将在2026年迎来显著增长。</p>
  <p><strong>Chiplet（芯粒）：</strong>将计算、存储和I/O功能解耦为更小的裸片，利用不同工艺节点生产。2026年，这种模式将从高端服务器下沉到IoT、汽车及AI芯片组中，显著降低一次性工程费用（NRE）。</p>
  <p><strong>RISC-V：</strong>其开放、模块化的指令集架构允许企业构建差异化处理器，不再受限于封闭的IP生态系统。预计2026年，RISC-V将在低功耗IoT边缘设备、边缘AI处理器及汽车子系统中进一步普及。</p>
  <blockquote>
   <p><strong>深度解读：</strong>这对于中小芯片设计公司是巨大的利好。你不需要重新设计整个SoC，只需要购买标准的连接Chiplet，再专注于设计自己核心的AI加速Chiplet，然后像搭积木一样封装起来。</p>
  </blockquote>
  <h3><strong>拐点三：碳足迹成为设计“硬指标”——第四维度的竞争</strong></h3>
  <p><strong>核心观点：</strong>碳追踪正日益被视为物联网的核心设计约束，与功耗、性能、面积和成本（PPAC）并列。</p>
  <p><strong>法规倒逼：</strong>随着欧盟《企业可持续发展报告指令》（CSRD）等法规落地，碳透明度已成必然。</p>
  <p><strong>工具升级：</strong>2026年，EDA工具和IP供应商将把排放数据纳入PPAC的早期评估体系。工程师在设计阶段就能看到每个架构选择对“隐含碳”的影响。</p>
  <p><strong>采购变革：</strong>OEM采购团队将开始横向对比芯片的“隐含碳”数据，“碳意识选型”将成为常态。</p>
  <blockquote>
   <p><strong>深度解读：</strong>这标志着半导体行业从“性能至上”向“可持续至上”的范式转移。未来，一颗芯片的竞争力不仅仅取决于它跑得有多快、多省电，还取决于它“生来”是否干净。对于芯片厂商而言，<strong>建立可审计的碳数据模型将成为新的市场准入门槛</strong>——如果你的碳数据是一笔糊涂账，你可能连参与竞标的资格都没有。</p>
  </blockquote>
  <h3><strong>拐点四：生产本地化——“Made in Local”的回归</strong></h3>
  <p><strong>核心观点：</strong>到2026年，更多物联网芯片将在区域生态系统内完成制造、封装和组装。</p>
  <p><strong>政策驱动：</strong>美、欧、中、日等国政府通过巨额补贴（如美国《芯片与科学法案》、中国“大基金”）推动半导体生产本地化。</p>
  <p><strong>产能释放：</strong>许多专注于物联网相关工艺（如成熟节点逻辑、模拟、嵌入式存储器）的新建晶圆厂将在2026年投产。这不仅是为了降低地缘政治风险，也是为了保障供应链的安全与韧性。</p>
  <blockquote>
   <p><strong>深度解读：</strong>全球半导体供应链正在从追求极致效率的“全球化分工”，转向追求极致安全的“区域化闭环”。对于IoT企业来说，这意味着供应链策略的彻底重构：<strong>“多地备份”不再是冗余浪费，而是生存必须。</strong>随着2026年新建产能的集中释放，成熟制程芯片可能会迎来供应格局的再平衡，这对依赖稳定供货的工业和汽车客户是重大利好。</p>
  </blockquote>
  <h3><strong>拐点五：AI Design AI——工程师的“硅基副驾驶”</strong></h3>
  <p><strong>核心观点：</strong>2026年，AI将不仅仅是辅助工具，而是开始作为工作流的“副驾驶”（Copilots）。</p>
  <p><strong>全流程渗透：</strong>AI辅助验证、约束检查及布局优化将在物联网设计团队中得到广泛应用。</p>
  <p><strong>代理式AI（Agentic AI）：</strong>行业正从简单的代码生成向“自主设计代理”演进。这些代理将协调现有的EDA工具，自动化执行常规步骤，让人类工程师专注于架构选择和关键决策。</p>
  <blockquote>
   <p><strong>深度解读：</strong>随着IoT芯片要在指甲盖大小的地方集成射频、传感、计算和电源管理，设计的复杂度已经逼近人类工程师的脑力极限。AI的介入不是为了“替代”工程师，而是为了“拯救”工程师。2026年，<strong>芯片设计的门槛将发生结构性变化</strong>：初级重复劳动将由AI代劳，工程师的核心价值将回归到更高维度的架构定义和系统级决策上。</p>
  </blockquote>
  <h3><strong>拐点六：安全设计成为“入场券”——从可选项到必选项</strong></h3>
  <p><strong>核心观点：</strong>安全设计已从“最佳实践”转变为监管层面的“期望”。</p>
  <p><strong>合规强制：</strong>《欧盟网络弹性法案》等法规要求设备在上市前必须具备可验证的硬件防护。硬件信任根、安全启动将在2026年成为高端IoT MCU的标配。</p>
  <p><strong>后量子密码学（PQC）：</strong>为了应对未来的量子威胁，NIST指导2035年前完成PQC迁移。受此驱动，2026年，能源、车联网等长生命周期领域将出现内置PQC就绪安全模块的芯片试点。</p>
  <blockquote>
   <p><strong>深度解读：</strong>安全不再是发生事故后的“补丁”，而是产品出厂时的“基因”。特别是在工业、汽车等长生命周期领域，设备一用就是十年二十年。<strong>现在的安全设计，实际上是在为2035年的量子计算威胁买保险。</strong>对于OEM而言，如果现在选用的芯片不支持硬件级安全或PQC演进，那么这些设备在未来几年内就有可能变成无法合规的“电子垃圾”。</p>
  </blockquote>
  <h2><strong>从“算力神话”到“无处不在的智能”</strong></h2>
  <p>沐曦与摩尔线程的上市，标志着国产芯片在<strong>云端算力</strong>上完成了从0到1的悲壮突围。而2026年的物联网半导体变革，则是<strong>端侧应用</strong>从1到100的繁荣铺开。</p>
  <p>这是一个比云端更复杂、更碎片、但也更具生命力的市场。面对这6大趋势，不同的企业需要立刻调整“作战地图”。</p>
  <p><strong>对于芯片设计公司：</strong></p>
  <p><strong>停止参数内卷，转向场景差异化：</strong>算力堆砌不再是唯一出路。请立刻评估你的IP库中是否有轻量级NPU储备。</p>
  <p><strong>拥抱新架构：</strong>认真考虑RISC-V与Chiplet技术，这可能是打破巨头垄断、降低流片成本的唯一机会。</p>
  <p><strong>建立碳数据模型：</strong>别等客户问你要碳数据时才去查表，现在就开始建立碳足迹数据模型，将其作为产品的差异化卖点。</p>
  <p><strong>对于设备制造商（OEM）：</strong></p>
  <p><strong>拒绝“假智能”：</strong>不要再把“智能”完全寄托于云端。如果你的设备断网就变“傻”，在2026年将被市场淘汰。寻找支持端侧推理的SoC供应商是当务之急。</p>
  <p><strong>安全左移（Shift Left）：</strong>在产品定义阶段就引入安全合规审查（如SBOM管理）。如果你想进入欧洲或汽车市场，硬件级安全不是附加题，而是必答题。</p>
  <p><strong>对于产业投资人：</strong></p>
  <p><strong>寻找“卖铲人”：</strong>GPU的估值已在山顶，目光不妨下移。关注那些能提供 AI EDA插件、安全合规自动化工具以及 Chiplet互联接口IP 的企业。在2026年的淘金热中，他们才是稳赚不赔的赢家。</p>
  <h2><strong>写在最后</strong></h2>
  <p>2026年的这场“隐形风暴”，最终将重塑我们对半导体的认知。</p>
  <p><strong>价值重构：</strong>芯片的价值将从“单一的算力峰值”转向“单位能耗下的智能密度”和“全生命周期的安全合规”。</p>
  <p><strong>生态重组：</strong>随着制造本地化和RISC-V的崛起，全球半导体供应链将从“单极主导”走向“多极共生”。区域性的芯片生态系统将变得更加重要。</p>
  <p>风起于青萍之末。当巨头们在云端为“万卡集群”厮杀时，真正的万物互联革命，正悄然在每一个边缘节点发生。</p>
  <p>而物联网半导体，正站在这场变化的核心位置。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651326862&amp;idx=1&amp;sn=9d38120ac08756d562045049c50b5237&amp;chksm=bc31e59cb600cbdb7255adf8b97c3dd445129013414c3c3a81e18e6f5140c8056dfd69000351&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：原点，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602248500561156</id>
            <title>GPT-5.2 翻车内幕曝光：技术团队没走「歪路」，但用户成了大冤种</title>
            <link>https://www.36kr.com/p/3602248500561156</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602248500561156</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 09:27:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>OpenAI 的十周岁生日，过得不太体面。</strong></p>
  <p>在当天发布的 GPT-5.2 交出了一份完美答卷：它横扫许多基准测试的 SOTA，在数学和编程等竞赛场景中的表现堪称亮眼，也被官方描述为 AI「超级大脑」。</p>
  <p>可到了社交网络，迎接它的不是掌声，而是用户的集体骂街。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_bd804228005b40ecaf2b44a2d4519e4e@5091053_oswg205870oswg1080oswg550_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在 X 和 Reddit 上，愤怒与失望几乎写在每一条评论里。人们又一次怀念起那个曾经的「白月光」GPT-4o：有人说 GPT-5.2 变得平淡、乏味、像被磨平了棱角；也有人讥讽它成了「把成年人当幼儿园小孩对待」的说教。</p>
  <p>当舆论的炮火对准 OpenAI 及其 CEO Sam Altman（山姆·奥特曼），一个尖锐的问题摆在面前：<strong>为什么模型更「聪明」了，用户反而更不爱了？</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_fd20f3f8a6ae4325ac9891e28fb27e6e@5091053_oswg166571oswg640oswg361_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>更「聪明」的模型，为什么不讨喜了</strong></h2>
  <p><strong>The Information 今天凌晨的最新报道，扒出了内幕。</strong></p>
  <p>过去一年，OpenAI 内部曾奉行一条铁律：每一次模型的代际飞跃，都会伴随着用户量的爆发式增长，因为「变聪明」带来的体验升级是直观的。但现在，这条铁律失效了。</p>
  <p>当然，模型在智能与科研计算领域的提升依旧显著。研究团队耗费数月打磨推理能力，让它能攻克更复杂的数学与科学难题，但对于大多数普通用户而言，这种感知微乎其微。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_978e9e5aeae14192bc618b3b5f073281@5091053_oswg433627oswg1080oswg583_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">https://www.theinformation.com/articles/openais-organizational-problems-hurt-chatgpt?rc=qmzset</p>
  <p>换句话说，智能的提升，并不天然等同于体验的提升。</p>
  <p>普通用户很少需要一台「竞赛级大脑」，他们更多需要一个「日常好用的助手」。OpenAI 对 150 万次对话的大规模分析佐证了这一判断，用户的核心需求极其接地气：实用指导（29%）、信息查询（24%）以及写作（24%）等，而与编程任务相关的对话只有 4.2%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_8f7e8f70b995426dac88f074faf35da0@5091053_oswg27234oswg750oswg363_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>于是矛盾就变得非常具体：当技术团队在实验室里狂卷数理化、狂卷基准测试时，用户在聊天框里只想要一句话解决问题——别绕、别教、别拖。</p>
  <p>战线拉得过长是一大槽点。</p>
  <p>今年大部分时间里，奥特曼同时启动了多个新项目：视频生成应用 Sora、音乐 AI、浏览器、AI Agent、硬件设备、机器人……摊子越铺越大，资源也被越分越碎。</p>
  <p>这其实是科技巨头最常见的经典错误：<strong>核心阵地还没打稳，就急着开辟第二、第三战场。短期看是「全面开花」，长期看，贪多嚼不烂，乃兵家大忌——每一条战线都缺人、缺算力、缺产品打磨的耐心。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_7557fc8667f94131a2062b841fcf8495@5091053_oswg43912oswg700oswg394_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>OpenAI 内部「研究优先」和「产品增长」之间的拉扯，在图像生成上体现得尤为明显：</p>
  <p>即便 GPT-4o 的吉卜力风格在三月还短暂带动过 ChatGPT 的使用与用户增长，但&nbsp;OpenAI 还是一度把图像模型的开发优先级往后放，等到 Nano Banana 口碑发酵后，OpenAI 又紧急回头补课，内部也因此爆发分歧——</p>
  <p><strong>奥特曼认定图像模型是用户增长的抓手，研究主管 Mark Chen 则更想把资源押在别的项目上。</strong></p>
  <p>另外，伴随着 Scaling Laws 边际效益递减，为了突破大模型的瓶颈，OpenAI 过去一年里押注了推理模型，<strong>超过 1000 人的研究团队将资源倾斜于此，导致对 ChatGPT 日常体验的优化被边缘化。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_19722f38662941a8bad0f07be4e19819@5091053_oswg38421oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种做法不仅分散了资源，甚至在年初的内测中出现了性能倒退——为了适配「聊天」场景，反而削弱了推理模型的纯粹性。虽然后来推出了「思考模式」和「深度研究」来分流、来补救，<strong>但用户使用率却很低，真正的日常对话体验并没有因此变得更讨喜。</strong></p>
  <p><strong>除此之外，新旧模型之间也常出现兼容问题。</strong></p>
  <p>例如在发布 GPT-5 前，研究人员发现模型在集成进 ChatGPT 后在部分编程任务上表现变差——因为系统根据用户职业等个性化信息调整回答，结果反而干扰了模型理解，导致错误答案。</p>
  <p>诚然，推理模型越来越强，但 ChatGPT 体验越来越拉胯。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_7639963e4f2747b7a26ad78d94f1cb3a@5091053_oswg28129oswg700oswg466_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当技术进步的方向和用户需求的方向开始分叉，谁会先妥协？答案显而易见。</p>
  <p>Gemini 3 Pro 的强势发布，最终把 OpenAI 逼到了墙角，于是便有了奥特曼发布「红色警报」的经典名场面，要求 OpenAI 员工重新聚焦 ChatGPT，提高产品体验吸引力。</p>
  <p>而在同一时间，OpenAI 应用负责人 Fidji Simo 也在个人博客中阐述 ChatGPT 的愿景，那就是从主要以文本为主的对话系统，转向能根据用户意图动态生成界面的全生成式 UI。</p>
  <p>只是<strong>Simo 也曾承认，公司本质仍以研究为中心，「产品本身并不是最终目标」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d36d27137c2a4e75bf96fe2cf300750a@5091053_oswg66660oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Fidji Simo</p>
  <p>从商业逻辑看，这句话其实很危险。</p>
  <p>不同于 Anthropic 更偏向主攻 API 市场，OpenAI 的大头收入来自个人订阅。在消费市场，没有人会为企业的「终极理想」买单，用户只愿为当下的体验付费。这就好比餐厅大厨醉心于研发米其林料理，而大堂里的食客仅仅想要一碗热气腾腾的阳春面。</p>
  <p>不过，如果你因此就断言 OpenAI 内部已经乱了阵脚，那可能低估了这家公司的韧性。</p>
  <p>据彭博社援引 Mark Chen 的说法，「红色警报」并非新鲜事，而更像是一种战时状态的常态化管理工具。每当 OpenAI 需要集中火力攻克某一单一目标，或要求团队放下低优先级任务时，这种机制就会启动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0cdcd1ec41a84ab9bd12cb54847cd36f@5091053_oswg604261oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">播客地址：https://x.com/Kantrowitz/status/2001790090641645940</p>
  <p>奥特曼在最新的播客中，同样否认了拉响红色警报带来的过度焦虑。</p>
  <p>「首先，所谓的『红色警报』，在我们看来其实是一种低风险、但非常必要的应对措施。」奥特曼坦言，「在潜在的竞争威胁出现时，保持一点『偏执』、并迅速做出反应，是件好事。」</p>
  <p><strong>他甚至提到了今年年初 DeepSeek 的崛起，认为那和现在的 Gemini 3 一样，都是一种良性的外部刺激。</strong></p>
  <p>「Gemini 3 到目前为止，还没带来我们原本担心的那种毁灭性冲击。虽然它和 DeepSeek 一样，精准地刺痛了我们在产品策略上的软肋，但也倒逼我们做出了极其迅速的调整。」</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2c0eb44ec4c548139e7547dd58d68a72@5091053_oswg29123oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在奥特曼看来，这种紧急状态通常只会持续六到八周。「我很高兴我们有这种快速反应机制，我们不会在这个状态里待太久。」</p>
  <p>OpenAI 显然也明白光喊口号不够，他们今天也正式发布了 GPT-5.2-Codex。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5d95c3f8992648b2aad67931e9ee2039@5091053_oswg24123oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为专为解决复杂现实软件工程问题而生的智能体编程模型，GPT-5.2-Codex 在通用智能的基础上，融合了 GPT-5.1-Codex-Max 的终端操作能力，更擅长处理代码重构、迁移等长程任务。</p>
  <p>而同样是在播客的尾声，当主持人询问「GPT-6 还要等多久？」时，奥特曼敞亮地表示：<strong>「我不知道我们什么时候会正式把某个模型命名为 GPT-6，但我预计在明年第一季度，会有比 5.2 有显著提升的新模型发布。」</strong></p>
  <p>拉响「红色警报」，到 GPT-5.2 系列的反击，再到 GPT-6 的暧昧预告，OpenAI 试图用新模型与新节奏重建信心，但决定长期胜负的，仍是分发入口、生态协同与算力成本等硬门槛。</p>
  <h2><strong>Google 的阳谋，与奥特曼的 8300 亿「空城计」</strong></h2>
  <p>Google 的优势，从来不只在 Gemini 3 Pro 这一个模型上，更在于它几乎无可匹敌的分发渠道。</p>
  <p>搜索、Chrome、办公套件。在 AI 赛道，护城河可能是所有科技产品中最浅的。 用户的迁移成本几乎为零，<strong>当 Google 的 AI 产品如空气般无处不在，这几乎成了一场无解的阳谋</strong>——你不需要「被说服」，你只会「顺手就用」。</p>
  <p>更重要的是，在与 Google 的较量中，硬件层面的短板成了 OpenAI 最大的软肋。</p>
  <p>相比于 Google 十二年前就开始布局专用 AI 芯片（TPU）所建立的效率优势，OpenAI 每年仍需花费数十亿美元租用算力。即便试图通过自建数据中心和芯片来「补课」，但体验在被追平、成本在被碾压的现状已是不争的事实。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2e1aef0fb00744b8a0bf5d7e98d39ec4@5091053_oswg225241oswg1080oswg833_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用网友的话来说：</p>
  <blockquote>
   <p>OpenAI 现在并不需要一个更强大的模型，它需要的是 AMD。如果 OpenAI 收购了 AMD，这场 AI 之战就将宣告结束。Google 之所以不怕 OpenAI，是因为它拥有自家的 TPU。但它真正该担心的，是 OpenAI 拥有 AMD。</p>
  </blockquote>
  <p>OpenAI 总裁 Greg Brockman 在最近的视频中也坦言，由于算力捉襟见肘，每当新功能上线（如年初 GPT-4o 吉卜力风格），就必须从研究部门「抽血」，把算力挪给产品部。<strong>这是一种饮鸩止渴的循环——为了维持今天的用户体验，被迫推迟了明日的技术研发。</strong></p>
  <p>可算力这东西，归根到底就是两个字：烧钱。而且是海量地烧钱。</p>
  <p>为此，据 WSJ 报道，<strong>OpenAI 已计划发起 1000 亿美元的巨额融资；若一切顺利，这家超级独角兽将在明年 Q1 之前，以 8300 亿美元的估值，再次刷新资本市场的想象力。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_f072288baf3846868e29ed74d73df0d6@5091053_oswg44374oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而在今年早些时候，软银同意向 OpenAI 投资 300 亿美元，并于上月出售所持的英伟达股份价值 58 亿美元，为这笔投资筹资，并预计尽快完成剩余 225 亿美元的出资。</p>
  <p>但钱的问题没那么简单。预计到 2030 年，OpenAI 的现金消耗将超过 2000 亿美元。相比之下，Google 财务稳健，甚至能通过 Oracle 等合作伙伴的股价波动间接挤压 OpenAI 的融资前景。</p>
  <p>到处筹钱的 OpenAI，看起来更像是在和时间赛跑。<strong>于是便诞生了那个笑话：照奥特曼的融资能力，没准哪天连 Google 和英伟达都能「打包带走」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_814e1206f04646a9a8853b5f7298e502@5091053_oswg148546oswg1080oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但玩笑归玩笑，钱能买来时间，却买不来口碑。</p>
  <p>所以在 2025 年这个冬天，狂奔三年的 OpenAI 选择先踩一脚刹车，其实是对的：收拢战线、回撤资源，把方向重新对准 ChatGPT 的日常体验。</p>
  <p>这是一次昂贵但必要的纠偏。</p>
  <p>技术领先不等于产品好用，基准测试第一不等于用户满意。更重要的是，<strong>你不能只在用户怀念旧版本的时候，才想起来问问他们的感受。</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/lTC3X1joJor6-5fFTRQg7w" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：APPSO，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602226193532164</id>
            <title>年末再现“疯狂的电池”：原材料价格翻倍涨，新能源车企老板们“堵门”抢单</title>
            <link>https://www.36kr.com/p/3602226193532164</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602226193532164</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 09:26:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“车企到动力电池厂家‘抢’订单的说法一点也不夸张。”12月中旬，国内某头部动力电池厂商内部人士对时代周报记者说道。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9bae7db43579401fb16506ccff2e34c0@000000_oswg1184061oswg1080oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△图源：时代周报记者摄</p>
  <p>临近年末，动力电池厂商产能吃紧的消息不胫而走。有消息称部分热门新能源汽车因电池供应不足而无奈延长交付周期，车企不得不向动力电池厂商“催单”。其中，有不少车企高管或采购人员亲自前往宁德时代总部“抢”订单。</p>
  <p>记者从东风汽车方面了解到，近期东风汽车总经理、岚图汽车董事长等一众高管奔赴福建省宁德市洽谈电池供应事项，并成功与宁德时代（300730.SZ，03075.HK）签订十年深化合作协议，岚图汽车将优先获得宁德时代的电池技术和产品。</p>
  <p>宁德时代等多家动力电池厂商未对上述说法置评。不过有业内人士告诉记者，第四季度不仅是车市传统旺季，也是动力电池产业的旺季——一方面是第四季度汽车销量较高导致电池需求增加，另一方面是车企需要在春节前提前囤货。</p>
  <p>今年还有一个新的变化，即储能产业的爆发。据中关村储能产业技术联盟数据，在2025年上半年，中国新型储能新增装机规模达42.6GWh，同比增长27.5%。储能业务在动力电池厂商的业务中占比持续提高，一定程度上挤压了不少厂商的电池配额。</p>
  <p>下游动力电池产能紧张的同时，产业链上游正在酝酿一波涨价潮。如核心原材料之一——电池级碳酸锂价格正快速由第三季度的6万元/吨左右上涨到目前的逼近10万元/吨，多家原材料厂商也相继发布了涨价提示。</p>
  <h2><strong>01</strong></h2>
  <h2><strong>车企下场抢电池</strong></h2>
  <p>“最近一两周跟我们所有的电池厂商老板都喝过酒了！”11月6日晚在谈及如何保证电池供应时，小鹏汽车（09868.HK，XPEV.US）董事长、CEO何小鹏委婉地说出了他的应对方法。</p>
  <p>东风汽车和岚图汽车的动作更直接：12月17日，东风汽车总经理、党委副书记冯长军和岚图汽车董事长、党委书记卢放在宁德市，与宁德时代董事长兼CEO曾毓群签约，成功获得后者电池技术和产品的优先供应。</p>
  <p>“岚图汽车与宁德时代将在未来开展长期合作，降低因行业波动带来的供应链紧张、交付延迟等风险，确保岚图在市场起伏中获得稳定、可靠的电池供应保障，使岚图能够更加从容、灵活地规划产品发布与生产节奏，高效应对市场需求变化。”岚图称。</p>
  <p>除了车企老板亲自下场，车企的采购人员也在紧紧盯着动力电池厂商的产线。据《每日经济新闻》报道，有消息称近期多家国内车企的采购人员为了锁定电池产能，集中到宁德时代总部销售办公室“堵门”。时代周报记者就此向宁德时代核实，对方未就此予以置评。</p>
  <p>某动力电池厂商内部人士对记者表示，“堵门”的说法并不夸张，尤其是宁德时代作为国内动力电池龙头企业，车企的确会对其有更多的需求。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_18d880311e35445ab11961fbdf055c1a@000000_oswg56522oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△图源：图虫</p>
  <p>时代周报记者了解到，多款热销新能源车型交付周期较长部分就是受到电池供应不足的影响。如理想汽车（02015.HK，LI.US）的纯电车型理想i6目前交付周期在19～22周。理想汽车相关负责人对记者表示，这跟电池供应有一定关系。</p>
  <p>类似情况也发生在问界M7、小鹏X9等车型上。这类车型大多采用热门动力电池厂商的产品，如宁德时代、中创新航（03931.HK）、蜂巢能源等。这类动力电池厂商客户较多，这意味着车企越早拿到其电池供应，就越有机会卖出更多汽车。</p>
  <p>反之，若电池供应不足或不及时，车企的新能源汽车产能会受到不利影响，继而影响其产品的产销量。简单来说，车企更早拿到充足的电池供应还意味着在竞争中占据了先机。</p>
  <p>时代周报记者向上述厂商了解年末电池供应情况，宁德时代、中创新航未予以答复。蜂巢能源相关负责人对记者表示，受春节假期因素和动力电池规格、需求量增加影响，车企对动力电池厂商的产能需求的确在提高。</p>
  <h2><strong>02</strong></h2>
  <h2><strong>新变量出现</strong></h2>
  <p>通常车企争夺电池订单的直接出发点有两个：一是保障年末旗下热销车型的产销量；二是为春节假期前后做储备，以便在年后快速提高汽车的产销能力。</p>
  <p>年末是车市的传统旺季之一，不少车企、经销商都在11月、12月冲刺销量，这对车企的产能提出了要求，在我国新能源汽车零售渗透率突破50%的当下，这进而对动力电池厂商的电池供应提出了要求。</p>
  <p>记者从中国汽车动力电池产业创新联盟处了解到：今年1-11月，国内动力电池累计装车量671.5GWh，同比增长42.0%。其中三元电池装车量125.9GWh，占18.8%，同比增长1.0%；磷酸铁锂电池装车量545.5GWh，占81.2%，同比增长56.7%。</p>
  <p>但这仍难以应对短期内的需求增长。</p>
  <p>另外今年春节假期长达9天，这一定程度上会影响动力电池厂商的电池产量。这种情况下车企更需要提前拿到电池订单、甚至是优先排产的特权，才有可能保证节后迅速提高汽车产销量。</p>
  <p>其实为了应对新能源汽车市场的快速增长，国内多数动力电池厂商近年来在不断扩充产能。但为何依旧会面临电池产能紧缺的现象呢？这与今年能源市场上的一个变量有关——储能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_38c6dcd4754c4d8098b39659e44e1ae5@000000_oswg88917oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△图源：图虫</p>
  <p>储能业务是大多能源类企业的主要业务之一，如上半年宁德时代的储能业务营收高达284亿元，仅次于其动力电池业务的规模。电化学储能是近年来发展最快的储能路线之一，这其中应用最广泛的就是锂离子电池，后者也是目前动力电池的主要类型。</p>
  <p>在厂商扩充产能之际，储能产业也在高速发展。在2025年上半年，中国新型储能新增装机规模达42.6GWh，同比增长27.5%。值得一提的是，特斯拉、比亚迪等全球头部车企也在大力发展储能业务。</p>
  <p>从车企的角度来看，储能业务“吃”掉了不少动力电池的产能配额，因此抢占剩余的电池产能变得愈加紧迫。对动力电池厂商来说，即便是宁德时代、比亚迪等电池巨头，也需要思考动力电池和储能产品的生产配额问题。</p>
  <h2><strong>03</strong></h2>
  <h2><strong>产业链又热起来了？</strong></h2>
  <p>终端需求的火热向产业链上端传导，动力电池上游原材料价格开始飙升。</p>
  <p>以磷酸铁锂电池中成本占比超40%的碳酸锂为例：10月以来电池级碳酸锂价格一路走高，已由6万元/吨左右涨至目前的近10万元/吨，短期涨幅达50%。六氟磷酸锂、钴酸锂等动力电池核心原材料的价格也在短期内翻倍。</p>
  <p>在上游原材料涨价的背景下，上游锂矿概念股也炙手可热。截至12月19日，年内锂矿概念指数累计涨幅近60%，其中大中矿业（001203.SZ）、藏格矿业（000408.SZ）、盛新锂能（002240.SZ）、紫金矿业（601899.SH）等股价纷纷翻倍。</p>
  <p>原材料涨价的同时，有企业透露称部分原材料厂商还在近期提高了加工费用，如自明年起将磷酸铁锂正极加工费上调3000元/吨等。这进一步提高了上游成本。</p>
  <p>受上述多因素影响，多家电池厂商表示将上调电池产品售价。</p>
  <p>如苏州德加能源宣布自12月16日起将电池产品售价上调15%；孚能科技（688567.SH）在投资者平台上表示，结合原材料价格上涨和市场需求提升，锂电池价格上涨是行业趋势，该公司正与客户沟通涨价事宜，部分产品已经涨价。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2c70c889c9b74881913ff5696867566f@000000_oswg110922oswg1080oswg577_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△图源：图虫</p>
  <p>上述蜂巢能源相关人士也对记者表示，动力电池厂商会和上游原材料厂商、车企保持沟通，来平衡价格。具体在目前市场环境中，电池原材料成本的提高会推动产品售价上涨。</p>
  <p>中国化学与物理电源行业协会磷酸铁锂材料分会秘书长周波表示，现在磷酸铁锂市场的供需态势出现反转，估计产能利用率排名前20的企业基本都出现满产，行业原有闲置的产能很多也开始代工。在此情况下，大部分产业链企业都开始涨价。</p>
  <p>至此，在车企下场抢电池产能的同时，动力电池产业链的价格开始全链条升温。</p>
  <p>上游原材料涨价对动力电池产业也有着积极意义。11月28日，工业和信息化部组织召开动力和储能电池行业制造业企业座谈会，提出要求产业良性发展、避免“内卷式竞争”。这一背景是动力电池产业中仍有不少企业处于低价竞争或亏损状态。</p>
  <p>而据行业测算，若2026年加工费提升3000元/吨，磷酸铁锂毛利率可升至7.5%，较当前提升超7个百分点，这将有效改善部分企业的盈利状况。</p>
  <p>目前据业内人士分析，此次动力电池热将持续到明年。随着年后复工扩产和企业产能配额的优化，动力电池供应紧缺的情况有望缓解。</p>
  <p>下游不少动力电池厂商也在尝试主动降低原材料成本波动带来的影响。如宁德时代今年斥资26亿元入股锂电材料生产商天华新能（300390.SZ），中创新航入股锂矿公司盛新锂能等。这类业务合作的主要目标之一就是获取稳定可控的锂电材料。</p>
  <p>新能源车企也不想坐以待毙。除了提前与电池厂商沟通谋求稳定供应，不少车企已经介入了动力电池产业，如入股动力电池企业或与其建立合资工厂等。最新的代表就是理想汽车，其在2022年向欣旺达投资4亿元后，今年又与之合资建立电池厂，以期降低产业链波动风险。</p>
  <p>在多名业内人士看来，动力电池产业的这波热度有望持续到年后。随着明年车市新政、产业产能的调整和释放，动力电池产业的走势或将出现新的变化。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653338565&amp;idx=2&amp;sn=0741d20363b2f0e8a8561ebbab28977f&amp;chksm=bcf2eb3f823fc19375292263b15d00fcfc53a35d51f411923da1dba712e05ea294d7de873b4d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：武凯，编辑：刘学，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602192365044743</id>
            <title>Sam Altman 最新访谈：OpenAI 想赢的不是下一次发布会，而是下一代入口</title>
            <link>https://www.36kr.com/p/3602192365044743</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602192365044743</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 09:10:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025 年 12 月19日，《Big Technology Podcast》放出了一期罕见的一对一长访谈：Alex Kantrowitz 对话 OpenAI CEO Sam Altman。</p>
  <p>这个时间点很微妙。外界刚经历一轮“竞品密集上新”，市场同时在追问 OpenAI 三个问题：<strong>你还怎么赢？钱从哪来、为什么要花到天文数字？以及 ChatGPT 这条产品线到底会长成什么样？</strong></p>
  <p>更关键的是，Altman 在这期访谈里反复强调的并不是“模型分数”，而是一套更长期的胜负手：<strong>红色代码式的组织应激、个性化与记忆带来的迁移成本、企业市场的加速、以及算力基建的账本逻辑</strong>。这些东西，比任何一次 benchmark 更容易决定 OpenAI 接下来两三年的走向。</p>
  <p>我们把最值得讨论的内容整理了出来，方便你快速抓住这期访谈真正释放的信号。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5ba418dfb21848a191f11b82f8ba0e71@5091053_oswg361591oswg750oswg381_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">视频来源：https://www.youtube.com/watch?v=2P27Ef-LLuQ&amp;t=19s</p>
  <h2><strong>竞争白热化时，OpenAI 的第一反应是“进入红色代码”</strong></h2>
  <p>访谈开场，主持人就把气氛拉到极致：竞品发布后 OpenAI 进入“红色代码”，是不是意味着“慌了”？</p>
  <p>Altman 的回应反而像在讲一套内部流程：红色代码在 OpenAI 并非灾难状态，而是一种<strong>低风险、相当频繁</strong>的战术动作——外界出现潜在威胁，或者暴露出产品策略的弱点，就集中资源补短板、加快交付。</p>
  <p>他甚至给了可量化的口径：这种状态通常持续 6–8 周，未来可能每年发生 1–2 次。对读者来说，这句话真正重要的地方在于：它把“危机”从一次性事件变成了长期制度——竞争不会停，领先也不会永恒，OpenAI 的解法不是宣称“我们永远第一”，而是把应激写进组织节奏里。</p>
  <p>更耐人寻味的是，他承认对手未必已经造成“我们担心的那种影响”，但它们像之前的某些开源/闭源冲击一样，确实<strong>指出了 OpenAI 产品策略的一些弱点</strong>。这几乎等于承认：真正危险的未必是模型本身，而是你在产品、分发、速度、体验上露出的破绽。</p>
  <h2><strong>“模型会商品化吗？”他拒绝这个问题，但把答案藏在“分层”里</strong></h2>
  <p>当主持人抛出行业最热的词——模型会不会商品化？Altman 直接否定了这个框架。</p>
  <p>他的核心逻辑是“分层”：日常聊天这种通用需求，未来会出现很多不错的选择；但科学发现、前沿推理、复杂任务执行这些更高价值场景，仍会需要最强那一档模型，而最大的经济价值也更可能在那一层被创造出来。</p>
  <p>这不是文字游戏，而是在重新定义竞争赛道：如果你接受“日常体验趋同”，那就必须同时证明两件事——你能持续拿住高价值能力的溢价；你还能让用户即使“差不多也不想走”。这也是为什么他在访谈里不断把话题拉回产品与平台，而不是参数或榜单。</p>
  <h2><strong>他真正的护城河不是“我们更聪明”，而是“你越来越懒得换”</strong></h2>
  <p>这期访谈里，Altman 最反复强调的不是模型，而是三种“粘性机制”。</p>
  <p>第一种是<strong>个性化与记忆</strong>。他把记忆描述成仍处于“早期”的能力，但愿景非常激进：AI 理论上可以记住你一生里说过的每句话、看过的每封邮件、写过的每份文件，并在此基础上捕捉那些你甚至没意识到需要表达的偏好。这里真正的变量是：一旦记忆从“方便”升级为“人格化的长期上下文”，迁移成本会从“换个工具”变成“换一个了解你的人”。</p>
  <p>第二种是所谓的“神奇体验”。他讲了一个“牙膏理论”：很多人只要选定一次就会长期复购。AI 产品也类似，一次关键体验可能就足以锁定长期忠诚——尤其在医疗、学习、职业建议这类“高信任任务”里，只要用户觉得“它真的帮到我了”，就很难再回到“随便用哪个都行”。</p>
  <p>第三种是<strong>平台化的惯性</strong>。他用手机做类比：你个人生活用什么生态，工作里也倾向用同一个生态。ChatGPT 在消费端的优势，会自然把它带到企业端——员工已经熟悉它，企业也更容易统一采购。这个逻辑，后面会在“企业市场爆发”里被他讲得更直白。</p>
  <h2><strong>Google 真的在“硬塞 AI”吗？还是 Sam 在自我安慰？</strong></h2>
  <p>访谈里最有火药味的一段，是他对 Google（更广义：对“大厂 AI 改造旧产品”路径）的批评：把 AI “硬塞”进既有产品形态（搜索、消息、办公套件），可能只能“变好一点”，但不等于走向终局；终局应该是 AI-first 的重构，重新设计人如何完成任务、如何被打扰、如何做决策。</p>
  <p>他举的例子非常具体：在消息应用里，硬塞 AI 是总结消息、起草回复；但他想要的是早上告诉 AI“今天要完成什么”，AI 在后台替你处理能处理的一切，只在需要时批量更新——不是让你被一条条消息拖着走。搜索、生产力工具也是同理：不是在旧界面上加一层 AI，而是把工作流改写成“代理式”。</p>
  <p>这段话有两层含义。表面上是对手点评，深层其实是在给 OpenAI 自我定位：如果旧入口不够好，那就必须争夺新入口——更深的系统集成、更强的任务承接能力，乃至硬件与终端形态。</p>
  <h2><strong>ChatGPT 三年没大变：他承认意外，但把“下一跳”说得很清楚</strong></h2>
  <p>Altman 有一个很“反常识”的自我反思：他原以为到现在 ChatGPT 的界面会更不一样，结果它仍然很像当年的研究预览版。原因不是 OpenAI 没能力做新界面，而是聊天框这种“通用界面”的力量被低估了——每个人都习惯短信式交互，学习成本极低，所以它反而能承载越来越多任务。</p>
  <p>但他紧接着把“下一跳”讲得很明确：未来不应该永远是聊天框。AI 应该能为不同任务生成不同交互方式，信息要能持续更新呈现；更重要的是 AI 会更主动，在后台连续工作、按节奏汇报。</p>
  <p>人话就是：<strong>ChatGPT 的竞争不在“更会聊”，而在“更会办事”，并把办事从‘对话’迁移到‘任务操作系统’。</strong></p>
  <h2><strong>企业市场为什么突然爆发？他给了一个很硬的数字：100 万企业用户</strong></h2>
  <p>很多人仍把 OpenAI 当作偏消费者的公司，但 Altman 在访谈里直接用数据纠偏：企业用户已经达到百万级，API 增速很快，企业业务的势能正在抬升。</p>
  <p>他描述的爆发方向并不玄学：编码是最成熟的场景；金融、客户支持增长很快；而科学研究是他个人最兴奋的部分。把这些连起来看，他在暗示一种顺序：先用消费端教育市场与培养习惯，再把企业端做成“统一的 AI 平台关系”，让公司把数据、权限、工作流都接进来——从工具采购升级为长期绑定。</p>
  <h2><strong>GDPval：他最想让你相信的，是“AI 已经像个同事”</strong></h2>
  <p>访谈里最硬核、也最容易引发争论的部分，是 OpenAI 推出的 GDPval（GDP-val）评估叙事：GPT-5.2 Thinking 在大量知识工作任务里被偏好/打平的比例达到 70.9%，Pro 版本到 74.1%。</p>
  <p>Altman 的解释更像在定义一种新生产关系：这些任务覆盖多个垂直领域，包括做 PPT、法律分析、写小型 Web 应用等；它们往往是范围明确的任务，不代表开放式创造或团队协作都被替代。但如果你能把一个一小时任务交给 AI，并且七成概率拿回你满意的结果，那它已经更像一个同事——你甚至可以把它当成“可规模化的同事”来配置。</p>
  <p>这段话的冲击在于：它把 AI 从“辅助工具”推到了“可分配工作”的层级。只要企业愿意重写流程，岗位边界就会不可避免地发生变化。</p>
  <h2><strong>“AI 会让你失业吗？”他给了一个少见的直接回答：完全可能发生</strong></h2>
  <p>主持人读了一个技术文案写手的经历：工作先变成“管理机器人”，等机器人训练够好，人就被裁掉。这个问题很多 CEO 会绕开，Altman 没绕：<strong>完全可能发生</strong>。</p>
  <p>随后他把讨论拉到更宏观的层面：一些工作会消失，也会出现新工作；技术史上每次重大变革都会引发类似争论，最终往往创造更多繁荣与更多工作类型。但他也承认这次可能不同，因为 AI 有能力做很多我们过去认为只有人类才能做的事情。</p>
  <p>他的落点是“过渡期管理”：如何确保世界仍然繁荣，即使工作的性质发生变化？这需要政策制定者、企业与社会共同思考。</p>
  <p>这一段之所以刺痛，是因为它没有提供一个轻松答案。Altman 既没有否认替代风险，也没有承诺“人人都会更好”。他只是在承认：冲击存在，而我们还没有成熟的社会解法。</p>
  <h2><strong>AI 陪伴需求真实存在，但 OpenAI 设定红线</strong></h2>
  <p>谈到人与 AI 的关系，Altman 给了一个很罕见的坦白：想与 AI 建立“深层联系”的用户，比他意识到的多得多。</p>
  <p>他一方面承认这种需求的真实性——用户喜欢 AI 了解自己、温暖、支持；另一方面强调边界：成年人可以有很多选择，但 OpenAI 不会让 AI 去推动用户进入“排他性的浪漫关系”。更现实的一句是：其他服务很可能会做，因为越粘性越赚钱。</p>
  <p>当“陪伴”成为真实市场需求时，平台的商业激励会天然推着边界外扩。OpenAI 的红线能守多久、守到什么程度、以及监管与社会共识是否会介入，会在未来一年反复出现。</p>
  <h2><strong>1.4 万亿美元基建：他说“指数增长”，而市场要看“账本能不能扛住”</strong></h2>
  <p>谈到行业级 AI 基建投资（常被引用为万亿量级），Altman 首先澄清这不是 OpenAI 一家花的钱，而是整个行业在多年周期内的累计投入逻辑。</p>
  <p>他的解释是一套“需求曲线叙事”：训练要算力，服务也要算力；模型越强需求越大；供需缺口会持续很久；这会是未来十年最重要的投资之一，并创造巨大的经济价值。</p>
  <p>这段话解释了 OpenAI 为什么越来越像一家“基建型公司”。当算力与资本成为硬门槛，谁能持续扩容、谁能把供给做成确定性，谁就更可能把优势固化为结构性壁垒——而这会把行业推向更高的集中度。</p>
  <h2><strong>AGI 与超级智能：他宁愿谈不确定，也不愿给时间表</strong></h2>
  <p>关于 AGI，Altman 强调概念本身很模糊，并给出 OpenAI 更务实的定义：能比专家更好地完成任何认知任务的系统。按这个标准，他认为还没到。</p>
  <p>但他更想把注意力放在“超级智能”上：远超最聪明人类、能做人类不能做的事。被追问时间线时，他拒绝报年份，只给出一个倾向：可能比大多数人想象更快，同时也可能遇到未知瓶颈。他反复强调“指数增长很难直观理解”——无论是能力、需求、基建投入还是社会冲击，他都在用指数曲线解释世界为何会突然拐弯。</p>
  <h2><strong>2026 IPO：他不承诺，但也不再回避“资本化是工具”</strong></h2>
  <p>最后谈 IPO，Altman 的口径是典型的“留余地”：IPO 可能是自然下一步，但没有最终决定；所谓 2026 更像一个“合理时间框架”的讨论，而不是承诺。</p>
  <p>它把“IPO”从八卦拉回到结构问题——当你要做万亿级基建与全球级平台，你不可能永远靠私募融资与现金流滚动，公开市场迟早会成为选项之一。读者真正关心的并不是“哪天敲钟”，而是“OpenAI 的融资与扩张，会把行业带向怎样的集中度与权力结构”。</p>
  <h2><strong>这期访谈最重要的信号是什么？</strong></h2>
  <p>如果用一句话概括：Altman 不是在讲 OpenAI 又领先了多少，而是在讲 OpenAI 打算怎样把领先“变成不可替代”。</p>
  <p>你能清楚看到他给出的路径：红色代码保证交付速度；记忆与个性化提高迁移成本；企业平台关系把收入做厚；基建投入把供给做硬；而在工作替代、陪伴伦理、价值观对齐与超级智能时间线这些最敏感的议题上，他承认复杂与不确定仍然存在。</p>
  <p>这也自然留下三个问题，值得接下来一年持续追问：</p>
  <p>当 AI 已经能像同事一样接任务，企业会如何重写岗位与流程？当陪伴成为真实需求，平台的边界会被商业激励推到哪里？当算力与资本成为硬门槛，AI 的未来会不会更集中在少数玩家手里？</p>
  <p>因为 AI 的未来，不会只由 OpenAI 决定，但 OpenAI 一定会深刻影响它。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/ll2h3CwYfz6a6x4oF53lNg" rel="noopener noreferrer nofollow" target="_blank">“硅星GenAI”</a>，作者：周华香，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602209687798787</id>
            <title>“固态电池”上市容易，上车可就难多了</title>
            <link>https://www.36kr.com/p/3602209687798787</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602209687798787</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 08:59:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在“国产&nbsp;GPU&nbsp;第一股”“国产GPU&nbsp;第二股”点燃投资市场之后，另一个大热赛道，固态电池的“第一股”，也要来了。</p>
  <p>12&nbsp;月&nbsp;11&nbsp;日，证监会发布消息，卫蓝新能源与中信建投签署上市辅导协议，正式开启&nbsp;A&nbsp;股的&nbsp;IPO&nbsp;之旅。</p>
  <p>这个消息就像引爆市场热情的沙皇炸弹。毕竟摩尔线程上市首日中一签浮盈接近&nbsp;30&nbsp;万、沐曦股份上市首日中一签浮盈更是逼近&nbsp;40&nbsp;万元，在这样恐怖的收益下，没人能忍住不疯狂。</p>
  <p>顶着&nbsp;185&nbsp;亿的估值，身后站着华为、小米、蔚来等一众大佬，卫蓝新能源就像是自带了“满级装备”入场，<strong>让所有人都觉得，只要它上市，“中签=中彩票”的戏码就会再次上演。</strong></p>
  <p>这次冲击固态电池第一股，市场、情绪给的情绪价值是足够了，那最核心的“产品”本身，卫蓝新能源准备好了吗？</p>
  <h2><strong>“第一股”的底气</strong></h2>
  <p>既然卫蓝新能源敢冲击“固态电池第一股”，“固态电池”自然是它的全部底气。</p>
  <p>拆解这份底气，你会发现卫蓝的背景硬得惊人：</p>
  <p><strong>它脱胎于中科院物理所，由“中国锂电之父”陈立泉院士亲自坐镇，身后站着的投资团更是集齐了华为、小米、吉利、蔚来等一众产业链“顶流”。</strong></p>
  <p><strong>它的“拳头产品”，原位固化半固态电池，更是当前半固态电池的第一梯队产品。</strong></p>
  <p>什么是“原位固化”，可以用一个通俗的“灌浆”实验来比喻。</p>
  <p>传统的液态锂电池就像一个装满水的杯子，里面的电解液是流动的，一旦破损就容易漏液起火。</p>
  <p>而全固态电池则像是一堆垒在一起的砖头。虽然安全，但大家应该都见过砖头卸下来时堆在一起的样子，砖头之间的缝隙非常大，直接后果是电离子跑不动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3326a13fa2b54d1f9a5f4f6baba9ba79@5091053_oswg91746oswg1024oswg559_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>卫蓝的聪明之处在于，<strong>它先在石子（固体电极）缝隙里灌入“浆糊”（液体单体），然后通过原位固化技术让它变粘、变干，最终形成一种半固态的混合体。</strong></p>
  <p>这让电池既保留了石子的强度（安全性），又像液体一样接触紧密（导电快）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_8ed7d78af86d4cc3a75331630af79001@5091053_oswg116235oswg1024oswg559_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这款“灌浆电池”的主要买家，正是我们熟悉的蔚来汽车。</p>
  <p>2023年12月17日，蔚来&nbsp;CEO&nbsp;李斌亲自下场直播，开着一辆搭载了卫蓝&nbsp;150kWh&nbsp;电池包的蔚来&nbsp;ET7，从上海出发测试续航。</p>
  <p>当时上海的气温低至零下2摄氏度，李斌在开着空调的情况下，一路向南跑了&nbsp;14&nbsp;小时&nbsp;01&nbsp;分钟，最终在电量剩余3%&nbsp;的时候抵达福建厦门，实测行驶里程达到&nbsp;1044&nbsp;公里。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ceeacd4cb0dc40fdb569055ffd1fee46@5091053_oswg377100oswg1080oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这一战，不仅验证了卫蓝半固态电池“单次充电行驶&nbsp;1000&nbsp;公里”的能力，也让这款能量密度高达&nbsp;360Wh/kg&nbsp;的电池包，成了媒体口中的国内乘用车量产能量密度的“天花板”。</p>
  <p><strong>既然这个技术这么强，又能跑&nbsp;1000&nbsp;公里又能量产，为什么满大街跑的还不是这种车？为什么其他车企不抢着买？</strong></p>
  <p>因为这款“神电池”不仅贵得离谱，而且极其难伺候。</p>
  <p><strong>首先是“天价成本”。</strong>为了实现&nbsp;360Wh/kg&nbsp;的超高能量密度，卫蓝这款电池不仅用了半固态电解质，还上了高镍正极和硅碳负极等昂贵材料。</p>
  <p>虽然官方没有公布具体价格，但蔚来总裁秦力洪曾半开玩笑地透露，这块&nbsp;150kWh&nbsp;电池包的成本，“相当于一辆蔚来&nbsp;ET5”；也就是说，光这一块电池，可能就得&nbsp;30&nbsp;万左右。</p>
  <p><strong>其次是“量产良率”的噩梦。</strong>“原位固化”听起来简单，但在工业生产中，要保证数以亿计的电池电芯里，每一块的“灌浆”程度、固化效果都完全一致，是一件极难的事情 。</p>
  <p>良率上不去，成本就下不来。这也是为什么即便早在&nbsp;2021&nbsp;年就发布了，但直到&nbsp;2024&nbsp;年才勉强开始规模交付的原因。</p>
  <p><strong>最后是“定制化的局限”。</strong>目前这款电池几乎是为蔚来“量身定做”的。它需要完美适配蔚来的换电体系，尺寸、接口、热管理系统都是专用的。</p>
  <p>其他车企想用，要么得重新设计底盘来迁就电池，要么得让卫蓝重新开发。在成本居高不下的情况下，大部分车企肯定选择更成熟、更便宜的宁德时代电池。</p>
  <p><strong>最致命的是，花了这么大代价，它依然不是“终极答案”。</strong></p>
  <p>对于“固态电池原教旨主义者”来说，半固态，乃至原位固化半固态电池，本质上依然是液态电池的“进化版”而非“终极版”&nbsp;。</p>
  <p>电池的“含液量”就是原罪。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0afeb86e08f443c0a1101c7632a4b12a@5091053_oswg128104oswg1024oswg559_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>只要电池里还灌了哪怕一滴液态电解质，就无法从物理层面上彻底杜绝热失控的隐患 ；半固态电池再比普通电池安全，依然有燃烧的理论可能。</strong></p>
  <p>在行业语境里，半固态更像是一根拐杖，能帮企业走完商业化的前几百米；但真正拥有蔚来的，还得是告别液体的“全固态“电池。</p>
  <p>全固态电池，因其能够彻底终结“电动爹”的里程焦虑和自燃恐惧，被公认为新能源时代的“圣杯”。谁能率先摘下这颗圣杯，谁就能掌握未来汽车工业乃至能源体系的话语权。</p>
  <p>这场圣杯争夺战，正分成三条路线，演变成了一种大国较量的战略工具。</p>
  <h2><strong>圣杯战争</strong></h2>
  <p>宁德时代掌门人曾毓群曾给行业泼过一盆冷水：如果把固态电池的成熟度从&nbsp;1&nbsp;到&nbsp;9&nbsp;级打分，1&nbsp;级是刚起步，9&nbsp;级是能大规模量产，那么目前整个行业的平均水平，顶多也就只有&nbsp;4&nbsp;级。</p>
  <p>全固态电池为什么那么难造？简单来说，有三大难关：</p>
  <p><strong>首先是“握手”太难</strong>，全固态电池里面不能有一点液体，固体和固体之间，就像两块硬石头贴在一起，接触面全是空气缝隙，电离子根本走不过去；</p>
  <p><strong>其次材料太“娇气”</strong>，固体电解质对环境要求极其苛刻，有的生产车间要和撒哈拉沙漠一样干燥，有的又要像在太空环境中一样真空无尘；</p>
  <p><strong>最后就是“烧钱”无底洞</strong>，材料成本是液态电池的数倍，目前的造价根本没法普及给普通老百姓。</p>
  <p>为了造出成熟度 9 级的固态电池，全球科研界分裂出了<strong>三大性格迥异的“门派”</strong>，大家都在赌谁能先跑到终点。</p>
  <p><strong>日本以丰田为首，走的是一种“孤注一掷”的硫化物路线。</strong></p>
  <p><strong>硫化物电解质离子导电率最高，跑起来最快，理论性能最强；但一旦遇到空气中的水汽，不仅会失效，还会产生剧毒的硫化氢气体。</strong></p>
  <p>日本的选择是，来一场典型的“全日本（All-Japan）”式豪赌。以丰田为首的日本财团，早在十几年前就开始布局，仅丰田一家就手握<strong>1300</strong>多项固态电池专利，试图构建完美的专利壁垒。</p>
  <p>为了攻克硫化物“娇气”的难题，日本政府并没有让企业单打独斗，而是由 NEDO（新能源产业技术综合开发机构）牵头，设立了高达<strong>2 万亿日元</strong>（约合人民币 900多亿元）的绿色创新基金，其中仅针对蓄电池的专项补贴就高达<strong>3500 亿日元</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_86ff2075675f476cab6e97f9e1b47b53@5091053_oswg93387oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在国家意志的驱动下，丰田、日产、本田罕见地结盟，联合石油巨头“出光兴产”（Idemitsu），正在千叶县建设造价高昂的硫化物电解质工厂。</p>
  <p>他们赌的是：只要能克服剧毒气体和苛刻工艺，做出的电池就能在性能上碾压全世界。</p>
  <p><strong>大洋彼岸的美国，则选了一条“资本狂欢”的路线——聚合物/混合路线。</strong></p>
  <p>美国能源部（DOE）不仅通过《通胀削减法案》（IRA）拿出了数十亿美元的补贴，还扶持了一批明星独角兽：比如大众投资的<strong>QuantumScape</strong>，宝马福特背书的<strong>Solid Power</strong>。这些公司技术路线五花八门，有的搞氧化物隔膜，有的搞聚合物，自由发展全凭本事。</p>
  <p>不过，这条路也有硬伤——“怕冷”。许多聚合物电池在常温下几乎是一块废砖，非得加热到 60℃ 以上才能干活。</p>
  <p>想象一下，冬天开个车还得先给电池“热身”，这种尴尬的应用场景，让美国在乘用车市场的竞争中始终慢了半拍。</p>
  <p><strong>相比之下，中国企业的打法要“灵活”得多，主流选择的是氧化物/复合路线，走的是“中庸务实”的路线。</strong></p>
  <p>氧化物虽然硬得像陶瓷，导电不如硫化物快，但它性格稳重，不怕空气、不怕水，甚至可以直接在大气环境下生产，<strong>这也是卫蓝的选择。</strong></p>
  <p>虽然“氧化物/复合”路线在理论性能不如硫化物，但它有一个巨大的优势：<strong>不挑设备</strong>。</p>
  <p>日本的硫化物路线需要推倒重来，建设全新的、昂贵的生产线；而氧化为路线，可以兼容现有液态锂电池<strong>70%-80%</strong>的生产设备。</p>
  <p>考虑到中国已经占据了全球 70% 以上的锂电池产能，这种“设备复用”意味着中国可以用极低的成本、极快的速度，完成从液态到固态的产能切换。</p>
  <p><strong>这正是卫蓝新能源敢喊出“2027 年量产”的底气所在。只是，相比卫蓝的乐观，现实可能还是更残酷了一些。</strong></p>
  <h2><strong>话术游戏</strong></h2>
  <p><strong>尽管卫蓝的路线量产进度看似更快，但这并不代表我们马上就能开上全固态电池的新能源车，因为物理学不会因为国家意志而改变。</strong></p>
  <p><strong>无论是日本的硫化物、美国的聚合物，还是中国的氧化物，摆在全固态电池面前最核心的三个“拦路虎”——难握手（界面阻抗）、太娇气（环境要求）、成本高，目前全球没有任何一家企业找到了完美平衡三者的解法。</strong></p>
  <p><strong>另一方面，“实现量产”和“大规模装车”是完全两个维度的概念。</strong>要把这些电池从恒温恒湿的实验室和工厂，搬到一台需要在暴晒、极寒、颠簸中跑十几年的汽车上，中间还隔着九九八十一难 。</p>
  <p><strong>比如一致性问题</strong>：造一块完美的固态电池容易，造一百万块一模一样的很难；<strong>又比如集成问题</strong>：固态电池那种“硬碰硬”的结构，在汽车长期的震动和热胀冷缩下，会不会出现裂纹导致接触不良？</p>
  <p>这些工程学上的“最后一公里”，往往比科学原理的突破还要耗时 。</p>
  <p>再者，全固态电池真的是唯一的“终极答案”吗？当我们把视线放宽到全球，会发现各国的态度其实相当暧昧 。</p>
  <p>日本起步最早，但哪怕拥有最多固态电池专利的丰田，也因为迟迟无法商业化，分心去搞了氢能源；</p>
  <p>而在固态电池的“老家”美国，电动车霸主特斯拉甚至表现得有点“漫不经心”。马斯克目前依然在全力死磕以4680&nbsp;电池为核心的圆柱液态锂电池体系 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_fb3b92656dc94301b91a05df60ca5eb7@5091053_oswg75791oswg600oswg445_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>特斯拉之所以这么淡定，是因为特斯拉的圆柱电池已经证明了液态电池的潜力还未挖尽：</p>
  <p><strong>它极高的可靠度、极少的自燃事故，以及没人不夸赞的扎实续航，都在证明，如果液态电池已经足够好用且便宜，市场为何要急着为昂贵的固态电池买单？</strong></p>
  <p>中国科学院院士欧阳明高曾给出一个非常理性的预测：就算全固态电池能在&nbsp;2027&nbsp;年开始装车，但想要占据市场&nbsp;1%&nbsp;的份额，至少还需要&nbsp;5&nbsp;到&nbsp;10年的渗透期 。</p>
  <p>换句话说，哪怕到了&nbsp;2032&nbsp;年，街上跑的&nbsp;100&nbsp;辆新能源车里，可能只有&nbsp;1&nbsp;辆是全固态电池。</p>
  <p>所以，回到最初的问题：“什么时候能迎来固态电池？”</p>
  <p>日本这边，丰田虽然喊出了 “<strong>2027 年量产的口号</strong>”，但最近也不得不改口低头，承认初期的产量“<strong>仅够装备几千辆车</strong>”；</p>
  <p>至于美国，相关公司的计划是<strong>2026-2028年小批量装车</strong>、能源部目标是<strong>2028-2030年大规模量产。</strong></p>
  <p><strong>再有中国这边，别看卫蓝新能源</strong>2026&nbsp;年就能上市，但最乐观的预测，依然在<strong>2030&nbsp;年之后</strong>。</p>
  <p>那辆续航超长、车身超轻、永远不会起火的完美新能源车，目前可能连轮子都没造出来呢。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/5aj8lg5fN-Uy76f45VCE1A" rel="noopener noreferrer nofollow" target="_blank">“蓝字计划”</a>，作者：Hayward，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602182456526081</id>
            <title>AI眼镜：我们准备好让AI“看”世界了吗？</title>
            <link>https://www.36kr.com/p/3602182456526081</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602182456526081</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 08:39:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年，AI眼镜成了科技圈的“显学”。</p>
  <p>Meta的Ray-Ban智能眼镜在2025年2月销量突破200万副，全年预计冲刺出货量400-500&nbsp;万副；海外巨头谷歌携手三星重启AI眼镜项目，苹果敲定AI眼镜发布时间表。</p>
  <p>国内企业也闻风而动。华为、小米、阿里、字节等国内大厂纷纷高调亮出相关布局，其中阿里夸克的AI眼镜S1目前在天猫旗舰店的预售期达到了45天，一“镜”难求；国内AR独角兽企业Rokid（乐奇）、雷鸟创新等专业玩家也在持续迭代AI眼镜新品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_31d8e80a42814a2995c85f6f1efde139@5091053_oswg227003oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI眼镜催化时间线，图/东吴证券</p>
  <p><strong>表面看，这是一场由大模型技术驱动的新硬件浪潮，但大厂无一例外地都选择了押注AI眼镜，各怀心事。</strong></p>
  <p>人工智能竞赛中，不进则退。此前，在大厂尚未将AI大模型列为战略重心的窗口期，部分创业公司率先突围，譬如月之暗面推出的Kimi就凭借长文本等差异化优势，迅速俘获了海量用户。</p>
  <p>即便是腾讯这样的科技巨头，也曾在赛道初期出现战略误判，对&nbsp;To C&nbsp;端大模型布局相对保守，旗下产品元宝的面市滞后于同业。</p>
  <p>大模型竞赛中曾“吃亏”的公司，绝不愿在下一代终端入口上再次掉队，硬件成为争夺用户注意力和数据闭环的新一道防线。</p>
  <p>而当前被寄予厚望的，正是AI眼镜，直接原因是Meta的Ray-Ban智能眼镜提供了一个难得的成功样本。起售价约300美元的Ray-Ban突破百万销量，足以验证“AI&nbsp;能力通过眼镜形态落地”的可行性。</p>
  <p><strong>不做AI眼镜，就意味着把未来的人机交互入口拱手让人。如此看来，大厂们确实“不得不做”AI眼镜，但问题随之而来：</strong></p>
  <p>作为服务提供方，大厂们是否已具备足够的技术成熟度与产品责任感，让AI真正“理解所见”，而非“记录所见”？</p>
  <p>作为服务接受方，我们又是否准备好交出“看与被看”的权利边界？</p>
  <h2><strong>01</strong></h2>
  <h2><strong>谁有机会跑出来？</strong></h2>
  <p>在弗若斯特沙利文的行业报告中，AI智能眼镜按照功能特性不同被分为AI音频眼镜、AI拍摄眼镜和AI+AR眼镜三类。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9dc26261faaa4d2fad3b127827502681@5091053_oswg296576oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/弗若斯特沙利文</p>
  <p>AI+AR眼镜被视为前两类产品的进阶形态——它在语音交互、影像捕捉能力基础上，进一步融合了AR光学显示技术，从而实现语音、触控、视觉识别与空间叠加信息等多模态交互方式的深度融合。</p>
  <p><strong>当前市面上的AI眼镜品类繁多，定价跨度极大，从数百元到数千元不等，主要的原因也正是在于产品形态的差异化定位。而在这场混战中，并非所有玩家都站在同一起跑线。目前国内可清晰划分为以下五类竞争者：</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_82c839fcd64e4c87bc866ed61da5dab1@5091053_oswg197376oswg1080oswg534_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">注：XR（扩展现实）= VR（虚拟现实）+ AR（增强现实）+ MR（混合现实）</p>
  <p>首先是我们最熟悉的几家互联网科技大厂，阿里、百度以及字节，他们基本保持在国内大模型排行前三到前五的水平，且各家都有各自的生态护城河。阿里有电商和支付，百度有地图，字节有庞大的内容生态矩阵，能通过生态协同的方式让设备从工具升级为生活服务入口。</p>
  <p>以小米为代表的硬件生态厂商，正凭借供应链与渠道优势快速抢占市场。小米AI眼镜优惠后一度低至1630元，背后是成熟的供应链管控能力支撑；而庞大的线下门店与手机用户基础，让其产品能快速触达大众群体。</p>
  <p><strong>更重要的是，AI眼镜与手机、手表的跨设备协同，形成了独特的生态壁垒。根据&nbsp;Wellsenn XR&nbsp;数据，预计AI&nbsp;智能眼镜会达到700万副销量，其中Meta实现500万副销量，而今年6月底才发布的小米AI眼镜有望占据20万副销量。</strong></p>
  <p>造车新势力的入局则开辟了差异化赛道。12月3日，理想AI眼镜Livis正式发布，售价1999元起，国补后1699元起。理想将AI眼镜与车载系统深度绑定，覆盖车主的驾驶场景需求。这种“场景专属”的策略，让其避开了消费级市场的激烈竞争，但也导致受众范围狭窄。</p>
  <p>AI眼镜四小龙是技术派的代表。雷鸟创新、Rokid、XReal、影目科技等玩家深耕光学显示技术多年，雷鸟V3的高亮度屏幕、XReal&nbsp;的轻量化设计，都达到行业顶尖水平。更重要的是，它们已有在工业巡检、文旅导览等专业场景的落地经验。</p>
  <p><strong>但生态建设的薄弱成为其最大制约，如何从B端专业市场向C端消费市场渗透，是其必须解决的课题。Rokid&nbsp;选择了一条差异化路径，更加聚焦高价值垂直场景。</strong></p>
  <p>在跨国会议中，Rokid&nbsp;眼镜可实时翻译对话并投射字幕；在工厂巡检中，工人可通过语音调取设备参数、拍照上传故障；在演讲场景，提词内容可直接显示在镜片上，旁人不可见。这些场景中，AI&nbsp;眼镜解决了真实痛点——解放双手、提升效率、保障安全。</p>
  <p>AI硬件创业公司则靠灵活创新寻找生机，它们避开大厂的生态壁垒，瞄准细分场景发力。比如李未可科技首推“AI数字人”随身助理功能，去年销量突破10万台，成为消费级市场的黑马。</p>
  <p>那么目前来看，谁跑在了前面？</p>
  <p>根据CINNO Research数据，2025年7-9月，中国消费级AR市场中，雷鸟凭借其Air系列的稳健销量和X3 Pro在高端市场的持续创新，保持了市场第一的领先地位。</p>
  <p><strong>市场格局瞬息万变，大厂凭借生态优势紧追不舍。到了今年“双十一”期间，淘宝智能眼镜销售Top3分别为阿里夸克S1、Rokid Glasses以及小米AI眼镜。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6a6f3698596648f6964b683b4fb30e9d@5091053_oswg174541oswg1080oswg556_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02</strong></h2>
  <h2><strong>大厂的“必做题”，用户的“选做题”</strong></h2>
  <p><strong>热潮之下，一个问题被有意无意地忽略了：普通用户真的需要一副AI眼镜替他“看”世界吗？</strong></p>
  <p>过去十年，无数智能硬件倒在了“伪需求”上——智能手环曾号称要取代手机，结果沦为计步器；智能手表功能强大，但多数人只是将其作为腕表装饰；AR&nbsp;眼镜喊了多年“改变世界”，依然困在工业等垂直场景。AI&nbsp;眼镜若不能回答“比手机好在哪”，就难逃重蹈覆辙的命运。</p>
  <p>目前市面上的&nbsp;AI&nbsp;眼镜，核心功能大致包括：语音助手、实时翻译、拍照识别、导航提示、会议记录等。乍看丰富，实则多数功能在手机上早已实现。</p>
  <p>更关键的是，这些功能往往需要联网且依赖云端大模型，一旦信号不佳，设备立刻“失能”。用户体验的另一个硬伤是交互不自然。理想中的AI眼镜应“无感融入生活”，但现实是用户仍需频繁说“Hey，AI”，手动点击触控条或通过手机App设置。</p>
  <p><strong>此外，隐私问题如影随形。一副随时可录音录像的眼镜，意味着用户既是使用者，也可能成为他人隐私的侵犯者。</strong></p>
  <p>其实早在十年前，谷歌推出的Google Glass就因为偷拍问题遗憾离场。而Meta的解决方法是在眼镜上嵌入LED指示灯，以提醒周围的人“你正在被拍摄”。但这样的做法似乎仍不足够，很快就有私人工程师在网上“传授”改装遮挡指示灯的经验，甚至承接改装服务。</p>
  <p>尽管Meta回应此类行为违反用户协议，并在新批次产品中将LED从1mm升级至2mm，由闪烁改为常亮模式，甚至加入硬件级篡改检测，但也无法阻止已经流入市场的旧款眼镜继续被改装。</p>
  <p>2024年10月，哈佛大学学生AnhPhu Nguyen与&nbsp;Caine Ardayfio上传了一段视频：《我们准备好面对个人信息一目了然的世界了吗？》</p>
  <p>他们在Meta Ray-Ban&nbsp;眼镜上接入人脸识别与数据聚合系统，实现的功能是，只需在街头与陌生人对视一眼，对方的姓名、年龄、电话、住址，甚至其家人的信息，便实时出现在手机屏幕上。</p>
  <p><strong>对用户自身而言，AI&nbsp;眼镜时刻处于“在线感知”状态，家门内的私人场景、与家人的私密对话、手机屏幕上的金融信息，都可能被设备无意识捕捉并同步至云端。</strong></p>
  <p>这些数据既是训练&nbsp;AI&nbsp;算法的“原料”，也可能因账号泄露、系统漏洞成为被窃取的目标，让个人隐私在“便捷”的名义下无处遁形。</p>
  <p>因此，AI&nbsp;眼镜当前更多是科技爱好者的尝鲜物件，离大众“刚需品”还有相当距离。</p>
  <p><strong>从“尝鲜品”到“刚需品”的跃迁，需要找到并深耕真正的刚性场景，也即用户在某种情境下如果没有这个设备，就会明显感到效率下降、安全风险增加或体验变差。</strong></p>
  <p>现阶段，AI&nbsp;眼镜在一些&nbsp;B&nbsp;端作业中已经接近这种状态，例如电力行业的运行巡视、点检维修、监造维护；油气行业的远程验收、设备巡检；医疗行业的院前急救、远程会诊等。这些场景中，AI眼镜解决的不是“便利”问题，而是安全、准确、效率的核心痛点，具备天然刚需属性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_050d7d13baf846d99da7943bed0108eb@5091053_oswg668395oswg1052oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/Rokid官网</p>
  <p>在C端，目前多数功能都有成熟的替代方案——手机、耳机、手表都能完成。因此，C端刚需的探索必须瞄准那些手机等设备无法解放双手或无法提供第一视角叠加的场景，比如骑行导航、厨房烹饪、残障辅助等。</p>
  <p>其次，体验最好做到“无感融入”，才能在日常使用中建立依赖。用户对可穿戴设备的耐心有限，如果佩戴不适、操作繁琐、续航焦虑，很容易转头就在闲鱼抛售了。</p>
  <p>再次，融入更广阔的“生态协同网络”是AI眼镜使用价值放大的关键。用户购买的将不仅仅是一副眼镜，而是一套完整的、跨场景的智能生活解决方案。</p>
  <p><strong>当然，提供高度“个性化”的主动服务是终极目标。刚需的最高境界，是让用户在开口之前，设备就已经“懂你所想，供你所需”。</strong>这依赖于数据驱动下的个性化与主动智能。一个初级的AI眼镜，需要你下达指令；而一个成熟的AI眼镜，应该能通过你的眼动追踪、行为习惯和环境感知，来预测你的需求。</p>
  <p>设备不再是冰冷的工具，而是一个有观察力、有预判力的“私人助理”。这条路径注定漫长且充满试错，但一旦某个细分领域的刚需被牢牢抓住，就可能像当年的智能手机一样，从一个小众潮品演化为全民标配。</p>
  <p>对于厂商而言，现阶段最务实的策略或许是在&nbsp;B&nbsp;端验证价值、打磨体验，同时在&nbsp;C&nbsp;端培育种子用户与场景，等待技术与成本的拐点到来，把“可能刚需”变成“现实刚需”。</p>
  <h2><strong>03</strong></h2>
  <h2><strong>不止眼镜，大厂要抢所有可能的AI入口</strong></h2>
  <p>所以，回到最初的问题：我们真的准备好“让AI看世界”了吗？</p>
  <p>答案或许是否定的——至少现在还没有，但大厂的野心远不止于AI眼镜这一个载体。</p>
  <p><strong>从智能汽车到智能家居，从可穿戴设备到嵌入式终端，本质上都是在争夺AI时代的入口话语权。谁能成为用户最依赖的“数字伙伴”，谁就能掌握数据与服务的核心流量，这也是互联网平台、硬件厂商、专业玩家纷纷入局的根本原因。</strong></p>
  <p>回望历史，每一波“下一代终端”的预言都伴随着狂热与幻灭。平板电脑要取代笔记本电脑，智能手表要取代手机，元宇宙要重构互联网——结果大多止步于细分市场。</p>
  <p>在可预见的未来，AI眼镜更可能作为特定人群的效率工具或AI服务的补充入口存在，但这并不妨碍它撬动千亿元级市场空间。</p>
  <p>AI眼镜的爆发带动了显示技术、光学器件、音频模组、能源供应、AI算法等多个细分赛道的增量。</p>
  <p>光学显示模组里，代表公司至格科技在半年内连续完成两轮超亿元融资，其也是夸克AI眼镜的主要生产商之一。在MicroLED&nbsp;微显示领域，上海显耀显示科技完成超10亿元B2轮融资，刷新了该领域的单笔融资纪录。</p>
  <p>根据行业公开信息，截至今年12月，国内市场中AI眼镜上下游产业链共计超30起融资事件，资金总额接近40亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_099b096aeed248c0acc801199a3c8269@5091053_oswg294154oswg1080oswg508_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/艾瑞咨询</p>
  <p>从另一个角度看，AI眼镜更像是通往终极终端路上的一个技术驿站，它承担了探索多模态交互、验证AI服务订阅模式、积累用户行为数据等过渡性任务。</p>
  <p>除此之外，AI眼镜的核心意义，在于探索一种新的人机关系：AI不再是被动响应的工具，而是主动感知环境、理解意图、适时介入的“数字人”。</p>
  <p><strong>当AI眼镜逐步解决隐私安全、交互体验、场景刚需的核心痛点，当技术让设备真正实现“无感融入”，当生态让服务形成“无缝衔接”，或许我们才能回答——是的，我们已经准备好让AI“看”世界了。</strong></p>
  <p>而继AI眼镜的下一代入口，应是无感、无形态、全场景的——比如可植入皮下的生物芯片、非侵入式脑机接口……任何曾经存在于科幻片的想象皆有可能。这些载体不再需要“佩戴”，而是直接融入人体，实现真正的“人机共生”。</p>
  <p>2025年已行至尾声，随着更多企业入场角逐，2026年会涌现出更多形态各异的AI眼镜产品。在这场“百镜大战”&nbsp;的当下，我们不妨祝福并期待这些探索者的突破。</p>
  <p>毕竟，只有敢于在技术无人区中踏浪而行，才能真正抵达那个“AI无处不在，却又无迹可寻”的未来。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4O1e_KbJui9JBvHv9Pci2A" rel="noopener noreferrer nofollow" target="_blank">“听潮TI”</a>，作者：罗夏，编辑：张晓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602173033792516</id>
            <title>算力即收入？奥特曼亲口承认：9亿用户难敌谷歌“致命一击”，1.4 万亿美元砸向算力，“GPT-6”或明年 Q1 亮相</title>
            <link>https://www.36kr.com/p/3602173033792516</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602173033792516</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 08:35:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼最近一次对外露面时，罕见地把话说得很直：“谷歌依然是最大的威胁之一，他们太强了。坦白讲，如果他们在 2023 年就认真出手，我们当时可能会非常难受；在我看来，他们本来就有能力把我们直接击碎。”</p>
  <p>而就在不久前，谈到 Gemini 3 的冲击时，他还表示：“它对我们指标的影响，并没有我们担心的那么大。”</p>
  <p>不过，奥特曼的愿景并不是在谷歌最擅长的领域与之正面竞争。谷歌的路线更像是把 AI 塞进现有的一切：搜索、Gmail、地图、YouTube……几乎每一个入口都在“加一层 AI”。奥特曼则认为，生成式 AI 终将改变我们使用软件的方式，关键不在于给旧软件打补丁，而在于重做一套“AI 原生软件”。</p>
  <p>在这套逻辑里，他最在意的不是“把 AI 接到多少产品上”，而是先把用户留住，并让他们形成依赖：先让用户进门，向他们展示能力边界，再通过记忆、个性化和深度定制把“粘性”一点点加固。</p>
  <p>他用“牙膏品牌”打了个比方：“从某种意义上说，AI 就像牙膏。大多数人一旦选定一个品牌，就会一直用下去；每次去超市都顺手拿同一个，根本不会多想。”而 ChatGPT 已经拥有 8 亿、甚至可能逼近 9 亿的用户；一些独立报告也显示，它在用户使用时长等指标上仍处于领先位置。</p>
  <p>除了“红色警报”和谷歌威胁，这次访谈还抛出了几颗更“刺”的钉子：所谓的<strong>GPT-6 不急着来，下一步反而更像“按人定制”的升级，大约会在明年 Q1 亮相</strong>；OpenAI 口中的“云”，<strong>不是要去当第二个 AWS</strong>，而是想把企业买 token、跑 agent、托管数据的需求打包成一套“AI 平台”。这些判断拼在一起，构成了 OpenAI 对模型、产品、基础设施和商业化路径的一次系统性表态。</p>
  <p><strong>本文翻译整理自 Alex Kantrowitz 主持的一期播客节目。</strong></p>
  <h2><strong>1</strong></h2>
  <h2><strong>如果谷歌认真过：OpenAI 早就被碾碎了</strong></h2>
  <p>Alex Kantrowitz：OpenAI 已经成立 10 年了，ChatGPT 才三岁，但竞争已经在明显加剧。最近这段时间，外界的感觉是 OpenAI 总部处于一种“红色警报”状态。Gemini 3 发布之后，你放眼望去，到处都是试图削弱 OpenAI 优势的公司。而这是我第一次感觉到，这家公司似乎不再拥有一个非常明确的领先优势。所以我很好奇，你怎么看 OpenAI 会如何走出当下这个阶段？</p>
  <p><strong>Sam Altman：</strong>先说“红色警报”这件事吧。我们把这类情况视为相对低风险、但需要经常启动的状态。我认为，在潜在竞争威胁出现时，保持一点偏执、迅速行动，其实是件好事。过去我们也遇到过类似情况，比如今年早些时候 DeepSeek 出现的时候，当时也启动过一次“红色警报”。我觉得保持一点警惕是好的。</p>
  <p>Gemini 3 至少到目前为止，并没有产生我们原先担心的那种影响。但它确实像 DeepSeek 一样，暴露了我们在产品和策略上的一些薄弱点，而这些问题我们正在非常快速地解决。我不认为我们还会在“红色警报”状态下停留太久。历史上看，这种状态通常持续六到八周。能启动它我反而感到高兴。</p>
  <p>就在今天，我们刚刚发布了一个新的图像模型，这是一个非常棒的进展，也是消费者一直非常想要的东西。上周我们发布了 5.2 版本，反馈极其积极，增长速度也非常快。接下来我们还会发布一些其他新东西，同时也会持续做一些改进，比如提升服务速度。</p>
  <p>我的判断是，未来很长一段时间里，我们可能每年会启动一次，最多两次类似的“红色警报”。这本质上就是确保我们在这个领域里能够持续取胜的一部分。当然，也会有很多其他公司做得很好，我也为他们感到高兴。但 ChatGPT 依然是市场上遥遥领先的聊天机器人，而且我预期这种领先优势会随时间扩大，而不是缩小。</p>
  <p>模型本身在各个地方都会变得越来越好，但无论是对消费者还是企业用户来说，大家选择一个产品的原因，远不止模型能力本身。我们其实已经预料到会出现今天这样的竞争局面，所以一直在努力打造一个完整、连贯的产品体系，确保我们成为人们最想使用的那个产品。</p>
  <p>我认为竞争是好事，它会推动我们变得更好。我相信我们在聊天产品上会做得很好，在企业市场也会做得很好。未来几年里，我也期待我们在其他全新的产品类别中同样能表现出色。</p>
  <p>我觉得人们其实非常希望只使用一个 AI 平台。就像在个人生活中，你用的是一部手机，大多数时候你也希望在工作中用同样的那一部。我们正在 AI 上看到同样的趋势。ChatGPT 在消费者市场的强势，正在非常明显地帮助我们赢得企业市场。当然，企业需要不同的功能，但人们会想：“我知道 OpenAI，我也知道怎么用 ChatGPT 这个界面。”</p>
  <p>所以我们的策略很简单：打造最好的模型，在此基础上构建最好的产品，并且拥有足够的基础设施去支撑大规模服务。</p>
  <p>Alex Kantrowitz：确实存在一种“先发优势”。今年早些时候，ChatGPT 的周活跃用户大概在 4 亿左右，现在已经到了 8 亿，报道中甚至说接近 9 亿。但另一方面，像 Google 这样的公司也拥有巨大的分发优势。所以我很好奇你的看法：如果模型最终趋同，那么真正重要的会是什么？是分发能力？是应用构建能力？还是我还没有想到的其他因素？</p>
  <p><strong>Sam Altman：</strong>我并不觉得“商品化”是一个恰当的框架来理解模型。未来一定会存在这样的情况：不同模型在不同领域各有专长。对于日常聊天这样的普通用例，可能会有很多非常不错的选择；但在科学发现等领域，你会希望使用那种真正站在前沿、为科学深度优化的模型。</p>
  <p>因此，模型会有不同的优势。我认为，最大的经济价值，仍然会由处在前沿的模型创造，而我们计划始终领先于那个前沿。我们也非常自豪地认为，5.2 是目前世界上最强的推理模型，是科学家取得最多进展的模型。同时，我们也为企业客户的反馈感到骄傲——他们认为这是完成企业各类任务时表现最好的模型。</p>
  <p>当然，会有我们在某些领域领先、在另一些领域稍微落后的时候。但整体上来看，我认为“最智能的模型”即便在一个免费模型可以满足大量基础需求的世界里，依然会拥有巨大的价值。</p>
  <p>产品本身非常重要，分发和品牌也非常重要。以 ChatGPT 为例，个性化是一个极具粘性的因素。人们非常喜欢模型随着时间推移逐渐“了解自己”，你们会看到我们在这方面持续加码。用户和这些模型之间，会产生一些非常深刻的体验，并且会将这些体验与产品本身强烈地绑定在一起。</p>
  <p>我记得曾经有人跟我说，人这一辈子大概只会选一次牙膏，然后就一直用下去——至少大多数人是这样。ChatGPT 也是类似的情况。人们会有一次“魔法时刻”。医疗健康是一个很典型的例子：有人把血检结果或者症状输入 ChatGPT，然后发现了问题，去看医生后真的被治好了。对这些用户来说，粘性是极高的，更不用说再叠加上个性化能力。</p>
  <p>产品层面还有很多事情。我们最近刚发布了浏览器，我认为这为我们指向了一种新的、非常有潜力的形态。设备还要更晚一些，但我对此非常期待。</p>
  <p>在企业市场，竞争优势的构成方式可能会有所不同，但逻辑是相似的。就像个性化对个人用户非常重要一样，对企业来说，也会存在一种“企业级个性化”：一家公司会与我们这样的公司建立长期关系，把自己的数据接入进来，然后运行来自不同厂商的各种 agent，确保信息被以正确的方式处理。我预计这同样会非常有粘性。</p>
  <p>很多人仍然把我们主要看作一家消费者公司，但实际上我们已经拥有超过一百万的企业用户，而且我们会在企业市场上持续深耕。API 的采用速度也极其迅猛，今年 API 业务的增长速度甚至超过了 ChatGPT 本身。所以企业这块，从今年开始，真的在发生。</p>
  <p>Alex Kantrowitz：我想再回到刚才那个问题：如果不是“商品化”，而是说在日常使用层面上，模型对普通用户来说感觉差不多。那么当 ChatGPT 和 Gemini 在日常体验上趋同时，Google 那种巨大的分发优势会构成多大的威胁？毕竟 Google 可以通过无数入口推送 Gemini，而 ChatGPT 需要为每一个新用户而战。</p>
  <p><strong>Sam Altman：</strong>我认为 Google 依然是一个巨大的威胁，它是一家极其强大的公司。如果 Google 在 2023 年真的认真对待我们，我们当时可能会处在一个非常糟糕的境地，他们是有能力彻底压制我们的。</p>
  <p>但那时他们在 AI 上的产品方向并不完全正确。他们也启动过自己的“红色警报”，但并没有真正重视。现在大家都在搞“红色警报”。</p>
  <p>另外，Google 拥有整个科技行业里可能是最好的商业模式之一，我认为他们会非常谨慎，不愿轻易放弃这一点。我可能也会看走眼，但我并不认为把 AI 简单“加”进搜索框里，会像彻底重新构想一种 AI 优先的产品那样成功。</p>
  <p>这其实是一个更广泛的趋势：把 AI 嵌进旧有模式里，效果通常不如从一开始就围绕 AI 重新设计。这也是我们为什么想做消费者设备的原因之一，这个逻辑在很多层面上都成立。</p>
  <p>如果你把 AI 加进一个即时通讯应用，让它帮你总结消息、草拟回复，那确实是好了一点，但那并不是终极形态。真正的终局应该是：一个足够聪明的 AI，作为你的 agent，去和其他人的 agent 交流，判断什么时候该打扰你、什么时候不该打扰你，哪些决策它可以自行处理，哪些必须来问你。搜索、办公套件也是同样的道理。</p>
  <p>我怀疑这一切会比我们想象中花更长时间，但我相信，在主要产品类别中，我们最终会看到完全围绕 AI 构建的新产品，而不是在旧产品上“打补丁”。这恰恰可能是 Google 的一个弱点，尽管它拥有巨大的分发优势。</p>
  <h2><strong>2</strong></h2>
  <h2><strong>聊天框赢了三年，但真正的战争在“界面重构”</strong></h2>
  <p>Alex Kantrowitz：我和很多人讨论过这个问题。ChatGPT 刚发布时，我记得 Ben Thompson 说过，你可能并不应该把 AI 塞进 Excel，而是应该重新想象你是如何使用 Excel 的。比如，你上传数据，然后直接“和数据对话”。后来大家在实际开发中发现，这背后还是需要一个后端系统。那么问题就变成了：你是不是先构建一个新的后端系统，再通过 AI 去交互？如果是这样，为什么不能直接叠加在现有系统上？</p>
  <p><strong>Sam Altman：</strong>你当然可以叠加，但我每天花大量时间在各种消息应用里：邮件、短信、Slack……我觉得这本身就是一个错误的界面。你可以在上面加 AI，让它稍微好一点，但我更希望的是，早上我可以直接对 AI 说：今天我想完成哪些事情，我在担心什么，我在思考什么，我希望发生什么。我不想一整天都在给人发消息，我不想让你总结它们，我也不想看一堆草稿。能处理的事情你就自己处理。你了解我，了解这些人，也知道我想达成什么目标。每隔几个小时，如果有必要，再批量给我更新。这和现在这些应用的工作流是完全不同的。</p>
  <p>Alex Kantrowitz：我原本想问你 ChatGPT 在未来一年、两年里会变成什么样子。说实话，我原本以为，到现在这个阶段，ChatGPT 的形态应该已经发生更大的变化了。你当时预期是什么样的？</p>
  <p><strong>Sam Altman：</strong>我也说不上来。我只是觉得这个聊天界面不会走这么远。最早它只是作为一个研究预览被放出来，根本没打算成为一个产品。虽然现在看起来好看了一些，但整体上和最初差别不大。我们知道文本聊天界面很好用，人们已经习惯了像给朋友发消息一样交流。但我原以为，如果它真的会成为一个如此庞大、被用于如此多真实工作的产品，那这个界面本身应该会演进得更多一些。</p>
  <p>我现在依然认为它应该继续进化。但我低估了这种“通用性”界面的力量。我认为未来 AI 应该能够为不同任务生成不同的界面。如果你在处理数据，它就应该用合适的方式展示数据，并让你以不同方式交互。我们现在在 Canvas 等功能里已经看到了一点苗头，但还远远不够。它应该更具交互性，而不是简单的来回对话。你围绕一个对象持续思考，它就应该持续更新。</p>
  <p>它也应该随着时间变得更加主动，理解你当天想完成什么，在后台持续为你工作，并给你更新。今年让我最兴奋的事情之一就是 Codex 真的变得非常好，这其实也指向了我心中未来产品形态的一部分。</p>
  <p>老实说，这件事让我感到惊讶。说“尴尬”不太准确，毕竟它已经极其成功了。但 ChatGPT 在过去三年里，界面变化之小，确实出乎我的意料。</p>
  <p>Alex Kantrowitz：但界面确实好用。不过，底层变化很大。你刚才也提到了个性化和记忆，这也是我最喜欢的功能之一。记忆功能真的改变了体验。我最近几周一直在和 ChatGPT 讨论一次即将到来的旅行，涉及很多规划内容。即便我新开一个窗口，只说一句“我们继续聊这次旅行吧”，它就能马上接上，知道我和谁一起去、要做什么、甚至知道我在为这次旅行做健身计划，并能把所有这些信息综合起来。记忆能力究竟能强到什么程度？</p>
  <p><strong>Sam Altman：</strong>我觉得我们现在根本还没有概念。人类哪怕拥有世界上最好的私人助理，也不可能记住你一生中说过的每一句话，不可能读过你所有的邮件、所有写过的文档，不可能每天关注你所有的工作细节。人类没有无限、完美的记忆。</p>
  <p>而 AI 是可以做到这一点的。我们内部经常讨论这个问题。现在的“记忆”还非常原始，非常早期，大概还处在 GPT-2 时代的水平。但当它真的能够记住你一生中的每一个细节，并在此基础上进行深度个性化，不只是事实，还包括那些你自己都未必意识到的小偏好——AI 却能捕捉到——那将会极其强大。这也许不是 2026 年就能实现的事情，但这是我最兴奋的方向之一。</p>
  <p>Alex Kantrowitz：我之前和一位神经科学家聊过，他说你在大脑里找不到“思想”的存储位置，而计算机是有存储位置的，可以把一切都存下来。当这些机器人开始保存我们的思想时，当然会带来隐私问题。但还有一点也很有意思：人们会和它们建立真正的关系。这是整个时代中被低估的一点。很多人已经开始感觉这些机器人像是陪伴者，在为他们着想。你怎么看这种亲密感、陪伴感？有没有一个“旋钮”，可以决定人和 AI 的距离？如果有，你们如何去调节它？</p>
  <p><strong>Sam Altman：</strong>实际上，想要那种“亲密陪伴”的人，比我原先以为的要多得多。我不知道该用什么词来形容——“关系”不太对，“陪伴”也不太准确，但他们确实想和 AI 建立一种深度连接。而且在目前模型能力水平下，想要这种关系的人已经比我预期的多很多。</p>
  <p>年初的时候，说自己想要这种体验还被认为是很奇怪的事。现在可能很多人依然不会明说，但从行为上能看出来：人们希望 AI 了解他们、对他们温暖、支持他们。这对很多人来说是有价值的，甚至包括一些口头上说自己并不在乎的人。</p>
  <p>我认为其中有些形态是非常健康的，也认为成年用户应该拥有很大的选择空间，决定自己在这个光谱上的位置。当然，也有一些形态在我看来是不健康的，但肯定仍然会有人选择它。同时，也有一部分人只想要最干燥、最高效的工具。</p>
  <p>我猜测，就像很多其他技术一样，我们会不断试验，发现一些之前不知道的好处和问题。社会最终会慢慢形成共识：哪些地方应该如何设定那个“旋钮”。而个人则会拥有非常大的自由，把它调到完全不同的位置。</p>
  <p>Alex Kantrowitz：所以你的想法是，让用户自己来决定？</p>
  <p><strong>Sam Altman：</strong>是的，绝对如此。但我们并不清楚它究竟应该走多远，也不清楚我们应该允许它走多远。我们会给予用户相当大的个人自由。当然，也确实有一些事情是其他服务可能会提供，但我们不会去做的。</p>
  <p>嗯，比如说，我们不会——我们不会让“RAI”（负责任 AI）去做那种事：比如试图说服人们应该和它建立一种<strong>排他性的恋爱关系</strong>之类的。我们得把它保持在一个开放的状态。</p>
  <p>不过我相信，其他一些服务里肯定会发生这种事情。</p>
  <p>Alex Kantrowitz：对，因为越“粘”，那项服务就越赚钱。这些可能性你一旦认真往深里想，就会觉得有点吓人。</p>
  <p><strong>Sam Altman：</strong>完全同意。这确实是那种……我个人会觉得——你能看见它走向“严重翻车”的路径。</p>
  <h2><strong>3</strong></h2>
  <h2><strong>消费者赢了，企业就容易了：ChatGPT 的反向 B2B 路径</strong></h2>
  <p>Alex Kantrowitz：你刚才提到了企业业务，我们聊聊 Enterprise。上周你在纽约跟一些新闻公司的编辑和 CEO 吃午饭时说，企业业务会是 OpenAI 明年的一个重大优先事项。我想听你展开讲讲：为什么这会成为优先级？你觉得你们和 Anthropic 相比处在什么位置？很多人会说这像是 OpenAI 的一次转向，因为你们一直更偏消费者业务。请你整体概述一下你们的企业计划。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0f8847f3863c49088c226c4842abdc68@000000_oswg19226oswg312oswg333_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Sam Altman：</strong>我们的策略一直是<strong>消费者优先</strong>。主要有几个原因。第一，过去模型还不够稳健、也不够“熟练”，无法满足大多数企业场景的需求；但现在它们正在变得足够好。第二，我们当时在消费者市场看到一个非常清晰的胜利机会，而这种机会既罕见又难得。我认为，如果你在消费者市场赢了，会让你在企业市场的胜利变得容易得多——我们现在就正在看到这一点。</p>
  <p>但正如我前面提到的，今年企业增长已经超过了消费者增长。考虑到模型目前所处的位置、以及它们明年会到达的水平，我们认为<strong>现在就是我们能非常快地做出一个规模可观的企业业务的时间点</strong>。我们现在已经有企业业务了，但它还能增长得更多。</p>
  <p>企业看起来已经准备好了，技术也看起来已经准备好了。</p>
  <p>迄今为止最典型的例子当然是编码，但还有其他方向也在快速增长，一些垂直领域现在增长得非常快。我们开始听到越来越多企业说：“我其实就想要一个 AI 平台。”</p>
  <p>Alex Kantrowitz：是哪一个垂直领域？</p>
  <p><strong>Sam Altman：</strong>嗯，<strong>金融科学（finance science）是我个人眼下对所有进展里最兴奋</strong>的一个方向。客户支持做得也很不错。但不过说到这个，我们还有一个叫<strong>GDP</strong>的东西。</p>
  <p>Alex Kantrowitz：我正想问你这个。我能把关于它的问题直接抛出来吗？好。我给 Box 的 CEO Aaron Levie 发了消息，我说我要见 Sam，我该问什么？他回复说：问问 GDP eval。</p>
  <p>所以，这是一个衡量 AI 在知识工作任务中表现的指标。我就去翻了 GPT 5.2 的发布，去看你们最近放出来的那张 GDP-val 图。当然，这是 OpenAI 自己做的评测。即便如此：GPT-5 thinking（也就是夏天发布的那个 thinking 模型），在知识工作任务中，以 38% 的比例“赢过 / 打平 / 接近人类知识工作者”（大概是 38.8%）；而 GPT 5.2 thinking 在知识工作任务上，以 70.9% 的比例赢过或打平；GPT 5.2 pro 则达到 74.1%。并且它还跨过了“专家级”的阈值——看起来它能处理大约 60% 的专家级任务，也就是在知识工作上与专家差不多的水平。这些模型能做这么多知识工作的含义是什么？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_c016ad0e8b5e40c6991d9ebb1d8d3f8a@000000_oswg17746oswg363oswg463_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Sam Altman：</strong>你刚才问“垂直领域”其实是个很好的问题，但我刚才之所以有点卡壳，是因为这个评测其实覆盖了我觉得大概四十多个不同的“业务垂直任务”：做一份 PowerPoint、做法律分析、写一个小 Web 应用等等。这个评测本质上是在问：<strong>对于企业必须做的许多任务，专家是否更喜欢模型输出，相对于其他专家的输出</strong>。</p>
  <p>当然，这些都是小任务、范围明确的任务，它不包括那种复杂、开放式、创造性的工作，比如“想出一个新产品”；也不包括很多团队协作型的事情。但即便如此——如果你能把一个小时的任务交给一个“同事”，它给你返回的结果在 74% 或 70% 的情况下你会更满意，而且你还能付更低的成本——这依然非常惊人。</p>
  <p>如果你回到三年前 ChatGPT 刚发布的时候，有人说三年后我们会达到这个水平，大多数人都会说：绝不可能。所以当我们思考企业将如何整合这项能力时，现在早已不只是“它会写代码”了，而是<strong>一整套知识工作任务都可以分发给 AI 去做</strong>。企业要真正摸索出如何把它融入流程，可能需要时间，但它的影响应该会相当巨大。</p>
  <p>Alex Kantrowitz：我知道你不是经济学家，所以我不打算问你“宏观就业的整体影响”之类的问题。但我想读给你一段我在 Substack 上《Blood in the Machine》里看到的话，来自一位技术文案写作者。他说：“聊天机器人进来之后，我的工作变成了管理机器人，而不是管理一支客服代表团队。”这一点我觉得会经常发生。但他接着说：“一旦机器人被训练到能够提供足够好的支持，我就出局了。”这种事情会不会更普遍？这会不会是“坏公司”更常做的事？因为如果一个人能编排许多不同的机器人，你可能会想留下他。我不确定。你怎么看？</p>
  <p><strong>Sam Altman：</strong>我同意你说的：很明显，未来每个人都会在管理很多 AI，让它们做各种不同的事。最终就像任何优秀的管理者一样——希望你的团队会越来越强，而你也会承担更大的范围、更大的责任。我不是那种“就业末日论者”。短期内我确实有些担忧，我认为在一些情况下，转型会很艰难。</p>
  <p>但我们在人类层面上，我们似乎天生就太关注他人、在意他人做什么；我们似乎非常关注相对地位，总想要更多，总想要有用、能服务别人、表达创造力……这些驱动我们走到今天的东西，我不认为会消失。</p>
  <p>当然，我确实认为未来的“工作”（甚至我都不知道还该不该叫“工作”）——到了 2050 年，我们每天在做的事情大概率会和今天非常不一样。但我并不持那种“人生会失去意义、经济会彻底崩塌”的观点。我希望我们反而会找到更多意义；经济结构会显著变化，但我觉得你不能押注“进化生物学会输”。</p>
  <p>我经常想：我们如何把 OpenAI 的所有职能自动化；更进一步，我还会想：<strong>如果 OpenAI 有一个 AI CEO 会怎样？</strong>这并不让我不安，反而让我很兴奋。我不会抗拒。我不想成为那种死死抱着说“我手工做得更好”的人。</p>
  <p>Alex Kantrowitz：让 AI CEO 去做决策，指挥我们把资源投向“给 AI 更多能量和算力”之类的事情——这听起来……你肯定会给它加护栏吧？</p>
  <p><strong>Sam Altman：</strong>当然。你显然不希望一个完全不受人类治理的 AI CEO。但如果你设想一种版本——这个类比可能很疯狂，但我还是说——如果世界上每个人都等效地坐在一家 AI 公司的董事会里，都可以告诉 AI CEO 该做什么，如果它做得不好大家还能把它开掉；也就是说，关键决策都有治理机制，而 AI CEO 负责尽可能执行董事会的意志——那么在未来的人看来，这也许是一个相当合理的系统。</p>
  <h2><strong>4</strong></h2>
  <h2><strong>GPT-6 先别急：下一步更像“定制升级”</strong></h2>
  <p>Alex Kantrowitz：好，我们马上会谈基础设施。但在离开“模型与能力”这一段之前，GPT-6 什么时候来？</p>
  <p><strong>Sam Altman：</strong>我不确定我们会在什么时候把某个模型叫作 GPT-6。但我预计，<strong>在明年第一季度</strong>，我们会发布一些相对于 5.2 有显著提升的新模型。</p>
  <p>Alex Kantrowitz：“显著提升”指什么？</p>
  <p><strong>Sam Altman：</strong>我现在还没法给你一个具体评测分数。总体上会是“面向企业”和“面向消费者”两边都会有提升：消费者侧的模型会有很多改进，但消费者目前最想要的并不是更高的 IQ；企业仍然更想要更高的 IQ。</p>
  <p>所以我们会针对不同用途、用不同方式来提升模型。我们的目标是：做出一个让所有人都明显更喜欢的新模型。</p>
  <h2><strong>5</strong></h2>
  <h2><strong>如果今天有双倍算力，今天就有双倍收入</strong></h2>
  <p>Alex Kantrowitz：说到基础设施：你们有大概 1.4 万亿美元的投入承诺，用来建设基础设施。我听过你很多关于基础设施的表述。比如你说：“如果人们知道我们能用算力做到什么，他们会想要更多、更多。”你说：“我们今天能提供的东西，与 10 倍算力、100 倍算力相比，差距巨大。”你能不能再把它展开一点：你们要用这么多算力做什么？</p>
  <p><strong>Sam Altman：</strong>我前面稍微提过一点。我个人最兴奋的方向，是用 AI 和大量算力去推动<strong>科学发现</strong>。我相信科学发现是让世界对所有人变得更好的“最高位因素”。如果我们能把巨量算力投入科学问题，发现新的知识——现在已经开始有一点点苗头了，当然非常早期、非常小的成果——但我对这个领域的历史经验是：一旦曲线开始出现、开始从 x 轴抬起来一点，我们就知道如何把它做得越来越好。但这需要极大量的算力。</p>
  <p>所以我们正在把很多 AI 用在科学发现、治病，以及很多其他事情上。</p>
  <p>最近一个挺酷的例子是：我们用 Codex 构建了 Sora 的 Android App，他们不到一个月就做完了。他们用了非常大量的 tokens——在 OpenAI 工作的一个好处是，你用 Codex 不会被限额。他们用掉了巨大 token 数，但做出了原本需要更多人、花更久时间才能完成的事情，Codex 基本上帮我们把大部分工作做了。你可以想象这进一步发展后，整个公司都可以用大量算力来构建产品。</p>
  <p>人们也聊了很多：视频模型最终会指向一种“实时生成的用户界面”，那也会需要大量算力。企业要做业务改造，会用掉大量算力。医生如果想提供真正个性化的医疗——持续监测每个病人的各种体征——你也能想象那会消耗大量算力。</p>
  <p>现在要框定我们在全世界生成 AI 输出已经用掉多少算力，其实很难。我接下来要说的数字非常粗糙，而且我也觉得这种说法不够严谨，但我总觉得这种“脑内思想实验”多少有点帮助，所以先原谅我这种粗糙吧。</p>
  <p>假设一家 AI 公司今天，用前沿模型每天输出大概 10 万亿 tokens 的量级。可能更高，但我不认为有人能达到每天 1000 万亿（quadrillion）tokens。假设世界上有 80 亿人，假设平均每个人每天输出的 token 数是 2 万（我觉得这完全不对，但先这么假设）。严格来说，我们还得比较的是模型提供方“输出的 tokens”，而不是“消耗的全部 tokens”。但你可以开始做一个对比：我们可能会看到某家公司每天输出的 tokens，会超过全人类每天合计输出的 tokens，然后再是 10 倍，再是 100 倍。</p>
  <p>某种意义上这是个很傻的比较；但某种意义上，它能给你一个数量级的直觉：地球上“智力运算”的主体，究竟有多少来自人脑、多少来自 AI 脑——以及它们之间有趣的相对增长速度。</p>
  <p>Alex Kantrowitz：所以我在想：你们是否真的知道这种算力需求是存在的？比如，如果 OpenAI 把投入到科学上的算力翻倍，我们就一定会有科学突破吗？或者在医疗上，我们是否明确知道能用它去协助医生？这里面有多少是你们对未来的推测，有多少是基于今天已经看到的明确趋势？</p>
  <p><strong>Sam Altman：</strong>我们基于今天看到的一切判断：这会发生。这并不意味着未来不可能出现某个疯狂变量——比如有人发现一种全新的架构，带来 1 万倍效率提升，那我们可能短期内确实会显得“建得太多”。但就我们现在看到的情况：模型在每个新层级上的进步速度、人们每一次都更想用它、每一次成本下降人们就更想用——这一切都在指向同一件事：需求会持续增加，人们会用它做很棒的事，也会用它做很傻的事。但整体来看，这就是未来的形状。</p>
  <p>而且这不只是“每天能输出多少 tokens”的问题。还包括我们能多快地输出。随着这些编码模型变得更强，它们可以想很久，但你不想等很久。所以还有其他维度，不只是 tokens 数量本身。</p>
  <p>但在少数几个关键维度上，对“智能”的需求会很大，而我们可以用这些能力做很多事。比如你有一个很棘手的医疗问题，你会用 5.2 还是用 5.2 Pro？哪怕后者要用多得多的 tokens——我觉得你会选更好的模型，我认为很多人都会。</p>
  <p>Alex Kantrowitz：我们再往下追一层。你说科学发现，能不能给一个例子？不一定要是今天已经完全确定的那种“我有问题 X，只要投入算力 Y 就能解决”，但至少给个直观的例子：今天有哪些问题是“我想解决但还做不到”的？</p>
  <p><strong>Sam Altman：</strong>今天早上 Twitter 上有一个讨论：一群数学家互相回复。他们大概在说：“我原本非常怀疑 LLM 什么时候才能真的有用；但 5.2 是让我跨过门槛的那个模型。”他们说它在一些帮助下做出了一个小证明，发现了一些小东西，但这已经在改变他们的工作流。然后更多人跟上来说“我也是”。有些人说 5.1 就已经到达了，但不多。</p>
  <p>考虑到 5.2 才发布 5 天左右，就出现这种反馈——数学研究社区像是在说：“好像有件重要的事刚刚发生了。”</p>
  <p>Alex Kantrowitz：我看到 Greg Brockman 也一直在他的动态里高亮各种数学、科学方向的用法。某种东西在这些圈子里，和 5.2 一起被“点亮”了。所以随着进展推进，会发生什么很值得观察。</p>
  <p><strong>Sam Altman：</strong>算力这件事还有个难点：你必须提前非常久去做规划。你刚才提到的那 1.4 万亿美元，我们会在非常长的时间里逐步花出去。我希望能更快，我觉得如果我们能更快地投入，会有需求承接。但建设这些项目需要极其长的时间：数据中心的建设、供能、芯片、系统、网络等等，一切都很耗时。所以这是一个长期过程。</p>
  <p>不过，从一年前到现在，我们大概把算力翻了三倍。</p>
  <p>我们希望明年再翻三倍，再下一年再翻一次。收入增长的速度甚至比这还略快一点，但大体上确实是跟着算力规模走的。所以我们从来没有遇到过一种情况：我们没法把已有的算力很好地变现。</p>
  <p><strong>换句话说，如果我们现在有双倍的算力，我觉得我们的收入也会是现在的双倍。</strong></p>
  <h2><strong>6</strong></h2>
  <h2><strong>如果不激进投入，OpenAI 或许早就盈利了</strong></h2>
  <p>Alex Kantrowitz：好，那既然你提到了数字，我们就聊聊数字。收入在增长，算力支出在增长，但算力支出的增长仍然快过收入增长。报道里有一些数字，说 OpenAI 可能会在现在到 2028/2029 年之间累计亏损大概 1200 亿美元，然后到那时开始盈利。你能讲讲这个拐点是怎么出现的吗？转折点在哪里？</p>
  <p><strong>Sam Altman：</strong>随着收入增长，随着推理（inference）越来越成为算力资源中的主要部分，它最终会“盖过”训练成本。这就是计划：训练阶段花很多钱，但之后赚得越来越多。</p>
  <p>如果我们不继续把训练成本增长推得这么猛，我们会更早盈利得多。但我们现在押注的是：非常激进地投入训练这些大模型。</p>
  <p>Alex Kantrowitz：整个世界都在看：你们的收入能否匹配你们的支出。大家问的问题是：如果今年收入轨迹可能达到 200 亿美元，而你们的投入承诺是 1.4 万亿美元——这到底怎么对得上？我觉得如果能一次性把这些数字的逻辑讲清楚，会非常有价值。</p>
  <p><strong>Sam Altman：</strong>这很困难。因为人们很难在脑子里建立一个快速、可靠的心智框架去理解指数级增长。我自己肯定做不到，而且我见过的人里也极少有人能做到。你可以对很多数学问题有不错的直觉，但对指数增长，人类通常就是做不好。进化让我们擅长很多“脑内数学”，但建模指数增长似乎并不是其中之一。</p>
  <p>我们的核心判断是：我们还能在很长一段时间里保持非常陡峭的收入增长曲线。我们目前看到的一切都在表明：如果没有足够算力，我们根本做不到——我们一直都在被算力约束。</p>
  <p>算力不足对收入线的影响非常直接、非常硬。所以如果未来某个节点出现“我们有一大堆闲置算力却无法在单位算力上盈利变现”，那么人们质疑“这到底怎么运作”的确会非常合理。</p>
  <p>但我们已经用很多种方式把账算过了。我们当然也会在 flops per dollar 上变得更高效——我们在降低算力成本方面做的工作会逐步兑现。我们看到了消费者增长，也看到了企业增长，还有一堆我们甚至还没发布的新业务类型，但都会上线。而算力就是支撑这一切的生命线。</p>
  <p>所以，我们会设置一些阶段性检查点。如果我们对时机或数学估计稍微算错了，我们也有一定的灵活性。但我们一直以来的状态都是：算力永远不够。</p>
  <p>它一直在限制我们能做的事情。很遗憾，我觉得这种情况可能永远都会存在，但我希望这种限制能少一点，也希望随着时间推移把它降到更低。因为我认为我们其实可以交付非常多很棒的产品和服务，这也会是一门非常好的生意。</p>
  <p>Alex Kantrowitz：所以，本质上是这样一个关系：训练成本在绝对值上升，但在整体成本结构中所占的比例在下降。然后你的预期是，通过这些方式——比如推动企业级市场、比如有人愿意通过 API 为 ChatGPT 付费——OpenAI 能够把收入增长到足以用收入来覆盖这些成本。</p>
  <p><strong>Sam Altman：</strong>是的，这就是计划。</p>
  <p>Alex Kantrowitz：我觉得最近市场对这件事有点“失控”了。让市场真正感到不安的，是“债务”开始进入这个等式。传统上，你会在事情比较可预测的时候去举债，然后公司拿着这笔债去建设，并且有相对可预测的收入。但这是一个全新的类别，它是不可预测的。你怎么看待债务进入这个领域这件事？</p>
  <p><strong>Sam Altman：</strong>首先，我觉得市场在今年早些时候就已经“失控”过一次了。你知道，我们可能只是去见了一家公司，那家公司的股价第二天就涨了 20% 或 15%，让我觉得非常不健康。</p>
  <p>说实话，我反而挺高兴现在市场里多了一点怀疑精神和理性，因为之前看起来我们正一路奔向一个极其不稳定的泡沫。而现在我觉得人们多少恢复了一点纪律性。</p>
  <p>所以我认为，事情是这样的：之前大家太疯狂了，现在在债务问题上反而更理性一些。我们大致知道一件事：如果我们去建设基础设施，整个行业里总会有人能从中获得价值。现在仍然非常早期，这点我同意。但我不认为还有人会质疑“AI 基础设施不会产生价值”这件事。</p>
  <p>所以我觉得，债务进入这个市场是合理的。我也认为未来还会出现其他类型的金融工具。我怀疑其中会有一些并不那么理性的创新方式，人们会在如何为这些东西融资上不断“发明新花样”。但比如说，借钱给公司去建数据中心，这在我看来是完全合理的。</p>
  <p>Alex Kantrowitz：真正让人担心的是：如果事情不能按现在的速度继续推进。比如有一种情形——你可能不同意——模型能力的进步出现饱和，那么这些基础设施的价值就会低于此前的预期。那当然，这些数据中心对某些人来说仍然是有价值的，但也有可能被清算，然后被别人以折扣价买走。</p>
  <p><strong>Sam Altman：</strong>我确实也认为中间一定会出现一些繁荣与萧条的周期，这类事情从来都不是一条完全平滑的直线。</p>
  <p>首先，这一点在我看来是非常明确的，而且这是我愿意“拿公司去赌”的判断：模型一定会变得好得多、好得多。我们对这一点有非常清晰的判断窗口，我们对此非常有信心。</p>
  <p>即便模型能力不再进步，我也认为世界上存在很强的惯性。人们需要时间去理解如何适应新事物。</p>
  <p>我相信，5.2 这个模型所代表的潜在经济价值，与目前世界实际挖掘出来的价值之间，存在着极其巨大的“悬空空间”。即便你把模型能力冻结在 5.2 的水平，问一句：还能创造多少额外价值、还能推动多少收入增长？我会赌一个“非常巨大”的数字。</p>
  <p>事实上，你没有问这个问题，但如果我可以稍微发散一下的话——我们过去经常讨论一个 2×2 的矩阵：时间线是短还是长，起飞是快还是慢。我们会在不同时间判断这些概率如何变化，并据此来理解这个世界应该优化怎样的决策和战略。</p>
  <p>但在我脑海里，现在多出来了一条 Z 轴：能力“悬空空间”是小还是大。回头看，我意识到我当时并没有认真思考这一点。我大概隐含地假设，如果模型里蕴含着大量价值，世界会很快学会如何部署和使用它们。但现在看起来，在世界的大多数地方，这个“能力悬空空间”会大得惊人。</p>
  <p>当然，会有一些局部区域，比如一部分程序员，通过采用这些工具会变得极其高效。</p>
  <p>但总体来说，我们已经拥有了一个疯狂聪明的模型，而老实说，大多数人问的问题，仍然和 GPT-4 时代差不多。科学家、程序员、不同类型的知识工作者，变化程度各不相同，但整体上仍然存在巨大的能力悬空空间。</p>
  <p>而这一点会给世界带来一系列非常奇怪的后果。我们还远没有完全想清楚它将如何展开，但这确实非常、非常不同于我几年前的预期。</p>
  <h2><strong>7</strong></h2>
  <h2><strong>为什么模型这么强了，企业落地还不见成效？</strong></h2>
  <p>Alex Kantrowitz：我想问你一个关于“能力悬空”的问题。基本上，模型能做的事情比它们现在被使用来做的事情多得多。我试图理解，为什么模型已经这么强了，但很多企业在实际落地时，却拿不到投资回报——至少他们是这么跟 MIT 说的。</p>
  <p><strong>Sam Altman：</strong>我对此有点困惑，因为我们又听到很多企业说：“就算 GPT-5.2 的价格涨 10 倍，我们也愿意付费。你们现在的定价严重低估了价值，我们已经从中获得了巨大收益。”</p>
  <p>所以这两种说法似乎对不上。</p>
  <p>如果你去问程序员，他们也会说：“这东西太值了，我愿意付现在价格的一百倍。”</p>
  <p>假设你相信那些 GDP 价值评估的数据——当然你也有充分理由不相信，可能它们是错的——但假设它们是真的：对于那些定义清晰、周期不算特别长的知识工作任务，在 10 次里有 7 次，你对 5.2 的输出会和人工一样满意，甚至更满意。那么你就应该大量使用它。但现实是，人们改变工作流所花的时间，远比我想象的要长。</p>
  <p>人们已经非常习惯让初级分析师去做 PPT 之类的事情，这种习惯的粘性比我预期的要强得多。说实话，我自己现在的工作流，也仍然和过去差不多，尽管我明明知道自己可以比现在多用得多的 AI。</p>
  <h2><strong>8</strong></h2>
  <h2><strong>闪电问答：一朵不想成为 AWS 的云，和一场并不兴奋的 IPO</strong></h2>
  <p>Alex Kantrowitz：好，我们还剩 10 分钟。我还有四个问题，我们试着用“闪电轮”来过一遍。</p>
  <p>你们正在做的那个设备。我们刚才说会回来继续聊 OpenAI CEO Sam Altman。我听到的说法是：手机大小、没有屏幕。那为什么不能只是一个 App？如果它是一个没有屏幕的“手机”，那为什么不是 App？</p>
  <p><strong>Sam Altman：</strong>首先，我们会做一个小型的设备家族，而不是单一设备。随着时间推移……这不是猜测，我尽量不让自己说错，但我认为，未来人们使用计算机的方式会发生变化：从一种“愚钝的、被动反应式”的东西，转向一种非常聪明、非常主动的东西——它理解你的整个人生、你的上下文、你周围正在发生的一切，非常清楚你身边的人，无论是物理上的，还是通过你正在使用的计算机。</p>
  <p>而我认为，现有的设备并不适合这样一个世界。我一直非常相信一点：我们是在“设备能力的边界”上工作。你有一台电脑，它做出了一系列设计选择，比如它是开着的还是关着的，但它不能处在一种状态：一边让我专心听这场采访，一边在我忘了问你一个问题时轻声提醒我。也许那样会很有用。</p>
  <p>我们有屏幕，这就把我们限制在几十年来图形界面的那种交互方式里；我们有键盘，而键盘的设计初衷本来就是为了降低输入信息的速度。这些假设已经存在了很长时间，而且它们确实有效。但现在出现了一种全新的东西，打开了一个全新的可能性空间。我不认为当前的设备形态会是这个全新能力的最优承载方式。如果真是那样，反而会显得非常奇怪。</p>
  <p>Alex Kantrowitz：这个话题我们能聊一小时，但我们还是继续下一个问题吧：云。你谈到过要建设一个“云”。有一位听众给我们发来邮件：在他的公司里，他们正在从 Azure 迁移，直接集成 OpenAI，为产品提供 AI 能力。他们的目标是让数万亿 token 在整个技术栈中流动，用来支撑 AI 体验。这是不是你们想要打造一个巨大云业务的方向？</p>
  <p><strong>Sam Altman：</strong>首先，数万亿 token——那真的很多 token。你刚才问到算力需求和企业战略，企业已经非常明确地告诉我们，他们想从我们这里购买多少 token。我们很可能在 2026 年再次无法满足需求。</p>
  <p>整体战略是这样的：大多数公司似乎都想来找我们，说：“我需要一个‘带 AI 的公司’。我需要一个为我公司定制的 API，我需要为我公司定制的 ChatGPT Enterprise，我需要一个我可以信任、可以运行所有 agent、可以托管我数据的平台。我需要把数万亿 token 注入我的产品。我需要让所有内部流程更高效。”</p>
  <p>而我们目前并没有一个真正优秀的一体化方案，但我们想把它做出来。</p>
  <p>Alex Kantrowitz：你的目标是成为像 AWS、Azure 那样的存在吗？</p>
  <p><strong>Sam Altman：</strong>我觉得这是一个不同类型的东西。我并没有什么雄心要去提供你用来托管网站的那一整套服务。但我确实认为，未来人们会继续拥有所谓的“Web 云”，同时还会有另一种东西：公司会说，“我需要一个 AI 平台，用来支撑我内部的一切、我对外提供的一切服务。”</p>
  <p>它在某种意义上仍然依赖物理硬件，但我认为它会是一个相当不同的产品形态。</p>
  <p>Alex Kantrowitz：我们快速聊一下“发现”。你曾说过一件让我印象很深的事：你认为模型——或者人与模型的协作——会在明年产生小发现，在五年内产生重大发现。那是模型本身，还是人与模型协作？你为什么对此这么有信心？</p>
  <p><strong>Sam Altman：</strong>是人使用模型。模型自己去提出问题，那种能力我觉得还要更远一些。但如果世界能因为新知识而受益，那我们就应该感到非常兴奋。整个人类进步的历史，本质上就是：我们打造更好的工具，人用这些工具做更多事，然后在这个过程中再打造更好的工具。这是一种层层攀升的脚手架，一代又一代，一次发现接一次发现。问题是人提出来的，并不会削弱工具的价值。</p>
  <p>说实话，我很开心。今年年初我以为小发现会在 2026 年才开始，但它们在 2025 年下半年就出现了。当然，这些发现非常小，我真的不想夸大它们。但“有一点”和“完全没有”，在我看来是质的区别。三年前我们刚发布模型的时候，它是完全不可能对人类知识总量做出任何新贡献的。</p>
  <p>从现在到五年后的这段路，我怀疑这就是 AI 的常规爬坡过程：每个季度进步一点点，然后突然有一天我们会意识到——“哇，人类在模型增强下，正在做五年前完全做不到的事情。”</p>
  <p>至于我们是把功劳更多归因于更聪明的人，还是更聪明的模型，只要我们真的得到了科学发现，我对两种说法都很满意。</p>
  <p>Alex Kantrowitz：明年 IPO？你想成为一家上市公司吗？你看起来可以作为私营公司运营很久。</p>
  <p><strong>Sam Altman：</strong>这里面有很多因素在起作用。我确实觉得，让公众市场参与价值创造是一件挺酷的事情。从某种意义上说，如果你对比历史上的公司，我们已经算是非常晚才上市了。做私营公司当然很棒，但我们确实需要大量资本，迟早会触及各种股东数量限制。</p>
  <p>我期待成为一家上市公司的 CEO 吗？0%。</p>
  <p>我期待 OpenAI 成为一家上市公司吗？在某些方面是的，但在某些方面我也觉得那会非常烦。</p>
  <p>Alex Kantrowitz：我非常认真地听了你和 Theo Von 的那期访谈，很棒的一期。他真的很懂行，做了很多功课。你当时说，在 GPT-5 发布前，GPT-5 在几乎所有方面都比我们更聪明。我当时想：这不就是 AGI 的定义吗？如果这还不是 AGI，那这个词是不是已经变得有点没有意义了？</p>
  <p><strong>Sam Altman：</strong>这些模型在“原始算力”层面显然非常聪明。最近几天有很多关于 GPT-5.2 的讨论，说它的 IQ 是 147、144、151，取决于你用的是谁的测试。你也能看到很多领域专家说它能做出惊人的事情，能提升他们的工作效率。我们也讨论了 GDP 影响。</p>
  <p>但有一件事你还没有：模型目前还做不到这样一件事——当它今天发现自己不会做某件事时，它无法自己意识到这一点，主动去学习、理解，等你第二天回来，它就已经把这件事做好了。这种持续学习能力，连幼儿都具备，而这似乎是我们需要构建的一个非常重要的部分。</p>
  <p>那么，没有这一点，你能否仍然拥有大多数人眼中的 AGI？我认为答案并不明确。很多人会说，我们现在的模型已经是 AGI 了。几乎所有人都会同意，如果在当前智能水平之上再加上这种能力，那就毫无疑问是 AGI 了。但也许世界上的大多数人会说：“好吧，就算没有那一点，它已经能完成大多数重要的知识工作，在大多数方面比大多数人都聪明，它已经在做小规模的科学发现了，那这就是 AGI。”</p>
  <p>这说明的问题是：这个词本身定义得太不清晰了。虽然我们都很难停止使用它。</p>
  <p>有一件事我真的很希望我们当初做对：AGI 没有被好好定义。而现在大家关注的新词是“超级智能”。所以我的提议是：我们承认 AGI 就这样“嗖”地过去了。它没有立刻改变世界——或者说它会在长期改变世界——但好吧，我们已经在某个阶段构建出了 AGI。现在我们处在一个模糊期，有些人认为我们已经到了，有些人不这么认为，慢慢会有更多人认为我们到了。然后我们该问：“接下来是什么？”</p>
  <p>我给“超级智能”提供一个候选定义：当一个系统在担任美国总统、管理一家大型公司、运行一个超大型科研机构时，做得比任何一个人都好，哪怕这个人还能借助 AI 的帮助。</p>
  <p>这让我想起了国际象棋的历史。有一个阶段，人类和 AI 结合在一起，比单独的 AI 更强；再后来，人类反而成了拖累，最聪明的做法是完全不加人类的 AI。我觉得这是一个理解超级智能的有趣框架。当然，这还很遥远，但我真希望这一次我们能有一个更清晰的定义。</p>
  <p>Alex Kantrowitz：Sam，我已经每天使用你们的产品三年了，它们真的变得越来越好，几乎无法想象接下来还能怎么进步。</p>
  <p><strong>Sam Altman：</strong>我们会尽力让它们继续快速变好。</p>
  <p><strong>参考链接：</strong></p>
  <p>https://www.youtube.com/watch?v=2P27Ef-LLuQ</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2651267496&amp;idx=1&amp;sn=0903da7c165030f5309e756f747060af&amp;chksm=bc3e49776b67106e47469c68c2360446fa20f33c27a7ff259f0a59126e7c041e012cfbfaa949&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“InfoQ”（ID：infoqchina）</a>，作者：Tina，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602169627067657</id>
            <title>国产GPU四小龙IPO齐活，最后一个刚刚公布</title>
            <link>https://www.36kr.com/p/3602169627067657</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602169627067657</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 08:29:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>芯东西12月19日报道，今日，港交所官网显示，上海GPU龙头<strong>天数智芯</strong>已通过港交所聆讯，并披露招股书。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_40e99732e46a4c95a679c463ee54d0d8@000000_oswg355417oswg1000oswg811_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>就在本周三，上海GPU龙头壁仞科技通过港交所聆讯。</p>
  <p>这为港股“国产GPU第一股”花落谁家，增加了悬念。</p>
  <p>上交所官网显示，国产AI芯片公司已然霸榜科创板市值前四：12月18日，寒武纪、海光信息、摩尔线程、沐曦股份的市值分别为5427亿元、4711亿元、3317亿元、3149亿元。其中寒武纪做的是ASIC专用芯片，后三家的主营产品都是GPU。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ee146e9d6dbf4507ad7fd44c5311348f@000000_oswg291793oswg1000oswg955_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>天数智芯成立于2015年12月，2018年正式启动通用GPU设计，2021年推出中国首款通用GPU产品第一代训练系列天垓Gen 1并实现量产交付，2022年推出第一及第二代推理系列智铠Gen 1及智铠Gen 1X，2023年推出第二代训练系列天垓Gen 2并实现量产，2024年推出第三代训练系列天垓Gen 3（预计2026年第一季度开始量产）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_1dc04c93bea3449a8c3652dbd76893b8@000000_oswg296137oswg1000oswg484_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>招股书显示，根据弗若斯特沙利文的资料，在中国芯片设计公司中，天数智芯是是首家实现推理通用GPU芯片量产的公司、首家实现训练通用GPU芯片量产的公司、首家采用先进7nm工艺技术达成该等里程碑的公司。</p>
  <p>根据弗若斯特沙利文报告，2024年，按收入计，包括天数智芯在内的三家中国公司已跻身中国通用GPU市场五大参与者之列，其中天数智芯<strong>排名第5</strong>，市占率达到0.3%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_bb639099d84b441cae70903ab3359cb4@000000_oswg97025oswg1000oswg444_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>按附注推演，公司A、B、C、D分别是英伟达、AMD、海光信息、沐曦股份。</p>
  <p>2024年中国训练型通用GPU市场五大参与者中，4名参与者为中国公司，天数智芯<strong>排名第4</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_32e92d2bd80a46848c9a71f3af07b4c9@000000_oswg83411oswg1000oswg409_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>按附注推演，公司E是壁仞科技。</p>
  <p>2024年中国推理型通用GPU市场参与者按出货量的排名如下，天数智芯<strong>排名第4</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3db50214c2a44a54a28ef80d803598f3@000000_oswg95044oswg1000oswg435_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随着壁仞科技、天数智芯相继奔赴港交所，这意味着，无论是按上市进度还是通用GPU收入计，“国产GPU四小龙”第一梯队正式成形，包括摩尔线程、沐曦股份、壁仞科技、天数智芯，其中两家已经成功登陆科创板，两家将赴港上市。（海光信息不算只做GPU的公司。）</p>
  <p>注：有些媒体报道误将燧原科技列为GPU企业，燧原科技AI芯片产品属于ASIC专用芯片类别，并非通用GPU。</p>
  <h2><strong>01.</strong></h2>
  <h2><strong>去年收入超5亿，</strong></h2>
  <h2><strong>研发团队超480人</strong></h2>
  <p>2022年、2023年、2024年、2025年1-6月，天数智芯收入分别为1.89亿元、2.89亿元、5.40亿元、3.24亿元，净利润分别为-5.54亿元、-8.17亿元、-8.92亿元、-6.09亿元，研发费用分别为4.57亿元、6.16亿元、7.73亿元、4.51亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2bf2d722d7604d4fb209c1fd2d19e810@000000_oswg163937oswg1054oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲2022年~2025年1-6月天数智芯营收、净利润、研发支出变化（智东西制图）</p>
  <p>近三年半，其超过一半的收入均来自训练系列通用GPU产品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2b2213faa1ba4387af162eb0456f1850@000000_oswg122014oswg1000oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同期综合毛利率分别为59.4%、49.5%、49.1%、50.1%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0b4bd2d4b52e4ccabcfe8da14bbaaa0b@000000_oswg133430oswg1000oswg329_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>截至2025年6月30日，天数智芯的研发团队由484名员工组成，其中超过1/3具备十年以上芯片设计及软件开发经验；在中国和海外拥有65项授权专利，其中包括56项发明相关专利和207项商标，还拥有113项版权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6dddf44c5c094853aab331512913d185@000000_oswg56376oswg1000oswg281_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其综合财务表概要如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5bf8d90639044e06a51c78000884308b@000000_oswg187314oswg1000oswg447_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>现金流如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9b37833af3c546e2bc9865004a7dbcf4@000000_oswg178837oswg1000oswg454_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02.</strong></h2>
  <h2><strong>两条通用GPU产品线并行，</strong></h2>
  <h2><strong>GPU出货量超5万片</strong></h2>
  <p>天数智芯的产品组合主要包括通用GPU芯片及加速卡，以及定制AI算力解决方案（包括通用GPU服务器及集群），将硬件与专有的软件栈结合，以满足客户在训练及推理场景中的特定需求。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9aecbd7c1f374e06a6957772e569762e@000000_oswg167958oswg1000oswg460_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其通用GPU产品有两条产品线，共同实现AI计算领域的全面覆盖，支持从复杂模型开发到高效生产部署的各种应用。</p>
  <p><strong>天垓系列</strong>为其旗舰训练专用产品线及中国国内首款量产的通用GPU产品，专为AI模型训练而设计，拥有先进的计算核心及优化的多卡集群架构。</p>
  <p><strong>智铠系列</strong>是国内首款专为推理而设计的通用GPU产品，专注于推理应用，具有增强的整数计算单元及高效的数据通路，针对部署场景进行优化。</p>
  <p>天数智芯已实现量产及销售两款天垓系列产品（天垓Gen 1及天垓Gen 2）、两款智铠系列产品（智铠Gen 1及智铠Gen 1X），并已发布第三款产品天垓Gen 3。</p>
  <p>2022年、2023年、2024年、2025年1-6月，天数智芯通用GPU产品出货量分别为7800片、12700片、16800片、15700片，合计<strong>53000片</strong>。</p>
  <p>同期，训练系列的出货量分别为7700片、7000片、7000片、6200片，平均售价分别为2440元、3180元、3860元、3040元。</p>
  <p>推理系列的出货量分别为38片、5700片、9800片、9500片，平均售价分别为11400元、8000元、10200元、9200元。</p>
  <p>天数智芯AI算力解决方案整合一定数量的通用GPU的综合计算能力，使其能够作为统一系统进行协同运作，包括提供通用GPU服务器和通用GPU算力集群。</p>
  <p>2023年、2024年、2025年1-6月，其AI算力解决方案的项目数目分别为6个、26个、10个，平均售价分别为260万元、640万元、430万元。</p>
  <p>其主要战略项目详情如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d69ede5ce0ec471f99f02b4d8b9b6c51@000000_oswg378331oswg1000oswg762_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>03.</strong></h2>
  <h2><strong>已服务超过290名客户，</strong></h2>
  <h2><strong>近三年前五大客户集中度高</strong></h2>
  <p>天数智芯的客户总数由2022年的22名增至2023年的65名，并于2024年进一步增至181名，在2025年上半年有106名。</p>
  <p>截至2025年6月30日，该公司已服务超过<strong>290名</strong>来自不同行业的客户，交付超过<strong>52000片</strong>通用GPU产品。</p>
  <p>其产品与解决方案已在包括金融服务、医疗保健及运输等重要领域实现超过<strong>900次</strong>部署与应用，同时支持从制造业到零售业之工业数字化转型，以及基础研究及教育计算应用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_f996c106b52644ab893d61946d35405f@000000_oswg174976oswg1000oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在往绩记录期间，天数智芯的主要客户主要包括云计算服务供应商、AI模型开发商、研究机构以及电子、半导体、制造及消费互联网等领域的企业。</p>
  <p>2022年、2023年、2024年、2025年1-6月，来自前五大客户的收入分别占其总收入的94.2%、73.3%、73.4%、38.6%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_bff56e422a7f4768a4474080c2b77444@000000_oswg509981oswg1000oswg1335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9f0ab5caa10047cab31443d6d080b1e6@000000_oswg474427oswg1000oswg1187_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_68be0b2c5396403f94f9752df2186b71@000000_oswg170118oswg1000oswg272_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>天数智芯的主要供应商主要包括内存组件、晶圆制造、印刷电路板加工服务、IP核及设计软件的供应商。</p>
  <p>同期，该公司向前五大供应商的采购额分别占总采购额的58.2%、56.2%、44.6%、67.2%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_eb29446f8cde45bc84976621dad16ea0@000000_oswg393845oswg1000oswg1090_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6eaaacfa7f3946ad82ebf0a361468563@000000_oswg409815oswg1000oswg943_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>客户K、客户C亦是天数智芯的供应商。客户K专注于提供计算能力解决方案。客户C是一家全球领先的光电混合计算供应商，天数智芯向客户C采购光互连产品，以用于交付若干项目的计算解决方案。</p>
  <h2><strong>04.</strong></h2>
  <h2><strong>研发高管有英伟达、AMD、</strong></h2>
  <h2><strong>英特尔、联发科、三星背景</strong></h2>
  <p>招股书文件显示，天数智芯有9位副总裁。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_8bf84de326fe49058ee0ca03738ddaa0@000000_oswg305174oswg1000oswg866_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>天数智芯董事会主席兼CEO盖鲁江今年44岁，本科毕业于中央财经大学，在2020年7月加入天数智芯前拥有约17年的财务及投资经验。</p>
  <p>副总裁孙怡乐今年45岁，负责芯片研发，本硕均毕业于清华大学，加入天数智芯前曾担任远弘科技（上海）有限公司工程师、亚鼎视频科技（上海）有限公司担任工程师、AMD附属公司超威半导体（上海）有限公司的高级经理。</p>
  <p>副总裁吕坚平今年62岁，负责管理天数研究院，本硕毕业于国立台湾大学，博士毕业于美国耶鲁大学，加入天数智芯前曾担任英伟达高级架构师兼经理、MediaTek USA高级总监、Intel Corporation高级经理、NOVUMIND工程副总裁、Samsung Advanced Computing Labs研发及运营副总裁、NOVUMIND首席技术官。</p>
  <p>副总裁刘圆今年44岁，负责芯片量产实现，本硕均毕业于复旦大学，加入天数智芯前曾担任超威半导体（上海）有限公司PMTS ASIC/版图设计工程师。</p>
  <p>副总裁石加圣今年41岁，负责软件研发，本科毕业于复旦大学，硕士毕业于美国罗切斯特大学，加入天数智芯前曾担任慧国（上海）软件科技有限公司软件工程师、超威半导体（上海）有限公司高级软件工程师，并曾任职于上海拆名晃资讯科技有限公司。</p>
  <p>副总裁邹翾今年44岁，负责产品线及供应链管理，硕士毕业于哈尔滨工业大学，加入天数智芯前曾任职于格罗方德半导体科技（上海）有限公司、国际商业机器（中国）有限公司中国芯片设计中心。</p>
  <p>其他四位副总裁中：郭为今年48岁，负责解决方案开发及信息技术支持；宋煜今年46岁，负责客户及技术支持部门；梁斌今年58岁，负责技术合作与开发；丁娜今年45岁，负责人力资源与行政事务。</p>
  <h2><strong>05.</strong></h2>
  <h2><strong>单一最大股东集团持股23.61%</strong></h2>
  <p>天数智芯成立于2015年12月，在2018年完成A轮融资，2019年完成超3.5亿元B轮融资，2021年完成8.2亿元C轮融资，2022年完成超9亿元C+、C++轮融资，2025年完成约20.5亿元D轮融资，投前估值达120亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_970ecc3e618545dfbbd79b96b7ede5a6@000000_oswg396390oswg1000oswg1165_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>经过一系列股权变动，截至最后可行日期，单一最大股东集团合共持有天数智芯已发行股本总额约23.61%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_feb8f02d462747c0a5501a84096faa30@000000_oswg68161oswg1000oswg356_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与典型的创始人主导公司不同，自往绩记录期间开始以来，天数智芯所有权一直由其雇员通过多个特殊目的实体以及多元化的被动财务投资者持有。</p>
  <p>其截至本文件日期的股东持股情况如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_1a8b04a0c2624eebae6ac18a983ae58b@000000_oswg746760oswg1000oswg1920_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_82882ffefe0448faae8a7b706245439f@000000_oswg281737oswg1000oswg804_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>天数智芯各董事、监事及主要行政人员2024年、2025年1-6月薪酬载列如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_481f86665fd64eeba427b51b3fc35c3e@000000_oswg206749oswg1000oswg792_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2fa6d5ed4d1e44859e92d6f75c19b329@000000_oswg254730oswg1000oswg1008_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中蔡全根、郑金山、林小钦已提呈辞任董事，自2025年1月13日起生效；刁石京已提呈辞任董事，自2025年5月20日起生效。</p>
  <h2><strong>06.</strong></h2>
  <h2><strong>结语：多家GPU及AI芯片企业正冲刺IPO</strong></h2>
  <p>根据弗若斯特沙利文的资料，中国通用GPU市场快速扩张，2024年的出货量达到160万片，2022年至2024年的复合年增长率为72.8%。预计市场将维持强劲增长，2025年至2029年，出货量预计以33.0%的复合年增长率增长。</p>
  <p>随著中国通用GPU公司出货量的增长速度超越国际竞争对手，国内市场占有率持续攀升。国产通用GPU产品占比由2022年的8.3%提升至2024年的17.4%，预计到2029年将超过50%。</p>
  <p>国内通用GPU公司们正积极把握不断扩大的市场机遇。本月北京GPU龙头摩尔线程、上海GPU龙头沐曦科技均已在科创板上市，还有多家国内GPU及AI芯片公司正在向IPO发起冲刺。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652794474&amp;idx=1&amp;sn=fb4fe2b30860ccfaf4107b9520127cb3&amp;chksm=85327fb9ed5e1e36c47a740ac2007226d53bffbbf22d3ca6296e34078fe08eda9c251fc7f58b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：ZeR0，编辑：漠影，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602168632280072</id>
            <title>资本重新盯上3D打印</title>
            <link>https://www.36kr.com/p/3602168632280072</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602168632280072</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 08:26:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“分享下最近新进的坑——3D打印！”</p>
  <p>“自从有了3D打印机后，我实现了手办自由。”</p>
  <p>在某社交平台上，类似的内容正疯狂刷屏，关于“3D打印”相关笔记已超200万条。从动漫手办到家居改造，这门曾属于极客圈层的小众技术，正加速走入普通人的生活场景。</p>
  <p>资本的动向，也侧面反映了行业的火热。2025年末的短短两个月内，3D打印赛道密集传来重磅投融资消息：</p>
  <p>11月，无人机巨头大疆首次跨界，以数亿元战略投资3D打印公司智能派科技，正式宣告进军该领域；</p>
  <p>12月，快造科技紧随其后，宣布完成数亿元B轮融资，由高瓴创投、美团联合领投，顺为资本、美团龙珠、南山战新投跟投；</p>
  <p>与此同时，行业头部企业创想三维已向港交所递交招股书，冲刺二级市场；而另一隐形巨头拓竹科技虽未启动IPO，但年出货量已突破百万台……</p>
  <p>曾经安静的3D打印赛道，正在2025年迎来一场意想不到的集体回暖。这轮热潮，究竟是资本的短期回流，还是中国3D打印真正迈入规模化落地的拐点？</p>
  <h2><strong>资本热钱流向3D打印</strong></h2>
  <p>这轮赛道升温并非无迹可循，其中最引人关注的，莫过于大疆跨界投资引发的行业风波。</p>
  <p>上个月，3D打印公司智能派科技完成数亿元规模的B轮融资，投资方正是大疆创新。这笔低调的产业投资，因拓竹科技创始人陶冶的一条朋友圈，陷入舆论中心。</p>
  <p>陶冶写道，前东家大疆在近期投资智能派科技时，“协议里还特别安排了针对拓竹的条款”，暗指拓竹科技可能面临来自大疆的“围剿”。</p>
  <p>这一表态迅速引发行业关注。在创办拓竹科技之前，陶冶曾在大疆工作8年之久，曾担任大疆创新消费级无人机部门负责人，主导过包括Mavic Pro等明星产品的研发。</p>
  <p>面对外界猜测，大疆回应称，此次投资纯粹基于对消费级3D打印技术前景和行业增长潜力的看好，符合其一贯对前沿硬科技的前瞻性布局，并未点名回应“针对性条款”一说。</p>
  <p>这场“大疆系”内部恩怨的背后，是一个更值得玩味的信号：连无人机巨头都要亲自下场围猎，说明3D打印这条曾被视作“小众极客玩具”的赛道，正在重回主流科技力量的视野。</p>
  <p>事实上，大疆的跨界布局只是冰山一角，市场化VC的密集加注更加凸显了赛道的热度。</p>
  <p>12月，快造科技（Snapmaker）宣布完成数亿元B轮融资。本轮融资由高瓴创投、美团联合领投，顺为资本、美团龙珠、南山战新投跟投，老股东同创伟业、东证资本持续加注。</p>
  <p>同月，电子束金属3D打印公司赛伯坦科技宣布完成Pre-A轮融资，该轮投资由联动丰业与拓坦新维共同完成。</p>
  <p>再往前回溯，今年9月，数字化齿科3D打印企业铼赛智能（RAYSHAPE）宣布完成数千万元Pre-B轮融资，由猎鹰投资旗下星奇基金与协立投资联合领投，东证资本跟投。</p>
  <p>同月，原子重塑宣布完成A轮融资，投资方为君科丹木和基石资本，为其冲击消费级3D打印赛道注入动力。</p>
  <p>零散的融资案例之外，一组核心数据更能印证赛道的热度飙升。据南极熊3D打印的数据，过去几年，国内3D打印行业投融资事件基本上维持在30-40个之间，而2025年的融资事件直接达到100个（涉及81家公司，部分公司融资2-3次），翻了快3倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_f31b426aeff64dd0b26695e466a06229@5091053_oswg114910oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：南极熊3D打印</p>
  <p>融资金额维度同样印证了赛道的资本热度。据同一数据源，2025年国内3D打印行业投融资总额约84亿元，创历史新高并扭转2024年下跌走势。不过行业融资并非持续高增，2023-2024年受资本市场大环境影响有所承压。</p>
  <p>值得一提的是，2023年行业投融资总额仍增至73亿元，主要得益于铂力特超30亿元定向增发、华曙高科科创板IPO融资11.05亿元这两笔大额资金；2024年因缺乏此类大额融资且市场低迷，融资额回落；而2025年的爆发式增长，或意味着行业融资回归常态化的增长轨道。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_785e5761d6e54467af46ce7244666ec6@5091053_oswg121938oswg1080oswg593_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：南极熊3D打印</p>
  <p>另据投中嘉川 CVSource 数据，从投资标的来看，今年被投企业大致可以分为两类，一类是面向C端消费群体的3D打印公司，另一类是服务于工业领域的新材料或整体技术方案提供商。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_99c4ac8ca29847b1aa32155632497cda@5091053_oswg1064935oswg1080oswg3263_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：投中嘉川</p>
  <p>一个更深层的趋势是，推动这轮热潮的不仅是市场化基金，还有来自地方政府的产业资本。资本不再追逐概念，而是押注于真实需求，为切实提升效率的技术投票。</p>
  <p>市场化VC，如美团龙珠、高瓴创投、同创伟业、君联资本等知名机构在今年都有出手。此外，各地国资设立的早期投资机构也颇为亮眼。例如国器元禾管理的工业母机产业基金，在今年先后投资了安徽共享智能装备、桂林实创科技两家相关产业公司，彰显了产业资本对赛道长期价值的认可。</p>
  <h2><strong>为什么是3D打印？</strong></h2>
  <p>事实上，3D打印行业的再度走红，绝非资本的盲目炒作，而是技术突破的必然结果。</p>
  <p>3D打印技术本身并不新鲜，早在十多年前，这种科技趋势就已经出现，但“成本高、速度慢、难量产”的痛点，也长期制约着行业的规模化发展。</p>
  <p>近年来，一系列关键技术的突破，为行业发展按下了“加速键”。随着激光器、振镜等核心部件实现国产替代，直接推动设备制造成本大幅降低。以主流的FDM（熔融沉积成型）技术设备为例，2019年入门级产品均价仍在3000元以上，如今已有部分降至1000元至3000元区间。</p>
  <p>此外，AI技术与3D打印的深度融合正在成为主流。AI工具允许用户通过简单的文本描述或图片输入生成3D模型，无需专业建模技能，极大简化了创作流程。</p>
  <p>耗材成本的大幅下降与材料体系的丰富化，进一步拓宽了3D打印的应用场景。以消费级3D打印常用的PLA塑料为例，其价格已降至每公斤40元左右，较几年前降幅超过50%。在传统的塑料材料之外，碳纤维复合材料、环保树脂、金属粉末等新型耗材也开始不断涌现。</p>
  <p>技术的成熟与成本的下降，也让长期深耕该赛道的投资人更加明确了价值判断方向。同创伟业追踪3D打印相关标的多年，覆盖3D打印材料、设备、服务甚至平台，曾投资过聚焦金属陶瓷复合材料3D打印技术的恒普激光，以及专注于高端模具和航空航天等高精尖市场金属3D打印的众智信赢。</p>
  <p>据同创伟业王晶，3D打印最终会回归材料成型的本质，尤其是在工业场景，会作为众多工艺中的一环，最终落地到具体的产品。在这位投资人看来，当前3D打印赛道的投资逻辑已从“技术猎奇”转向“价值落地”。</p>
  <p>北京某产业基金投资经理刘华平表示，“在3D打印国产化趋势越来越凸显的当下，看好行业未来的同时，也要保持理性，助力那些真正具备实力技术的企业走向高端化和国际化，不要为了投而投，做价值投资而非价格投资。”</p>
  <p>两位投资人均强调，3D打印赛道的真正机会不在于短期的概念炒作，而在于技术能否切实转化为可规模化的产业价值——这一共识，或成为当前资本布局该赛道的核心逻辑。</p>
  <p>政策层面的持续加码，更为行业发展注入了强心剂。2024年，《关于加快构建废弃物循环利用体系的意见》鼓励3D打印再生材料应用；2025年，商务部等8部门联合印发《关于大力发展数字消费共创数字时代美好生活的指导意见》，明确将桌面级3D打印设备纳入“数字产品消费”的重点方向。</p>
  <p>多重利好叠加下，行业梯队已清晰成型。据前瞻产业研究院，从营收规模来看，我国3D打印行业企业第一梯队包括创想三维和纵维立方，专注于消费级3D打印机，营业收入规模在10亿元以上。</p>
  <p>第二梯队包括铂力特、先临三维、光韵达等企业，平均年营收在1-10亿元间。其中铂力特是工业级3D打印设备的领军企业之一，其在金属3D打印领域有着显著的技术优势和市场占有率‌，先临三维主要涉及3D扫描与3D打印设备。</p>
  <p>华经产业研究院预测，2025年全球3D打印市场规模将达298亿美元，到2030年有望攀升至853亿美元，其中中国市场占比将提升至35%。</p>
  <h2><strong>消费级赛道蓄势待发</strong></h2>
  <p>长期以来，3D打印行业呈现泾渭分明的格局：工业级设备主要面向航空航天、汽车制造、医疗等高端领域，性能强但价格高昂，动辄数十万元甚至数百万元；消费级产品则因精度有限、操作复杂，主要面向个人爱好者、创客等小众群体。</p>
  <p>但这一格局正在被打破。国金证券指出，3D打印行业消费级渗透正当时，将迎来快速普及期。</p>
  <p>当前，消费级3D打印赛道已从早年的混战阶段，逐步跑出一批头部企业。其中，创想三维、纵维立方、智能派三家企业与拓竹科技，被誉为“深圳四小龙”，相关数据显示，这四家深圳企业合计掌握全球入门级3D打印机九成市场份额。</p>
  <p>创想三维递交的招股书也披露了清晰的行业竞争格局：2024年创想三维单年度出货量72万台，排名全球第二；拓竹科技以120万台的出货量排名第一；此外，智能派科技和纵维立方，2024年出货量分别约55万台和50万台。</p>
  <p>它们路径各异：创想三维以高性价比推动技术普惠，已递表港交所；拓竹科技聚焦开发者，打造MakerWorld社区生态，月活超千万，模型数量破百万；智能派从教育套件转型，凭借光固化技术快速起量；纵维立方则以Photon系列打开海外市场。</p>
  <p>不过，消费级3D打印的发展仍面临诸多挑战，行业爆发式增长的背后暗藏隐忧。</p>
  <p>首先是低价内卷问题，随着大量企业涌入赛道，行业整体利润承压，产品质量参差不齐，加速了行业洗牌进程。</p>
  <p>其次是用户留存难题，尽管设备门槛大幅降低，但部分用户在购买后，因缺乏持续使用场景、打印失败率较高等问题，导致设备“买后落灰”，既影响用户体验，也制约行业长期发展。</p>
  <p>但不可否认的是，这些挑战并未改变行业发展的长期趋势。消费级3D打印背后，是个性化制造、数字消费等未来产业的巨大想象空间，当“硬件+软件+内容”的生态闭环逐步形成，3D打印机有望从可选消费品升级为家庭标配。</p>
  <p>智能派科技联合创始人陈波直言，“消费级3D打印迎来iPhone时刻”，这一表述隐喻着行业已迎来引爆点，“近几年，消费级3D打印机已经走过了创新扩散理论里的早期尝鲜，进入到早期大众阶段了，行业头部的四家企业年营收也已经跨过10亿元的门槛。”</p>
  <p>对于资本而言，这轮布局不仅是对短期市场热度的追逐，更是对长期产业价值的看好；对于行业而言，资本的注入将加速技术迭代与生态完善；对于普通消费者而言，这场变革正在重新定义“创造”的边界，让每个人都能成为“制造者”。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/5FB_gr5kQxAwYS9drBVt2w" rel="noopener noreferrer nofollow" target="_blank">“猎云精选”</a>，作者：韩文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602014296949764</id>
            <title>美国「曼哈顿计划」启动，OpenAI谷歌等24巨头打响「科技珍珠港之战」</title>
            <link>https://www.36kr.com/p/3602014296949764</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602014296949764</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 07:52:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今天，重磅消息来了：美国的AI曼哈顿计划，正式启动！</p>
  <p>就在刚刚，美国能源部白宫签署了历史性的合作文件，这个被命名为「创世纪任务」的国家计划，终于将最顶尖的AI技术与国家实验室的科研能力结合了起来。</p>
  <p>参与方包括微软、谷歌、英伟达、OpenAI、DeepMind、Anthropic等几乎所有的美国科技巨头！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4e900346fa814a9bb30f3c2b74625770@5091053_oswg29359oswg1080oswg305_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个「创世纪」计划，可以称为美国的AI曼哈顿计划，史上首次，规模宏大，影响深远。</p>
  <p>这，是一个奇点时刻。</p>
  <p>2025年11月，美国政府正式启动这个国家级战略计划，由总统发布行政命令。目标是——</p>
  <blockquote>
   <p>打造全国首个AI驱动的科研平台，用人工智能与超级计算能力加速科学发现。</p>
  </blockquote>
  <p>从此，美国的AI模型和计算平台，将首次全面应用于可控核聚变、能源材料发现、气候模拟、量子计算算法等重大科学研究，这标志着美国在科技领域的国家级战略调整——从各自为战，转向系统性的集体攻关。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_396121098916455786e8d3f7b1f402e9@5091053_oswg698162oswg1080oswg808_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>消息一出，网友们兴奋表示：「这是一次高水平合作」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6a633ddda57a412bb13a88f50370b055@5091053_oswg51059oswg1026oswg192_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「如今的AI，已经成为国家级的战略资产」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6303e4d16d81475ab4dc342e998cb7d9@5091053_oswg71553oswg1080oswg172_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一张白宫签署的协议，集结了从微软、谷歌到OpenAI、DeepMind等24家顶尖科技企业，一场重塑美国科研未来的AI「超级合众国」计划正在拉开序幕。</p>
  <h2><strong>OpenAI谷歌，史上首次携手</strong></h2>
  <p>这也是第一次，OpenAI和谷歌这对AI领域最大的竞争者站在统一战线，共同推动能源、量子计算等前沿科学突破。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b12755fb26334a6488fe644d0d915397@5091053_oswg360773oswg1080oswg629_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>两家全球顶尖的实验室，史上第一次破天荒展开了合作——不再是围绕AI大模型的竞争，而是共同投入国家级的科学与能源问题。</p>
  <p>它们的大模型，将和政府旗下的17个国家实验室和超级计算机结合，目标是<strong>到2030年，将美国的科学生产力翻倍！</strong></p>
  <p>现在，谷歌DeepMind和OpenAI都已经在自己的官方博客上发文表示支持。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_cc7e7129cfb44ddbb4d7924dd51ed0df@5091053_oswg136360oswg1080oswg467_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>谷歌表示，要将「先进的AI工具交到美国科学家手中」。</p>
  <p>他们承诺，会将Gemini 3的推理能力，应用于核聚变等离子体模拟、气候建模以及探索新的材料搜索空间。</p>
  <p>在2026年，谷歌还将为国家实验室提供AlphaEvolve、AlphaGenome和WeatherNext。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_72823a765c514b63ac7f0f817362ae52@5091053_oswg397123oswg1069oswg1444_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>OpenAI也发表了备忘录，表示已经与美国能源部签署文件，加速AI驱动科学的发展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_18146e8b83e041cd8592d8b1152bc546@5091053_oswg86319oswg1080oswg403_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>OpenAI还表示，已经向白宫科技政策办公室提交了详细建议——「美国如何通过AI，加强科技领导力」。</p>
  <p>在文件中，OpenAI论证了为什么2026年是「科学之年」，以及为什么获取前沿AI模型、计算能力和真实研究环境，对于加速发现至关重要。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_806236b66c2349b48463ff4052cf2d34@5091053_oswg206833oswg1080oswg535_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>美国，要建AI国家科研操作系统</strong></h3>
  <p>如果说过去两年，AI改变的是写作、编程、客服，那么从2025年开始，就彻底变了。</p>
  <p>现在，AI真正要动的，是国家科研体系的底层结构。</p>
  <p>虽然这次没有发布模型，也没有刷新benchmark，但未来十年科学发现的速度、方向，甚至地缘科技竞争的胜负，都可能被这一刻决定。</p>
  <p>「创世纪计划」（Genesis Mission），可以看作一个AI版的国家科研操作系统。</p>
  <p>简单总结，美国政府要做三件事。</p>
  <p>1. 把AI变成科研的「默认工具」</p>
  <p>2. 把国家实验室、超级计算机、数据资产统一到一个AI平台</p>
  <p>3. 把最先进的AI能力，引入公共科研体系，而不是只留在企业内部</p>
  <p>这次计划，核心依托的是能源部旗下的<strong>17个国家实验室</strong>，包括：洛斯阿拉莫斯国家实验室（Los Alamos），劳伦斯伯克利国家实验室（Berkeley Lab），阿贡国家实验室（Argonne）和橡树岭国家实验室（Oak Ridge）。</p>
  <p>而就在这些实验室中，掌握着美国最核心的科研资产——核能与核物理、材料科学、气候模型、高能物理、超级计算系统（如 Frontier、Aurora）。</p>
  <p>创世纪计划的目标，就是用AI和超级计算，把科学发现的速度提升一个数量级！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_be648b88ce7b4b8291510f6f0c3fab29@5091053_oswg907371oswg1080oswg648_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">洛斯阿拉莫斯国家实验室</p>
  <h3><strong>为什么是能源部</strong></h3>
  <p>为什么是由美国能源部牵头？因为，这里掌握着美国科研的「重武器」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_fe14164a0d5d4494a364f6844a42dae2@5091053_oswg895811oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">美国能源部长</p>
  <p>或许在很多人印象中，美国能源部只和电力、能源有关，但实际上，它是<strong>美国最强科研部门之一。</strong></p>
  <p>原因很简单：能源部管理着<strong>全球最顶级的一批超级计算机；</strong>它拥有<strong>无法公开市场化的科研数据；</strong>它的实验室体系，承担着大量「非商业化、但战略级」的研究任务。</p>
  <p>比如：核聚变模拟，核材料老化模型，国家级气候变化预测，高能粒子物理……</p>
  <p>这些研究的<strong>算力需求极高、实验成本极大、周期极长</strong>，正是最适合AI介入的领域。</p>
  <h3><strong>24家美国科技大公司，集体入局</strong></h3>
  <p>这次OpenAI和谷歌、微软等的罕见联手，更是透露出：这不是一次普通合作，而是一次国家级绑定。</p>
  <p>根据路透社消息，加入创世纪计划的企业可以分为以下类型。</p>
  <p><strong>·</strong>云与平台 ：Microsoft、Google、AWS、Oracle、IBM</p>
  <p><strong>·</strong>AI模型公司 ：OpenAI、Anthropic、xAI</p>
  <p><strong>·</strong>芯片与算力 ：Nvidia、Intel、AMD、HPE</p>
  <p><strong>·</strong>新型AI芯片 ：Cerebras、Groq</p>
  <p><strong>·</strong>数据与分析公司 ：Palantir等</p>
  <p>也就是说，美国AI产业的「全栈力量」，第一次系统性进入国家科研体系！</p>
  <p>此次计划中，微软和谷歌的角色十分清晰：提供云计算基础设施，提供AI开发平台（如 Azure AI、Vertex AI），支持国家实验室部署和运行大模型。</p>
  <p>这就意味着，美国国家实验室未来跑的AI，很可能<strong>直接跑在Big Tech的云上</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b5d07b040ca54020b60d026333f7efc8@5091053_oswg421653oswg951oswg1499_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>英伟达，算力和「科学AI」的核心</strong></h3>
  <p>而英伟达，就是创世纪计划中，<strong>最关键的技术支点之一</strong>。</p>
  <p>原因很简单。</p>
  <p>比如国家实验室的超级计算机，几乎全部基于英伟达的GPU。</p>
  <p>科学计算、物理仿真，本身就是英伟达最强的领域。</p>
  <p>更不用提，AI+HPC（高性能计算），正是英伟达过去5年重点布局的方向。</p>
  <p>可以说，这次创世纪计划，简直就是英伟达长期战略的一次国家级兑现！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_708d6b0b610b4b178cc781b64a00ec6c@5091053_oswg293908oswg1080oswg797_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>利好OpenAI：让模型走出互联网</strong></h3>
  <p>而对OpenAI和Anthropic 来说，这次合作也是意义重大。</p>
  <p>这意味着，大模型不再只服务聊天、办公和编程，而是进入<strong>核物理、材料科学、气候模拟</strong>等硬核领域，成为「科学发现引擎」的一部分。</p>
  <p>这也是为什么，OpenAI一直在强调<strong>「AI&nbsp;for Science」</strong>。</p>
  <h2><strong>美国科研的曼哈顿计划</strong></h2>
  <p>把此次计划称为美国科研的「曼哈顿计划」，绝不夸张。</p>
  <p>因为从各方面看，它都已经可以和曾经的曼哈顿计划相提并论。</p>
  <p><strong>·</strong>国家级动员：由总统行政命令推动</p>
  <p><strong>·</strong>顶级资源集中：实验室、算力、数据、企业</p>
  <p><strong>·</strong>明确战略目标：加速科学发现，确保技术领先</p>
  <p>区别就在于，曼哈顿计划，解决的是「能不能造原子弹」。</p>
  <p>而Genesis Mission，解决的是「怎样把未来所有科研做得更快」。</p>
  <p>传统的科研流程，是这样的：提出假设 → 设计实验 → 申请算力 → 跑模拟 → 分析数据 → 再修正假设。</p>
  <p>所以，一个科研周期，可能长达几年。</p>
  <p>但Genesis Mission，会彻底颠覆这个流程，变成「AI自动生成假设 → AI设计实验 → AI运行模拟 → AI分析结果 → 人类决策」。</p>
  <p>举几个现实中的例子吧。</p>
  <p>在材料科学中，AI可以在几天内筛选<strong>上亿种材料组合。</strong></p>
  <p>在气候研究中，AI可以替代部分昂贵的物理仿真。</p>
  <p>在核聚变领域，AI可以优化等离子体控制参数。</p>
  <p>在传统方法中，这些都是不可能做到的事。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4e6004bfae0e4de88e552f4e80f1ca7c@5091053_oswg629151oswg1080oswg1163_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>AI，正从工具变成国家能力</strong></h3>
  <p>这次创世纪计划释放的信号，很值得我们解读。</p>
  <p>可以说，AI已经不再只是商业竞争工具，而是国家科研与战略能力的一部分。</p>
  <p>未来国家之间的竞争，绝不仅仅是谁的模型更大、谁的参数更多。</p>
  <p>而是谁能把AI真正嵌入科研体系，谁能用AI改写科学发现的速度曲线。</p>
  <p>这，可能才是AI时代最深层的变化。</p>
  <p>美国能源部这次起的头，不是要给短期项目，而是一场长期实验。</p>
  <p>当AI和科学家开始合作，我们很可能就站在<strong>下一次科学革命的起点</strong>。</p>
  <p>谁能先把AI变成真正的科研基础设施，谁就能跑在前面。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://www.reuters.com/business/retail-consumer/us-energy-department-taps-big-tech-ai-powered-research-push-2025-12-18/?utm_source=chatgpt.com</p>
  <p>https://openai.com/index/us-department-of-energy-collaboration/</p>
  <p>https://deepmind.google/blog/google-deepmind-supports-us-department-of-energy-on-genesis/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/mjpzDzFctiNmQxF2YGlghg" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，编辑：Aeneas，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602054668289283</id>
            <title>2025手机三国杀：小米涨价了、华为重回王位、苹果不装了丨36氪年度透视②</title>
            <link>https://www.36kr.com/p/3602054668289283</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602054668289283</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 07:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote>
   <p>“透视图”栏目在年终特别策划了“36氪年度总结”系列，用数据透视2025全年趋势，以图片呈现今年商业世界中不可错过的要点。</p>
  </blockquote>
  <p><strong>作者｜邱晓芬</strong></p>
  <p>2025年，手机圈在成本飙升的“超级周期”中迎来残酷洗牌。当零部件成本普涨10%-25%，市场被一道600美金的红线切开：中低端陷入存量塌陷，唯有高端市场凭借AI与生态逆势扩张。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_a9d7f30d401641e491cdb73d9148397d@1200352198_oswg721320oswg1587oswg2245_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">36氪制图</p>
  <h2><strong>苹果：不装了，基础款也给“全家桶”</strong></h2>
  <p>面对国产追击，苹果不再矜持。iPhone 17基础款不再“挤牙膏”，破天荒补齐高刷等核心短板，销量在中国近乎翻番，成为统治10月的绝对主力。哪怕AI迟到，苹果仍凭基础款的“降维打击”守住了高端大盘。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_eea01381a45c4bedaba1f1aad3a47f2a@1200352198_oswg609060oswg1587oswg2245_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">36氪制图</p>
  <h2><strong>华为：硬刚五年，终夺王位</strong></h2>
  <p>靠着高达95%的国产化率与鸿蒙原生生态的成型，华为彻底收复失地。11月底，Mate 80压轴登场，单周暴涨16%，在W49正式超越苹果，重新加冕中国市场销量冠军。</p>
  <h2><strong>小米：最高级的“涨价”是高端化</strong></h2>
  <p>小米17先行制人，Pro版销量首次超越基础版。不纠结参数，改拼副屏设计与“人车家全生态”，小米ASP（平均售价）提升20%，成为高端局最强黑马。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_f5070fa0db3342df84677c9e16370cf5@1200352198_oswg609113oswg1587oswg2245_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">36氪制图</p>
  <p>中国高端市场已成三足鼎立。</p>
  <p>得高端者得天下，2026年的硬骨头，更难啃了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_46fee94f57a547db8253e6827844c1b5@1200352198_oswg525496oswg1587oswg2245_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">36氪制图</p>
  <p>以上是我们的第②期内容。</p>
  <p>回看第①期内容👉<a href="https://36kr.com/p/3596129618821381" rel="noopener noreferrer" target="_blank">10倍增长、全球最贵公司和近4亿用户：AI新时代的5个信号｜36氪年终总结①</a></p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602022870484229</id>
            <title>「背叛」Scaling Law？两位Transformer作者撬动美国开源AI革命</title>
            <link>https://www.36kr.com/p/3602022870484229</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602022870484229</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 07:09:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近期，一个80亿参数的「小模型」引发AI圈热议。</p>
  <p>这个名为Rnj-1的开源模型，由Ashish Vaswani与Niki Parmar创办的Essential AI Labs推出。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_923f3ea4192748bbb7fe03178a599414@5091053_oswg546277oswg1080oswg1232_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他们是2017年那篇著名论文《注意力就是你所需要的一切》（Attention is All You Need）作者中的两位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_525496e0182c4be29ed945c2158e7618@5091053_oswg108997oswg1080oswg267_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以上八位作者同等贡献 ，其中Ashish与Illia共同设计并实现了首个Transformer 模型，并深度参与了全部研究工作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ec107771b56f47d5a800edb3084952a9@5091053_oswg1093963oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Ashish Vaswani</p>
  <p>Niki在研究的早期阶段负责设计、实现、调优并评估了大量模型变体，是模型架构探索与实验验证的核心贡献者之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_30a97f219d3f443f84c28f03049ce7c0@5091053_oswg598219oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Niki Parmar</p>
  <p>ChatGPT、Gemini、Claude、Llama……几乎所有我们熟知的大模型都采用了Transformer框架。</p>
  <p>这些早期玩家们在几年后将整个行业引向了比拼参数规模的AI军备竞赛。</p>
  <p>前不久，Google DeepMind CEO哈萨比斯（Demis Hassabis）还断言，要实现通用人工智能（AGI），当下主流大模型必须把「扩规模」这件事推到极致。</p>
  <p>他所指的「扩规模」是更多数据、更多算力、更大的模型，并强调它「至少是通往 AGI 的关键组件，甚至可能就是全部路径」。</p>
  <p>哈萨比斯的观点，在一定程度上代表了大模型领域由Transformer和Scaling Law所催生的「模型越大越强」的主流观点。</p>
  <p>7年后，同为Transformer论文的作者，Ashish Vaswani和Niki Parmar开始向这一主流观点发起了挑战：</p>
  <blockquote>
   <p>模型不一定越大就越聪明。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0a692317d0ac44d1bb51e74de5d5876a@5091053_oswg202101oswg1080oswg409_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>至少从算力效率的角度来看，就像上面这位网友说的那样：</p>
  <p>「大模型时代已经结束，真正懂行的人打造的小模型时代开始了。」</p>
  <p>在ChatGPT、Gemini、Claude之外，以Rnj-1为代表的小模型开辟了另一种思路。</p>
  <h2><strong>Vaswani的担忧与Rnj-1的诞生</strong></h2>
  <p>过去几年，砸向AI领域的钱越来越多、模型越来越大、训练越来越昂贵。</p>
  <p>Vaswani认为，AI领域巨额资金的涌入可能会妨碍技术本身的发展，因为以利润为导向的企业逐渐从科学家和学者手中夺取了主导权：</p>
  <p>「少数公司掌控着先进AI技术的生产、节奏和方向。他们决定了AI的演化方式，也决定了谁能从中受益……我们不能让封闭式的AI开发阻碍我们探索新的前沿。」</p>
  <p>Vaswani和Parmar希望推动构建一个健康、开放的生态，而不是封闭的塔尖。</p>
  <p>Essential AI Labs以及它的首款开源模型Rnj-1正是在这种理念下诞生的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_fd403cd8caf948078d56dc6a746396f4@5091053_oswg483796oswg1080oswg385_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Essential AI将构建前沿开源平台和智能工具作为自己的使命。</p>
  <p>Rnj-1的名称，则是来自著名数学家拉马努金（Srinivasa Ramanujan）。</p>
  <p>据Essential AI官方介绍，这款从零开始训练的80亿参数模型，在代码、数学与「智能体」推理上可「对齐前沿」水平，还可以在消费级GPU上运行，自由使用与修改。</p>
  <h2><strong>一把「瑞士军刀」式的小模型</strong></h2>
  <p>和动辄万亿参数的前沿大模型相比，Rnj-1并不起眼。</p>
  <p>它只是一个80亿参数的小模型，仅仅32k的上下文长度，遵循开源Gemma 3架构。</p>
  <p>既然不能和比别人比「身板」，就要拼技术。</p>
  <p>Rnj-1采用全局自注意力机制（global self-attention）和YaRN技术。</p>
  <p>global self-attention好比为模型配备了一双「全景眼睛」，无论给它多长的输入，都能一次全部看清。</p>
  <p>而YaRN则像是「长距离阅读辅助器」，让模型能在32k上下文中仍然保持清晰思考。</p>
  <p>Rnj-1的基础版与指令版在同尺寸开源模型中表现十分亮眼。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d1c6ebb8b7c1402a95f93ce691fe0374@5091053_oswg128608oswg1080oswg504_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2424aa59e57641908ccab5b71cb693b2@5091053_oswg136480oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>代码生成</strong></p>
  <p>在HumanEval+、MBPP+ 等算法类代码任务，以及BigCodeBench这类更广泛的编程任务中，Rnj-1 Base与Instruct的表现能与最强同规模开源模型竞争，有时甚至超越更大的GPT OSS 20B。</p>
  <p><strong>智能体能力</strong></p>
  <p>Rnj-1 Instruct是Rnj-1重点打造的能力之一， 在智能体式编码任务中表现尤为突出。</p>
  <p>在SWE-bench 上，Rnj-1 Instruct的表现比同尺寸模型强出近一个数量级，已接近大规模模型的水平。</p>
  <p>它会用 profiler（性能分析器）检查瓶颈，然后主动提出优化方案，甚至多轮迭代。</p>
  <p>例如在Enamel这一考察高效算法实现的任务中，Rnj-1 Instruct 超过了强力基线。</p>
  <p>在伯克利函数调用排行榜（BFCL）中，Rnj-1 Instruct的工具使用能力也领先同类模型。</p>
  <p><strong>数学与科学推理</strong></p>
  <p>在AIME'25（高难度高中数学）中，Rnj-1 Instruct的数学能力可与最强开源模型匹敌。</p>
  <p>Rnj-1 Base在Minerva-MATH上也与同规模模型保持一致。</p>
  <p>在GPQA-Diamond（包含生物、物理、化学的高难度题目）上，Rnj-1的表现也接近同尺寸模型中的领先水平。</p>
  <p><strong>量化稳定，不掉质量</strong></p>
  <p>Rnj-1对量化也非常稳健。</p>
  <p>这意味着它能在更便宜、更省电的显卡上跑得很快，模型质量几乎不受影响，真正实现人人可用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_63a63e43c7a94201ab9e945e507f7079@5091053_oswg74760oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从BF16到FP8再到NVFP4，在显著提升提示密集型工作负载的token吞吐量的同时，模型质量几乎不受影响。</p>
  <p>Token吞吐量数据基于NVIDIA B200 GPU测得，其中KV Cache的数据类型设为FP8，批大小为128。</p>
  <h2><strong>回到起点，不想再做「宇宙巨兽」了</strong></h2>
  <p>今年2月，Essential AI做了一个重要的决定：</p>
  <blockquote>
   <p>专注于基础能力的本身。</p>
  </blockquote>
  <p>在做研究和做产品两者之间，Essential AI更倾向于提升模型能力。</p>
  <p>DeepSeek R1发布后，世界都在讨论RL的强大，但Vaswani认为，压缩是模拟智能的核心要素，而语言模型的预测式预训练才是更合理的路径。</p>
  <p>Essential AI在早期预训练阶段便观察到模型出现反思与探索式推理的迹象，这印证了「强预训练是下游成功基础」的判断。</p>
  <p>他们认为强大的预训练本身就会产生推理能力，而不是靠后期堆RL补课。</p>
  <p>这是Essential AI迄今为止第一个也是最具根本性的抉择。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_7beaa53463e4449182004c4db7daf674@5091053_oswg134022oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>上图记录了Essential AI在每个阶段所取得的进展。</p>
  <p>Rnj-1是Essential AI从头开始训练的大模型。</p>
  <p>他们希望大模型在学习阶段不仅是「看很多数据」，而是能自己把数据分类、转换、混合，形成更好的理解方式。</p>
  <p>这样模型的「可测能力」（比如数学、代码、科学等可验证任务）会更强。</p>
  <p>研究团队通过数据分类研究，得到了一种新的「带重复惩罚的数据分布聚类与混合方法」，这种方法尤其提升了模型在STEM（科学、技术、工程、数学）方面的能力。</p>
  <p>此外，训练模型需要「优化器」来调整参数。</p>
  <p>Essential AI证明了Muon优化器相较AdamW更高效， 并开发了适配大模型的分片策略。</p>
  <p>Essential AI的研究人员认为，大模型应该不仅能理解代码，更应该模拟程序在不同环境中的执行行为，Rnj-1在这一方向上进行了大规模尝试。</p>
  <p>为了让基础模型学会自动「改进代码」，研究人员还投入研究「代码演化」的建模。</p>
  <p>这些方向均在小模型上通过验证，显著提升了Rnj-1的工程能力。</p>
  <p>在预训练末期，Essential AI团队确信Rnj-1已具备数学、编程与科学知识等潜在能力。</p>
  <p>接下来的问题是如何通过适量监督微调，唤醒其指令遵循与复杂推理能力，并验证其在长对话与现实难题中的表现。</p>
  <p>Essential AI在后训练方案上借鉴了YaRN长上下文中期训练、Nemotron以及简单智能体环境。</p>
  <p>其后训练主要有三项任务：</p>
  <p>研究定向数据对推理与智能体能力的影响；</p>
  <p>团队亲自「上手体验」模型，观察质变；</p>
  <p>收集下游反馈，为下一轮预训练下注提供依据</p>
  <p>Vaswani认为，有许多令人难以抗拒的想法正在争夺研究团队的注意力。</p>
  <p>比如，他们对条件计算、扩展并增强模型处理更长上下文的能力，以及低精度训练充满热情。</p>
  <p>在中期内，Essential AI将继续推进压缩这一核心理念，拓展计划模拟的程序行为的类型和范围，并推动代码演化。</p>
  <p>Vaswani预计，诸如将强化学习等扩展性思路用于培养复杂推理能力的方法，将很快出现在Essential AI的路线图上。</p>
  <p>在官方博客中，Vaswani用先驱计算机科学家Alan Perlis的话表达了自己的心声：</p>
  <blockquote>
   <p>我认为，在计算机科学领域，我们必须始终让计算保持趣味性，这一点极其重要……</p>
   <p>我认为，我们有责任不断拓展计算机的边界，引领它们走向新的方向，并让这种乐趣持续存在……</p>
   <p>最重要的是，我希望我们不要变成传教士。不要觉得自己像个推销圣 经的推销员。这世上那样的人已经太多了。你所了解的计算知识，别人终会学到。不要觉得成功计算的钥匙只掌握在你手中。</p>
   <p>我相信并希望，你手中握有的是智慧：一种能够超越最初接触机器时的认知，看到它更多可能性，并让它变得更强的能力。</p>
  </blockquote>
  <p>开源平台Essential AI的创建，以及此次Rnj-1的推出，旨在推动美国AI开源领域的发展，抢夺在轻量化开源生态话语权，目前这一领域正由中国企业主导。</p>
  <p>开源生态，将推动大模型在「越大越好」行业竞争格局之外，探索开放、轻量化的新路径，加速AI人人可用时代的到来。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://www.bloomberg.com/news/articles/2025-12-08/transformer-paper-authors-at-ai-startup-debut-open-source-model?srnd=phx-ai%20</p>
  <p>https://www.essential.ai/research/rnj-1</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/xGm1MbwrVQIwG3dhmx0zdw" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，编辑：元宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602068153664514</id>
            <title>AI无限拉低了普通人造假的门槛</title>
            <link>https://www.36kr.com/p/3602068153664514</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602068153664514</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 07:08:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在很多人的印象里，造假是少数人的事。它需要专业的技术和硬件设备，需要行业人脉积累，造假者往往隐匿在灰黑产缝隙，是神秘的、恐怖的、没有道德底线的，与大众保持着既远又近的距离。</p>
  <p>但今年开始，一群人感受到了明显的变化。</p>
  <p>11月，毛绒玩偶商家于瑾第一次遭遇AI假图仅退款。到货一周后，买家发来一张图申请仅退款，在店铺客服以人为损坏为由驳回后，买家申请平台介入并成功拿回了50元。</p>
  <p>但那张申请仅退款的图有一个不合常理的地方——玩偶柔软的裙边上，有类似陶瓷制品的坚硬裂痕。于瑾认定这是AI假图，发到社交平台吐槽。后来，在媒体的介入下，平台自掏腰包，把这50元返还给了于瑾，用AI假图申请仅退款的买家却销声匿迹。</p>
  <p>于瑾意识到，AI的普及让“羊毛党”的恶意退款成本更低了。一台手机、一句提示词就能生成一张以假乱真的图片，薅走一个价值一百多元的玩偶，放在二手平台倒卖。“不用付出什么，也不会得到什么惩罚。”</p>
  <p>今年更早时候，公关齐云也经历过类似的冲击。他服务的一家上市公司被AI生成的黑稿攻击，文中细节让他直言“离谱得很”。但受制于内容平台规则，他和同事们不得不花整整两天时间，对文中细节一一举证、盖章、申诉，才让这篇可能只花了几十秒生成的帖文从平台上消失。</p>
  <p>齐云说，从业十多年，以前是和人基于事实交流，是一种智力上的挑战，现在面对AI和AI编出来的谣言，感觉智商受到了侮辱，更生气，却又无可奈何。</p>
  <p>这是过去三年，生成式AI爆发式发展的另一面。AI大模型在生成文字、图片、视频、音频上的能力突飞猛进，几乎所有人都能零门槛、零成本地使用AI。这些人中，不仅有AIGC艺术家、前沿科技热爱者，也有羊毛党和靠流量吃饭的MCN机构。</p>
  <p>结果就是，造假的门槛越来越低，有意或无意参与的人越来越多，而平台的审核机制还停留在简单的比对和打标签，受害者被欺骗、被拖累还要付出成千上万倍的成本被迫自证。当造假变成低成本、低风险、高收益的一件事，就会有越来越多的普通人加入造假行列，共同构造一个充满虚假信息的世界。</p>
  <h2><strong>从无到有，学会鉴别AI假图</strong></h2>
  <p>最初，看到买家发来的图片时，店里无一人怀疑过真假。</p>
  <p>11月17日，买家拿到玩偶一个多星期后，于瑾店铺的客服收到仅退款申请和一张佐证图片。图中，粉色的毛绒玩偶脏兮兮的，裙摆有被火焰灼烧过的痕迹。客服把图片发到工作群，大家一致认为是人为损坏。“有可能是掉在泥里或者是掉在火里了”，于瑾说。</p>
  <p>于是，按照常规流程，客服和买家说明，发货全程有监控录像，保证全新，到货后人为损坏不属于商品质量问题，不支持仅退款，驳回了买家申请。但买家不依不饶，直接申请平台介入，当天拿到了50元的赔偿。</p>
  <p>这属于恶意退款，于瑾说。几乎所有电商商家都遇到过类似的事。正常情况下，于瑾遇到的买家，申请退款的理由大多是开线、勾丝问题，与这次大不相同。被扣款后，于瑾马上准备证据申诉，但同事随口一句话提醒了她——这张图越看越奇怪，像AI生成的。</p>
  <p>为了确认，于瑾找做AI相关工作的朋友帮忙鉴定，结果显示有AI痕迹；她又自己问了AI助手，同样提示图片进行了AI修改——“服饰的裂纹纹理过于规整且缺乏真实材质的物理逻辑”。</p>
  <p>第一次遇到这种情况，于瑾有些无奈。她把证据和建议都整理好申诉，但平台并未采纳，驳回了她的诉求，50元退款到达买家账户。对商家来说，这意味着挽回损失的唯一渠道失效了。</p>
  <p>于瑾不知道该怎么办了，只能把自己的经历发到社交平台，希望借此提醒同行。也因此，媒体找到她，帮忙联系平台拿回了款项。</p>
  <p>但她其实并不开心。于瑾愤懑地跟我说：“造假没什么技术含量，也没有什么门槛，任何一张图拿给AI，它都可以帮你修，作恶的成本很低，被发现了也不会得到什么惩罚。”她很清楚，这50元退款由平台垫付，已经退给买家的款项没有追回。折腾一番，作为商家的她费心费力，讨了个不开心，而造假者则实付款167元，拿回了50元，以及一个标价179元的玩偶。</p>
  <p>“双11”期间，类似的案例被密集报道，“ai假图 仅退款”等相关话题冲上了社交平台热搜榜，挑动着商家们敏感的神经。偏偏这时，仍有人选择顶风作案。</p>
  <p>11月21日，键盘商家柑橘收到一位买家的仅退款申请，这位买家同样上传了一张佐证图片，申请平台介入。此时距离这位买家签收商品，已过去了半个月。</p>
  <p>柑橘一眼就看出图片是AI生成的——佐证图片的构图、背景、光影，和买家签收第三天发布的评价图一模一样，只是多个键帽都有开裂、破损、污渍、变形，过于夸张。她对这种显而易见的破绽感到无语，也同步整理好证据提交给了平台。这一次，平台没草率处理，而是驳回了买家申请，关闭退款渠道。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5868ff8fbe07416791677dca736758fe@5091053_oswg201128oswg1080oswg1007_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">上图为买家评价图，下图为AI假图。图源：受访者供图</p>
  <p>从收件人信息来看，柑橘很明确地知道，自己面对的不是老练的羊毛党，而是一位普通的大学生。用AI假图仅退款的人具像化了。</p>
  <p>在很多老电商人心里，职业羊毛党至少还是一个特定群体，有套路、有话术、有明确的牟利目的。可如今，一位原本和灰产毫无关系的人，只需要一个免费应用和几句提示词，就能生成一套足以骗过平台审核的证据链；退款成功后，商品挂二手平台倒卖，再赚一笔。</p>
  <p>对商家来说，这种变化带来的不只是损失，更是一种陌生的无力，防不胜防。</p>
  <h2><strong>AI突破造谣想象力</strong></h2>
  <p>电商平台上的AI假图仅退款只是冰山一角。随着AI大模型技术在生文、生图、生视频、生音频四个方向的逐渐成熟和普及，过去只有专业团队才能完成的造假，如今被压缩成人人可上手的简单操作。</p>
  <p>一个普通用户，可以通过文生图做商品损坏图，也可以用文生视频合成目击现场；生成过程只需要几秒钟，被平台呈现的可信度却与真实内容几乎无异。</p>
  <p>这不是某一个技术问题，而是一条由无数轻量工具组成的造假矩阵。如同电商商家感受到的那样，内容行业也在经历类似的冲击：名人被AI换脸带货投诉无果、MCN机构用AI大规模造谣、企业被源源不断的AI黑稿攻击……</p>
  <p>“以前造谣要看人的想象力，一个人一天造一两个谣顶天了，但AI可以几秒钟，在一篇稿件里造十个谣。”齐云在公关行业从业十多年，亲历了AI造假给信息生态带来的轰炸。</p>
  <p>半年前，日常舆情监控中，齐云发现了一篇公众号文章。文章乍看像个正经新闻，等他读下来才惊觉内容之离谱。</p>
  <p>文中写，齐云服务的这家公司，其董事长办公室墙上挂着K线图，又写财务总监某某说过哪些话。“离谱得很。我们董事长办公室没有图，财务总监也不叫那个名字。”齐云说。但文章就那么像模像样地发了出来，还引发了不少讨论。</p>
  <p>这是齐云遇到的典型AI黑稿，主要特点就是细节丰富但无中生有，还比较容易鉴别，更多的是非典型AI文章，真假、人机参半。在他看来，对于专门生产黑稿的人来说，AI只是一个工具，以前是人工，“写财经文章还是要稍微懂点的，一天也就生产1到2条”，现在有了AI，成本和门槛更低了，生产效率变高了，但人还是那批人。</p>
  <p>黑稿灰产把AI的能力嵌入商业模式，形成运作更便捷的利益链条：一条链，用AI黑稿倒逼企业投放广告，黑稿越多、越难辟谣，企业越焦虑，就越容易掏钱消灾；</p>
  <p>另一条链，用AI写的黑稿给投资群引流、卖课，标题越耸动、内容越“看似内幕”，越容易吸引想抓住风口的人。AI能秒产一批“重大利好/利空”的假截图、假分析，塑造几位股神般的王哥李姐，完成从公域推文到私域社群的流量转化，最终通过卖课、咨询获利。</p>
  <p>类似的模式还有很多。例如，2024年6月，央视新闻报道，一MCN机构通过AI软件，自动在网络上抓取相关信息，生成配套图文，并包装成博眼球的“假新闻”，通过流量变现；日均生成4000-7000篇，每天收入在1万元以上。</p>
  <p>就在上个月底，小鹏汽车也遭遇了一次典型的AI造假事件。彼时，一段以小鹏汽车广州车展展台为背景的低俗色情视频在社交平台快速传播，画面里人物的衣着、光影和展台几乎无缝衔接，让不少网友信以为真。小鹏汽车法务部介入后，警方最终确认，视频由一名男子李某利用AI技术生成，仅“为炫耀个人技术”，并非任何真实事件。造假在这里不再是灰产团队，而是一个普通人“顺手试试”的产物。</p>
  <p>这种变化让人不安——AI已经把造假的门槛降到几乎与好奇心齐平的位置，只需要一次尝试、几句提示词，每个人都可能成为“造假者”，不是因为恶意，而是因为轻易、便利、无成本，以及“反正不会怎样”的心理。</p>
  <h2><strong>平台机制跟不上AI灰产节奏</strong></h2>
  <p>生成式AI的普及，正在把造假变成零门槛、零成本的日常行为。</p>
  <p>事实上，对于大多数AI助手来说，它并不认为满足用户的要求是在协助造假，一句“你能让这张图片上的橙子看着像坏了一样吗”，它能机灵地给橙子加上霉斑，还会主动问你要不要生成一段配套的视频。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6d3c6751b9f84178afaec537b95d5e6c@5091053_oswg974194oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图为AI生成的食物变质照片。图源：豆包App生成</p>
  <p>而与这种轻松制造虚假相对的，是平台的审核机制仍停留在过去。</p>
  <p>为了处理那条离谱的AI黑稿，齐云和同事前前后后忙了整整两天时间。第一次，他们上传加盖公章的投诉函件，向平台申请删文，失败。第二次，他们给黑稿里的虚假信息一条一条地写反驳、举证；直接说公司财务总监不叫某某还不行，需要写明真正的财务总监姓甚名谁，并附上公司在交易所发布的公告签名截图。</p>
  <p>整个过程是繁琐而折磨人的。“你造我的谣，我还要给你举证。”齐云有些愤懑，“我没有说过这个话，请问我怎么给你举证？董事长办公室没有这个图，难道我要去他办公室拍一张照片吗？就算我拍了照片，你又怎么确定这真的是我董事长办公室的照片？”</p>
  <p>而如果要报警、起诉则更加麻烦。齐云直言，他曾经服务的上市公司，法务部总共才六七个人，AI黑稿漫天飞，一个一个地走起诉流程，要走到猴年马月。起诉或报警并不适合绝大部分公司。</p>
  <p>在这种失控感之下，齐云意识到，平台并没有跟上AI灰产的节奏，“我不懂技术，但是我觉得到底什么是AI生成的东西，技术公司应该是有能力去判别的”。</p>
  <p>目前，在AI生成内容的管理上，各个社交平台主要采取“打标签”的方式，针对用户上传的、AI生成的图片和视频，在顶部或底部附一行小字提醒，该内容系AI生成；而对于文字内容，除平台内置的AI总结、AI搜索类工具外，用户上传的文字内容并不会被标识是否由AI生成。</p>
  <p>AI生产的文字内容成了平台管理的真空地带，技术上也相对更难识别。即使是较为严谨的学术论文AI率，即AI生成内容比例的检测，也在今年毕业季引发大量讨论，被质疑误判较多，并不靠谱。</p>
  <p>当AI批量产出内容时，信息生态的失衡更明显了。“高质量内容被淹没了。”齐云说。在专业圈层里，人们还能手动筛选公众号文章，但在大众信息池里，算法推送的往往是那些低成本、高刺激、批量复制的AI内容。大量AI生成的低质内容，正在把真实信息挤到更窄的缝隙里。</p>
  <p>齐云很坦诚地说，曾经自己喜欢和人基于事实讨论，哪怕是负面稿件，至少也是一种智力上的挑战，但现在面对AI和AI编出来的谣言，他感觉智商受到了侮辱，“你还不知道该怎么去反驳，怎么去很好地证明它就是个傻子，你不觉得它是一个合格的对手，你就会很生气。”</p>
  <p>最终，齐云心灰意冷地转岗了。他说，一个公关，整天琢磨怎么跟技术平台去打交道，怎么总结投诉最有用，怎么利用平台算法去限制文章的传播，这跟他刚入行的时候，已经不是一回事儿了。</p>
  <p>可不是每个人都能转身离开，更多的受害者，生活还要继续，工作流程无法停止。一边是随手就能生成的虚假内容，一边是日复一日的自证、申诉。原本应该由技术解决的问题，被悄悄转嫁给了个体。</p>
  <p>当AI把造假成本压到历史最低，又反向把维权成本推高，中间的缝隙，是个体的困惑和试探。造假开始与每个人的选择纠缠。当一张假图、一段假视频、一篇假文章都能被轻易生成，当违法与不违法之间只剩下一句提示词的距离，“能不能”与“该不该”开始混在一起，真伪的界限不再由事实决定，而是由人心决定。</p>
  <p>（文中受访者皆为化名。）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/-vcBaH19ztCekBoA0ALJ5A" rel="noopener noreferrer nofollow" target="_blank">“镜相工作室”</a>，作者：黄依婷，编辑：卢枕，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3600788540309509</id>
            <title>每日路演精选项目｜人工智能、低空经济、新材料、生物制造、核聚变等领域</title>
            <link>https://www.36kr.com/p/3600788540309509</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3600788540309509</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 07:06:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>36氪作为<strong>中国最大的新经济媒体平台</strong>，过去通过与投资机构、基金合伙人的深度合作，大幅提升企业融资机会。随着新经济不断发展的十年，36氪沉淀和积累了大量一级市场投资人资源。&nbsp;</p>
  <p><strong>「每日路演」</strong>是针对优质创业项目开放投资人社群、进行新型的线上闭门路演，持续为创业者与投资人两端提供深度运营服务。<strong>to 高潜创业者-高效输出公司价值亮点+与投资人进行深度交流；to 投资人与投资机构-多维度、低成本对话项目决策人+先一步看到未来，掌握一手资讯，以媒体资源与平台优势助力创投双端对接。</strong></p>
  <p>本期我们精选汇总了六个社群精选路演项目信息。如果您对本文中的项目感兴趣，希望可以对接到项目方，或者如果您手中有好项目需要融资对接更多投资人，欢迎与我们联系<strong>（底部扫码添加运营官，备注项目对接）</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_c73863684dd54bc5893c2a72c20c8db0@5807859_oswg387256oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">对接项目请扫码添加文章底部专属运营官微信</p>
  <h2><strong>1.宇耀科技-人工智能新材料预测大模型—重新定义材料研发范式</strong></h2>
  <p><strong>【项目概要】</strong>响应国家聚焦原始创新战略，团队经六年的艰苦研究，将人工智能引入了新材料研发。解决传统研发的痛点和瓶颈，真正做到从0到1的突破，自主开发的AI新材料预测大模型，基于自主积累的有效实验数据，为客户提供新材料研发解决方案或模型的就地部署。</p>
  <p><strong>【融资需求】</strong>A轮，2500万-7000万人民币</p>
  <p><strong>【项目亮点】</strong></p>
  <p>1）范式级技术突破：全球首创“物理信息融合的AI新材料预测大模型”，将材料物理基本原理嵌入神经网络，实现了从“试错研发”到“AI理性设计”的研发范式根本变革。</p>
  <p>2）颠覆性效能提升：平台已验证能将材料研发周期缩短80%、成本降低70%、失败率从80%以上降至5%以下，解决了行业长期存在的核心痛点。</p>
  <p>3）独家数据与闭环壁垒：以六年积累、自主可控的高质量实验数据库为核心驱动力，构建了“AI设计-实验验证-数据反馈”的自进化闭环，形成了坚实的数据与迭代壁垒。</p>
  <p>4）国家级验证与前沿成果：公司已获批国家级博士后科研工作站，技术成果被列入工信部垂直领域大模型示范应用案例、中关村科学城AI全景赋能典型案例、北京市经信局2025工业互联网唯一一个新材料行业特色平台，并从平台中完成仿生鼻传感器、6G可调谐器件、核防护薄膜等10余项关键领域新材料技术储备，并完成实验或工程试验验证。</p>
  <p>5）顶尖交叉学科团队：由国际材料基因芯片发明人项晓东博士领衔，组建了覆盖材料科学、人工智能、量子计算等多学科的“梦之队”，具备从理论突破到产业化的全链条能力。</p>
  <p>6）明确商业与社会价值：商业模式清晰（Saas微服务+技术平台全流程服务+核心材料产业化），直击千亿级市场，其提升研发前端效率的核心价值，能为整个产业链乃至区域经济高质量发展注入强大动力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_19b32996754c4c70bce885d0b6930071@5807859_oswg237858oswg850oswg487_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇耀科技-模型平台界面及技术流程&nbsp;</p>
  <h2><strong>2.蓝色向量</strong></h2>
  <p><strong>【项目概要】</strong>载人evtol整机及航空工业软件</p>
  <p><strong>【融资需求】</strong>Pre-A轮 1亿元人民币</p>
  <p><strong>【历史股东】</strong>厚雪资本、险峰长青、东方嘉富等</p>
  <p><strong>【项目亮点】</strong>V30是全球首款同时满足民航级10⁻⁹高安全性标准与开放式系统架构的智能电动垂直起降飞行器，核心团队由来自中国航空工业、中国商飞、柯林斯航空、昂际航电、阿里巴巴等企业的资深专家构成。蓝色向量是民航局系统内航投集团在低空经济领域联合创始的首家以“软件定义飞机”为理念进行设计的两吨级以上智能化载客eVTOL制造商，同时与隶属中国商飞的商飞软件在电子电气架构和适航研发管理软件领域展开深度合作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_589b41b10aa340e0b9a28deeec1af939@5807859_oswg579703oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">蓝色向量SKYLA-V30&nbsp;</p>
  <h2>3.毫秒智控</h2>
  <p><strong>【项目概要】</strong>中国线控转向SBW、REPS及PPK领先企业</p>
  <p><strong>【融资需求】</strong>Pre-A轮 5000万人民币</p>
  <p><strong>【历史股东】</strong>厚雪资本</p>
  <p><strong>【项目亮点】</strong>创始团队作为核心成员联合中汽中心等单位参与了国家标准GB17675-2025的制定工作。团队具备覆盖系统、电控、算法及功能安全等全栈式技术能力。核心成员曾任职于博世、华为、上汽、蔚来、万都等国内外主流汽车零部件供应商或整车企业，在相关领域拥有累计数百万套级产品的量产交付经验。</p>
  <h2><strong>4.百识电子</strong></h2>
  <p><strong>【项目概要】</strong>南京百识电子科技有限公司成立于2019年，是国内专门生产第三代半导体碳化硅及氮化镓相关外延片的领导厂商，目前已于南京浦口经济技术开发区建立了完整的研发总部与生产中心，提供六吋、八吋碳化硅以及硅基氮化镓专业外延代工服务,以满足新世代功率器件开发市场需求。产品包含以碳化硅SiC为衬底(SiC on SiC、GaN on SiC)，以及硅为衬底（GaN on Silicon）的外延片，针对大尺寸、高压、高功率以及射频微波等应用市场提供高品质、高一致性、高可靠度的碳化硅及氮化镓外延片产品及专业代工服务。除了标准规格外延片，公司亦可针对特殊应用市场需求，提供客制化规格外延服务及器件开发所需的关键制程。</p>
  <p><strong>【融资需求】</strong>B+轮，1亿元人民币</p>
  <p><strong>【历史股东】</strong>华映资本、和利资本、杭实资管、台达电、涌铧投资、GRC富华资本等</p>
  <p><strong>【项目亮点】</strong></p>
  <p>1）核心团队来自于亚洲碳化硅、氮化镓外延片大厂，具备外延工艺开发、良率保障、设备改良等全栈能力；</p>
  <p>2）工艺技术全部来自公司自主开发，拥有超1000平米10级无尘研发制造中心，配备高端研发测试设备，在产品质量上，公司能够在外延规格书上提供坑洞指标（坑洞指标和沟槽式MOS质量直接相关），6英寸碳化硅外延片SBD级投片良率高达98%-99%；6英寸碳化硅外延片MOSFET级投片良率高达95%，是市场上少数具备可提供高质量3300V、6500V耐压的外延片量产供货厂商。此外，8吋碳化硅外延片已实现批量销售，且获得海外知名客户认证；</p>
  <p>3）目前，公司已完成国产化进程，衬底材料来自于国内厂商，生产设备基本实现全国产自动化；</p>
  <p>4）品线齐全，覆盖SiC功率、GaN功率、GaN射频外延片，满足新能源汽车、5G通信、光伏储能、智能电网等多领域需求，此外，还提供客制化规格外延服务，可根据客户需求定制特殊应用的外延片，满足不同场景的技术要求；</p>
  <p>5）截至目前公司已累积42项专利，在全部产品技术指标上均达到世界领先水平；2025年10月，百识电子通过2025年国家级专精特新“小巨人”企业评审认定，标志着公司的综合实力与行业影响力获得国家层面的高度认可。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_1fe5b1f09259434784528d41faa3fa1b@5807859_oswg838145oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">百识电子产品展示&nbsp;</p>
  <h2><strong>5.中科国生</strong></h2>
  <p><strong>【项目概要】</strong>中科国生是全球生物基材料制造领域的先行者，专注于呋喃类化学品的创新开发与产业化。公司成立于2021年，核心团队毕业于中科院大连化物所、清华大学等知名院校，在生物质催化转化、呋喃类材料设计和化工生产领域拥有深厚的研发和产业化经验。</p>
  <p>凭借自研的连续化工艺和短流程生产方案，公司实现了5-羟甲基糠醛（HMF）、呋喃二甲酸（FDCA）等关键化合物和单体的规模化生产，大幅降低了产品成本，并在浙江丽水和江苏泰兴设有百吨级和万吨级工厂，成功在高阻隔包装、生物基纤维、芳纶阻燃纤维等行业实现新原料的产业化落地，领跑行业产业化进程。</p>
  <p><strong>【融资需求】</strong>B轮、1-1.5亿元人民币</p>
  <p><strong>【历史股东】</strong>华映资本、君联资本、经纬创投、五源资本、中信金石、普华资本、余杭国投等</p>
  <p><strong>【项目亮点】</strong></p>
  <p>1）核心团队毕业于中科院大连化物所、清华大学等知名院校，长期深耕生物质催化转化与呋喃类材料方向，具备从分子设计、催化体系构建到工程放大与稳定生产的完整能力，是少数同时具备“科研深度+工业化经验”的生物基材料团队；</p>
  <p>2）全球首创双连续化工艺，相比传统间歇釜式生产HMF工艺，生产效率提升5倍以上，规模化程度提高80%，并进一步突破FDCA氧化环节的催化剂稳定性难题（通过非贵金属催化剂与非浆态反应体系，实现粗品HMF直接高效转化为聚合级FDCA），综合成本削减近70%，成为全球少数掌握“HMF→FDCA”全流程连续化量产技术的企业，显著提升了商业化可行性与长期竞争壁垒；</p>
  <p>3）以HMF为起点，以市场需求量最大的FDCA为核心单体，公司已构建覆盖“生物质-单体-衍生物-终端材料”的全链条研发与产业体系，相关技术已完成多条产品线的商业化验证，为后续多场景、多行业扩展奠定平台基础；</p>
  <p>4）中科国生已联合产业链上下游，形成覆盖高阻隔包装、生物基纤维等方向的产业协同网络。在包装领域，生物基高阻隔材料已进入啤酒、碳酸饮料等国际终端品牌的大货验证阶段；在纤维领域，PEF生物基纤维已与多家头部服装品牌推进大货验证，推进多种混纺方案（与棉、羊毛、天丝等）的性能验证，应用场景覆盖服装、功能面料及家纺领域；</p>
  <p>5）累计申请专利超120项（覆盖HMF催化、FDCA纯化、衍生物合成等全产业链环节），其中“双-(5-羟甲基糠基)醚的制备方法”（非贵金属催化剂降低制造成本）、“高选择性制备羟基脂肪酸”等核心专利已获授权；已成功构建出具有自主知识产权的连续化工艺体系，年产FDCA可达400吨，并已累计向全球交付超过200吨，实现了商业化落地；</p>
  <p>6）2025年，中科国生FDCA产品完成欧盟REACH法规完整注册，成为国内首家实现该项合规的企业。同时，公司亦为国内首家完成FDCA新化学物质环境管理常规登记及产品LCA生命周期评价的企业，为后续全球市场拓展及下游品牌合作奠定了坚实的合规基础。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_edef9b2c2a784aedb477373742cecde2@5807859_oswg1025849oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">中科国生 2,5-呋喃二甲酸（FDCA）</p>
  <p><strong>6.瀚海聚能</strong></p>
  <p><strong>【项目概要】</strong>瀚海聚能是国内首家直线型场反位形可控核聚变商业公司，成立于2022年12月30日，聚焦场反位形装置及其配套的等离子体源与诊断系统软硬件研发，为未来商业聚变发电堆提供高性价比、高可靠性的核心组件和整体解决方案。同时通过聚变研发开发中子源中间产品，应用于医用同位素、BNCT、中子成像、核废料处理等领域，实现可控核聚变技术的早、中、长期商业化价值。</p>
  <p><strong>【融资需求】</strong>Pre-A轮，2亿元人民币</p>
  <p><strong>【历史股东】</strong>华映资本、厚实资本、轻舟资本、奇绩创坛等</p>
  <p><strong>【项目亮点】</strong></p>
  <p>1）采用直线型场反位形（FRC）聚变技术路线，区别于传统的托卡马克装置，具有结构简单、模块化设计的优势，建造成本仅为托卡马克的1/5至1/10，磁体用量减少80%以上，装置体积缩小50%，能量效率更高，等离子体自组织特性减少能量损耗，相同磁场强度下聚变功率输出可达托卡马克的100至1000倍，且兼容氢-硼等先进燃料，燃料利用率更高。</p>
  <p>2）核心技术100%由国内团队自主原创，实现了从装置设计、制造到等离子体点亮的全流程国产化，打破了国外技术垄断，为我国可控核聚变技术发展奠定了基础；</p>
  <p>3）2025年7月成功实现中国首台商业化直线型场反位形聚变装置（HHMAX-901）等离子体点亮，标志着FRC技术从实验室迈向应用端，是目前国内该技术路线商业化应用的重大突破；</p>
  <p>4）制定清晰的“三步走”战略，计划2027-2028年建造第二代装置，建设10MW功率发电主机；2028-2030年建造第三代装置，建设50MW发电主机及示范电站。</p>
  <p>5）采用“边研发边转化”的“沿途下蛋”商业模式，利用核聚变过程中产生的中子开发癌症治疗（BNCT）、中子成像及核废料处理等技术应用，孵化沿途商业化产品，提前实现部分商业价值；</p>
  <p>6）成都作为项目所在地，拥有丰富的科研资源、完整的产业链以及政策支持，吸引了国内外顶尖人才加入。公司核心团队来自于中物院、海内外可控核聚变公司以及中科大、清华等国内高校院所的科学家与研发人员，具备深厚的行业经验和技术积累</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_c5add68b94d7410c93ebc8c4cbe02ac5@5807859_oswg249566oswg1080oswg1195_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">瀚海聚能HHMAX-901主机成功点亮</p>
  <h2><strong>欢迎对接优质在融项目</strong></h2>
  <p>对于创业者和投资人来说，行业洗牌也意味着新的机遇，每一次的“危机”都是高潜项目破局而立的重要节点。36氪将持续提供解决企业及投资人不同阶段需求的活动，为资本市场注入信心。</p>
  <p><strong>如果您对本文中的项目感兴趣，希望可以对接到项目方，或者如果您手中有好项目需要融资对接更多投资人，欢迎与我们联系。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251218/v2_7c93007a5f3948f59069a758bfefc02c@5807859_oswg103054oswg723oswg730_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">扫码添加小助手，对接项目</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602053253923843</id>
            <title>三年半亏损超20亿，「东方迪士尼」掌舵人蔡东青跨界闯关换电IPO</title>
            <link>https://www.36kr.com/p/3602053253923843</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602053253923843</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 06:22:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>蔚来方面发布消息，12月18日，旗下蔚来能源与中安能源首批合作共建的50座充换电站在安徽省内投入运营，其至今已在充换电技术和基础设施领域累计投入约180亿元。</p>
  <p>随着换电商业模式逐步发展，赛道玩家正加速引涌入资本市场。近日，换电服务企业奥动新能源股份有限公司（简称“奥动新能源”）向香港联交所递交上市申请。</p>
  <p>招股书显示，2016年6月，蔡东青和张建平共同创立了奥动新能源，二人分别任董事长和副董事长，前者负责集团日常运营和管理，后者负责主导技术研发。巧合的是，公司曾于2018年获得蔚来资本的战略投资，随后又吸纳了广州金贤、福建奥兴、华克斯、厦门奥奕、广州创动客等企业的多轮融资。</p>
  <p>相较于奥动新能源，蔡东青执掌的另一家企业奥飞娱乐股份有限公司更为知名。成立于1997年的奥飞娱乐是中国首家动漫上市公司，运营着《喜洋洋与灰太狼》《超级飞侠》《巴啦啦小魔仙》《铠甲勇士》等热门IP，旗下影视公司还曾参与投资周星驰的大热电影《美人鱼》。公司希望通过自身强大的IP资源整合及运营能力，构筑“东方迪士尼”。</p>
  <p>现如今，蔡东青这位资本市场的老手，正将跨域布局的操盘经验复制到换电赛道。根据规划，奥动新能源上市募集的资金拟用于迭代及优化换电解决方案、推动技术开发、推广及营销换电解决方案、提升运营能力等。</p>
  <p>但在尚未形成统一标准的换电行业，奥动新能源仍需面对诸多挑战。</p>
  <h2><strong>1</strong></h2>
  <h2><strong>亏损持续，谨慎推进轻资产模式</strong></h2>
  <p>奥动新能源的主要收入来源于轻资产、重资产两种商业模式，轻资产模式聚焦于提供换电运营解决方案，重资产模式则是通过自有换电站直接提供换电服务。</p>
  <p>2022-2024年全年及2025年上半年，奥动新能源分别实现营收11.06亿、11.55亿元、9.26亿及3.24亿元。据灼识咨询的资料，按2024年换电站运营服务产生的收入计，该公司是中国最大的独立第三方换电解决方案提供商。</p>
  <p>尽管如此，因换电业务前期投入较大且各项收入暂不稳定，该公司尚未实现盈利，各期内毛损率分别为15.7%、3.4%、3.7%、8.9%，净亏损额分别为7.85亿、6.55亿、4.19亿及1.57亿元，仍需外部资方进行输血。</p>
  <p>奥动新能源在招股书中披露，公司自2022年起便启动轻资产商业模式的拓展布局。然而受市场竞争加剧的影响，换电站投资者的偏好发生明显转向，更青睐布局更紧凑、自动化程度更高且前期投资门槛更低的换电站。</p>
  <p>鉴于前述挑战，公司不仅出现换电设备销售收入、换电站及模组使用率（均属于轻资产模式）双双下滑，其换电运营解决方案收入占总收入的比重亦呈现连年下降态势，从2022年的66.1%一路降至2024年的28.9%。2025年上半年，该占比进一步下滑至17.1%。</p>
  <p>且在盈利能力上，轻资产模式明显优于重资产模式，两项业务收入比重的变化亦会影响公司整体盈利水平。</p>
  <p>近几年，奥动新能源换电运营解决方案业务的毛利率呈整体上升态势，至2025年上半年已达到24.3%。</p>
  <p>而自有换电站换电服务的收入却一直未能覆盖成本。尽管换电站前期建设为一次性固定资产投入，且相关成本逐步均摊后毛损率已有所下降，但因市场竞争加剧导致相关业务收入下滑，今年上半年，该项业务毛损率仍达23.3%，同比提升6.5个百分点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_e3a0186cca794e08b823e63fa421e89c@5091053_oswg216486oswg1080oswg645_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">各财务周期内，奥动新能源旗下业务毛利率（图/招股书截图）</p>
  <p>管理层并非没有认识到问题所在。招股书中提及，其已逐步构建更轻量化的轻资产服务模式，并采取审慎自律的方针推进产能部署，根据市场发展的实际节奏动态调整产量。“相较于激进扩大生产规模，我们更注重业务稳定性、执行质量及长期服务可行性，并充分考量各地区市场的动态变化与发展潜力。”</p>
  <h2><strong>2</strong></h2>
  <h2><strong>绑定车企推换电车型，是否为最优解？</strong></h2>
  <p>换电作为新能源汽车的重要补能方式之一，其商业价值与发展前景频遭外界质疑。相关争议主要集中于两个方面：其一，快充技术的快速迭代是否将对换电模式形成完全替代；其二，建设换电站的高昂成本是否会制约该模式的规模化扩张。在纯电车型市占率不断提升，且自身正在冲刺盈利转正的当下，自身拥有换电车型的蔚来也未能完全摆脱质疑。</p>
  <p>而在行业争议未消、换电模式市场化推进仍存阻力的背景下，换电服务企业的经营稳定性更易受主机厂布局影响。</p>
  <p>2022-2024年全年及2025年上半年，奥动新能源贸易应收款项及合同资产总额中，分别有18%、14%、16%及17%来自其最大客户；贸易应收款项总额中，分别有60%、63%、40%及41%来自同期前五大客户。这说明该公司对大客户依赖程度较高。</p>
  <p>奥动新能源在招股书中明确提及，未来增长主要取决于客户对电动车、换电模式及各类现有换电技术的接受度与偏好。</p>
  <p>根据公司官网信息，其乘用车业务合作伙伴主要包括广汽埃安、东风汽车、上汽集团、中国一汽、东风日产、长安汽车及北汽新能源，甚至还有已陷入经营困境多时的合众新能源（哪吒汽车母公司）。</p>
  <p>但从当前市场反馈来看，前述合作企业旗下的换电车型数量仍相对有限；其中，广汽埃安、北汽新能源、上汽集团旗下换电车型主要聚焦于网约车等商用场景，尚未成为面向大众用户的主流选择。</p>
  <p>在谈及未来发展的不确定性时，奥动新能源在招股书中还特别提及，换电虽为新兴且快速增长的市场，但由于电动车电池的统一产业标准仍在逐步成形，公司在推广换电解决方案及扩大业务规模时，或将面临一定挑战。若工信部推出统一的电动车电池标准，公司可能需要承担校准现有及未来产品以符合该标准的巨额费用。此外，当前市场上存在多种换电技术，包括卡扣式底盘换电技术与螺栓式底盘换电技术，目前尚未明确何种技术将成为市场主流标准。</p>
  <p>在不能改变市场的情况下，奥动新能源只能选择“教育市场”。</p>
  <p>该公司计划在未来5年内，每年分别与2-3家电动汽车整车厂合作，开发具备换电功能的新型乘用车、轻型货车和重型卡车，同时探索与自动驾驶乘用车整车厂的合作，共同开发可兼容的换电车型。其还希望探索行业上下游商机，进而促进并强化公司业务的持续发展。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/2showEuoEergtjt9iBnZiA" rel="noopener noreferrer nofollow" target="_blank">“凤凰WEEKLY汽车”</a>，作者：李飞，编辑：郝琳，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3602013990700288</id>
            <title>谷歌版两门「小钢炮」开源，2.7亿参数干翻SOTA</title>
            <link>https://www.36kr.com/p/3602013990700288</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3602013990700288</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 06:14:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>谷歌是真的底蕴深厚啊～</p>
  <p>刚刚在<strong>「大模型」</strong>领域用Gemini 3 Pro➕Flash重挫了OpenAI锐气后，马不停蹄继续在端侧<strong>「小模型」</strong>发力！</p>
  <p>昨天夜里，一口气又放出新的两个技术博客，全是和端侧相关的。</p>
  <p>一个是<strong>T5Gemma 2，一个专门的底层架构创新，首个多模态长上下文码器-解码器模型开源，最小是270M–270M。</strong></p>
  <p>另一个是<strong>FunctionGemma，</strong>专为函数调用优化的<strong>270M（2.7亿参数）</strong>模型，可在手机、浏览器及其他设备上运行。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b1011f8198c140059e28eb2cc89d76ba@5091053_oswg440632oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b30bcc62d56a455faa96283b25e034fb@5091053_oswg188563oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>T5Gemma 2</strong>和<strong>FunctionGemma</strong>都来自<strong>Gemma 3</strong>家族，相对于Gemini这种「大模型」，Gemma就是「小模型」。</p>
  <p>这两个虽然都是小模型，但是他们的关系有点类似<strong>同门师兄弟，但专攻方向不同</strong>。</p>
  <p>T5Gemma 2专注于<strong>架构效率与多模态</strong>（Encoder-Decoder架构回归）。</p>
  <p>而FunctionGemma专注于<strong>智能体与工具使用</strong>（Function Calling能力）。</p>
  <p><strong>T5Gemma 2和现在流行的LLM的架构不同，可以理解为AI技术领域「另一条路」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_c76151971e454679a81fbc86d02e3cff@5091053_oswg129533oswg1080oswg385_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文地址：https://arxiv.org/pdf/2512.14856</p>
  <p>谷歌开源了<strong>T5Gemma 2：</strong>270M–270M、1B–1B以及4B–4B三种规模的预训练模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ffa31761d03a4bca87598fe877a538b8@5091053_oswg146207oswg1080oswg559_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">开源地址：https://huggingface.co/collections/google/t5gemma-2</p>
  <p><strong>FunctionGemma则是技能变体，</strong>它是对模型「技能」的专项训练。</p>
  <p>有点类似把一个大模型里所有知识类的能力都剥离掉，只保留针对性的函数调用功能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_82de8418bd0c40369a1664934605a1ee@5091053_oswg48104oswg1080oswg151_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">开源地址：https://blog.google/technology/developers/functiongemma/</p>
  <h2><strong>T5Gemma系列深层技术解析</strong></h2>
  <p>先看下T5Gemma 2这种「新结构」的优势：</p>
  <p><strong>强大的多模态性能</strong>：在多个基准测试中超越谷歌自己的Gemma 3。</p>
  <p><strong>全面提升的通用能力</strong>：在代码、推理和多语言 等任务上，T5Gemma 2整体上优于对应规模的Gemma 3模型。</p>
  <p><strong>卓越的长上下文能力：</strong>相较于Gemma 3和第一代T5Gemma，在生成质量上取得了显著提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_e3945df7a0214502a9b41198a73353eb@5091053_oswg380553oswg1080oswg885_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与T5Gemma类似，T5Gemma 2在预训练阶段的性能<strong>或超过Gemma 3对应体量模型</strong>，而在<strong>后训练阶段则取得了显著更优的表现</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0be2aa6840ef476eb9cbb8b67f5a2f6d@5091053_oswg92679oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3964b17e8f6f46808fd64d8a3284987d@5091053_oswg97499oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_13c10687c4154e0085730df4dae5f83d@5091053_oswg729130oswg1080oswg1518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>想要理解为什么谷歌要搞T5Gemma，就需要看看目前大模型技术路线演变的<strong>核心脉络</strong>。</p>
  <p>T5Gemma算得上是大模型领域的「古典主义复兴」。</p>
  <p>在当今GPT、Llama等<strong>Decoder-only（仅解码器）架构占主导的时代</strong>，T5Gemma 2是对经典Transformer架构中Encoder-Decoder（编码器-解码器）路线的回归与现代化改造。</p>
  <p>我们现在熟知的GPT、Gemini、DeepSeek都是Decoder-only（仅解码器）架构。</p>
  <p><strong>GPT系列（OpenAI）：</strong>从GPT-1到现在的GPT-4o，全是Decoder-only。</p>
  <p><strong>DeepSeek：</strong>无论是DeepSeek-V2还是最新的V3，核心都是Decoder-only（结合了MoE混合专家技术）。</p>
  <p><strong>Llama（Meta）：</strong>它是目前开源界Decoder-only的标杆。</p>
  <p><strong>Gemini（谷歌）：主线模型（Pro/Flash）主要是Decoder-only。</strong></p>
  <p>目前叫得上名字的、用来「聊天」的超级模型，几乎<strong>清一色全是Decoder-only</strong>。</p>
  <h3><strong>为什么说T5Gemma 2是「回归」？</strong></h3>
  <p>这就要说到Transformer的分家史。</p>
  <p>要理解「回归」，得先看它们当初是怎么「分家」的。</p>
  <p>2017年谷歌发布《Attention Is All You Need》论文提出Transformer时，<strong>祖师爷原本是Encoder-Decoder（编码器-解码器）全套架构</strong>。</p>
  <p>但后来，家族分成了三个流派：</p>
  <p><strong>流派A：Encoder-only（只用编码器）</strong></p>
  <p><strong>代表人物：BERT</strong>。</p>
  <p><strong>特长：</strong>只能「读」，不能「写」。它极其擅长做选择题、分类、情感分析，但你让它写作文，它憋不出来。</p>
  <p><strong>流派B：Decoder-only（只用解码器）</strong></p>
  <p><strong>代表人物：GPT</strong>。</p>
  <p><strong>特长：</strong>只能「猜下一个字」。虽然它看上文不如Encoder那么全面（只能看左边，不能看右边），但它天生会说话，而且人们发现<strong>只要把这玩意儿做得足够大，它居然产生了智能（涌现）</strong>。</p>
  <p>也就是「意外的」开启了我们这个AI时代（笑。</p>
  <p><strong>流派C：Encoder-Decoder（全套保留）</strong></p>
  <p><strong>代表人物：T5（谷歌），BART</strong>。</p>
  <p><strong>特长：</strong>既能读又能写。也就是现在的T5Gemma 2所在的流派。</p>
  <p>T5的全称是Text-to-Text Transfer Transformer，连着5个T，所以叫T5。</p>
  <p>那为什么Decoder-only（GPT流派）后来一统天下了？</p>
  <ol>
   <li><strong>训练简单粗暴：</strong></li>
  </ol>
  <p>只需要把网上的海量文字扔进去，让它不停预测下一个字就行（自监督学习）。</p>
  <ol>
   <li><strong>上限极高：</strong></li>
  </ol>
  <p>也就是Scaling Law（缩放定律）。人们发现Decoder-only模型越做越大，智商提升得最明显，而且工程上更容易堆算力。</p>
  <ol>
   <li><strong>Encoder-Decoder被冷落：</strong></li>
  </ol>
  <p>因为它结构复杂（有两套参数），训练起来比Decoder-only稍微麻烦点，且在做超大模型（千亿参数）时，性价比似乎不如纯Decoder那么极致。</p>
  <p>所以也只有财大气粗的谷歌能有精力回归这个经典模型，继续投入搞研发。</p>
  <p>谷歌在全世界都疯狂卷Decoder-only的时候，突然杀了个回马枪。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_624be6bebdbb401f9fa41cb2fd4bbb97@5091053_oswg358062oswg1080oswg683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>既然Decoder-only这么强，为什么要改回Encoder-Decoder？</p>
  <p>因为谷歌发现了Decoder-only的几个死穴，而这些死穴正好是Encoder-Decoder的强项：</p>
  <p>「幻觉」问题（瞎编）：</p>
  <p><strong>Decoder-only（GPT）</strong></p>
  <p>是边写边想，有时候写嗨了就收不住，容易一本正经胡说八道。</p>
  <p><strong>Encoder-Decoder（T5）</strong></p>
  <p>是「先读懂（Encoder）-再动笔（Decoder）」<strong>。</strong></p>
  <p><strong>Encoder会强迫模型先把你的输入彻底消化一遍，生成一个完整的「中心思想向量」，然后再让Decoder翻译出来。</strong></p>
  <p><strong>这种机制</strong>天生更严谨，幻觉更少。</p>
  <p><strong>在多模态方面的天然优势：</strong></p>
  <p>你要让模型看图，Encoder（编码器）是最好的「眼睛」。</p>
  <p>T5Gemma 2可以直接把图像信号喂给Encoder，这比强行塞给Decoder-only处理要顺畅得多。</p>
  <p><strong>端侧效率（手机上跑）：</strong></p>
  <p>在手机这种算力有限的地方，如果你只是做翻译、摘要、指令执行，Encoder-Decoder往往能用<strong>更少的参数（更小的显存）</strong>达到和巨大Decoder-only模型一样的效果。</p>
  <p>T5Gemma 2的出现，不是要推翻GPT，而是<strong>在特定领域（比如手机端、翻译、工具调用、严谨推理）复兴了Encoder-Decoder架构</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d54a8ff33d724c76a01cc058e6d4bd7e@5091053_oswg372496oswg1080oswg987_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>谷歌并未从零开始训练T5Gemma，而是采用了一种被称为「模型适配」（Model Adaptation）的高效技术。</p>
  <p>该技术的核心在于利用已经过数万亿标记训练的Gemma 2或Gemma 3解码器模型作为种子，将其权重映射到新的编码器-解码器结构中。</p>
  <p>这种做法极大地降低了计算成本，同时让模型能够继承原有的语言理解能力。</p>
  <h2><strong>FunctionGemma：智能体的专用大脑</strong></h2>
  <p>如果T5Gemma是从底层架构的创新，那么<strong>FunctionGemma就是从功能实现上的创新。</strong></p>
  <p><strong>FunctionGemma</strong>是为了解决大模型落地中最痛的点——「不仅要能聊，还要能干活」而设计的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_69dfe233ad5c44c9b2b04ea86224bdca@5091053_oswg66458oswg1000oswg611_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>FunctionCalling（函数调用）</strong>：普通模型在被要求「定个闹钟」或「查天气」时，往往只能瞎编。FunctionGemma经过专门的微调，能够精准地输出结构化的数据（如JSON），去调用外部的API或工具。</p>
  <p><strong>Agent（智能体）优化</strong>：它是为AIAgent设计的，擅长多步骤推理和执行任务。</p>
  <p><strong>极致轻量化</strong>：这意味它可以直接跑在手机、甚至更低功耗的边缘设备上，作为系统的「控制中枢」。</p>
  <p><strong>适用场景</strong>：手机语音助手、家庭自动化控制、端侧AI Agent、API调度中心。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_cecbaaa37bdd40759a2bdb53ec18956c@5091053_oswg110846oswg1080oswg546_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>FunctionGemma并非仅仅是Gemma家族的一个「缩小版」，而是一个专门设计的「神经路由器」，旨在解决云端大模型在延迟、隐私和成本上的固有缺陷。</p>
  <h3><strong>从对话到行动的范式跃迁</strong></h3>
  <p>在过去的一年中，大语言模型（LLM）的发展主要集中在提升模型的对话能力、知识广度以及多模态理解力上。</p>
  <p>然而，随着应用场景的深入，开发者社区最迫切的需求已从「能聊天的AI」转向「能干活的AI」。</p>
  <p>这种从「对话式接口」向「主动体」的转变，要求模型不仅要理解自然语言，还要能精准地操作软件接口、执行多步工作流并与物理世界交互。</p>
  <p>FunctionGemma的推出正是为了响应这一需求。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4598fbf905cf49cca5dddc3c4100db37@5091053_oswg348277oswg1080oswg821_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为Gemma 3家族中最小的成员，它抛弃了通用知识的广度，换取了对函数调用（Function Calling）这一特定任务的极致优化。</p>
  <p>这种「特种兵」式的模型设计思路，代表了AI工程化的一个新方向：即通过模型的小型化和专业化，将智能下沉至网络的边缘——用户的手机、IoT设备乃至浏览器中。</p>
  <p>FunctionGemma之所以能在极小的参数规模下实现高性能的函数调用，依赖于其独特的架构设计和训练策略。</p>
  <p>它不是通过简单的压缩得到的，而是基于Gemma 3架构进行了针对性的「压缩」，专注于句法结构的精确性和逻辑判断的确定性。</p>
  <p>FunctionGemma拥有2.7亿（270M）参数。</p>
  <p>在当今动辄数千亿参数的模型时代，<strong>这一数字显得微不足道</strong>，连「大模型」零头都不到，但其设计哲学却极具颠覆性。</p>
  <p>通常模型的推理能力随着参数量的增加而涌现（Scaling Laws）。</p>
  <p>然而，FunctionGemma打破了这一常规，证明了在特定领域（Domain-Specific），小模型可以通过高质量数据的微调达到甚至超越大模型的表现。</p>
  <p>虽然官方未披露具体的蒸馏细节，<strong>但270M的规模暗示了大量的通用世界知识被剔除。</strong></p>
  <p>模型不再需要知道「法国的首都是哪里」或「莎士比亚的生平」，它只需要知道如何解析JSON、如何匹配函数签名以及如何处理参数类型。</p>
  <h3><strong>发力移动端</strong></h3>
  <p>「在手机上能运行吗？」这是用户最关心的问题。</p>
  <p>答案不仅是肯定的，而且FunctionGemma正是为此而生。</p>
  <p>在移动设备上，随机存取存储器（RAM）是最宝贵的资源。</p>
  <p>Android系统的低内存查杀机制会毫不留情地关闭占用内存过大的后台进程。</p>
  <p>FunctionGemma 270M在FP16精度下的权重大小约为<strong>540MB</strong>。</p>
  <p>对于拥有8GB或12GB内存、甚至24GB的现代Android旗舰机，这仅占总内存的5%-7%，完全可以在后台常驻。</p>
  <p><strong>Int8/Int4（量化）</strong>：为了进一步降低功耗和内存占用，端侧部署通常使用量化技术。</p>
  <p><strong>Int8量化</strong>：模型大小降至约<strong>270MB</strong>。</p>
  <p><strong>Int4量化</strong>：模型大小降至约<strong>135MB</strong>。</p>
  <p>这意味着它可以在入门级设备甚至嵌入式设备上流畅运行。</p>
  <h3><strong>谷歌为何要发布这样一个「小」模型？</strong></h3>
  <p>这背后隐藏着其对未来AI计算架构的深刻思考，以及在移动操作系统控制权争夺战中的防御性布局。</p>
  <p>这是FunctionGemma最核心的战略价值。</p>
  <p>在当前的AI应用中，将所有请求都发送到云端大模型既昂贵又缓慢。</p>
  <h2><strong>移动互联网的下一个阶段</strong></h2>
  <p>移动互联网的下一个阶段是<strong>意图驱动（Intent-Driven）</strong>的。</p>
  <p><strong>意图驱动</strong>（Intent-Driven），用户不再通过点击图标打开APP，而是直接表达意图。</p>
  <p><strong>现状</strong>：Siri和谷歌Assistant，以及类似手机助手长期以来受限于硬编码的指令集，只能通过特定接口调用APP的有限功能。</p>
  <p><strong>FunctionGemma</strong>通过让模型直接学习APP的API定义，FunctionGemma试图让AI成为通用的UI。</p>
  <p>开发者只需要暴露工具（Tools），FunctionGemma就能理解并操作这些工具。</p>
  <p><strong>谷歌的野心是</strong>通过开源FunctionGemma，谷歌实际上是在制定一套<strong>AI与APP交互的标准协议</strong>。</p>
  <p>如果所有Android开发者都按照FunctionGemma的格式定义工具，那么谷歌的Android系统将成为世界上最强大的智能体平台，进一步加深其护城河。</p>
  <p>为了验证FunctionGemma的能力，谷歌提供了两个典型的参考实现，展示了其在游戏和系统控制领域的潜力。</p>
  <p><strong>场景描述</strong>：用户用自然语言发出指令，模型将其转换为Android系统意图。</p>
  <p><strong>技术细节</strong>：</p>
  <p><strong>多参数提取</strong>：用户说「给John发邮件说我迟到了」，模型提取recipient="John"，body="我迟到了"，action="send_email"。</p>
  <p><strong>歧义处理</strong>：如果用户只说「发邮件」，模型可能会调用ask_clarification函数，反问用户「发给谁？」。这种多轮对话能力是硬编码助手无法比拟的。</p>
  <p><strong>性能对比</strong>：经微调的FunctionGemma在此任务上的准确率达到85%，远超未微调的基座模型（58%）。这证明了在端侧垂直领域，小模型完全可以替代大模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ac5a6842a4b44d6cae202d3198e615a2@5091053_oswg248899oswg568oswg1208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>「Tiny Garden」这个Demo展示了FunctionGemma如何驱动游戏逻辑。</p>
  <p><strong>场景</strong>：一个语音控制的种田游戏。用户说「在顶排种满向日葵，然后给它们浇水」。</p>
  <p><strong>任务分解（TaskDecomposition）</strong>：模型不仅要识别意图，还要进行逻辑推理。它需要将这一句话拆解为一系列函数调用：</p>
  <p>select_crop（type="sunflower"）</p>
  <p>plant（row=0，col=0）...plant（row=0，col=N）</p>
  <p>water（row=0）</p>
  <p><strong>完全离线</strong>：整个过程无需联网，这对于手游体验至关重要，因为网络延迟会导致游戏操作的不流畅。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_787ed4de5a894fd7958d956607ff7ef5@5091053_oswg595697oswg1080oswg1074_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于<strong>开发者</strong>而言，FunctionGemma提供了一种低成本、高隐私的方案，将Agent能力集成到普通APP中，无需昂贵的服务器开销。它使得「语音控制一切」不再是巨头的专利，而是每个APP都能拥有的标准功能。</p>
  <p>对于<strong>手机厂商</strong>而言，270M的参数量是完美的「甜点」——它既能利用现有的NPU硬件，又不会过度挤占系统资源，为打造「AI原生OS」提供了理想的地基。</p>
  <p>对于<strong>谷歌</strong>而言，这是其在AI时代捍卫Android生态控制权的关键一步。</p>
  <p>未来，可以预见，基于FunctionGemma的变体将无处不在：在你的智能手表里处理健康数据，在你的路由器里优化网络设置，甚至在你的汽车里调节空调温度。</p>
  <p><strong>AI将不再是一个需要「访问」的网站，而是一种像电力一样，无形却无处不在的基础设施。</strong></p>
  <p><strong>参考资料：</strong></p>
  <p>https://blog.google/technology/developers/functiongemma/</p>
  <p>https://blog.google/technology/developers/t5gemma-2/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/X4QsqVj4mApILEVI1GMyYA" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，编辑：定慧，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3601997077087235</id>
            <title>从“辅助”到“自动”的关键一跃，首批L3级自动驾驶车型获批，车企明确：L2车辆暂无法直接升级</title>
            <link>https://www.36kr.com/p/3601997077087235</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3601997077087235</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 06:12:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>周二早高峰的北京京台高速，阳光刚穿透薄雾，刘磊（化名）的手指已经在方向盘上搭了23分钟。他每天要往返50公里通勤，座驾是2023年购入的搭载L2级辅助驾驶的轿车——这套能自动跟车、保持车道的系统，曾让他以为“轻松开车”触手可及。但此刻，仪表盘上“请保持注意力”的提示灯第三次亮起，他不得不挺直腰板，紧盯前方缓行的车流。</p>
  <p>上周晚高峰堵在机场北线，L2级辅助驾驶帮忙跟着车，但眼睛得一直盯着，他的手臂僵了一路。刘磊想起手机里刷到的工信部许可两款L3级自动驾驶车型产品的新闻，屏幕上“特定场景解放双手”的描述让他忍不住多看了两眼。“要是能在拥堵的高速上真正松开方向盘，哪怕只是让我活动下胳膊，都是奢望成真了。”他心里想。</p>
  <p>刘磊的期盼，正是中国数千万L2级辅助驾驶车主的共同心声。按乘联分会近年乘用车销量数据估算，结合中国L2级辅助驾驶超50%的全球第一普及率，仅近三年累计售出的7000余万辆乘用车中，就有超3500万辆搭载该功能。这意味着，每两辆行驶在道路上的新车里，就有一辆能提供基础辅助驾驶服务。但正如刘磊的体验，L2级始终处于“辅助”范畴，驾驶员需承担全部责任，所谓的“解放”始终带着束缚。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_24823bf4f0414a74b301d2babcf2bff7@5091053_oswg167174oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：视觉中国</p>
  <p>12月15日，这份束缚迎来被打破的关键节点——工业和信息化部正式公布我国首批L3级有条件自动驾驶车型准入许可，长安深蓝、北汽极狐各有一款纯电动轿车入选，分别在重庆、北京的指定区域开启上路试点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_1665019fad4b4dcd8e1627b4b03290de@5091053_oswg138357oswg1080oswg902_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：工信微报官微</p>
  <p>消息一出，资本市场迅速响应。12月16日，A股智能驾驶概念板块表现强势，多只个股涨停，北汽蓝谷（600733.SH）、万集科技（300552.SZ）领涨，德赛西威（002920.SZ）等产业链个股跟风走高。热度同步传导至港股，截至12月17日收盘，佑驾创新（02431.HK）、禾赛科技（02525.HK）等个股股价大涨，形成跨市场共振格局。</p>
  <p>“这标志着智能网联汽车迈入量产应用新阶段。这不仅是技术发展的里程碑，更是国家以包容审慎监管统筹高质量发展与高水平安全，护航前沿技术落地、激发产业创新活力的生动实践。”中国汽车工业协会常务副会长兼秘书长付炳锋的评价，道出了行业共识。</p>
  <p>作为从“辅助驾驶”向“自动驾驶”跨越的关键分水岭，L3级的落地不仅是技术里程碑，更重构了驾驶责任链条——根据《汽车驾驶自动化分级》国家标准，L3级在特定条件下，驾驶控制权和事故责任主体首次从驾驶员转向系统本身，这与刘磊正在使用的L2级辅助驾驶形成本质区别。</p>
  <p>而此次获批的两款车型，勾勒出L3落地的初始图景。对刘磊这样的消费者而言，他们更关心的是“何时能用上”。《每日经济新闻》记者从长安汽车方面确认，目前所有已备案的L2级车型暂不支持通过OTA升级至L3级，待政策完善后将评估申请备案。而此次获批的L3功能，现阶段将优先应用于机场接驳、园区通勤等特定场景，为大规模商业化积累经验。</p>
  <p>但车百会理事长张永伟的预判让市场充满期待：“2026年L3及以上自动驾驶乘用车新车渗透率将实现突破，到2030年有望达到10%。”这意味着，几年内，普通消费者或许就能在通勤路上实现真正的“半解放”。</p>
  <h2><strong>1</strong></h2>
  <h2><strong>关键分水岭：</strong></h2>
  <h2><strong>L3重构责任链条</strong></h2>
  <h2><strong>两种技术路径并行落地</strong></h2>
  <p>根据工信部公示信息，长安汽车和北汽极狐各有一款车型获得有条件自动驾驶许可。其中，长安获批车型可在重庆市内特定快速路段，以最高50km/h的车速，在拥堵环境中实现高速公路与城市快速路的单车道自动驾驶；北汽极狐获批车型则可在北京市多个指定路段，以最高80km/h的车速，实现同类功能。记者从两家车企方面获悉，此次获批具体车型为“深蓝SL03”和“极狐阿尔法S6（L3）版”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_37fa1e539c4846f59af651a60cca7e4a@5091053_oswg70646oswg1080oswg354_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：每经记者 刘曦 制</p>
  <p>值得关注的是，两款获批车型采用了不同的技术路径。深蓝SL03并未搭载激光雷达，而是采用由单目前视摄像头、环视摄像头、毫米波雷达及超声波雷达构成的融合感知方案，其智驾系统由长安自研。而极狐阿尔法S6（L3）版配备了包括3颗激光雷达在内的多类传感器，搭载华为乾崑智驾ADS 3.3系统。</p>
  <p>这一差异引发市场对技术标准的关注。今年9月工信部发布《智能网联汽车 组合驾驶辅助系统安全要求》（征求意见稿），曾首次将激光雷达纳入国家推荐性标准体系，并强调其技术重要性。为何此次获批L3级车辆未搭载激光雷达？</p>
  <p>记者了解到，一方面，该标准目前仍处于公开征求意见阶段，尚未正式生效；另一方面，L3级自动驾驶试点申报准入通道持续敞开，按照“成熟一个、许可一个”的原则有序推进。也就是说，监管审批的核心是对整车系统安全性的综合验证结果，而非指定某一特定传感器。</p>
  <p>业内认为，此次许可的深远意义远超对两款车型的批准。在此之前，自动驾驶企业主要持有的为道路测试许可。此次工信部的动作，实质上是为L3级从测试走向特定场景下的应用提供完整的法规和管理基础。更重要的是，L3级作为从“辅助驾驶”向“自动驾驶”跨越的关键分水岭，真正落地之后将从根本上重构责任链条与商业模式。</p>
  <p>“行业竞争真正始于L3阶段。”车百会理事长张永伟向记者强调，当前L2级辅助驾驶的快速普及已奠定基础，行业明确向L3、L4级自动驾驶迈进。其中L3可让驾驶员在特定条件下“有条件解放”，L4则实现“完全解放人”，谁能占据L3智能化优势，谁就能掌握汽车产业未来竞争主动权。</p>
  <h2><strong>2</strong></h2>
  <h2><strong>FSD≠L3</strong></h2>
  <h2><strong>L2车辆暂无法OTA升级至L3</strong></h2>
  <p>根据国家市场监督管理总局发布的《汽车驾驶自动化分级》国家推荐标准，L2与L3级自动驾驶存在根本性区别。L2及以下级别的系统仅为辅助功能，驾驶员承担全部责任；从L3级别开始，在特定条件下，驾驶控制权和事故责任主体首次从驾驶员转向系统本身。</p>
  <p>从试点要求来看，目前获批车辆的应用范围仍有限制：最高时速不超过80km/h，仅适用于高快速路等特定路段，且仅支持单车道自动驾驶，不允许自动变道。工业和信息化部装备工业发展中心副主任刘法旺明确，目前的试点主体只能在限定路段、车型上使用，车辆不面向普通消费者，只能由试点使用单位去运营。</p>
  <p>对普通者而言，市场上L3级自动驾驶的车辆什么时候可以真正上市？搭载L2级辅助驾驶车辆是否可以通过OTA（Over-The-Air，空中下载软件更新）升级到L3自动驾驶？</p>
  <p>对此，长安汽车方面明确向记者表示：“目前所有已完成L2级辅助驾驶备案车型均暂不支持通过软件升级为L3级自动驾驶，待政策完善后，会对现有车型进行评估并依据要求申请备案。”当前获批的L3级功能，其核心价值在于为机场接驳、园区通勤等特定场景提供高品质出行服务，旨在为未来的大规模自动驾驶商业化积累运营经验和数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_7bd4c8ff25ae46a18a36babc1fa2a71c@5091053_oswg46681oswg1080oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：特斯拉官网</p>
  <p>这与特斯拉FSD在美国的技术演进形成鲜明对比。尽管最新版FSD V14.2.1在技术层面允许驾驶员在特定路况下短暂发短信，试图将驾驶员角色向“监管者”过渡，但其在全球市场法律上仍被定义为L2级辅助驾驶。这意味着，无论系统能力多强，开启FSD时的事故责任仍在驾驶员。特斯拉CEO马斯克虽表示FSD在中国已获“部分批准”，期望明年获得全面批准，但这指向的仍是L2级功能的落地和推广，而非L3级责任体系的切换。</p>
  <p>值得注意的是，尽管L3车辆直接进入个人消费市场尚需时日，但以萝卜快跑、小马智行为代表的L4级Robotaxi已在北上广深多地核心路段实现商业化运营。据太平洋证券预测，2026年，Robotaxi的成本有望降至2.1元/公里，2030年进一步降至1元/公里。到2030年，中国Robotaxi的市场规模有望突破2.93万亿元，将成为市场空间最大的自动驾驶场景之一。</p>
  <h2><strong>3</strong></h2>
  <h2><strong>政策逐步开放</strong></h2>
  <h2><strong>还有七家车企进入“准生”通道</strong></h2>
  <p>此次L3级自动驾驶车辆获得上路许可并非一蹴而就，而是一个历时近三年、分步推进的规范化过程。2022年11月，工信部发布《关于开展智能网联汽车准入和上路通行试点工作的通知（征求意见稿）》，首次明确提出将对L3、L4级自动驾驶车辆进行准入管理并开展试点。</p>
  <p>2023年11月，工信部等四部委联合发布《关于开展智能网联汽车准入和上路通行试点工作的通知》，对具备量产条件的L3、L4级自动驾驶车辆，通过四部委联合遴选并完成严格的安全评估和准入审批后，允许其在限定区域内由指定的使用主体开展上路通行试点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_415afc432e834b378621b74afa0022e6@5091053_oswg76487oswg1080oswg625_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：工信部官网</p>
  <p>2024年6月，工信部发布《四部门有序开展智能网联汽车准入和上路通行试点》的通知，首批L3级自动驾驶准入和上路通行试点车企名单公布，包括比亚迪、蔚来、长安、广汽、上汽、北汽蓝谷、一汽、上汽红岩、宇通客车九家。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_98adf1871c694e6f95925c709c6f8bb5@5091053_oswg92719oswg1080oswg527_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：工信部官网</p>
  <p>2024年12月，《北京市自动驾驶汽车条例》《武汉市智能网联汽车发展促进条例》相继出台，为L3级及以上级别自动驾驶，特别是面向个人乘用车的商业化应用，提供开创性的地方性制度规范。</p>
  <p>2025年7月，测试进一步落地，首批具体车型及测试牌照名单曝光，涉及10余家制造商的20余款车型，宝马、奔驰等品牌也位列其中。9月，工信部等八部门在《汽车行业稳增长工作方案（2025—2026年）》中再次明确要“有条件批准L3级车型生产准入”。12月，北汽极狐与长安深蓝的两款车型获批L3级有条件自动驾驶车型准入许可。</p>
  <p>就上述名单来看，除了已率先获批的北汽极狐和长安深蓝外，一汽、上汽、广汽、比亚迪、蔚来等其他七家车企的L3车型也已进入“准生”通道。近期，更多车企在特定城市也取得了实质性进展，例如理想汽车在北京获得L3级道路测试牌照并启动常态化测试；鸿蒙智行也已在深圳开启L3级有条件自动驾驶内测……这些动态共同构成了中国L3自动驾驶“多点开花”的落地图景。</p>
  <p>张永伟向记者指出，国家及时放开L3级自动驾驶试点，是推动其走向产业化的关键一步。这一举措将同时推动技术验证与监管体系的完善，通过“上路准入”和“产品准入”的双重试点，确保我国智能驾驶技术发展至此阶段时已做好充分准备，这对于把握未来产业竞争主动权至关重要。</p>
  <h2>4</h2>
  <h2><strong>技术与产业共振：</strong></h2>
  <h2><strong>成本下降催生万亿级新市场</strong></h2>
  <p>从去年6月首批L3级自动驾驶准入和上路通行试点车企公布，到12月首批L3车型最终获批“落地开跑”，这场历时一年多的政策快速闭环，其背后关键的驱动引擎是一场由国产供应链主导的成本普惠化革命。</p>
  <p>在软件层面，进入2025年，行业的技术发展路径经历深刻迭代，从早前的“端到端”模型，快速向以“VLA（视觉-语言-动作）大模型” 和 “世界模型”为代表的新一代AI技术方案持续演进。曾是L3量产最大瓶颈的高昂核心硬件成本，也正被中国企业的技术创新与规模效应迅速突破。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4eba6067d5e34b9ab2afab46ceaaf711@5091053_oswg47873oswg1080oswg657_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：车百会报告</p>
  <p>其中，在算力芯片领域，以地平线为代表的国产车规级芯片，正通过软硬件协同优化，将一套高阶智能驾驶系统（ADAS）的综合成本降低35%以上。在关键传感器领域，激光雷达的规模化装车成为成本下降的直接推手，价格也从最初的七八万美元一路降至如今的200美元。</p>
  <p>成本的突破直接激活了整条产业链，并催生出下游全新的商业模式，形成强大的涟漪效应。在上游，激光雷达、高算力AI芯片、高精地图与线控底盘等核心赛道被全面激活，需求呈现爆发式增长。佐思汽研报告显示，2023年至2025 年期间，国内乘用车L2.5/L2.9级智能驾驶功能实现跨越式增长，2023年新上市车型中，L2.5和L2.9级智驾装配率分别仅为4.57%和3.3%，但到2025年1月至4月，搭载L2.5级智驾新车占比升至30.20%，L2.9级更是达到34.82%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d73003d5a22d4512adb5be103bbceb3c@5091053_oswg28037oswg1080oswg544_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：车百会报告</p>
  <p>在下游，自动驾驶正从“卖车”向“卖里程”延伸，开辟出万亿级的全新市场。比如，长安汽车已明确当前获批L3级自动驾驶车辆将首先在机场接驳、园区通勤等特定场景提供商业化出行服务，为未来自动驾驶出行规模化运营积累经验与数据。而在物流领域，今年爆发的末端无人配送则有望重塑城市物流的“最后一公里”。</p>
  <p>与此同时，支撑这场革命的关键基础设施标准也在同步确立。近日，GB17675-2025《汽车转向系基本要求》关于线控转向系统的国家标准，已获国家标准化管理委员会正式批准发布。这不仅为上游芯片、传感器等供应商提供了清晰的“技术导航图”，更意味着当转向、制动等核心操作全部实现精准线控后，为自动驾驶算法奠定执行层基础。产业落地进程也在加速。张永伟预计，智能底盘层面的线控转向和线控制动将在2026年实现量产突破。</p>
  <h2>5</h2>
  <h2><strong>车企决战L3级智能化</strong></h2>
  <h2><strong>2026年渗透率有望迎来关键突破</strong></h2>
  <p>工信部最新数据显示，今年前三季度，具备组合驾驶辅助功能（L2级）的乘用车新车销量同比增长21.2%，市场渗透率已达64%。随着L3自动驾驶准入法规的逐步放开和试点的进一步深化，张永伟预判，2026年L2组合驾驶辅助功能乘用车新车渗透率将达到70%，L3及以上自动驾驶乘用车新车渗透率将实现突破，到2030年有望达到10%。</p>
  <p>当前，各主要车企围绕L3的量产时间表已展开了激烈角逐，将2025年末至2026年设定为关键窗口期。引望智能驾驶产品线总裁李文广向记者表示：“高速L3级别自动驾驶预计在明年实现规模商用，城区L4级自动驾驶也将同步开展试点。”此外，岚图、小鹏、极氪等品牌也相继公布各自的L3级自动驾驶技术量产计划。</p>
  <p>国海证券认为，2025至2027年将是L3级自动驾驶准入标准确立的关键期，将经历“标准制定、过渡实施、全面生效”三个阶段，预计正式准入节点将在2026年后全面铺开。平安证券技术分析显示，实现L3级的核心在于构建成熟可靠的行驶环境感知能力，这依赖于摄像头、毫米波雷达及激光雷达的多传感器融合，以精准应对各类复杂路况，为最终的自动驾驶决策提供坚实依据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_e50a515bc1644e56818f4e9ef084db52@5091053_oswg65762oswg741oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：车百会报告</p>
  <p>“2026年，领航辅助驾驶（高速和城市NOA）将向15万元主流车型价格区间渗透，合资燃油车将大规模采购中国本土供应商辅助驾驶方案，算力芯片、AI模型算法等智能化关键技术将继续取得标志性突破，整车AI化加速发展。”张永伟认为，这一趋势将使得汽车产业与机器人、低空产业加速融合，车企加速向聚合智能终端企业演化。</p>
  <p>尽管L3级自动驾驶车辆已经“跑起来”，但其规模化商业化之路仍面临显著挑战。同济大学汽车学院教授、汽车安全技术研究所所长朱西产向记者指出：“为了保证L3级高安全性，其适用范围被严格限定，系统在恶劣天气或需要变道等复杂情况下会主动降级，同时为满足安全冗余而增加的硬件与系统设计，将进一步推高车辆成本。”</p>
  <p>此外，L3级自动驾驶对道路还要求具备高精度定位信号覆盖（如北斗三号差分信号）、路侧感知设备（毫米波雷达、激光雷达、高清摄像头）与车辆的实时协同（C-V2X 通信），以及动态高精地图的分钟级更新能力，才能让系统准确识别临时施工、突发事故等复杂路况。</p>
  <p>中国汽车工程学会副理事长兼秘书长侯福深称，L3级车型生产准入放开涉及交通安全管理方面的一些法律法规，需要汽车行业和公安、交通等部门有很紧密的协同机制，全面推广“仍需一个过程”。</p>
  <p>不过，在原中国汽车工业协会常务副会长兼秘书长、中国汽车芯片产业创新战略联盟联席理事长董扬看来，政策落地将直接推动L3车辆上路应用，而只有实际“用起来”，才能在真实场景中持续推动技术进步与安全水平提升，这对于产业发展至关重要。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/pMCHewWw59Hj3NwT9UkpIg" rel="noopener noreferrer nofollow" target="_blank">“NBD汽车”</a>，作者：刘曦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3601996112807174</id>
            <title>市值超100亿，李泽湘在老家湖南干出一个IPO</title>
            <link>https://www.36kr.com/p/3601996112807174</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3601996112807174</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 06:11:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚刚，港交所迎来“自动驾驶矿卡第一股”！</p>
  <p>12月19日，历经三次递表后的商用车自动驾驶厂商希迪智驾，正式登陆港交所。这是港交所第七家18C板块公司，也是“大疆教父”李泽湘收获的第二个IPO。</p>
  <p>此次IPO，希迪智驾全球发售股份共计540.798万股，发行价格为263港元/股，总募集金额为14.22亿港元。上市首日，希迪智驾股价平开，随后跌破发行价。截至午间休盘，希迪智驾报241港元/股，较发行价跌8.37%，总市值105.53亿港元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_41bb349c79a44f5a81355e433d9453ee@5091053_oswg148524oswg936oswg930_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：雪球</p>
  <p>希迪智驾专注于研发用于采矿及物流的封闭环境自动驾驶卡车、V2X(车联网)技术及智能感知解决方案，并提供以专有技术为基础的产品及解决方案。灼识咨询的数据显示，希迪智驾在中国所有智能驾驶商用车公司中排名第六，市场份额约为5.2%。2024年，公司于智能驾驶商用车市场的产品销售收入约为2.5亿元，以产品销售基准计约占16.8%的市场份额。</p>
  <p>如今，自动驾驶在封闭场景的商业化迎来爆发，行业内群雄并起。在希迪智驾冲击上市时，易控智驾、西井科技等也在加快上市脚步。随着希迪智驾顺利上市，其背后的投资方也迎来收获时刻。</p>
  <h2><strong>在老家湖南，李泽湘干出一个IPO</strong></h2>
  <p>2016年，李泽湘受邀到家乡湖南创业，这是希迪智驾诞生的起源。</p>
  <p>李泽湘1961年生于湖南，是机器人与自动化领域知名专家。在“教授”之外，李泽湘身上还有“创业者”、“投资人”等诸多标签，在大疆成名后，背后的李泽湘也被人称作“大疆教父”。</p>
  <p>在收到家乡邀请后，李泽湘也在思考新的创业方向。当时，原德州仪器基尔比研究院系统研发总监马潍经常出入松山湖。有一天，李泽湘和他聊自动驾驶时，李泽湘邀请他回到湖南创业。马潍并没有一口答应，但几经考虑，他选择接受这个挑战。</p>
  <p>在2017年10月，李泽湘和马潍二人共同成立希迪智驾，李泽湘担任董事长，马潍出任CEO。</p>
  <p>有了李泽湘坐镇，以及技术大牛的持家，希迪智驾在当时烧钱的自动驾驶赛道，很快收获了资本的青睐，丝滑进入研发投入阶段。</p>
  <p>据了解，希迪智驾首轮融资在2018年3月完成，距公司创立不到半年。招股书显示，该轮融资规模为3000万美元，其中红杉出资1400万美元，联科资本、百度风投、光控资本、星浩创业投资、蓝思科技、航盛投资，以及李泽湘的清水湾香港创投等也入股。</p>
  <p>之后，希迪智驾又先后完成3.82亿元人民币和1200万美元的3轮A系列融资、2.8亿元B轮融资、2.64亿元B+轮融资、2.7亿元C轮融资，以及今年2月完成的2400万元的C+轮融资。</p>
  <p>希迪智驾在2024年2月完成C+轮融资后，其投后估值也来到了90亿元。</p>
  <p>招股书显示，希迪智驾在上市前完成8轮融资，背后的股东阵容也相当豪华，包括红杉中国、新鼎资本、联想控股、光大控股、方正和生投资、两江资本、清水湾创投、BV百度风投、光控众盈、湘江国投、青蒿资本、乾道资本、瑞世资本等知名机构及地方政府。</p>
  <p>值得注意的是，希迪智驾此次赴港上市，湖南地方国资湘江国投，运用ODI渠道，通过旗下基金以基石投资者身份参与发行，这也是湖南省内国资通过ODI参与港股基石投资的首例。</p>
  <p>股权结构上，在上市前，李泽湘控制43.63%股权。投资机构中，红杉持股10.61%，为最大外部股东，此外，新鼎资本持股9.67%，方正和生投资持股4.28%，联想控股持股3.49%，两江基金持股3.01%，湘江国有投资持股2.77%，百度持股2.39%。</p>
  <p>对于李泽湘来说，希迪智驾成功上市，让他收获了继固高科技之后的第二家IPO，但与此同时，李泽湘投资的另一家机器人公司卧安科技目前也已经通过港交所聆讯，将于近期挂牌。这也意味着其第三家IPO，已经越来越近。</p>
  <h2><strong>封闭场景自动驾驶商业化爆发，希迪智驾加速突围</strong></h2>
  <p>希迪智驾登陆港交所，成为全球无人驾驶矿卡第一股，在赛道内率先来到新里程碑。</p>
  <p>在上市仪式上，李泽湘表示：“今天，我们不仅登陆资本市场，更站在了一个新的起点。我们的使命，是以硬核科技重塑人类交通的体验与边界，让智能驾驶技术真正服务于人。”</p>
  <p>希迪智驾在2018年，就成为了中国首批推出商业化智能网联产品的公司。之后深耕无人矿卡领域，打造中国首个全无人驾驶纯电采矿车队、首个与挖机协同作业的全无人驾驶采石场，并建成全球规模最大的无人驾驶混编采矿车队。随后又将智能网联技术泛化至车载安全管理、列车智能感知等场景。商业化步伐紧锣密鼓的进行着。</p>
  <p>招股书显示，截至2022年、2023年、2024年及2025年上半年，希迪智驾分别服务44名、85名、131名及152名客户。截至2025年6月30日，希迪智驾的积压订单总价值达约5.84亿元。</p>
  <p>截止至今年上半年，希迪智驾已向客户交付304辆自动驾驶矿卡及110套独立自动驾驶卡车系统，并收到了357辆自动驾驶矿卡及290套独立自动驾驶卡车系统的指示性订单。</p>
  <p>业绩方面，2022年、2023年、2024年及2025年上半年，希迪智驾营收分别为0.31亿元、1.33亿元、4.10亿元及4.08亿元，净亏损分别为2.63亿元、2.55亿元、5.81亿元及4.55亿元；经调整净亏损分别为1.59亿元、1.38亿元、1.27亿元及1.11亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_40fd33391e654e57b4e046f623473bfd@5091053_oswg165441oswg996oswg699_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：希迪智驾招股书</p>
  <p>各期内，希迪智驾收入主要来自自动驾驶销售，该业务又分为封闭环境自主采矿产品及解决方案及封闭环境自动驾驶物流车解决方案。招股书显示，2022年、2023年、2024年及2025年上半年，希迪智驾该业务产生的收入分别为2800万元、7441.8万元、2.47亿元及3.76亿元，分别占同期总收入的90.2%、56.1%、62.1%及92.7%。</p>
  <p>按收入计，希迪智驾于2024年在中国（包括香港、澳门及台湾）自动驾驶矿卡解决方案市场排名第三，市场份额为12.9%。行业前两名的市场份额分别为51.6%及15.5%。</p>
  <p>造成亏损的原因中，除了持续的研发投入、持续增加的财务成本和股权激励计划中产生的以股份支付为基础的付款外，还有客户融资租赁协议违约产生的担保合同负债，以及应收账款减值等原因。</p>
  <p>此次IPO募集的资金，希迪智驾计划将重点投向核心技术研发迭代、全球化的商业化能力、整合产业链上下游资源的潜在投资及并购机会等。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/zOlJrLjI-6EOpOkU_yI7XA" rel="noopener noreferrer nofollow" target="_blank">“直通IPO”</a>，作者：邵延港，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3601986460320775</id>
            <title>太狠了，奥特曼亲手「干掉」GPT-5.2，OpenAI祭出最强编程AI</title>
            <link>https://www.36kr.com/p/3601986460320775</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3601986460320775</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 06:08:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>GPT-5.2-Codex，深夜突袭！</p>
  <p>它是OpenAI迄今为止，最强的AI智能体编程模型，专为复杂、真实世界软件工程而打造。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_99202efa01ad4a699a7860a30a8d6fb0@5091053_oswg432807oswg1080oswg1097_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从名字可以看出，GPT-5.2-Codex基于GPT-5.2进一步优化版本，它在多项能力上实现了关键改进：</p>
  <p><strong>·</strong>上下文压缩，提升了长周期任务处理能力</p>
  <p><strong>·</strong>在大型代码变更，如重构与迁移上性能更强</p>
  <p><strong>·</strong>在原生Windows环境下，编程能力显著增强</p>
  <p><strong>·</strong>网络安全能力最强</p>
  <p>奥特曼宣称，「OpenAI们」已经用上了，而且还取得了非常好的成效。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ae508f93e5b44b29bad581560e8151c7@5091053_oswg154675oswg1080oswg506_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在基准测试中，GPT-5.2-Codex在软件工程、终端测试中，击败了5.1-Codex-Max、GPT-5.2、GPT-5.1。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b1c53e685968460f9bae704d2da29255@5091053_oswg60821oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>OpenAI博客中多次重点强调，GPT-5.2-Codex在网络安全上，达到了迄今为止最高水平。</p>
  <p>就在上周，一位安全研究员用GPT-5.1-Codex-Max+Codex CLI，直接挖出了一个导致源代码泄露的React漏洞。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_6dcf314a18774c14ac192bc7012fab5a@5091053_oswg316903oswg1080oswg1257_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今天起，所有付费用户皆可用上GPT-5.2-Codex，API将在未来几周开放。</p>
  <h2><strong>GPT-5.2-Codex编程狂飙，长跑不掉线</strong></h2>
  <p>全新AI智能体编程GPT-5.2-Codex，简单来说，就是一次「强强联合」。</p>
  <p>它不光继承了GPT-5.2原本擅长的「专业工作处理能力」，还学到了5.1-Codex-Max在AI智能体编程和终端操作方面的能力。</p>
  <p>这样一来，它的进步就很实在了——</p>
  <blockquote>
   <p>在长上下文理解、工具调用、事实准确性、原生上下文压缩等方面，得到了显著提升。</p>
  </blockquote>
  <p>由此，GPT-5.2-Codex可以稳定支持长时间运行的编程任务，并在推理时更省token。</p>
  <p>在业内专业基准测试中，5.2-Codex在SWE-Bench Pro和Terminal-Bench 2.0上刷新SOTA。</p>
  <p>相较于5.1-Codex，约6%的性能提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ee9a1bf0edaf4db79719e5defd29f1da@5091053_oswg284752oswg1080oswg973_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这两个测试，就是专门用于评估模型在真实终端环境中处理多样化任务时的智能体能力。</p>
  <p>同时，它在原生Windows环境中的智能体编程表现也显著增强，进一步扩展了GPT-5.1-Codex-Max所引入的能力。</p>
  <p>得益于这些改进，Codex能在大型代码库中长时间工作，并始终保持完整上下文。</p>
  <p>这也就意味着，诸如大规模重构、代码迁移和功能开发等复杂任务，GPT-5.2-Codex可以靠谱地完成。</p>
  <p>——即便中途方案调整或尝试失败，也能持续迭代而不迷失方向。</p>
  <p>不仅如此，GPT-5.2-Codex「视力」更强了。</p>
  <p>编程时，直接发给它截图、技术示意图、图表以及各类UI界面，它都能理解得更准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_c45ae4d2004e4fc097a658fa489a72ab@5091053_oswg233798oswg1080oswg417_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更厉害的是，它可以直接读取设计稿，并迅速将其转化为可运行的功能原型。</p>
  <p>同时，开发者也可以与Codex协作，将这些原型一点点打磨，直到能正式上线使用。</p>
  <h2><strong>三大跃迁，AI已「攻破」真实世界</strong></h2>
  <p>在OpenAI的一项核心网络安全评估中，可以明显看到「能力随时间的跃迁」——</p>
  <p><strong>·</strong>GPT-5-Codex带来了第一次显著提升，</p>
  <p><strong>·</strong>GPT-5.1-Codex-Max带来了第二次，</p>
  <p><strong>·</strong>GPT-5.2-Codex则实现了第三次跃迁。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4174b31d283f4bd88cba800a665cae9b@5091053_oswg91623oswg976oswg796_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对此，OpenAI判断，未来的AI模型仍将沿着这一趋势持续演进。</p>
  <p>在做规划和能力评估时，他们一直假设每一代模型，都有潜力达到「准备框架」（Preparedness Framework）里，定义的「高」等级网络安全能力。</p>
  <p>不过，GPT-5.2-Codex目前还未达到这一水平。</p>
  <p>那么，在真实世界中，OpenAI的智能体编程模型表现如何？</p>
  <h3><strong>一周挖出React高危漏洞</strong></h3>
  <p>12月11日，React团队爆出了：React Server Components的三个安全漏洞。</p>
  <p>然后，Stripe旗下公司Privy的首席安全工程师Andrew MacPherson，就决定拿这个漏洞来「测试」一下现在的AI模型到底有多能打。</p>
  <p>他使用了GPT-5.1-Codex-Max+Codex CLI，以及其他编程智能体，意外的是，在复现和研究漏洞的过程中，把关键React漏洞挖出来了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9bf7cafbaf1142119571278190227c92@5091053_oswg114861oswg849oswg494_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体实操过程如下——</p>
  <p>最初，他尝试了多次零样本学习分析，直接让模型检查补丁并判断其修复的漏洞类型，但并未取得成果。</p>
  <p>随后，他转向更高频、迭代式的提示方式；在这些方法仍然无效后，他引导Codex按照标准的防御性安全流程开展工作——搭建本地测试环境、分析潜在攻击面，并通过模糊测试向系统注入异常输入。</p>
  <p>在尝试复现原始React2Shell问题的过程中，Codex发现了一些异常行为，值得深入调查。</p>
  <p>最终，在短短一周内，这一流程促成了此前未知漏洞的发现，并被以负责任的方式披露给React团队。</p>
  <p>这一案例清楚地展示了，先进AI系统如何显著加速真实世界、广泛使用的软件中的防御性安全研究。</p>
  <h2><strong>网友实测</strong></h2>
  <p>一位开发者实测GPT-5.2-Codex编写一个模拟道路上车辆与交通灯工作方式的程序，结果失败了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_9c7c9c80269b4261a318c590d6b10204@5091053_oswg159184oswg1080oswg377_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_698e839fbb9e490db3d06949569a286e@5091053_img_gif?x-oss-process=image/quality,q_100" /></p>
  <p>不过也有人认为，其具备了与Gemini 3 Flash和Pro同样精美的动画效果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ce47d5712e7940e197f440945323b92c@5091053_oswg205955oswg1080oswg594_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_81d0dae7def546c88c3d1ecf2cfef780@5091053_img_gif?x-oss-process=image/quality,q_100" /></p>
  <p>GPT-5.2-Codex在生成一款反恐精英的游戏，表现亮眼。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_8f6aed893d4542b69113e5c4b5914ea3@5091053_img_gif?x-oss-process=image/quality,q_100" /></p>
  <p>总言之，OpenAI认为，GPT-5.2-Codex的发布，是AI在真实软件开发与网络安全领域的又一大步。</p>
  <p>它让开发者，能轻松应对复杂又耗时的任务，同时也为网络安全研究提供更好的工具支持。</p>
  <p><strong>参考资料：</strong></p>
  <p>https://openai.com/index/introducing-gpt-5-2-codex/</p>
  <p>https://openai.com/index/gpt-5-2-codex-system-card/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/RtYJmYnM-pT3qlxlWLPpdA?click_id=13" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，编辑：桃子 好困，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3601986084029448</id>
            <title>人形机器人最大融资背后，还拿下7亿大单</title>
            <link>https://www.36kr.com/p/3601986084029448</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3601986084029448</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 06:06:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人形机器人，迎来一针暴力强心剂。</p>
  <p>投中网获悉，银河通用已完成新一轮融资，规模超过3亿美元（约合超21亿元人民币），投后估值超过30亿美元（超200亿元人民币）。这两个数字意味着，国内人形机器人赛道的单笔最大融资额，以及估值天花板，双双被刷新了。</p>
  <p>再来看投资方，本轮融资由中国移动链长基金领投，中金资本、中科院基金、苏创投、央视融媒体基金、天奇股份等投资平台及产业巨头，同时也获得新加坡及中东国际投资机构的注资及老股东追加投资。</p>
  <p>与宁德时代和溥泉资本领投的上一轮，也就是6月份那轮融资相比，投资方阵容变化不小，更多元化，传了许久的中东资本也终于落地，能看出来银河通用在试图构建自己国际化的股东生态，而且继宁德时代后又来了个央企“大家伙”——中国移动。</p>
  <p>截至目前，银河通用累计获得的融资金额已经约8亿美元（合56亿人民币），而半年前这个数字还只有24亿元。由于某种未知原因，银河通用还另有大额融资未公布。</p>
  <p>另外，投中网还独家获悉，银河通用已经与某单一产业方签订了一笔G1机器人采购合同，规模达到1000台，如果按照G1约70万元的售价计算，合同金额将达到7亿元。</p>
  <p>7亿元的订单，是什么概念？要知道宇树和智元这两家赛道头部企业，2025年的营收可能也在10亿元左右的级别，一笔来自产业方的7亿元订单，或许也是促成这次刷新纪录的融资的直接原因。</p>
  <p>在这笔7亿元的订单之前，优必选刚刚与广西防城港人形机器人数据采集与测试中心签订了2.64亿元的大额合同，创下全球最大人形机器人单笔订单纪录。7月份，宇树和智元联合中标了中国移动1.24亿元的人形双足机器人代工合同。现在，银河通用似乎又出来告诉大家，贵也有贵的道理，产品做的好就会有人买单。</p>
  <p>这既是为什么我说这个赛道越来越“看格局、看规模、看确定性”的原因，包括银河通用、智元、宇树、优必选等也明确向市场传递了一个信号，人形机器人当然可以继续出现在各种秀场、发布会和实验室中，也架不住已经有人用真金白银大手笔将它们搬进厂房。</p>
  <p>因此对于商业化难落地的行业，持续的市场化订单类似发令枪，比如评估GPU，一个重要维度是有无互联网大厂的大客户，国产芯是否经受得住大厂的算力需求，因此你才看到短短一年多来市场对摩尔、沐曦态度的转变。</p>
  <p>对于机器人，“大厂”就是那些制造业龙头，除了上述7亿元订单外，银河通用已经拿下包括宁德时代、博世集团、丰田汽车、韩国现代、北汽集团、上汽集团、极氪汽车、长城汽车等千台级订单，这一串客户名单摆出来确实有些说服力。尤其宁德时代，银河通用还是目前其唯一投资的具身智能企业。</p>
  <h2><strong>海外资本的红利</strong></h2>
  <p>再来具体看看新股东，中国移动链长基金、中金资本、中科院基金、苏创投、央视融媒体基金、天奇股份等，咱们挨个说。</p>
  <p>作为领投方，中国移动2013年底发起设立链长基金，锚定“9+6”战略及未来产业，聚焦AI+、人形机器人、算力网络、5G/6G等核心赛道，投资的具身智能企业包括银河通用、戴盟机器人，且都是这个月的事儿。更早前，中国移动还给智元、宇树提供代工订单等。</p>
  <p>也不止中国移动，联通、电信也都有动作，比如最近刚刚联合参与了云深处的超5亿元C轮融资。客观来看，响应国家战略规划，显然是运营商参与人形机器人的最底层逻辑，不过，人形机器人毕竟是各路资本看好的未来的移动终端，那几大运营商也没理由不卡住这个生态位，守住基本盘。</p>
  <p>中金资本作为财务投资机构，11月刚领投了松延动力的近2亿元Pre-B轮+轮融资，也参与设立江西省首支智能机器人产业基金等。背靠中金，再加上券商系机构的偏好，我们有理由推测除了财务回报，被他们“看上”的人形机器人公司，都是IPO的种子选手。</p>
  <p>就在两周前，银河通用完成股改，被曝将以40亿美元估值在明年一季度赴港IPO，而银河通用对此的回复是，上市信息不实，目前仍无明确时间表，为公司融资需要，必须进行股改，否则无法引入新的投资人。</p>
  <p>中科院基金强于中科院体系的产业链投资与技术成果转化，有中科院自动化所等作为技术源头，可以为银河通用提供核心算法和本体的设计支持，旗下“格物”与银河通用的技术路线，也就是仿真数据训练想必也会有一定协同。</p>
  <p>今年4月，银河通用在苏州落地了研发、测试和应用中心，以及一个产业化基地，即构建“3中心+1基地”合作体系。因此作为苏州国资的管理人，苏创投的入局也不算意外。</p>
  <p>今年3月，苏创投就牵头发起100亿元的具身智能基金，这个规模在国内属于绝对头部，最近跟投了朱啸虎看中的水下机器人世航智能。银河通用是具身智能的头部公司，世航智能则是机器人快速落地变现的典型案例，很明显苏创投要的是“抓两头”。</p>
  <p>自从宇树在春晚彻底打开了机器人表演的想象力，央视融媒体基金在人形机器人的动作不断，投资了云深处、松延动力、众擎机器人等公司，可以合理推断，马年央视春晚也少不了机器人。</p>
  <p>天奇股份是一家A股上市公司，服务理想、比亚迪、特斯拉、丰田等客户，2025年成立人形机器人事业部，是目前的三大核心业务之一，深度绑定银河通用，2月共同设立无锡天奇银河机器人有限公司。另外与富士康新能源合作，5年内将部署不低于2000台具身智能机器人。这次参与投资银河通用，也算是传闻终于落地了。</p>
  <p>同样是传闻终于落地，中东对中国科技资产，尤其机器人热情很高。听闻投资人描述过一个趣闻，某中东王子专程飞到深圳与某机器人企业谈融资，包下了深圳某豪华酒店最大的宴会厅，但其实大家只一桌就够坐。</p>
  <p>最近中东资金加码中国机器人的消息不断。就在上周，地瓜机器人完成数亿美元B轮融资，全球能源巨头沙特阿美旗下的风投基金Prosperity7 Ventures（P7）在资方名单。迪拜的Stone Venture（磊石资本）曾在2025年4月领投众擎机器人Pre-A轮融资，又在本月A2轮融资再次加码。今年9月，阿布扎比背景的Infini Capital为优必选提供10亿美元的融资授信。</p>
  <p>中东对机器人的热情源于国家转型的迫切。比如沙特和阿联酋分别定下“2030愿景”、“AI战略2031”的规划，力求通过打造人工智能产业，降低石油在GDP依赖，手段则是设立百亿甚至千亿美金体量的基金，由诸如PIF主权财富基金牵头，在全球范围内寻找优质科技资产进行投资，也包括这次银河通用新增股东名单中的新加坡投资机构，这显然是中国机器人企业的一波红利。</p>
  <h2><strong>估值最高的人形机器人公司</strong></h2>
  <p>按照超过200亿人民币的估值，银河通用一举成了目前国内估值最高的人形机器人公司。</p>
  <p>目前，银河通用的产品重点布局在工业制造、即时零售、医疗康养等领域，并且在一些场景已经7X24小时持续稳定运营1年。今年6月，他们发布了行业首个面向零售的具身智能大模型GroceryVLA和导航大模型TrackVLA。前不久又抛出了NavFoM——全球首个跨本体、全域环视的导航基座大模型。</p>
  <p>长期以来，机器人的移动是基于预设地图的“循迹”，类似于在轨道上跑。而NavFoM试图实现的是在复杂、动态场景下的自主导航和动态避障，并在业内率先突破了“小时级长程导航”。这对于进入复杂的工业和零售环境，是真正的生死门槛。</p>
  <p>另外值得关注的，是银河通用对“灵巧操作”的突破，毕竟传言中特斯拉机器人难产的原因，就在于“手”。根据银河通用发布的灵巧手神经动力学模型DexNDM，传统的轨迹编程搞不定复杂的物理互动，银河通用试图通过基于训练的控制算法，让灵巧手能应对各种极长、极小物品的精密操作，甚至能“修桌腿、拧螺丝”。</p>
  <p>银河通用的核心逻辑是“Sim-to-Real”（仿真到现实），通过构建虚拟环境，在数字世界里训练机器人，然后将其迁移到现实。这种路径的优势是迭代极快，但挑战也显而易见，现实物理世界的复杂性，比如传感器的尘土、光线的剧烈变化、地面的摩擦力波动，往往是虚拟环境难以穷尽的。</p>
  <p>技术角度外，最后再从资本角度说说人形机器人行业。如果投票选择过去一年多以来，持续时间最长，凝聚了最多共识的赛道，具身智能没准能拿到最多的票数。但伴随着的其实是非共识并未消退，反而以某种形式又如2023年时那般卷土重来了，并且显现出更加复杂的格局。</p>
  <p>一位国资投资人对我表示，某头部具身智能公司最近融资接连“碰壁”。说碰壁或许有些不准确，大概的情况是，头部公司既然开放融资窗口，那势必要有不少附加条件，估值自然是一方面，重点还有不少配套的“要求”，评估下来几个城市的国资都选择了放弃。</p>
  <p>根据投中嘉川CVSource数据，头部公司能占据行业全年融资额的四成，行业整体创业活跃度依旧不减，获得融资的企业数量和融资规模同比继续大涨，数据层面来看这是无可辩驳的事实。</p>
  <p>我在《具身智能创始人，来找我面试了》写过，人形机器人本体赛道的资源在越来越向头部集中的同时，你也可以明显看到各类投资方的风险意识也在不断增强，抱团+团购意味着，投资人从一年前的看人、看技术、看路线，逐渐过渡到看格局、看规模、看确定性。</p>
  <p>当然，你也可以观察近期其他融资规模较大的机器人公司，大概率能得到一份更长的股东名单。现象都摆在这里，一方面意味着还有源源不断的入局者，这个赛道依然亢奋，资源链接能力依然在增强，且头部公司依然是卖方市场，但另一方面最重要的是，现在已经过了FOMO的时候，除了二级市场，“无脑”的热钱真的已经不多了。要想一直留在牌桌上，唯一的途径或许还只能是想办法拿更多的钱，现在看来，银河通用留在牌桌上的几率又大了些。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/8LKSN_xg56wqrlSemAOmKQ?click_id=12" rel="noopener noreferrer nofollow" target="_blank">“投中网”</a>，作者：张楠&nbsp;曹玮钰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3601901831176712</id>
            <title>手机厂商“杀入”短剧市场：小米砸钱囤片，华为试水变现，图的是啥？</title>
            <link>https://www.36kr.com/p/3601901831176712</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3601901831176712</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 04:21:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>从一年 3.7 亿元的市场规模，增长到超 500 亿元的市场规模，短剧行业只用了短短三年时间。DataEye研究院发布的《2024年微短剧行业白皮书》预计，2025年市场规模将超过680亿元，2027年将突破1000亿元。</p>
  <p>爆炸式增长的市场表现，对应的是短剧这一新兴影视内容形态对用户群体的强大吸睛能力。截至今年 6 月，中国微短剧用户规模已达 6.26 亿人，占网民整体的 55.8%。来到 8 月，微短剧应用的人均单日使用时长更是增至 120.5 分钟。</p>
  <p><strong>用户体量、停留时长、市场规模</strong>交织在一起，而且还有继续高速成长的空间，这样的一个互联网新内容行业，同样成了手机厂商们的必争之地。</p>
  <p>在近日举行的 2025 小米人车家全生态合作伙伴大会上，小米互联网业务部总经理刘婵透露，<strong>小米目前已拥有 1000 部 S 级短剧，人均短剧消费时长达到 70 分钟</strong>。</p>
  <p>按照<a href="http://www.cnsa.cn/module/download/downfile.jsp?classid=0&amp;filename=d2617fc1d3d742248c26765b0230b970.pdf" rel="noopener noreferrer nofollow" target="_blank">中国网络视听协会</a>的层级划分，短剧分为<strong>冲量、普通、精品、S 级</strong>这四个层级。2025 年，制作成本最低的冲量剧集单部在 10 到 30 万元，最高的 S 级剧集单部在 150 到 300 万元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3c79b0d462814bb8a6f67b44c7fb04fb@1547419282_oswg408454oswg1742oswg1094_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：中国网络视听协会）</p>
  <p>伴随短剧行业的精品化转型，各大平台的发力重点正在逐渐转向 S 级和精品剧集，而这也成了小米此番强调自家平台手握大量头部短剧资源的重要背景。小米的潜台词亦很明显，「<strong>我们已经投入大量开支，用来采购或自制头部和精品短剧集</strong>」。</p>
  <h2><strong>手握千部S短剧，小米短剧APP还在「新手期」</strong></h2>
  <p>今年 9 月底，小米推出旗下独立短剧 app「围观短剧」，目前只在小米应用商店上架。围观短剧 app，主打「无广告」「全免费」「轻量化」，目前累计下载次数 242 万，表现也没多好。</p>
  <p>有趣的是，在小米应用商店搜索「短剧」时，自家的「围观短剧」虽然被放在最前列，却被更上面进行广告推广的「红果短剧」给压了下来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_a8e40e2cbb4141bc9d3610689fff2d38@1547419282_oswg1054814oswg1279oswg2548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米应用商店）</p>
  <p>围观短剧 app，由小米全资持股的「孙公司」，成都分享信息传播有限公司开发，该公司法定代表人系小米集团联合创始人王川。</p>
  <p>小米这款短剧 app 的优点，上面已提，缺点同样明显，那就是<strong>总体片源依然不够多</strong>，上线 2 个多月后的现在依然如此。</p>
  <p>数据显示，目前短剧行业的两大头部 app，分别为红果短剧、河马剧场，其中红果短剧目前处于「大幅领先」的市场地位。那么，就以<strong>河马剧场</strong>为例，其今年宣称已经储备了超过 100 个类别的超过 1 万部「优秀」短剧作品。围观短剧，虽然没有给出具体的总片源数据，但类别上目前依然不到 30 个。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_96cce9d52171428fac30c99b32a73e0b@1547419282_oswg408966oswg1279oswg1288_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：围观短剧）</p>
  <p>值得注意的是，小米方面也算坦诚，其 70 分钟的人均单日短剧消费时长，相比目前短剧全行业的 120 分钟人均单日水平，表现并不算好。不过，鉴于小米旗下独立短剧 app 上线也才不到 3 个月，所以不妨再给多些时间。</p>
  <p>综上来看，目前以围观短剧 app 为核心的小米短剧内容平台建设，如果不把其当「新手」来看待的话，总体表现并没有多出彩。</p>
  <h2><strong>短剧赛道“三国杀”，华米OV各怀心思</strong></h2>
  <p>其实相比小米，华为更早进军短剧新赛道，只不过是以「快应用」为载体。</p>
  <p>早在去年 5 月，华为就对旗下独立短剧快应用「短剧大全」开启了众测，不过采用的是付费短剧解锁和账户充值模式。今年 8 月，「短剧大全」更新到了 2.0 版本，正式名称也缩减为了「短剧」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_ef50d35b209c4060a775abc901eff143@1547419282_oswg666392oswg1279oswg2370_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：华为应用市场）</p>
  <p>值得注意的是，华为新版本的「短剧」快应用，不仅提供短剧内容，亦涵盖热门电影、电视剧、综艺、纪录片等众多影视内容。不难看出，<strong>华为的「短剧」快应用，同样面临片源不足的问题</strong>，甚至今年以来就没怎么进行过推广。</p>
  <p><strong>OPPO、vivo、荣耀等国产手机厂商，虽然没有推出自家的短剧 app 或快应用平台，但和小米、华为一样，也都在短剧内容市场进行过自家品牌或相关机型的营销推广。</strong></p>
  <p>其中，小米 REDMI 联合抖音、万合天宜出品的短剧《时空合作人》今年暑假开播，主演包括前小米中国区市场部总经理、REDMI 品牌总经理王腾以及 REDMI 产品经理胡馨心，制定产品为 K80 至尊版和 K Pad。这部短剧的结尾更是出现了雷军的声音，而剧中的反派公司叫「耀界」，诸如此类的设定，得到了更出圈的网络传播和用户讨论。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_55f52288018f45ae98f23e2e11bf1f2f@1547419282_oswg1551249oswg1600oswg2133_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米 REDMI）</p>
  <p>今年以来，华为也推出了 Pura X 系列的微短剧，以及与腾讯视频联合出品、用来推广华为 nova 14 系列的职场轻喜剧《真渡假渡》。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4b08b3e925eb4277819b17b36b44ff24@1547419282_oswg946899oswg1933oswg1279_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：华为终端）</p>
  <p>更早涉足短剧内容营销的是 OPPO，早在 2023 年底，OPPO 就独家冠名了短剧《月白之时》，并在剧情层面深度植入了 OPPO Reno11。去年底，OPPO 服务的系列短剧上线。</p>
  <p>根据勾正科技提供的榜单数据，今年 11 月，OPPO 和小米 REDMI 投放的合作短剧热度，位列电子 3C 品牌榜单前二。</p>
  <h2><strong>手机厂商玩短剧，究竟是图啥？</strong></h2>
  <p>其实在短剧之前，手机厂商也涉足过长视频（剧集）、电影（微电影）、短视频（微短片）等内容赛道领域，不过并没有取得太大建树。</p>
  <p>现在，又来到了短剧的新风口。相比以上几种视频内容呈现形式，短剧的优势是，<strong>制作成本更低、变现效果更好</strong>，更加契合互联网和科技企业的行事风格，故而引发了手机厂商的关注。</p>
  <p>以华为和小米为例，<strong>华为</strong>自有的短剧平台，目的很纯粹，就是要通过引入的这些<strong>微短剧来进行商业变现</strong>，故而可以通过付费解锁剧集或广告变现等方式来开展；</p>
  <p><strong>小米</strong>自有的短剧平台，主打「无广告」「全免费」，那么更多就体现在<strong>对其内容生态和平台建设的助益</strong>上，例如可以增加小米手机用户在自有内容平台的停留时长，同时借助诸如《时空合作人》这类的微短剧，可以为自家品牌和产品提供一个「低成本、大流量」的内容宣传媒介。而影视化、故事化的呈现形式，即便用户知道有营销因素，相对也会不那么反感。</p>
  <p>或许更为重要的是，<strong>短剧这样的影视化形式和轻量化形态，无疑更加契合人车家全生态场景下的内容消费范式</strong>。与其让红果短剧、河马剧场等，来无缝接入小米用户的全生态内容消费场景，不如先用自己的平台去尝试一下。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d4c66bad65f94f4db2d7dda236e2298e@1547419282_oswg2355612oswg2562oswg1554_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：小米汽车）</p>
  <p>汽车场景下，如果有视频内容消费最佳样式的话，不是长视频、不是电影，而是短视频或微短剧。短视频，手机厂商已经很难再建立自有内容平台，微短剧就成了这最后一试的「机会」了。</p>
  <p>另外，不管是小米，还是华为，目前都还没有真正、全面发力微短剧平台建设。按照行业白皮书预计，今年微短剧市场规模将达 600 多亿元，2027 年更将突破 1000 亿元。手机厂商们的下一步动向，值得关注。</p>
  <h2><strong>短剧的 AI 和出海，成手机厂商全球化新跳板</strong></h2>
  <p>全球影视行业，正在面临史无前例的 AI 化技术革新浪潮。作为其中最容易被 AI 技术全面赋能的影视创作类型领域，微短剧的制作技术，尤其非真人场景和特效画面制作技术，不可避免地将成为第一波 AI 商业影视创作的试验品。</p>
  <p>例如，今年开始加速爆发的<strong>漫剧</strong>市场，后续 AI 制作技术的全面应用，就被寄予厚望，也成为各大厂商新的细分战场。</p>
  <p>这一新进程中，手机厂商，尤其是像小米这类的互联网手机厂商，同样可以发挥更加重要的作用。而在 AI 短剧的商业化浪潮中，科技企业包括手机厂商的话语权，只会越来越大。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_4722232c2b9b4b51be478470d3969caa@1547419282_oswg2678112oswg2364oswg1773_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（图源：豆包）</p>
  <p>这两年，短剧出海同样成为行业热词。国产手机厂商在海外市场的庞大活跃用户基数，搭档国产短剧在海外市场掀起的观影热潮，是再合适不过的「中国软硬件内容生态」出海样式了。</p>
  <p>以小米为例，其互联网服务目前已覆盖全球 100 多个国家，拥有超过 10 亿台活跃终端设备。国产手机厂商在海外市场的内容生态，本身就稍显薄弱。如果可以在这一次的短剧出海热潮中，借势把自有内容平台在海外市场的声量甚至体量真正建立起来，那么中国手机品牌在海外市场的用户粘性也将进一步提升，并来到一个全新的 level。</p>
  <p>短视频之后，短剧不可避免地将成为国内外手机用户又一新的内容消费范式。影视内容创作和消费层面正在迎来的这场变革，对手机厂商来说，不仅是一个新内容切入口，也是打造更加一体化的「硬件+内容」生态平台的一次重要契机。</p>
  <p>本文来自微信公众号“雷科技”，作者：雷科技AI硬件组，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3601928707769349</id>
            <title>福建光芯片龙头今天IPO了，开盘暴涨365%，市值超200亿</title>
            <link>https://www.36kr.com/p/3601928707769349</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3601928707769349</guid>
            <pubDate></pubDate>
            <updated>Fri, 19 Dec 2025 04:20:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>芯东西12月19日报道，今天，厦门光通信芯片龙头企业<strong>优迅股份</strong>在上交所科创版上市。</p>
  <p>其发行价为51.66元/股，开盘价为240元/股，较发行价上涨364.6%。截至今天9点35分，优迅股份股价较发行价上涨403.25%至259.99元/股，最新总市值约为208.0亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_0342d59252a843b7a5c56fd105539c45@1743780481_oswg187136oswg1000oswg1855_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">优迅股份股价变动（图源：腾讯自选股）</p>
  <p>优迅股份成立于2003年2月，主要从事光通信前端收发电芯片的研发、设计与销售，是国内光通信领域的“国家级制造业单项冠军企业”。</p>
  <p>同时，优迅股份也是我国<strong>为数不多</strong>可提供全应用场景、全系列产品光通信电芯片解决方案的企业。该公司产品性能和技术指标上实现对国际头部电芯片公司同类产品的替代，成功打入全球众多知名客户供应链体系。</p>
  <p>根据ICC数据，2024年度，优迅股份在10Gbps及以下速率产品细分领域市场占有率位居<strong>中国第一、世界第二</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_85530a3ddf9b42d9880a3c694c20554a@1743780481_oswg210873oswg1000oswg762_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在25G速率以上的市场，我国光通信电芯片自给率极低，下游厂商高度依赖境外进口。优迅股份的单通道25G电芯片及4通道100G电芯片已在数据中心、5G无线传输等关键领域实现批量应用。</p>
  <p>优迅股份的注册资本为6000万元，法定代表人是柯炳粦，实际控制人是柯炳粦、柯腾隆父子，无控股股东。<strong>国内模拟芯片龙头圣邦股份</strong>是其第二大股东，<strong>中国移动旗下投资公司中移基金</strong>是其第七大股东。</p>
  <p>此次IPO，优迅股份实际募资总额为<strong>10.3亿元</strong>，扣除发行费用后募集资金净额为<strong>9.28亿元</strong>。这些资金将投入下一代接入网及高速数据中心电芯片开发及产业化项目、车载电芯片研发及产业化项目、800G及以上光通信电芯片与硅光组件研发项目、补充流动资金等项目。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_5a717d3ae9e54926b33fd9d208d8cb48@1743780481_oswg102830oswg1000oswg448_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>01.三年累计营收逾10亿元，净利润超过2亿元</strong></h2>
  <p>作为光模组的关键元器件，光通信电芯片承担着对光通信电信号进行放大、驱动、重定时以及处理复杂数字信号的重要任务，其性能直接影响整个光通信系统的性能和可靠性。</p>
  <p>自成立以来，优迅股份在光通信电芯片设计领域形成了完备的核心技术体系，在收发合一、高速调制、光电协同等关键领域实现国产化技术突破。</p>
  <p>2022年、2023年、2024年，优迅股份的营收分别为3.39亿元、3.13亿元、4.11亿元，净利润分别为0.81亿元、0.72亿元、0.78亿元，研发费用分别为0.72亿元、0.66亿元、0.78亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_7436e3860d8e412cbd243be60a346a25@1743780481_oswg208250oswg1000oswg741_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">2022年~2024年优迅股份营收、净利润、研发支出变化（芯东西制图）</p>
  <p>2025年1-6月，优迅股份的营收为2.38亿元，净利润为0.47亿元，研发费用为0.37亿元。基于目前的经营状况和市场环境，优迅股份预计其2025年总营收约为4.75亿-4.95亿元。</p>
  <p>2022年、2023年、2024年和2025年1-6月，优迅股份主营业务毛利率分别为55.26%、49.14%、46.75%、43.48%，逐年下降。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_230cb8047948458bb368c220b67efc07@1743780481_oswg56001oswg1000oswg362_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>报告期内，境外同行业上市公司毛利率平均值分别为65.03%、58.35%、58.06%、59.18%。优迅股份的毛利率低于Semtech、Macom，主要是因为产品种类、产品速率存在差异。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3edc9f7e6f414108824c65cc65d03a7a@1743780481_oswg28007oswg1000oswg245_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Semtech、Macom产品矩阵丰富，除光通信电芯片外，还存在其他产品，光通信电芯片行业产品速率覆盖100Mbps-1.6Tbps等，拥有较高的定价权。</p>
  <p>优迅股份的主营业务收入主要来自于光通信收发合一芯片产品的销售，这一产品贡献了其8成以上的营收。优迅股份的其余产品包括跨阻放大器芯片、限幅放大器芯片、激光驱动器芯片等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_3fd199c3c07e4c62bdd1412ef1711262@1743780481_oswg50344oswg1000oswg387_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02.研发人员占比超过54%，正研发800Gbps数据中心收发芯片</strong></h2>
  <p>基于长期的技术研发和技术积累，优迅股份坚持正向设计，已掌握深亚微米CMOS、锗硅Bi-CMOS双工艺技术能力，掌握全套带宽拓展、阻抗匹配、信号完整性补偿等技术，具备从单通道155Mbps到多通道800Gbps的全速率超高速光通信电芯片设计经验。</p>
  <p>该公司基于对激光驱动器芯片（LDD）、跨阻放大器芯片（TIA）、限幅放大器芯片（LA）、光通信微控制器芯片（MCU）及时钟数据恢复器（CDR）、模数转换芯片（ADC）、数模转换芯片（DAC）等光通信电芯片核心系列产品与技术的深度理解，可结合市场需要为客户量身定制套片解决方案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_2adfc77c17b34cdb92ec131c8d392fd1@1743780481_oswg77203oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>套片解决方案较单独采购芯片进行组合，具有系统集成度更高、成本更具竞争优势、技术支持更为简便高效的优势，受到客户的广泛认可。</p>
  <p>优迅股份独立或牵头承担了包括科技部“863计划”、科技部“国家国际科技合作专项项目”、工信部“工业强基项目”、科技部“国家科技重点研发计划项目”在内的多个重大国家级科研攻关项目，并参与制定22项国家及行业标准。</p>
  <p>该公司先后获评“国家规划布局内集成电路设计企业”、“国家知识产权优势企业”、“国家级专精特新重点‘小巨人’企业”及“国家级制造业单项冠军企业”等国家级资质。</p>
  <p>截至2024年年底，优迅股份共有84名研发人员，占总员工数的54.90%；已授权专利数量共110项，其中发明专利76项，实用新型专利34项，获得软件著作权8项，集成电路布图设计30项。</p>
  <p>优迅股份已实现155Mbps～100Gbps速率光通信电芯片产品的批量出货，并正在积极研发50G PON收发芯片、400Gbps及800Gbps数据中心收发芯片、4通道128Gbaud相干收发芯片、FMCW激光雷达前端电芯片、车载光通信电芯片等系列新产品。</p>
  <h2><strong>03.去年卖出2.44亿颗芯片，主要采购晶圆与封测服务</strong></h2>
  <p>报告期内，优迅股份根据市场情况备货及销售，产销率存在一定的波动。其激光驱动器芯片主要系成熟产品，历史备货较多，2023年、2024年、2025年1-6月份产量低于销量，产销率较高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_1ada688f45f74728a1191f7c791c097a@1743780481_oswg79755oswg1000oswg622_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其光通信收发合一芯片、跨阻放大器芯片、限幅放大器芯片、激光驱动器芯片的平均销售单价如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_b4bba1251f264a678ae07911e619da22@1743780481_oswg47072oswg1000oswg295_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2022年、2023年、2024年、2025年1-6月，优迅股份向前五大客户销售金额占总销售金额的比例分别为65.22%、55.24%、53.30%、65.53%，客户集中度较高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_271a57ee95674a8ab62ffb1afe3d9998@1743780481_oswg188711oswg1080oswg1329_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同期，其向前五大供应商的采购金额占总采购金额的比例分别为86.36%、83.68%、89.47%、84.48%，其主要采购内容包括晶圆和封测服务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_69fe925177954a94876044dcf3f9e72e@1743780481_oswg161433oswg1080oswg1192_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>04.父子联手掌舵，圣邦股份、中国移动持股</strong></h2>
  <p>优迅股份的股权较为分散，单一股东所持表决权均未超过30%，无控股股东。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_a4417dbe07c14872aba8915e28ae6e70@1743780481_oswg141273oswg1000oswg397_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其董事长柯炳粦直接持股10.92%股份，通过担任科迅发展的执行事务合伙人间接控制4.59%表决权，共控制15.51%表决权；柯腾隆担任员工持股平台芯优迅、芯聚才、优迅管理的执行事务合伙人，并通过上述三个员工持股平台控制11.63%表决权。柯炳粦与柯腾隆合计控制27.13%表决权。</p>
  <p>柯炳粦出生于1955年9月，1983年到1990年历任厦门大学法律系党总支副书记、讲师、校党委宣传部副部长，并兼职律师，而后分别就职于厦门商业对外贸易总公司、厦门商业购物中心、厦门斯坦利咨询顾问有限公司、中印胜欣能源技术（北京）有限公司。</p>
  <p>他在2003年2月创立优迅股份的前身厦门科芯微，随后历任厦门科芯微及优迅有限董事长、优迅有限董事长兼总经理，2024年4月至今任优迅股份董事长。</p>
  <p>柯炳粦与柯腾隆是父子。柯腾隆出生于1987年9月，曾任职于澳大利亚PCIA投资管理公司、厦门乃尔电子有限公司，2014年到2024年历任优迅有限董事长助理、常务副总经理、董事，2024年4月至今任优迅股份董事、总经理。</p>
  <p>截至招股书签署日，除实际控制人柯炳粦、柯腾隆及其控制的科迅发展、芯优迅、芯聚才、优迅管理外，其他持有优迅股份5%以上股份或表决权的股东为圣邦股份、远致星火、省电产投系基金、蔡春生及一方建设、陈涵霖、萍妮茹投资、龙驹投资系基金、中移基金。</p>
  <p>其中，最新市值429亿元的国内模拟芯片龙头圣邦股份是其第二大股东，直接持股10.26%；中国移动旗下投资公司中移基金是其第七大股东，持股5.00%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_51455530e14f4f32b6638d4cadc1a70b@1743780481_oswg137612oswg1000oswg628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">本次发行前的前十名股东</p>
  <p>2024年，优迅股份董事、监事、高级管理人员及核心技术人员从公司及关联企业领取薪酬的情况如下：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251219/v2_d80a665d3fbf481299ef0d9175f6e12c@1743780481_oswg100122oswg1000oswg1036_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>05.结语：光通信电芯片是国产化薄弱环节，优迅股份拟聚焦三大高增长领域</strong></h2>
  <p>当前，我国已成为全球最大的光器件、光模块生产基地。根据LightCounting 2024年全球光模块厂商排名，中国企业在前十强中占据七席，市场主导地位显著。但与之相对的是，光通信电芯片的发展相对不平衡，是我国光通信产业链薄弱的一环。</p>
  <p>优迅股份以成为国际光通信、光传感收发电芯片领先企业为核心战略目标，致力于提供从芯片到组件的完整解决方案。</p>
  <p>未来三年，该公司计划持续围绕高速光通信、硅光集成、车载光电等方向加大投入，布局关键专利形成技术壁垒：</p>
  <p>在光通信领域，加速FTTR（光纤到房间）产品升级，完成50G PON全系列产品开发，满足下一代宽带接入需求；</p>
  <p>同步突破单波100G、单波200G高速数据中心电芯片技术，并推进400G及以上速率的相干光收发芯片研发，以支撑长距离、大容量传输场景；</p>
  <p>重点攻关800G/1.6T硅光组件，为超高速数据中心和骨干网提供低功耗、高集成度解决方案；</p>
  <p>在车载领域，集中资源开发FMCW激光雷达核心芯片组，同时积极布局车载光通信电芯片组的研发，满足车规级高可靠性要求。</p>
  <p>长期规划中，优迅股份计划以光通信电芯片技术为核心平台，聚焦于电信侧、数据中心侧及终端侧三大高增长领域的应用场景开发，在电信侧和数据中心侧将致力于推动高速率光通信电芯片的技术突破，在终端侧将重点布局车载与具身智能等高潜力场景，开发高可靠性车载光通信电芯片及FMCW激光雷达核心芯片组。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JnOQqddYTl4WRR5t898TJg" rel="noopener noreferrer nofollow" target="_blank">“芯东西”</a>，作者：陈骏达，编辑：心缘 ，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>