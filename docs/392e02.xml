<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3612259589386755</id>
            <title>背叛初衷，“美国支付宝”要靠银行牌照续命了</title>
            <link>https://www.36kr.com/p/3612259589386755</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612259589386755</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:21:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>曾经的屠龙少年，到底是妥协了。</p>
  <p>当年，PayPal 以“颠覆者”之姿登上舞台，怀揣着颠覆传统银行金融体系的初心，立下了打造独立于银行体系之外的全球电子货币系统的雄心壮志。</p>
  <p>但事实上，公司的发展方向从来都不只是个体意志的选择，而是整体宏观环境和社会结构下，所做出的最现实抉择。</p>
  <p>曾经想颠覆银行的paypal开始努力成为银行。前不久，Paypal向监管提交申请，计划成立一家名为「PayPal Bank」的工业银行。</p>
  <p>之所以选择成为银行，是因为银行牌照是 PayPal 为数不多的救命稻草。</p>
  <p>PayPal 九成收入依赖支付业务，本质上是一家靠 “过路费” 生存的公司。但 PayPal 既无流量壁垒，也无政策保护，市场正被 Block、Apple Pay、Google Pay 蚕食，市占率三年内下滑了14.5个百分点。</p>
  <p>而手握银行牌照后，PayPal 将提升其各业务条线的竞争力。届时，其支付业务将拥有更多流量入口，信贷业务也将获得更低的资金成本。</p>
  <p>曾经，那个初生牛犊不怕虎的少年，终究是有了中年人对现实妥协的无奈。</p>
  <h2><strong>“过路费”越来越难收了</strong></h2>
  <p>正如中国没有沃尔玛，美国也出不了美团，企业出生地用户习惯、监管环境、区位特征等地缘因素的不同，会让出身相同的公司活成截然不同的两种物种。</p>
  <p>支付宝和Paypal就是最典型的案例。</p>
  <p>两者都是从电商支付起家，后逐渐形成了C 端钱包 + 日常/跨境支付的综合金融工具。虽然表面功能相似，但他们的商业模式却天差地别。</p>
  <p>和支付宝形成了支付、信贷、财富管理多元驱动的业务格局不同，Paypal收入集中在支付业务上，其支付收入占比在90%以上。</p>
  <p>Paypay的信贷、财管没有发展起来，既和监管环境有关也和竞争格局有关。</p>
  <p>美国对非银行机构的信贷、理财等金融业务监管极严。PayPal没有全功能银行牌照，没办法独立放贷，贷款业务需要合作银行提供资金，它只能赚技术服务费。同样，财富管理也只能做代销，难成核心收入。</p>
  <p>当然，对于规模庞大的信贷生意来说，就算只赚技术费，规模也可观。但问题是Paypal做信贷业务并无太大竞争力。</p>
  <p>Paypal的信贷产品包括“Pay in 4”（先买后付）、PayPal Credit（虚拟信用卡）以及PayPal Working Capital（商家贷款），但唯独缺少个人信贷。</p>
  <p>这是因为竞争环境不允许，个人信贷这门生意被互联网银行盯上了，典型如SoFi都把缺资产、缺数据的学生贷款利率压到了5.99%。而paypal从合作银行那拿到的资金成本就在4.5%至6%。用低利率服务优质客群的逻辑，在paypal这是很难成立的。</p>
  <p>虽然信贷跑不通，但好在美国的支付生意实在是太好赚钱了。</p>
  <p>PayPal 平均能从每笔交易中抽取1.7%-2.0%的费率。这个费率是其全业务的整体平均抽成率，包括不漏出品牌的技术服务，如果是商业交易或者跨境交易，实际费率会更高。</p>
  <p>对比之下，国内移动支付的费率大多在0.2%-1.2%。美国移动支付普及率不高，paypal的高费率出了不少力。</p>
  <p>但Paypal变现集中在支付，说明了它本质是靠收“过路费”活着的公司。过路费+高费率，意味着低壁垒，一旦竞对卷费率，Paypal的份额会掉的很厉害。</p>
  <p>这也是paypal现在最大的问题，亚马逊、苹果、谷歌等流量巨头持续拓展支付业务，以及Wise、Payoneer、Stripe等低费率的价格战竞争下，paypal市占率三年下降了14.5个百分点。</p>
  <p>市场份额流失也使paypal的用户增长出现瓶颈，2024年PayPal活跃用户数量较2022年减少100万。进入2025年后，paypal交易频次也出现下降，二季度交易笔数同比下降5%。业务不景气也让paypal的股价跌到了2017年的水平，这在美国科技股中很罕见。</p>
  <p>节节败退下，银行牌照是paypal为数不多的救命稻草。</p>
  <h2><strong>需要银行牌照提升竞争力</strong></h2>
  <p>12月15日，paypal延续了“跌跌不休”的趋势，但盘后转涨1.5%。</p>
  <p>“久旱逢甘霖“的导火索是paypal宣布：公司已向犹他州金融机构部和联邦存款保险公司（FDIC）提交申请，计划成立一家犹他州特许工业贷款公司（ILC），名为“PayPal银行”。</p>
  <p>银行牌照意味着更完整的金融闭环，如果拍照被批准，PayPal 将从“支付工具”向覆盖存、贷、支付的“综合金融平台”演进，并将提升其各个业务条线提升竞争力。</p>
  <p>例如，paypal的支付业务在白热化竞争中，不仅份额掉得快，盈利空间也被严重压缩，其支付业务毛利率从2019年的42%降至当下的35%。</p>
  <p>而申请银行牌照后，它不仅能靠存贷业务获得更多流量入口，还能提升支付业务利润率。</p>
  <p>在海外，paypal的支付流程：商家通过paypal向合作银行发收款指令-商家合作行联系VISA-VISA联系消费者发卡行-发卡行通过VISA向商家合作行付款。</p>
  <p>其中，每一环交易都要雁过拔毛的抽一笔“过路费”（手续费）。而paypay如果成为银行，可绕过其它银行直接接入卡组织网络，有机构预计其“通道费成本降低60%”。</p>
  <p>除了支付业务外，paypal也可以通过银行牌照提升信贷等业务的竞争力。</p>
  <p>上文已经提到，paypal的信贷业务受制于人，需要和银行合作，paypal不仅只能分技术费，甚至因为高资金成本缺乏个人贷款的竞争力。</p>
  <p>但有了银行就不一样了，PayPal称，获监管批准后，paypal银行计划向客户提供计息储蓄账户，且客户存款将有资格获得FDIC的保险保障。这意味着，其贷款资金来源将从高息、波动大的合作银行，转向成本更低的内部存款。</p>
  <p>而从过去看，银行牌照也往往能加速信贷业务的发展。2021年，Sofi通过收购Golden Pacific Bank获得全国性银行牌照后，用户数从185万飙升至1000万，总资产增长了4倍。</p>
  <p>如果把视角放开，透过Paypal申请银行牌照这件事不难发现，海外金融科技公司正试图摆脱“中间商”定位。</p>
  <h2><strong>美国金融科技公司开始摆脱Baas模式</strong></h2>
  <p>过去十几年，美国的科技巨头做金融都喜欢借用别人的牌照（BaaS模式）。</p>
  <p>典型如paypal给用户做分期、给商户放贷款都是靠合作银行WebBank“借牌”发放。前几年各个科技公司发的稳定币，也有不少是靠有相关牌照资质的“Paxos们”做合规。</p>
  <p>BaaS模式的优势有很多，例如轻资产、扩张快等等。但劣势也很明显，不仅利润要被分走一块，一旦竞争激烈，依靠BaaS模式的金融科技公司也难形成差异化优势。</p>
  <p>所以，新的趋势出现了，越来越多金融科技公司开始去拿相应的监管牌桌。例如，paypal的同行Block（前身为Square）已经获得了犹他州ILC牌照，加密资产新贵如Circle、Ripple最近也获得了初步的银行监管批准。</p>
  <p>金融科技公司们抢牌照既是为了提升竞争力，也是为了在链上金融的新叙事中获得合规壁垒。</p>
  <p>从竞争的角度看，随着存量时代到来，有中间商属性的生意，利润正变得越来越低。就比如，前文提到的paypal，因为本质上处在“收过路费”的中间商业环节，难以形成差异化壁垒，市占率、利润率持续走低。中间环节利润越来越低，中间商们必须要抢上游牌照了。</p>
  <p>而抛开竞争，银行牌照也能增加金融科技公司链上叙事的胜率。</p>
  <p>在链上叙事中，以稳定币为代表的链上金融解决了“货币数字化”的问题，其开展的链上金融革命有望从今传统金融格局。而从实际进展看，这种叙事已经到了必须要被重视的阶段。</p>
  <p>截止今年上半年，全球加密货币市值加起来到了3.3万亿美元，自2023年以来，上涨了快三倍。3.3万亿美元相当于全球GDP的3%。如果把整体加密资产，视作一个国家经济体，它已经击败法国位列全球第7。</p>
  <p>而对于一个冲击传统金融格局的新物种来说，始终绕不开监管法则，相关公司最稳妥的办法就是主动加入监管体系，而金融科技公司们拿下银行牌照，意味着数字资产将融入银行体系。他们也将真正成为受监管的银行机构，确定性和合规壁垒大幅提升了。</p>
  <p>可以说，以paypal为代表的金融科技公司们能不能摆脱“中间商”定位，将决定着他们最终的价值。这一点也适合绝大部分行业。</p>
  <p>免责声明:本文（报告）基于已公开的资料信息或受访人提供的信息撰写，但读懂财经及文章作者不保证该等信息资料的完整性、准确性。在任何情况下，本文（报告）中的信息或所表述的意见均不构成对任何人的投资建议。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/woMyX3GPCqoQGFuwWBAgAg" rel="noopener noreferrer nofollow" target="_blank">“读懂财经”</a>，作者：杨扬，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612251724956933</id>
            <title>机器人与时间赛跑：一场关于春晚、商业化、上市窗口的争夺赛</title>
            <link>https://www.36kr.com/p/3612251724956933</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612251724956933</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:20:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>编者按：</strong></p>
  <p><strong>岁末将至，站在2025年的时间节点回望，技术浪潮的奔涌、消费需求的变迁、商业模式的迭代，构成了全新的商业图景。连线Insight推出年终盘点专题系列，试图捕捉不同企业在这幅变局图景中，如何应对挑战、抓住机遇。本期为第二篇，关注具身智能行业。</strong></p>
  <p>时代变了，机器人也来抢春晚名额了。</p>
  <p>近期，一则消息在具身智能行业引发震动：智元机器人和宇树科技为争夺2026年总台马年春晚的最大赞助商资格，开价均达到数千万元级别。</p>
  <p>这天恰巧是CCTV总台《2026年春节联欢晚会》发布主题和主标识的日子。据36氪报道，知情人士称春晚成为具身智能需要抢占的高地，不少机器人公司都参与了竞标。<strong>其中智元机器人和宇树科技正在高价争夺春晚赞助席位，智元率先开价6000万元，宇树直接将报价拉升至1亿元。</strong></p>
  <p>截止发稿，智元机器人已回应称“不是真的”，而宇树科技并未回应。</p>
  <p>目前，关于春晚赞助商的具体名单尚未公布，只有《晚点 LatePost》报道了火山引擎将成为 2026 年中央广播电视总台春节联欢晚会独家AI云合作伙伴，字节跳动旗下的智能助手豆包也将配合上线多种互动玩法。</p>
  <p><strong>而机器人企业将以什么形式出现在春晚的舞台上，讨论依然在继续。</strong></p>
  <p>毕竟，宇树科技旗下的机器人，在2025年便已经在春晚舞台上亮相过，并成功获得了大面积的社会关注。</p>
  <p><strong>我们看到，人们看似在关注一场品牌营销的竞标，实则在关心整个机器人行业的走向：概念验证阶段即将结束，产业进入商业化落地的全新阶段。</strong></p>
  <p>当“春晚”成为机器人企业考虑的课题之一，竞争的本质已经改变。数年温和的技术迭代过程结束了，市场争夺成为重头戏。接下来，曝光、订单、融资、上市，每一个环节都成为机器人企业必争的高地。</p>
  <h2><strong>争夺春晚：机器人企业今年更需要被关注</strong></h2>
  <p>花上亿元赞助一台晚会，这笔账怎么算？</p>
  <p>春晚赞助从来不便宜。除去赞助费，技术团队驻场、备用方案准备、运营团队对接、反复彩排及配套宣传方案等隐形成本，往往让企业的实际投入在报价基础上翻倍。</p>
  <p><strong>但对如今的机器人企业来说，为春晚花钱确实有必要，即使最终没抢到赞助名额，能够争取上节目也是值得的。</strong></p>
  <p>2025年蛇年春晚，宇树科技16台H1人形机器人与16位舞蹈演员共同演绎了舞蹈《秧BOT》，机器人身着东北棉袄、灵巧舞动转帕，与舞者默契配合，让宇树从科技圈的明星企业一跃成为全民认可的国家科技力量代表。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ca1cbe25218248958348130023705ccd@000000_oswg92111oswg889oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇树科技机器人在2025年蛇年春晚，图源CCTV直播</p>
  <p>据央视网数据，2025年蛇年春晚全媒体累计触达168亿人次，直播总收视份额达78.88%，创下近12年来的收视新高。</p>
  <p><strong>除去流量效应，“登上春晚”本身也足以为品牌背书。官方背书和品质认证让宇树在与地方政府谈合作、与大型国企谈订单、获得政策支持等方面都占得先机。</strong></p>
  <p>春晚带来的效益，最先被下游感知。</p>
  <p>有媒体报道，宇树上完春晚后，需要租赁机器人的政府机关和企业都首选宇树，一位下游机器人租赁公司老板，一个多月靠出租机器人赚了十几万元。</p>
  <p><strong>2025年，机器人与春晚的联系绝非偶然。</strong></p>
  <p>首先是政策支持。2025年3月两会期间，具身智能首次被写入政府工作报告，标志着国家战略层面的明确支持。</p>
  <p>其次是技术发展逐渐成熟。据艾瑞咨询报告，具身智能的自主化程度已达到类似自动驾驶L2-L3的过渡阶段，质变的临界点就在眼前。未来2-3年内，模型能力很可能实现飞跃性突破。</p>
  <p><strong>机器人企业对春晚的关注背后，有一层紧迫的现实逻辑：商业化落地中，如果各家企业在技术上拉不开绝对差距，那么谁先抢占用户心智，谁就能在融资、招聘、合作生态等各方面占得先机。</strong></p>
  <p>无疑，在这个特殊的时间节点，春晚提供的曝光，既是向资本市场释放信心的信号弹，也是向潜在用户喊话的号角。</p>
  <h2><strong>具身智能企业们，量产与商业化进展如何？</strong></h2>
  <p>春晚之争只是一个缩影，2025年，机器人行业真正的战场在量产和商业化。在争夺战中，头部企业的进展最具代表性。它们的量产能力和商业化路径，很大程度上决定了整个行业的走向。</p>
  <p>宇树科技创始人王兴兴公开表示，2024年宇树营收已超过10亿元，并实现连续五年盈利。据高工机器人产业研究所数据，2024年宇树机器狗年销量高达2.37万台，约占全球市场69.75%的份额，人形机器人交付量突破1500台。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_3f4f79da571e4af187d71ba42f71c6c0@000000_oswg67716oswg1080oswg775_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇树科技创始人王兴兴，图源宇树科技官方微信公众号</p>
  <p>而据智元机器人披露，截至2025年12月初，智元三大产品线累计下线5000台通用具身机器人，其中灵犀X1／X2系列1846台，远征A1／A2系列1742台，精灵G1／G2系列1412台。</p>
  <p><strong>从生产能力与发展速度上，两家头部企业各有千秋。</strong></p>
  <p>起步于2016年的宇树，是相对“老牌”的机器人公司，在硬件能力上积累深厚。业内人士认为，宇树能够实现盈利的核心原因在于其成熟的硬件把控能力，其完成商业化的机器人不是通过堆料，而是在数个环节做到最合适、成本最优。</p>
  <p>一项可供参考的事实是，宇树科技新品人形机器人R1，AIR版售价仅2.99万元起，尽管当前宇树的主要收入来源仍然集中在四足机器人领域，但人形机器人成本的降低，无疑在应用场景、规模化上为其打开想象空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1db13cc1e0cb496a992819634abdbd9f@000000_oswg187924oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">宇树科技R1不同版价格及配置，图源宇树科技官网</p>
  <p>成立于2023年的智元机器人，发展时间虽短，但产品落地速度、资本背景都很强，其创始人彭志辉即为业内广受关注的“华为天才少年”稚晖君。据公开信息，两年时间里，智元已完成11轮、累计超50亿元融资，估值达150亿元人民币。</p>
  <p>据《财经》报道，智元的重心正在快速由研发转向商业化，多位核心人员离职，将研发部门分拆成独立的业务部门，为每条产品线设置自己的研发团队，通过内部赛马的方式快速迭代，核心目标是快速量产、抢占市场。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_32acef62939e4dc296b76965ba4fd7f1@000000_oswg68054oswg802oswg774_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">智元机器人联合创始人及CTO彭志辉，图源智元机器人官方微信公众号</p>
  <p>2025年，机器人在各个应用场景落地趋势明显，众多工商业订单也向国内头部厂商涌来。7月，智元与宇树共同中标中移（杭州）人形双足机器人代工服务采购项目，总标包金额1.24亿元；9月，优必选宣布获得2.5亿元人形机器人产品及解决方案采购合同。</p>
  <p><strong>据公开信息统计，国内企业公开订单总金额已突破46亿元，数量超2万台。</strong></p>
  <p><strong>从金额与数量，不难看出市场对机器人赛道的期望颇高。但针对当前的不少“亿元级订单”，业内也存在质疑的声音。</strong></p>
  <p>摩根士丹利报告指出，许多厂商高调宣布的“大额订单”中，相当一部分属于框架协议订单或意向订单，执行确定性较低。</p>
  <p>高盛今年11月对9家中国人形机器人供应链企业的调研显示，虽然供应商规划的年产能介于10万台到100万台之间，但没有一家公司确认收到大规模订单或明确的生产时间表。</p>
  <p><strong>或许，机器人真正的商业化瓶颈在于应用场景。</strong></p>
  <p>据艾瑞咨询的《2025商用具身智能白皮书》，具身智能商业化的突破点需要在续航、延迟、执行、可靠性与经济效益等五大维度均跨过可用门槛。当前最接近这个标准的，只有工业制造和物流仓储场景。</p>
  <p>尽管轮式机器人在续航、稳定性以及导航精度上，已能满足大部分工厂场景需求，但却很难深入到更复杂的场景中。</p>
  <p><strong>相比工业场景，家庭、养老等场景更少结构化，任务重复度更低，ROI更难计算。在更贴近这些场景的人形机器人上，仍有不少难题亟待解决。</strong></p>
  <p>宇树科技创始人王兴兴便曾坦言，当前开门、拖地等动作对人形机器人而言还很复杂，让机器人直接去家中干活不太现实。</p>
  <p>人形机器人技术瓶颈依然明显。例如，机器人的“一双手”作为核心部件，既要结构紧凑，又要保证敏捷性和可靠性，便衍生出“三难困境”。倘若无法完成这项突破，家庭场景的精细操作就无法实现。</p>
  <p>更深层的问题在于经济性。业内估计，一台足够成熟的人形机器人价格约在30万至50万元，唯有能在同一场景中承担约十类以上的任务，投入与产出相比才能算得上“划算”。</p>
  <p>如今，人形机器人的主要应用方向仍是表演和科研。据人形机器人场景应用联盟统计，截至2025年上半年，教育科研机构采购量占人形机器人总订单量的75%。</p>
  <h2><strong>趁着“概念热”，抢摊IPO是必然</strong></h2>
  <p>尽管商业化路径尚未完全跑通，但资本市场的热情已经沸腾。</p>
  <p>据华芯资本统计，2025年前七个月，具身智能行业一级市场融资总金额超过300亿元，而2024年上半年这个数字还只是75亿元。</p>
  <p>据IT桔子数据，2025年前11个月，中国机器人产业链相关投融资事件达557起，总融资额超过839亿元。</p>
  <p>今年融资额最高的20家AI相关创业公司中，有九家都是具身智能方向。</p>
  <p>二级市场同样火热。《证券时报》9月末统计，A股中110只人形机器人概念股年内平均上涨67.63%，有18只股票价格较去年末实现翻倍。</p>
  <p><strong>在热钱涌入的同时，机器人企业掀起了IPO热潮。</strong></p>
  <p>港交所18C条款的调整，为机器人企业打开了上市通道。市值门槛降至40亿港元，让更多处于早期阶段的企业看到了可能性。据公开信息，除了已经上市的越疆科技，仙工智能、斯坦德机器人、云迹科技、优艾智合等公司已经递表。</p>
  <p>宇树科技在2025年11月完成境内上市辅导，预计年内于A股主板递表。据公开信息，宇树C轮融资后估值为120亿元。乐聚机器人在今年9月完成股改后，10月拿到近15亿元Pre-IPO轮融资。</p>
  <p>与之对比，智元的路径更为迂回。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7769780595c24d3d9744e85b1e60f642@000000_oswg112000oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">智元远征A2机器人在上海武宁路桥</p>
  <p>今年10月，智元机器人通过旗下平台智元恒岳，成功收购科创板上市企业上纬新材，获得其63.62％股份。尽管智元多次否认“套壳上市”，这一操作仍被外界视为“曲线上市”。</p>
  <p><strong>为何头部企业都在抢摊IPO？</strong></p>
  <p>首先是资金需求。上市潮的背后，是一级市场融资空间的收窄。业内人士指出，尽管行业融资金额和频率仍在上升，但估值断层正在加剧。而机器人是资本密集型行业，需要持续投入研发、产能建设和市场拓展。从一级市场获得高估值融资的难度在增加，二级市场成为更现实的选择。</p>
  <p>其次是时机窗口。尽管行业存在“泡沫论”讨论，但投资市场依然对具身智能的故事保持兴趣。国家政策也在大力支持——“十五五”规划建议明确提及推动具身智能成为新的经济增长点，北京、上海、深圳等地相继出台专项扶持政策。</p>
  <p><strong>如果说当前“具身智能”概念仍处于高热阶段，那么没人能保证热度永远存在。一旦市场对“故事”失去耐心，估值压力将迅速传导，因此机器人企业必须抓住窗口期。</strong></p>
  <p>2025年11月27日，国家发改委政策研究室副主任李超公开表示，当前人形机器人技术路线、商业模式、应用场景尚未完全成熟，需要防范风险。</p>
  <p>金沙江创投主管合伙人朱啸虎今年3月公开表示正在“批量退出人形机器人公司”，直言行业“商业化路径不清晰”。也有行业投资人士认为，机器人领域泡沫很大，80％现存人形机器人公司未来可能会被淘汰。</p>
  <p><strong>对于初创公司，压力也源于跨界而来的大厂对手。</strong></p>
  <p>华为、小米、小鹏、奇瑞等硬件大厂纷纷入局，美团、阿里、京东等互联网巨头则大量投资机器人公司，不仅提供资金，还能提供场景和数据。11月5日，小鹏汽车发布了人形机器人“IRON”，计划2026年底量产。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8c3d62c4cdfb47088fe7f4d7ad211a52@000000_oswg18687oswg1080oswg534_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">小鹏汽车董事长及创始人何小鹏在发布会介绍人形机器人“IRON”，图源何小鹏官方视频号</p>
  <p>竞争格局在快速变化。大厂的加速介入，让创业公司的生存空间进一步收窄。</p>
  <p>在这种背景下，通过上市获得资金、提升品牌影响力，成为创业公司的战略选择。但上市不是终点，而是新阶段的起点。二级市场对业绩的要求更加严格，上市后如何持续增长，将是更大的考验。</p>
  <p><strong>争夺春晚曝光、争夺订单、争夺商业化落地、争夺上市窗口，一系列动作背后，是机器人企业对时间的焦虑。技术路线还在探索，商业化路径尚待跑通，但资本热潮已经推着企业向前冲刺。谁能真正在细分场景中扎下根、跑得通，谁就能率先“造血”，靠真实价值活下来。</strong></p>
  <p>无论最终是谁上春晚，当烟花散尽，如何让机器人从舞台走向嘈杂的工厂和千万的家庭，才是这场竞争的真正终局。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg2MTc4Nzg5MQ==&amp;mid=2247554539&amp;idx=1&amp;sn=3b0acd2d7f687a9404c5283d0f9f347d&amp;chksm=cf887ffc7953f42e287cd6704c0c578df7726758f54cbb82976a040dd9215b9f5d6a5d64a85a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“连线insight”（ID：lxinsight）</a>，作者：熊逾格，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257750844681</id>
            <title>清华唐杰：领域大模型，伪命题</title>
            <link>https://www.36kr.com/p/3612257750844681</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257750844681</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:20:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>清华教授唐杰最新在微博发表了自己关于AI的一些感悟，非常值得一读～</p>
  <p><strong>共八个小点</strong>，不算长篇大论，但扎实有料：</p>
  <ul>
   <li>基座模型继续scaling仍然高效；</li>
   <li>真实使用体验想进一步上台阶，长尾能力的对齐和推理增强绕不过去；</li>
   <li>Agent代表模型开始进入环境、开始形成生产力；</li>
   <li>一旦模型进入持续交互的世界，记忆机制、在线学习、自我评估就会成为核心工程题，而不是可选项；</li>
   <li>AI终究要落到替人完成工作、创造增量价值上；</li>
   <li>领域大模型是个伪命题；</li>
   <li>……</li>
  </ul>
  <p>唐杰表示，发微博是想分享一下，希望对大家有用。</p>
  <p>兹以推文刊载，供大家广泛阅读、传播。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_5ede2ba69b994664bb573fdd2e28ab31@46958_oswg304697oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以下为其感悟原文：</p>
  <h2><strong>01，关于scaling基座模型</strong></h2>
  <p>预训练使得大模型已经掌握世界常识知识，并且具备简单推理能力。</p>
  <p><strong>更多数据、更大参数和更饱和的计算仍然是scaling基座模型最高效的办法。</strong></p>
  <h2><strong>02，关于激活对齐和增强推理能力</strong></h2>
  <p><strong>激活对齐和增强推理能力</strong>，尤其是激活更全面的长尾能力是保证模型效果的另一关键，通用benchmark的出现一方面评测了模型通用效果，但也可能使得很多模型过拟合。</p>
  <p>真实场景下是如何让模型更快、更好的对齐长尾的真实场景，增强实际体感。</p>
  <p>mid和post training使得更多场景的快速对齐和强推理能力成为可能。</p>
  <h2><strong>03，关于Agent</strong></h2>
  <p>agent是模型能力扩展的一个里程碑，也是体现ai模型进入人类真实（虚拟/物理）世界的关键。</p>
  <p>没有agent能力，大模型将停留在（理论学习）阶段，就类似一个人不断学习，哪怕学习到博士，也只是知识积累，还没有转化为生产力。</p>
  <p>原来的agent是通过模型应用来实现，现在模型已经可以直接将agent数据集成到训练过程，增强了模型的通用性，其实难题还是不同agent环境的泛化和迁移并不是那么容易，因此<strong>最简单办法也只有不断增加不同agent环境的数据和针对不同环境的强化学习。</strong></p>
  <h2><strong>04，关于模型记忆</strong></h2>
  <p><strong>实现模型记忆成为一个必须做的事情</strong>，这也是一个模型应用到真实环境必须有的能力。</p>
  <p>人类记忆分为短期（前额叶）、中期（海马体）、长期（分布式大脑皮层）、人类历史（wiki或史书）四个阶段。</p>
  <p>大模型如何实现不同阶段的记忆是个关键，context、rag、模型参数可能分别对应了人类的不同记忆阶段，但如何实现是个关键，一种办法是压缩记忆，简单存在context，如果大模型可以支持足够长的context，那基本有可能实现短中长期的记忆。</p>
  <p>但<strong>如何迭代模型知识，更改模型参数这还是个难题。</strong></p>
  <h2><strong>05，关于在线学习与自我评估</strong></h2>
  <p><strong>在线学习与自我评估。</strong></p>
  <p>有了记忆机理，在线学习成为一个重点，目前的大模型定时重新训练，这有几个问题：</p>
  <p>模型无法真正的自我迭代，但模型的自学习自迭代一定会是下一个阶段必然具有的能力；</p>
  <p>重新训练还比较浪费，同时也会丢掉很多交互数据。</p>
  <p>因此如何实现在线学习是个关键，自我评估是在线学习的一个关键点，要想模型自我学习，模型首先要知道自己对还是不对，如果知道了（哪怕概率知道）模型就知道了优化目标，能够自我改进。</p>
  <p>因此构建模型自我评价机制是个难题。</p>
  <p><strong>这也可能是下一个scaling范式。</strong></p>
  <p>continual learning/real time learning/online learning？</p>
  <h2><strong>06，关于模型研发和应用结合</strong></h2>
  <p>最后，大模型的发展越来越端到端，不可避免的要把模型研发和模型应用结合起来。</p>
  <p><strong>ai模型应用的第一性不应该是创造新的app</strong>，他的本质是agi替代人类工作，因此研发替代不同工种的ai是应用的关键。</p>
  <p>chat部分替代了搜索，部分其实融合了情感交互。</p>
  <p>明年将是ai替代不同工种的爆发年。</p>
  <h2><strong>07，关于多模态和具身</strong></h2>
  <p>写在最后的是多模态和具身。</p>
  <p>多模态肯定是个未来也很有前景，当下的问题是多模态不大能帮助到agi的智能上界，而通用agi的智能上界到底在哪儿还不知道。</p>
  <p><strong>可能最有效的方式还是分开发展，文本、多模态、多模态生成。</strong></p>
  <p>当然适度的探索这三者的结合肯定能发现一些很不一样的能力，这需要勇气和雄厚的资本支持。</p>
  <p>同理，如果看懂了agent就知道具身的痛在哪里了，太难通用了（也不一定），但至少少样本去激活通用具身能力基本不可能。</p>
  <p>那怎么办呢，采数据，或者合成数据，都不是那么容易，也贵。</p>
  <p>但反之一旦数据规模上去了，通用能力出来了自然会形成门槛。</p>
  <p>当然这只是智能方面的难题，对于具身，机器人本身也是个问题，不稳定，故障频繁都限制了具身智能的发展。</p>
  <p>2026年这些都将取得长足进步。</p>
  <h2><strong>08，关于领域大模型和大模型应用</strong></h2>
  <p>也讨论一下领域大模型和大模型应用。</p>
  <p><strong>我一直认为领域大模型就是个伪命题，都agi了哪有什么domain-specific agi……</strong></p>
  <p>但，agi还没实现，领域模型会长时间存在（多长，不好说，ai发展实在太快了）。</p>
  <p>领域模型的存在本质上是应用企业不愿意在ai企业面前认输，希望构建领域know how的护城河，不希望ai入侵，希望把ai驯化为工具。</p>
  <p>而ai的本质是海啸，走到哪里都将一切卷了进去，一定有一些领域公司走出护城河，自然就卷进了agi的世界。</p>
  <p>简而言之，领域的数据、流程、agent数据慢慢的都会进入主模型。</p>
  <p><strong>而大模型的应用也要回到第一性原理，ai不需要创建新的应用。</strong></p>
  <p>ai的本质是模拟人或者代替人或者帮助人实现人类的某些必须要做到事（某些工种）。</p>
  <p>可能就是两种，一种就是ai化以前的软件，原来需要人参与的改成ai，另一种就是创造对齐人类某个工种的ai软件，替代人类工作。</p>
  <p>所以大模型应用需要帮助到人、创造新的价值。</p>
  <p>如果做一个ai软件没人用，不能产生价值，那这个ai软件肯定没有生命力。</p>
  <p>参考链接：https://weibo.com/2126427211/5247011059141988</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/krtUS58RrBX4UHnMZLPy4w" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612255778206210</id>
            <title>2025年，AI在重复互联网打法</title>
            <link>https://www.36kr.com/p/3612255778206210</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612255778206210</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:19:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI亦难逃“流量魔咒”，市场正呈现与互联网时代惊人相似的推广逻辑。</p>
  <p>争夺春晚流量盛宴，就是最新具象的表现。作为年终最大的流量池，抢占春晚舞台，已经成为争抢超级市场应用的快速入口。此前，无论是微信摇一摇，“集五福”抢红包，甚至京东、抖快和B站，都曾站上春晚的舞台。</p>
  <p>而今年，这个位置，AI上桌了。12月24日，有报道表示，字节跳动旗下火山引擎将成为2026年中央广播电视总台春晚独家AI云合作伙伴，其智能助手豆包也将配合上线多种互动玩法。</p>
  <p>种种消息表明，豆包距离一款国民级应用的距离，越来越近。而凭借AI时代的超级入口，字节也正形成“流量—产品—流量”的闭环。</p>
  <p>实际上，不仅仅是字节，放眼过去，无论是OpenAI的GPT系列、谷歌的Gemini，还是DeepSeek以及其他AI应用，其市场策略无不遵循着“争夺流量入口”的原则。</p>
  <p>这一现象，在互联网大厂尤为明显。数据显示，2025年第一季度，全球前十大AI应用的用户获取成本中，流量渠道占比平均达到68%，而产品差异化功能投入仅占22%。这一比例与2015年移动互联网应用的投入结构几乎一致。</p>
  <p>更值得关注的是，产品“日活/月活”比值，也已成为衡量AI产品成功的关键，而这正是互联网产品常用的核心。</p>
  <p>一定程度上，尽管被誉为“第三次工业革命”，AI生态卡位战进攻的本质，仍是下一代流量分配权。</p>
  <h2><strong>-01- “得流量者得天下”？</strong></h2>
  <p>剥开技术炫酷的外衣，审视这场席卷全球的AI热潮，一个熟悉的市场逻辑正愈发清晰：得流量者得天下。</p>
  <p>巨头们倾尽资源，争夺入口、抢夺用户、构建生态闭环，其核心打法与二十年前互联网时代争夺门户、十年前移动互联网时代争夺超级App的逻辑，如出一辙。</p>
  <p>以字节跳动的豆包AI为例，这款产品通过抖音、今日头条等成熟流量池进行推广，用户在使用短视频和新闻资讯服务时频繁接触豆包AI的入口和提示，形成“流量—产品—流量”的闭环。最新数据显示，豆包的日均活跃用户数(DAU)突破1亿。</p>
  <p>在硬件端，豆包通过与手机厂商进行系统级合作，让AI助手获得直接调用App、完成跨应用任务的权限（如自动比价、行程规划），试图成为手机底层的新入口。</p>
  <p>另外，豆包明显延续了互联网时代的“产品思维”。</p>
  <p>有报道称，据业内人士透露，在豆包内部，判断标准也变得更加务实。一个新功能是否成立，不再看大厂员工的内测反馈，而是进行“盲测”，找10个完全不懂技术的普通老百姓，如果其中有 7 个人不仅愿意用，还产生了忍不住“剁手”分享的冲动，这才是一个合格的“Aha Moment”。</p>
  <p>同样，腾讯的混元大模型通过微信生态进行渗透，用户在使用微信聊天、朋友圈、小程序时都能感受到AI的无缝衔接。这种借助已有流量入口快速获取用户的方式，与当年微信通过QQ导流、淘宝通过阿里系产品导流的逻辑如出一辙。</p>
  <p>以腾讯元宝为例，依托微信这一无可比拟的社交与流量帝国，腾讯元宝将AI能力像水电煤一样，无感地融入视频号、企业微信、公众号等每一个场景，实现最自然的用户触达和转化。</p>
  <p>可以看到的现象是，在微信生态中，随时可调用的元宝，某种程度上，使得微信用户形成了对元宝的“依赖”。</p>
  <p>当然，阿里方面，不管是千问的加速迭代，还是灵光的推出，以及其他业务线下AI应用的快速跟进，无一不在彰显出其对AI赛道的志在必得。此外，阿里还通过千问，打通淘宝、高德、饿了么等核心业务的API，将AI能力具象化为可编排的“服务原子”，旨在成为阿里生态的智能总枢纽。</p>
  <p>毋庸置疑的是，2025年，AI应用已如空气般渗透进社会的毛细血管。</p>
  <p>中国互联网络信息中心发布的《生成式人工智能应用发展报告（2025）》（以下简称《报告》）显示，截至2025年8月，我国累计有538款生成式人工智能服务完成备案，263款生成式人工智能应用或功能完成登记。</p>
  <p>苹果应用商店中，甚至将AI应用单列为“日常好工具”，对此的介绍是“有了AI，面对各类场景与需求，满眼都是捷径”。</p>
  <p>这一定程度上也意味着，AI应用，不再是“高大上”的意识形态，已经成为一种“日常工具”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_4523f43ca023487aaf7dc135ca3d1b7d@5951134_oswg331223oswg1080oswg928_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：苹果App Store将AI应用单列为“日常好工具” &nbsp; 来源：App Store 《听筒Tech》截图</p>
  <p>尤其令人瞩目的是，随着“AI+”行动的推进，逐步发展成“国民应用”。一种乐观的表象便是，街头巷尾，各种年龄群体，对AI应用已经并不陌生。《报告》显示，截至2025年6月，我国生成式人工智能用户规模达5.15亿人，普及率为36.5%，移动端用户规模更达7.2亿。</p>
  <p>但能看到的是，进入下半年后，AI应用的推进速度更是明显加速。不管是阿里，还是字节、腾讯，抑或百度等其他，都在以抢跑的姿势快速迭代产品，并争夺流量卡位，早日拿到下一场工业革命的王牌。</p>
  <h2><strong>-02- 争夺下一代流量分配权</strong></h2>
  <p>在AI从业人员升哥看来，巨头之间争夺的本质，是下一代流量分配权。</p>
  <p>一个不容忽视的事实是，在这个AI应用爆发的时代，传统搜索引擎和App商店的中心化地位正在被撼动。</p>
  <p>“从年初的Deepseek开始，用户获取信息的起点，便逐步从‘搜索框’转向‘对话界面’。”在升哥看来，随着技术的快速迭代，一条日渐清晰的路径是，谁控制了对话的起点，谁就掌握了新时代的流量闸门。</p>
  <p>“因此，巨头们争夺的不仅是AI应用本身，更是成为用户与数字世界交互的首要智能代理（Agent） 。”升哥指出，本质上，这也是2025年国内互联网巨头为何始终在将关注点集中在“流量入口”的关键因素所在。</p>
  <p>在升哥看来，究其根源，最核心的因素，实际上来源于资本压力与商业化的迫切需求。</p>
  <p>“众所周知，AI基础建设，给企业带来的财务压力巨大。”升哥指出，资本急切需要看到商业回报，最直观的证明就是用户规模与市场份额。</p>
  <p>事实上，诚如升哥所言，目前，市场对“AI商业化能否形成可持续的盈利闭环”存在普遍担忧。</p>
  <p>在此背景下，快速获取海量用户，既能满足资本市场对增长故事的期待，也为未来的订阅、服务收费和生态盈利奠定基础。也正因此，从互联网时代继承而来的“规模至上”的估值逻辑，在AI时代被全盘沿用。</p>
  <p>另一方面，技术差距的缩小，也在倒逼巨头之间的竞争，从单纯的“技术跑分”转向“场景落地”和“用户体验”。</p>
  <p>升哥便直言，“当技术本身难以形成绝对壁垒时，生态和流量就成为关键的护城河。”</p>
  <p>更重要的是，AI尤其是大模型的进化，严重依赖“数据飞轮”：更多的用户产生更多的交互数据，数据用于训练和优化模型，更好的模型又吸引更多用户。要启动这个飞轮，必须有一个巨大的初始流量作为“第一推动力”。</p>
  <p>互联网大厂，则恰恰手握这把钥匙，AI竞赛重回流量逻辑，也是技术、资本、市场与人性在现阶段复杂交织的必然结果。</p>
  <p>当然，另一个事实是，整个行业正处在从“App时代”向“智能体时代”转型的3-5年混合期，用户如何与AI共处、依赖何种AI服务的习惯，正在形成。</p>
  <p>“时间窗口稍纵即逝。巨头们不惜代价地推广，目的就是为了在用户心智中刻下烙印，形成使用依赖和路径习惯，构建极高的迁移成本。”升哥解释。</p>
  <p>当然，拥有庞大的本土用户流量，就意味着拥有定义产品、培育产业链、制定行业标准的主动权。这也是典型的互联网“赢家通吃”思维在新时代的打法再现。</p>
  <p>不过，依赖流量和生态的“旧剧本”，虽然能快速催熟市场，但也可能导致重复投入、垄断固化。</p>
  <p>升哥认为，引领AI走向更可持续的未来，行业仍需要探索新的可能性。</p>
  <p>比如，流量垄断并非无懈可击。未来的竞争焦点，应从争夺用户停留时长，转向提升AI完成复杂、长链条真实任务的可靠性与效率上，“一个能自主完成从市场分析、代码编写、测试到部署的AI软件工程师，其价值远大于一个通用助手。”</p>
  <p>一定意义上，“得流量者得天下”，是技术爆发期与市场成熟度不匹配下的必然产物，也是商业力量驾轻就熟地运用历史经验的结果。</p>
  <p>不过，在更多的“升哥”看来，当行业的关注焦点从“用户量”变为“价值创造量”，AI的发展才能真正驶向属于智能时代的“新大陆”。</p>
  <p>（文中均为化名。）</p>
  <p>（头图由《听筒Tech》拍摄。）</p>
  <p>（声明：本文仅作为信息交流，不构成任何投资参考建议。）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/5_BxIH60Gd7A4BctKpoiVQ" rel="noopener noreferrer nofollow" target="_blank">“听筒Tech”</a>，作者：杨林，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612227990995975</id>
            <title>Gemini 3预训练负责人警告：模型战已从算法转向工程化，合成数据成代际跃迁核心，谷歌碾压OpenAI、Meta的秘密武器曝光</title>
            <link>https://www.36kr.com/p/3612227990995975</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612227990995975</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:19:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_35cc8c4d6a2246728e07b2f8d81ecd9e@000000_oswg787472oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2025 年底，大模型行业的“年终决战”正式打响，各家纷纷亮出压箱底的杀手锏，就在这场激烈角逐中，Gemini 3 以绝对王者之姿强势突围，一登场就刷新了行业的认知边界。</p>
  <p>11 月 18 日，Gemini 3 直接“横扫”多项权威基准测试，以“世界最强多模态理解”“交互最深智能体”“推理怪兽”的姿态，强势碾压全球所有同类模型。谷歌 CEO 桑达尔·皮查伊亲自为其站台，直言这是“迄今为止最智能的模型”。消息一出，整个 AI 圈瞬间沸腾，所有人都在追问：Gemini 3 的强悍，到底藏着什么秘诀？</p>
  <p>答案在发布当天就有了初步线索。Google DeepMind 研究与深度学习副总裁 Oriol Vinyals 直接在推特上“剧透”：<strong>“Gemini 3 这么强，核心秘诀就两点：更好的预训练，更好的后训练。</strong>”这番直白的表态，让“预训练”与“后训练”瞬间成为行业热议的核心话题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_5bded75537d1424ba23f6bb83a15feb2@000000_oswg187866oswg513oswg919_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近日，<strong>Gemini 3 预训练负责人之一、开创性论文 RETRO 的合著者 Sebastian Borgeaud</strong>&nbsp;首次现身播客，深度拆解了这款顶级模型背后的实验室逻辑。在他看来，Gemini 3 的飞跃绝非单一环节的突破，而是无数细节持续优化的结果：“我们几乎每天都能找到让模型变更好的地方，整个团队都在加速前进。”</p>
  <p>更关键的是，Sebastian Borgeaud 点出了一个核心转变：<strong>谷歌已经不再是单纯“做模型”，而是转向“做系统”。</strong>&nbsp;这一观点恰好与 DeepMind 联合创始人兼 CEO 戴密斯·哈萨比斯不谋而合。哈萨比斯此前就公开表示，Gemini 3 的强大，根源在于“研究、工程和基础设施”的深度融合。</p>
  <p>Gemini 3 的秘诀，其实侧面反映了当下行业的深刻变革：<strong>AI 已经从“无限数据”的规模化时代，正式迈入“数据有限”的新阶段。</strong>&nbsp;这一趋势不可逆转，也倒逼整个行业重新思考创新方向。在 Sebastian Borgeaud 看来，合成数据、推理轨迹、长上下文、持续学习、端到端检索训练，再加上靠谱的评估体系，这些将共同构成 AI 行业未来的进化路径。</p>
  <p>其实早在经典的 Chinchilla 项目中，DeepMind 团队就已经摸到了关键规律：<strong>在训练计算量固定的前提下，与其盲目扩大模型规模，不如更快地扩展数据规模，这样能训练出更优的模型。</strong>&nbsp;这一结论放到现在依然极具现实意义，它直接决定了模型训练后的推理服务效率和使用成本，是企业落地 AI 的核心考量之一。</p>
  <p>作为从强化学习转向表征学习的资深研究者，Sebastian Borgeaud 的预训练功底堪称深厚：从 Transformer 架构，到 BERT、XLNet，再到 DeepMind 第一篇大语言模型论文 Gopher，丰富的研究经历让他形成了独特的“研究品味”，这也为 Gemini 3 的预训练突破埋下了伏笔。</p>
  <p>针对行业内&nbsp;<strong>“预训练 Scaling Law 已死”</strong>&nbsp;的争议，Sebastian Borgeaud 给出了明确回应：“规模依然重要，但架构创新和数据创新的权重已经显著提升，甚至变得更为关键。”</p>
  <p>那么，在数据受限的大背景下，如何实现更好的模型效果？<strong>合成数据</strong>成了行业追捧的热门方案，但 Sebastian Borgeaud 的态度却相当审慎：“这确实是个有意思的方向，但必须极度谨慎。”</p>
  <p>在他看来，合成数据的核心风险不是“没效果”，而是“用错了还浑然不觉”。一旦数据分布发生偏移，模型看似答题能力提升，但可能会陷入“自嗨”的闭环里。为此，他给出了一套稳妥方案：用强模型生成合成数据后，必须通过小规模的可控消融实验，验证其带来的收益和潜在副作用。</p>
  <p>但即便如此，一个核心疑问仍未解决：<strong>“用合成数据训练出的模型，能否超越它的‘老师’？”</strong></p>
  <p>值得一提的是，谷歌的模型训练一开始融合了多种来源的数据，这也为 Gemini 3 的多模态优势打下了基础。</p>
  <p>Sebastian Borgeaud 还透露，DeepMind 正在推进&nbsp;<strong>“后 Transformer 架构”</strong>&nbsp;的创新，同时十分看好&nbsp;<strong>“原生态模型”</strong>。尽管这种模型的研发成本高昂，但长期价值值得投入。此外，今年兴起的<strong>强化学习规模化趋势</strong>，他们也有丰厚的预训练阶的经验可以复用，形成了技术协同效应。</p>
  <p>在播客后半段，Sebastian Borgeaud 把话题转向<strong>下一轮预训练的热点</strong>。他认为，预训练不会再沿着“更大、更长、更贵”的单一路线走下去，重点会转向架构创新：</p>
  <p><strong>长上下文和注意力机制是其中的关键变量</strong>。如果上下文越长，模型推理时可携带的信息越多，模型能力边界也就越宽。</p>
  <p>更长期的方向，是把检索与搜索更深地融入训练，做端到端、可微的学习，让模型把“会检索”变成内生能力，而不是上线后再外挂工具。他判断，强化学习的规模化可能推动这一进程，但要沉淀为稳定的架构与训练范式，不是一时之功，还需要数年。</p>
  <p>另一条主线是<strong>持续学习</strong>。Sebastian Borgeaud 直言，基础模型一旦预训练结束，知识就基本定格：明天出了新论文、新发现，模型不会自己更新。眼下行业更可行的办法主要发生在产品推理侧——接入检索，把最新信息实时拉进上下文，再基于这些材料完成推理，从而避免频繁重训底座、缓解知识过期。</p>
  <p>这与他参与的&nbsp;<strong>RETRO 项目</strong>思路一致，将知识放在外部库，模型负责推理。他认为检索增强这套方法近年才走向成熟，未来几年有望更深地进入 Gemini 这类头部模型。更远的目标则是改变训练方式，让模型能在真实世界的数据流上持续训练，实现真正意义上的“持续更新”。</p>
  <p>Sebastian Borgeaud 还单独拎出来<strong>评估</strong>这件事，将其视为预训练阶段的核心难题。“如果评估体系跟不上，很容易陷入‘看似提升’的假象内耗，根本分不清是模型改对了，还是数据出了问题。”也正因为如此，谷歌内部搭建了专属的评估体系。毕竟外部基准很容易被污染，保留内部的评估阵地才是关键。</p>
  <p>他认为评估需要跨越两道鸿沟：一是在小模型上验证有效的改进，能否顺利迁移到大规模模型上；二是预训练阶段的优势，能否在后训练之后转化为真实可用的能力。</p>
  <p>最后，<strong>服务成本</strong>也是绕不开的现实约束。随着用户规模不断扩大，推理预算变得越来越敏感，预训练环节也必须为“上线落地”负责，在提升模型能力的同时，还要降低成本、节省资源。</p>
  <p>对于 Gemini 3 目前的表现，<strong>Sebastian Borgeaud 直言“超出预期”</strong>。他认为，模型是真的越来越聪明了，这种进步不仅体现在基准测试的屠榜成绩上，更反映在真实工作场景的使用体验中。</p>
  <p>展望未来，他预测 Gemini 将更好地服务于科学研究，甚至有可能凭借助力重大发现拿下诺贝尔奖；同时也会越来越深入地融入普通人的生活，解决各类实际问题。</p>
  <p><strong>“进步的脚步看不到尽头，至少未来一年，这种加速前进的势头不会放缓。”</strong>&nbsp;这正是他的对未来的预言。</p>
  <p><strong>播客里还分享了更多关于 Gemini 3 训练背后的细节和 Sebastian Borgeaud 的精彩观点，我们翻译了该内容，并在不改变原意基础上进行了删减和整理，以飨读者。</strong></p>
  <h2><strong>Gemini 3 强大的“秘方”：更好的预训练与后训练</strong></h2>
  <p>Matt Turck：我想从 Oriol Vinyals 的一条推文开始。Oriol 是 Google DeepMind 研究与深度学习副总裁，也是 Gemini 联合负责人。他在 Gemini 3 发布时说，模型背后的秘密非常简单：更好的预训练和更好的后训练。考虑到 Gemini 3 相比之前最先进水平的跃迁幅度，这听起来很朴素。你怎么看？在某种意义上，真的就是这么简单吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我不确定这算不算秘密。至少从我的角度看，这很正常。人们有时会期待从一个 Gemini 版本到下一个版本，会有某个重大变化并带来巨大差异。以我的经验，可能确实有一两件事带来的提升更大，但总体上是很多变化、很多来自一个非常大团队的工作累积起来，才让 Gemini 3 比之前几代好这么多。我想这会成为一个反复出现的主题：像 Gemini 3 这样的发布，是大团队共同促成的结果。</p>
  <p>Matt Turck：这对 AI 进展意味着什么？从外部看似乎只是调了一些“旋钮”就实现了跃迁。这对未来意味着什么？我们接下来可以期待什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：有两点。第一，以这种方式我们仍然能取得这么多进展，这仍然很了不起，而且进展并没有放缓。有很多“旋钮”、很多改进，我们几乎每天都能找到能让模型更好的东西。第二，我们不再是在构建一个模型，而是在构建一个系统。人们有时会觉得我们只是在训练一个神经网络架构，但我们实际上也在构建围绕网络的整个系统。</p>
  <p>Matt Turck：大家最关心的是：这对真正的智能进展意味着什么？我们不必深入讨论“AGI”，但我们该如何理解模型进展：它是通往智能的路径，还是只是为了在某个基准上表现更好？是什么让你相信核心模型在变得更聪明？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：基准表现确实在持续提高，而且前沿基准的设计正在变得越来越难。即使对我这样有计算机科学背景的人来说，模型能回答的一些问题也需要我花相当长时间才能答出来。这是基准视角。我们会频繁评估，也非常谨慎地保留测试集。但人们常担心对基准过拟合，或所谓 benchmaxing（刷榜 / 跑分）。我认为这些担忧并没有很充分的依据。</p>
  <p>另一个更让我有信心的方面是：内部人们使用模型来提升生产力的时间在不断增加。每一代新模型都很明显能做新的事情，并且在研究与日常工程工作中比上一代提供更大的帮助。这也说明模型在变得更有能力，并在做非常有用的事情。</p>
  <p>Matt Turck：如果把视角拉远，你还会对现状感到惊讶吗？从你的角度看，我们相比几年前你的预期是领先、按计划，还是落后？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：事后说“按计划”很容易。如果我诚实面对自己，我觉得我们领先于我原本以为能达到的位置。2019 或 2020 年开始做大语言模型工作时，很难相信我们现在所做一切的规模，以及模型如今的能力。当时如果看 Scaling Law ，它们确实指向这个方向，也有一些人非常相信这些。但我不确定当时我是否会重注押它一定会实现并达到今天的状态。</p>
  <p>一个随之而来的问题是：如果未来还能保持过去五年的同类进展，这会把我们带到哪里？我认为未来几年会发生非常酷的事情。</p>
  <p>Matt Turck：你认为短期两到三年会走向哪里？AI 会提出新的科学发现、获得诺贝尔奖吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这是其中一部分。在科学方面，DeepMind 历史上做了很多工作，也有大量工作继续朝这个方向推进。我认为未来几年会有一些重大的科学发现。</p>
  <p>另一方面，在我日常的研究和工程工作中，我也很期待我们如何用这些模型推动更多进展，同时更好地理解我们正在构建的系统，并进一步发展我们自己的理解和研究。</p>
  <p>Matt Turck：行业里有一个重要主题：自动化 AI 研究与工程。如果外推，会通向类似“AI 2027”的情景，出现某种断点。从务实角度，你今天在工作中使用 AI 是什么样？你觉得几年后会意味着什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我认为与其说是自动化，不如说是让我们更快，让我们把更多时间投入到更高层次的研究部分。语言模型研究的日常工作中，我们要处理基础设施层面非常复杂、非常大的系统，所以相当多时间用在跑实验、盯实验、分析数据、收集结果。真正有意思的部分是形成假设并设计新实验。我认为后两部分仍将主要由我们来做。第一部分，尤其在接下来一年，随着更多能动式（agentic）工作流被启用，会越来越能够加速我们的工作。</p>
  <p>Matt Turck：你认为各个前沿 AI 实验室基本都在朝同一个方向做同样的事情吗？几乎每周或每月都有新模型，我们已经被“惯坏了”。Gemini 3 刚发布时，几乎就在我们录制前两小时，GPT 5.2 也发布了。你怎么看？未来会怎样？会有人脱颖而出吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：不同实验室的工作确实有相似之处，底层技术也相似。如果大家都在训练类似 Transformer 的模型架构，我不会惊讶。但在其之上，确实存在专业化：研究树上不同分支会被不同公司探索与利用。例如，DeepMind 在视觉与多模态方面一直很强，这一点今天仍然成立，也体现在使用方式与基准表现中。推理方面，OpenAI 提出了第一个模型，但我们也有相关研究脉络。所以有相似之处，但并不完全相同。</p>
  <p>至于未来是否会有人脱颖而出，我不确定。有一点很清楚：今天要在 Gemini 这样的模型上继续取得进展，确实需要很大的团队和大量资源。但这并不意味着今天的方式就是最优的。颠覆性研究可能出现，使得更小团队在某种形式上实现超越。这也是我喜欢在 Google 的原因之一：Google 有做更探索性研究的历史，研究覆盖面很广，而且这些研究很多时候与 Gemini 并行推进，我们也能利用其中一些进展并将其带入 Gemini。</p>
  <p>Matt Turck：在 DeepMind 或行业其他地方，是否有团队在半秘密或完全秘密地研究“后 Transformer”架构？有一天会突然出现让大家惊讶的成果吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我相信有。Google 和 DeepMind 内部确实有团队在模型架构方面做研究。至于这些研究是否会成功，很难说，因为研究想法真正能奏效的很少。在此期间，一家公司相对另一家的核心优势，可能就是人才质量。</p>
  <p>Matt Turck：我提到的那条 Oriol 的推文，被 Demis Hassabis 引用转推。他说真正的秘密是研究、工程和基础设施的结合。这是 Google 的“秘方”吗？你们做了垂直整合（端到端整合）？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这确实有帮助，是重要的一部分。研究与工程的界限也很有意思。我认为随着时间推移，这条界限变得模糊：在这些很大的系统上工作时，研究看起来像工程，工程也反过来像研究。这种思维方式在 DeepMind 过去几年发生了变化：以前可能更偏传统研究心态，但现在做 Gemini 更像研究工程。</p>
  <p>基础设施也非常重要。我们在构建超级复杂的系统，因此拥有可靠、可用、可扩展的基础设施，是不让研究工程被拖慢的关键。Gemini 3 是在 TPU 上训练的，不是在英伟达芯片上训练的，这体现了端到端整合。</p>
  <h2><strong>Sebastian 的工作内容与研究品味的养成</strong></h2>
  <p>Matt Turck：你是 Gemini 3 的预训练负责人之一。这具体意味着什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这项工作包含几部分。第一部分是研究：让模型变得更好。但现在不太是我亲自跑实验，而是帮助设计实验，并与团队成员一起审查结果。</p>
  <p>第二部分是协调与集成。团队规模很大，在预训练侧包含数据、模型、基础设施、演进等，日常参与的人可能有 150 到 200 人。把所有人的工作协调成一个能共同构建的整体很复杂，也需要时间。对我来说这很重要，因为能把每个人的进步释放出来，才是我们取得最大进展的关键，而不是让少数人短期跑在前面。短期可能有效，但长期真正成功的是能整合很多人的工作。</p>
  <p>Matt Turck：你在哪里长大？你是如何成为今天的你？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我在欧洲多个地方长大，搬家比较多。我出生在荷兰，7 岁时搬到瑞士。父亲来自瑞士，母亲来自德国。我大部分学校教育以及高中开始阶段在瑞士完成，主要使用法语，也有德语部分。15 岁时我搬到意大利，在那里完成高中，大概到 19 岁。那时我原本打算去苏黎世联邦理工学院学习，但某天早上查排名时看到剑桥排在前面，就决定申请。几个月后收到录取，于是搬到剑桥，在计算机实验室完成本科和硕士。</p>
  <p>Matt Turck：你成长过程中是数学很强、偏理工、偏计算机的孩子吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我父亲有技术背景。我大概 10 或 11 岁开始和他一起写程序学习，一直很喜欢。我在学校的数学和科学一直比较轻松，数学考试几乎不需要复习也能考得很好。这在大学里明显改变，但那就是我的高中经历。</p>
  <p>Matt Turck：你从学校到现在的路径是什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这也比较幸运。硕士期间有一门课的授课人也是 DeepMind 的研究员。最后一节课结束后，我去问他能否给我内推。他让我发简历给他看看能做什么，我由此获得了 DeepMind 面试机会。那是 2018 年。我大学毕业后以研究工程师身份加入 DeepMind（当时还不是 Google DeepMind）。</p>
  <p>Matt Turck：你最开始做什么？后来如何发展到成为 Gemini 3 的预训练负责人之一？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我最开始做强化学习方向：训练无监督网络，在 Atari 环境中学习关键点，尝试让智能体玩 Atari。我做了大约 6 个月，但不太喜欢这种偏合成的部分。我更想做真实世界数据，产生更直接的真实世界影响。我总体更喜欢做“能用起来的东西”，不太喜欢纯粹学术式研究。</p>
  <p>这促使我转向表征学习：构建或训练能形成良好表征、可用于不同任务的神经网络。我参与的第一个项目叫“从真实世界数据中学习表征”。当时我们不得不把“真实世界数据”写进项目名里，因为否则大家会默认是合成环境或合成数据；这一点后来完全改变。</p>
  <p>之后在大语言模型与 Transformer 方面，我们研究 Transformer 架构，以及 BERT、XLNet 这类模型，学习这些表征并尝试改进。</p>
  <p>Matt Turck：你做过 RETRO，对吗？能谈谈吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：之后我们开始做大规模化大语言模型。首先是 Gopher，我认为那是 DeepMind 发表的第一篇大语言模型论文。那时团队大概 10 到 12 人，已经很清楚这类研究无法靠个人完成。</p>
  <p>这也是我开始做预训练、做大规模预训练的阶段。我形成了自己的研究取向，也很享受这项工作。我们训练了一个密集 Transformer 模型，参数规模约 2800 亿，数据约 3000 亿 token。现在我们不会再用当时那样的方式做事，但那是一次很棒的学习经历。</p>
  <p>之后出现了两个项目：Chinchilla 与 RETRO。Chinchilla 重新审视模型规模与数据规模如何扩展，尤其从训练计算量最优的角度：训练计算量固定时，如何训练出最好的模型？应该增加模型规模还是增加数据规模？我们重新审视了 OpenAI 的相关工作，发现相较于扩展模型规模，更应该更快扩展数据规模。这在今天仍然很相关，因为它影响训练后推理服务成本以及使用成本。</p>
  <p>RETRO 更偏架构创新：研究如何通过给模型加入从大规模文本语料库检索的能力来改进模型。与其让模型把所有知识都存进参数里，我们让模型在训练和推理时都能查找特定内容。</p>
  <p>Matt Turck：你提到“research taste”。这是什么意思？对研究者有多重要？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这很重要，也难量化。第一，研究不是孤立的；你的改进必须能与其他人的研究整合。假设你让模型变好，但让其他人使用模型难度增加 5%，这不是好权衡，因为会拖慢其他人的研究，累积下来会拖慢长期进展。</p>
  <p>第二，要对复杂性敏感。复杂性具有主观性，但我们有复杂性预算，也有研究风险累积的上限。意识到并管理它很重要。很多时候我们不一定用性能最强的版本，而是愿意牺牲一些性能，选择更低复杂度的版本，因为这能支持未来取得更多进展。</p>
  <p>Matt Turck：这也包括对什么可能有效的直觉判断吗？毕竟算力有限。&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：是的。有些人这方面更强，经验也很重要。研究侧确实受算力瓶颈限制；如果算力更多，会更快取得更多进展。你需要判断研究树上哪些方向值得探索、做哪些实验。大多数研究想法都会失败，你需要判断何时该转向别的方向，何时该继续推进。深度学习里，负面结果并不一定意味着方法不行，往往只是还没把它做成，意识到这一点也很难。</p>
  <p>Matt Turck：你们如何平衡短期与长期？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：总有关键路径事项需要做：某部分需要改进，或已知某部分不够好。我们会投入很多精力去修复这些问题。原因之一是它们能确定性地让模型变好，是较安全的投入；原因之二是那些不够好、不够完美的地方，往往在扩大规模或模型更强时暴露问题，所以需要认真解决。</p>
  <p>另一部分是探索性研究：可能进入下一版或再下一版 Gemini 的想法，潜在收益更大，但尚未完全验证。如何平衡没有明确答案，也有周期性：做 scale-up 时探索性研究更多；临近扩大新架构或新模型规模时，会更偏执行导向，重点在去风险、补齐最后不确定因素。</p>
  <h2><strong>预训练 Scaling Law 已死？从无限数据向有限数据的深层转变</strong></h2>
  <p>Matt Turck：研究与产品之间的张力如何？会不会因为与其他实验室竞赛而有压力，比如为了某些基准目标？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我认为在 Google 这类压力很少，因为领导层有研究背景。他们知道可以强推某些基准或目标，但最终重要的是研究进展与把研究做成。我个人日常几乎不感受到这种压力。</p>
  <p>Matt Turck：DeepMind 的团队如何组织？预训练有几百人？是否有后训练、对齐团队？大家如何协作？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我们有预训练团队、后训练团队。预训练侧有人做模型、数据、基础设施，也有评估（eval）。很多人低估了评估研究的重要性，但它很难做好。也有大型团队做基础设施和上线服务。</p>
  <p>Matt Turck：Gemini 3 用起来和 2.5 很不同。是否有一个关键架构决策解释差异？你会怎么描述架构？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：从高层看，架构与上一代相比变化不大，更像是多个因素叠加带来的大幅改进。它是基于 Transformer 的混合专家（MoE）架构。粗略看，你仍能在其中辨认出原始 Transformer 论文里的很多组件。</p>
  <p>Matt Turck：能用科普方式解释 MoE 吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：Transformer 大体有两块：注意力模块负责在不同 token 之间混合信息；前馈模块更多提供模型推断所需的“记忆”和计算能力，它对单个 token 计算，因此可以并行。在原始 Transformer 中，这部分是一个密集计算的隐藏层：输入线性变换到隐藏维度，经过激活函数，再线性变换回输出。</p>
  <p>混合专家的核心想法是把“使用的计算量”和“参数规模”解耦，通过动态路由，把计算分配到某些“专家”上执行，而不是把计算量与参数规模完全绑定。</p>
  <p>Matt Turck：Gemini 原生多模态。从实际角度看，这意味着什么？是否会更贵？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：原生多模态意味着不分别训练图像模型、音频模型、文本模型，而是同一个模型、同一个神经网络共同处理不同模态。</p>
  <p>成本大致有两类。第一是复杂性成本：做的事情更多，不同模态会相互作用，与研究中的不同部分产生交互，因此需要花时间处理复杂性。第二是计算成本：图像输入通常比纯文本大，朴素处理会更贵，但也有很多研究在提升效率。我认为收益总体上远大于成本，这也是我们训练这些模型的原因。</p>
  <p>Matt Turck：2025 年很多人讨论“预训练 Scaling Law 已死”。Gemini 3 是否证明 Scaling Law 仍在继续？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：这些讨论对我来说有点奇怪，因为我的经验不匹配。规模在预训练中很重要，是让模型变好的关键方面，但人们高估了它：它重要，但不是唯一因素。规模带来的好处相对可预测，这就是 Scaling Law 告诉我们的。但这只是其中一部分；架构创新与数据创新同样重要，甚至今天可能比纯扩规模更重要。不过规模仍然重要。</p>
  <p>Matt Turck：今年后训练出现了强化学习规模化、测试时计算规模化。预训练这边是否也在继续加速？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：更合适的说法是这些因素会叠加。规模是一条轴，模型与数据也会提升性能。有时创新带来的收益超过继续扩规模；有时纯扩规模才是正确答案。强化学习规模化也出现了类似现象；因为我们有预训练经验，很多经验教训可以复用到强化学习规模化上。</p>
  <p>Matt Turck：Gemini 3 的预训练数据混合是什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：数据从一开始就是原生多模态的，包含许多不同来源。</p>
  <p>Matt Turck：我们会不会用完数据？合成数据今年使用增加。合成数据在哪里有帮助，哪里没有？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：合成数据很有意思，但必须非常谨慎，因为很容易用错。常见做法是用强模型生成合成数据，再用更小规模消融实验验证其效果。一个关键问题是：能否用合成数据训练未来的模型，并让这个模型比生成合成数据的模型更强？我们为此花了很多时间思考并做研究。</p>
  <p>至于是否用完数据，我不这么认为。我们也在这方面做工作。但更可能发生的是范式转变：从数据无限环境转向数据受限环境，这会改变研究方式与问题思路。一个类比是，大语言模型之前，很多人在 ImageNet 等基准上工作，也处在很数据受限的环境；那个时期的一些技术因此又变得有意思。</p>
  <p>Matt Turck：行业里还有“推理轨迹（reasoning traces）训练”的概念：让模型展示推理过程，用来训练下一代模型。你怎么看？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我不能评论具体细节。泛泛来说，这与合成数据问题相关，我们的思路类似。另一个关键主题是：模型如何用更少的数据学习。</p>
  <p>我这里的“数据受限”不一定指数据更少，而是指数据是有限的，范式从“无限”转为“有限”。</p>
  <p>从另一个角度，架构改进的含义之一是：用同样数据训练能得到更好结果；等价地，也可以用更少数据达到旧模型的同等结果。但就今天所需的数据量而言，我们仍比人类可用的数据量高出好几个数量级。人类还有进化过程等因素，这类高层换算需要很多假设，但一阶近似下，我们确实用得更多</p>
  <h2><strong>长上下文、注意力机制：未来预训练的重要方向</strong></h2>
  <p>Matt Turck：你对预训练进展的哪些方向感到兴奋&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：Gemini 1.5 在长上下文能力上有很大跃迁，这使模型与智能体能处理更长的上下文，例如在代码库上做大量工作时上下文会不断增长。未来一年左右，这方面会有更多创新：让长上下文更高效，也让模型支持更长上下文。</p>
  <p>对我们来说，注意力机制方面最近也有一些有意思的发现，会影响未来几个月的研究，我对此非常兴奋。</p>
  <p>我也想强调：进展往往来自许多因素累积。我们已经看到很多小到中等规模的改进：修复某个问题、修复某个 bug、某项研究显示出前景。这些叠加会推动大量进展。</p>
  <p>Matt Turck：RETRO 强调效率，小模型做更多；而 Gemini 3 是海量数据与长上下文。长上下文是否会让 RAG/ 搜索不再需要，一切被折叠进模型？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：RETRO 的核心是检索信息而不是存储信息，不一定是为了让模型更小。它更像是让模型在预训练意义上做更多推理，而不是只存知识。这一点今天仍然重要。</p>
  <p>直到最近，预训练的迭代周期通常比后训练慢很多，因此预训练侧做大改动风险高、耗时长。RAG 或搜索可以在后训练中做，迭代更快，也能提供很强性能。</p>
  <p>但从根本上说，我相信长期答案是以端到端、可微的方式学会这些能力：在预训练（或未来某种训练形式）中，把检索作为训练的一部分，把搜索作为训练的重要部分。我认为强化学习规模化可能开启了这个过程，但架构侧仍有很多工作。这会在未来几年出现，而不是立刻。</p>
  <p>我还想强调：让预训练更好的不只有架构，还有基础设施、数据与评估。评估非常难，在预训练中更难，因为要跨两个差距：一是小模型评估要能预测大模型 scale-up 后的方向；二是预训练评估还要能代理后训练之后的效果。评估上的进展非常重要，也很难，它帮助我们判断模型侧或数据侧的改动是否是真实改进。</p>
  <p>Matt Turck：你们内部会自己建立一套评估体系，对吗？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：是的，而且越来越是这样。外部基准可以用一段时间，但很快会被污染：它们会以不同形式出现在论坛或网络各处。如果训练数据覆盖到这些内容，就很难检测评估泄漏。要防止自欺、避免误以为自己更强，唯一办法是创建内部留出的评估集，并真正把它们留出。</p>
  <p>Matt Turck：对齐在预训练层面重要吗，还是主要在后训练？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：主要是后训练，但确实有一些部分与预训练相关，我们也会考虑。我不能讲太多细节。</p>
  <p>Matt Turck：如果核心数据来自互联网，而互联网有很多糟糕内容，对齐的最基础做法是否就是把某些内容从模型中排除？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我没有明确结论。但你不希望模型去做那些糟糕事情。从根本层面，模型需要知道那些事情是什么，因此至少要训练一部分内容，让它知道并学会避开；否则用户提到糟糕内容时，模型可能连在说什么都不知道，也就无法判断“这是糟糕的事情”。</p>
  <p>持续学习很重要&nbsp;</p>
  <p>Matt Turck：Deep Think 是不同模型，还是同一模型的一部分？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我不能评论太多。</p>
  <p>Matt Turck：模型“思考”10 秒、20 秒时幕后发生什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：核心是生成“思考”。不只是在模型深度方向做计算，也在序列长度方向做计算，让模型在序列上进行更多推理。模型会形成假设、检验假设、调用工具验证、进行搜索调用等，最后可能查看思考过程并给用户确定答案。</p>
  <p>Matt Turck：智能体部分，以及 Google 的 antigravity 项目，你觉得哪里有意思？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我们日常很多工作偏执行，例如盯实验。我认为智能体在这里影响最大。</p>
  <p>从预训练角度看，感知与视觉很重要，因为模型需要与电脑屏幕交互；屏幕理解做得好非常关键。</p>
  <p>Matt Turck：vibe coding（氛围编程）是预训练带来的还是后训练带来的？如何把“氛围”做进模型？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：你问五个研究者会得到五种答案。也有人谈“大模型气场”，认为更大模型可能“感觉”不同。我不会用这些词来表述，但我认为模型“氛围 / 感觉”更多来自预训练，而非后训练。至于 vibe coding 本身，我认为更偏强化学习规模化与后训练：可以获得大量数据，把模型训练到在这方面做得很好。</p>
  <p>Matt Turck：什么是持续学习？它会如何影响重训？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：持续学习是让模型随着新知识出现而更新。例如明天出现新科学突破，我们昨天训练的基础模型在预训练阶段并不知道它。</p>
  <p>过去几年这方面进展很大，主要在后训练：使用搜索工具并进行搜索调用，模型在某种意义上能访问新信息。这也类似 RETRO 的思路：通过检索，把知识语料与推理部分外化。</p>
  <p>预训练侧也有关联：如果能持续扩展用户上下文，模型在上下文中获得越来越多信息，在某种程度上就具备持续学习成分。</p>
  <p>更范式性的变化是：是否能改变训练算法，使模型可以在来自现实世界的数据流上持续训练。</p>
  <p>最值得关注的研究热点&nbsp;</p>
  <p>Matt Turck：持续学习之外，你觉得今天哪些研究方向最值得关注？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：很多小改动仍在累积，这是历史上推动进步的主要方式，我不认为它会停止。长上下文架构与研究是一个方面；注意力机制是一个方面；从无限数据转向有限数据的范式转变也会带来很多变化与有趣研究。</p>
  <p>另一个重要方面是：使用模型的人增长很快，因此预训练侧也越来越要考虑上线服务成本。预训练侧能做什么，让模型质量更好、服务更便宜，并在推理时消耗更少资源。</p>
  <p>Matt Turck：给想成为你这样的学生或博士生一些建议：几年尺度应该聚焦什么？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：越来越重要的是：能做研究，同时理解系统层面。我们在构建复杂系统，能理解从 TPU 到研究的整套堆栈，是一种优势：能发现不同层之间的空白，也能把研究想法一路推演到 TPU 堆栈层面的影响。能做到这一点的人会产生很大影响。应关注研究、工程与系统结合，而不仅是纯架构研究。</p>
  <p>我也对 RETRO 那类检索研究很感兴趣。我认为它直到现在才接近成熟，但情况在变化。未来几年，让类似方法对 Gemini 这类领先模型变得可行，并非不合理。</p>
  <p>Matt Turck：为什么以前不成熟，为什么可能改变？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：与复杂性有关，也与这样一个事实有关：它带来的能力可以在后训练中更快迭代。用搜索与后训练数据，可以用更简单方式给模型提供相似能力。随着后训练与强化学习规模化发展，重心可能再次向预训练侧转移。</p>
  <p>Matt Turck：你认为 AI 领域有哪些方向被过度投资？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：情况已经好很多。两年前我看到人们还在做专门模型来解决一些任务，而这些任务可能在半年到一年内就会被通用模型覆盖。现在大家更相信：对不需要极度专门化的任务，用通用模型更合理，即使不是当前版本，下一版本可能就能做到。这意味着如何使用模型、以及 harness 等研究变得越来越重要；也包括如何让模型与这些 harness 更稳健、能从错误中恢复。</p>
  <p>Matt Turck：对创业公司有什么建议？基础模型越来越强，似乎缩小了创业空间。&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：可以比较一年前或一年半前模型能做什么，再看今天能做什么，然后外推。模型正在改进的领域会继续改进；也可能有一些领域进展不大，那些可能更值得研究。我没有具体例子，这是总体建议。</p>
  <p>Matt Turck：从你个人经历的角度，你对未来一年到两年有什么期待？&nbsp;</p>
  <p><strong>Sebastian Borgeaud</strong>：我很喜欢日常工作中的一点：与很多人一起工作，并向许多研究人员学习。这在很大程度上驱动着我。每天我来上班都会与非常聪明的人交流，他们会教我以前不知道的东西，我很喜欢这部分。</p>
  <p>我已经多次提到：有太多因素会叠加，很多方面仍有改进空间。我非常好奇，因为我看不到这类工作继续带来进步的尽头。能够见证并看到这能把我们带到多远，非常有意思。至少在接下来一年左右，我看不到它会放缓。</p>
  <p><strong>参考链接：</strong></p>
  <p>https://www.youtube.com/watch?v=cNGDAqFXvew&amp;t=442s</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&amp;mid=2247652167&amp;idx=1&amp;sn=b5242de056a538ecc5b49fc57a615232&amp;chksm=fa1f2ffdee820996bd2b3bc1f51ef568c2a7b53997bd5a96190501ef6cb4807143a19fd18f4f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“AI前线”（ID：ai-front）</a>，作者：高允毅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612229188715522</id>
            <title>百度等巨头、A股公司齐入局，2025年具身智能CVC投资力度全揭秘</title>
            <link>https://www.36kr.com/p/3612229188715522</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612229188715522</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 12:19:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着人工智能从“感知智能”向“具身智能”跃迁，机器人技术正加速实现从虚拟交互到物理执行的突破。具身智能不仅成为通向通用智能的关键路径，更被视作新一轮产业变革的核心引擎。&nbsp;</p>
  <p>在此背景下，资本市场对具身智能赛道的关注度持续飙升。&nbsp;</p>
  <p>据IT桔子数据，截至2025年12月21日，今年中国具身智能赛道的融资事件有超305起，较去年增长了近2倍；总融资额估算超过了380亿元。&nbsp;</p>
  <p>数据背后，是超过600多家投资方的“真金”加码助力。其中百度、阿里、美团等大厂及各类产业资本组成的CVC力量，凭借资本与场景的双重优势，成为推动赛道发展的核心动能。&nbsp;</p>
  <p>今年产业资本对具身智能创业企业的投资力度究竟如何？还有哪些CVC产业方比较活跃？&nbsp;</p>
  <h2><strong>&nbsp;一、核心力量：互联网/科技/AI巨头的投资布局与战略解读</strong></h2>
  <p>互联网、科技及AI巨头凭借技术积淀、场景资源与资本实力，在具身智能投资领域展现出高度的战略自觉性，其布局并非盲目撒网，而是紧密围绕自身核心业务生态，形成了差异化且精准的投资逻辑，具体投资数据如下表所示：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_763ea77f12a04679b0f20a1e4cd6bda0@000000_oswg336649oswg1080oswg918_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据IT桔子据，大厂巨头在具身智能赛道的投资呈现出“高频次、强聚焦”的特征：8家核心大厂全年投资次数合计达62次，其中百度风投以13次投资位居首位，联想创投/联想之星以11次紧随其后，国香资本（商汤）与蚂蚁集团均以8次投资并列第三，形成第一投资梯队。&nbsp;</p>
  <p>投资力度上，8家大厂全年估算投资总额区间达14.5-34亿元，除科大讯飞单家投资金额或少于1亿元外，百度风投、联想创投/联想之星、蚂蚁集团、美团/美团龙珠、京东等均有2-5亿元的大额布局，彰显出大厂对赛道的坚定信心。&nbsp;</p>
  <p>基于上述投资数据，大厂的战略逻辑可归纳为三大核心方向：&nbsp;</p>
  <p><strong>其一，技术基座卡位。</strong></p>
  <p>以百度风投为代表，聚焦具身智能大脑这一核心技术领域，通过投资星海图等企业，强化在大模型与机器人融合技术上的布局，构建“云端训练+边缘计算+终端执行”的技术闭环。&nbsp;</p>
  <p>阿里巴巴则依托通义千问大模型优势，投资原力灵机等企业，推动多模态模型在具身智能硬件中的落地，夯实技术基座。&nbsp;</p>
  <p><strong>其二，场景协同赋能。</strong></p>
  <p>美团的投资紧密围绕“科技+零售”战略，布局具身智能大脑与机器人本体，旨在通过无人配送、智能履约等机器人应用，降低服务成本、提升服务密度，与自身本地生活服务生态形成深度协同。&nbsp;</p>
  <p>京东则聚焦电商零售场景，通过投资智元机器人等企业，推动具身智能机器人在仓储、物流、居家服务等场景的应用，构建“硬件+软件+服务”的生态闭环。&nbsp;</p>
  <p><strong>其三，生态圈层构建。</strong></p>
  <p>大厂普遍摒弃粗放式投资，转而追求商业生态互补与技术协同，通过投资覆盖机器人本体、算法、零部件等关键环节，形成完整的产业生态链。例如，联想创投聚焦机器人应用场景，蚂蚁集团侧重AI算法，讯飞创投今年侧重投资机器人零部件及应用领域，均是通过精准投资完善自身生态的关键拼图。&nbsp;</p>
  <p>更多可参见：美团对机器人的投资布局，京东对机器人的投资布局&nbsp;</p>
  <h2><strong>二、生态补位：传统企业CVC的跨界布局</strong></h2>
  <p>除科技巨头外，传统企业尤其是A股上市公司旗下CVC成为2025年具身智能投资的重要补充力量，其凭借产业资源优势，以跨界投资的方式切入赛道，寻求产业升级与新增长曲线，具体投资情况如下表：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_89ff7e0342344e17b49a1364dbd79729@000000_oswg302462oswg1080oswg934_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>根据IT桔子统计，8家核心传统企业CVC全年对具身智能创业企业的投资次数合计达43次，投资力度估算总额超5亿元。&nbsp;</p>
  <p>其中首程资本以10次投资成为传统企业CVC中的投资频次冠军，其投资金额或达2-6亿元，与科技大厂的大额布局不相上下；多家传媒上市公司投资的GP央视融媒体产业投资基金以6次投资位居第二，东方精工虽投资次数仅3次，但凭借数亿元+的投资力度展现出强劲的布局决心。&nbsp;</p>
  <p>数据显示，部分新能源车企和制造类企业CVC的投资呈现出鲜明的产业协同属性：&nbsp;</p>
  <p>典型CVC如上汽（尚颀资本）、歌尔股份（同歌创投）、龙旗科技聚焦机器人本体制造与硬件环节，与自身制造优势形成互补。&nbsp;</p>
  <p>其中，尚颀资本作为上汽集团旗下私募股权投资平台，通过投资逐际动力，并推动其与上汽集团在具身智能领域展开深度合作，合作核心是双方联合研发适用于汽车生产流水线的工业具身机器人。&nbsp;</p>
  <p>据悉，2025年7月份，<strong>上汽集团与逐际动力</strong>LimX Dynamics在北京正式签署战略合作备忘录，宣布建立长期战略合作伙伴关系，并成立具身智能联合实验室，携手推动具身智能在汽车产业链的技术创新、研发协同和人才培养。&nbsp;</p>
  <p>另外，A股上市公司龙旗科技今年3月参与智元机器人的B轮数亿元投资，半年后就促成了相关的战略合作落地。&nbsp;</p>
  <p>10月，<strong>智元机器人与龙旗科技</strong>签署战略合作协议，龙旗科技下达‌数亿元规模的框架订单‌，采购智元精灵G2机器人，预计部署‌近千台‌，这是国内工业具身智能领域的重要订单。&nbsp;</p>
  <p>该合作方案以消费电子制造为切入点，聚焦验证具身智能在‌柔性生产‌和‌质量控制‌中的价值，为工业巡检等垂类场景提供可复制模式，推动制造业运营效率提升。‌&nbsp;</p>
  <p>另外一些CVC则呈现了不同的投资路径，比如平台型企业如中国移动（中移创新产业基金）则通过投资机器人本体企业，探索智能硬件与通信服务的融合场景。首程资本、央视融媒体产业投资基金等则采取全面覆盖策略，广泛布局赛道关键环节，抢占未来产业变革先机。&nbsp;</p>
  <h2><strong>&nbsp;三、新生势力：新兴机器人公司的投资入局</strong></h2>
  <p>值得关注的是，除传统大厂与传统企业外，作为新兴机器人创业公司，他们左手从上市公司、巨头和大厂手里融资拿钱，右手开始积极通过投资参与具身智能生态的构建，具体投资数据如下表：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_530f060758364c1a9a52fc70a52f32d9@000000_oswg160740oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据IT桔子数据，3家新兴机器人公司全年对具身智能企业的投资次数合计达16次。&nbsp;</p>
  <p>其中智元机器人以9次投资成为该阵营的核心力量，投资频次非常高，但作为独角兽公司，其投资金额力度相比上市公司和科技大厂要少很多，单笔投资主要在数百万元及数千万元级别，鲜少过亿元。&nbsp;</p>
  <p>银河通用机器人以4次投资紧随其后，乐聚机器人以3次投资完成初步布局，整体呈现出“高频次、精准化”的投资特征。&nbsp;</p>
  <p>这类新兴企业的投资逻辑主要基于技术协同与生态互补，共同推动具身智能产业的技术迭代与生态完善。&nbsp;</p>
  <p>比如，今年8月，智元机器人正式入股深圳玉树智能机器人。玉树智能背靠A股环卫上市公司，是玉禾田集团旗下孙公司。&nbsp;</p>
  <p>早在6月，双方就宣布签署战略合作协议，成立“<strong>深圳玉树具身机器人智创中心</strong>”，专注于<strong>具身机器人的数据采集与技术创新</strong>，重点为机器人通用智能应用打基础，解决行业长期依赖仿真数据的局限性。&nbsp;</p>
  <p>智元机器人一边与上市公司合作拿下订单，推进商业化；另一边通过生态式投资，不仅强化了自身在赛道中的生态话语权，也为行业培育了更多技术创新力量。&nbsp;</p>
  <p>总结来说，2025年具身智能赛道的CVC投资呈现出“科技巨头引领、传统企业补位、新兴企业协同”的多元格局，资本流向与投资布局均围绕技术突破与场景落地展开，彰显了赛道从概念炒作向价值落地的转型趋势。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjQ2NzA2Mg==&amp;mid=2649626450&amp;idx=1&amp;sn=a6c3fdf1499b7f404fd8d4af58b8bf73&amp;chksm=bfbe275eafab56ba3284cfa18c65998801b0d069d1df4cf6de93fa6685941b6cc6e0268828f6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT桔子”（ID：itjuzi521）</a>，作者：吴梅梅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612280889558025</id>
            <title>算法算不到的意外：Waymo无人车，成了临时产房</title>
            <link>https://www.36kr.com/p/3612280889558025</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612280889558025</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:51:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】又一个生命在Waymo后座里降临！科技追求可控，但生命偏要在最意外的时刻闯进来。当自动驾驶撞上人类最混乱的瞬间，硅谷才真正意识到：世界不会按算法的节奏运行。</strong></p>
  <p>旧金山的深夜，一辆Waymo无人车行驶在去往UCSF医院的路上。</p>
  <p>激光雷达、摄像头、毫米波雷达把整座城市扫描得一清二楚，连夜间几厘米的障碍物都能识别。</p>
  <p>可在车内，是另一幅完全失控的画面<strong>：</strong>&nbsp;孕妇痛得呼吸紊乱，紧紧握着座椅边缘，完全无法预测下一秒会发生什么。</p>
  <p>Waymo的远程团队首先察觉到异样。系统监测到「乘客坐姿变化剧烈、肢体动作不规律」，声音检测更是发现了高强度波动。</p>
  <p>系统随即启动了自动报警流程，向911发出求助。</p>
  <p>无人车调整了路线和车速，最终，孩子还是抢在到达医院之前降生了。</p>
  <p>Waymo事后给媒体的回应，倒是保持了硅谷式的幽默：</p>
  <blockquote>
   <p>有些新乘客，就是等不及体验人生第一程ride。</p>
  </blockquote>
  <p>而这项婴儿无需送往医院的「光荣传统」，也被延续了下来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_43fde52378ec42f1b018eb59eabef9e7@46958_oswg513071oswg870oswg672_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>最意外，也是最古老的「产房」</strong></h2>
  <p>如果你以为，这只是无人车时代才有的新鲜事，那可就大错特错了。</p>
  <p>「后座分娩」，算得上是人类延续了几十年的「光荣传统」。</p>
  <p>医学上，产妇从出现剧烈宫缩到生产，可能只有几十分钟。</p>
  <p>而在城市里，救护车的平均等待时间往往比人们想象得更长。</p>
  <p>当交通拥堵、救护车延迟、产程突然加速，这些条件叠在一起，就极有可能导致「来不及去医院」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_891a264b1abc48acad0dd2721e21941b@46958_oswg314013oswg672oswg423_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但是无论时代背景如何变迁，这种「生命加速」的瞬间从未缺席。</p>
  <p>早在2015年，一位印度德里妈妈因为救护车一直没来，只能叫Uber，最终她在出租车后座诞下了孩子。</p>
  <p>事后，这对夫妇给孩子起名为Uber。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7e30785aad4e46d48579a5ac0a043483@46958_oswg158851oswg600oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在英国伦敦，有乘客在Uber上提前临盆，司机和家人在狭窄的后座上帮忙接生。</p>
  <p>事后大家还笑谈要给孩子起个特别的名字。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b908a6d57c7341a88f743250a13e0e8e@46958_oswg53684oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">伦敦乘客在Uber后座提前临盆，司机和家人合力接生</p>
  <p>在美国纽约，也有出租车司机见证过这样的突发状况。</p>
  <p>司机一边打电话一边指导乘客呼吸，沉着地稳定局面。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_74f11479ce0f41cf8711c1e3d77c1909@46958_oswg119578oswg1024oswg682_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Luis Leonardo和他的丰田汉兰达SUV</p>
  <p>无论是伦敦黑出租、纽约黄出租，还是Uber网约车，后座的空间比方向盘更接近生命的诞生。</p>
  <p>正因如此，才会出现伦敦、纽约、印度、加州这些看似分散，却有共同逻辑的故事。</p>
  <p>Waymo只是把这个混乱又惊喜的「后座分娩传统」，带入了硅谷的自动驾驶时代。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8aef724a95754fdd872344e09b2251c0@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p class="img-desc">Waymo官方发布的传感器可视化画面（彩色点云 / 物体框选）</p>
  <p>当然，形式变了。但那种突如其来的惊喜和无可避免的混乱感，跟老出租车时代，也没太大区别。</p>
  <h2><strong>当自动驾驶遇上生命的失控</strong></h2>
  <p>自动驾驶，从诞生起就在追求一种极致的「可控」。</p>
  <p>路线可控、速度可控、行为可控，甚至连紧急状况都被写进了标准操作程序（SOP）。</p>
  <p>Waymo的代码里密密麻麻都是交通规则、优先级、避障逻辑……但唯独没有一条，是写给人类的身体节奏的。</p>
  <p>生命不会等系统加载完毕，更不会遵守「最佳路径规划」。</p>
  <p>它总是突兀、混乱、不讲逻辑，是算法里最难处理的非线性变量。</p>
  <p>如果无人车遇到非交通类紧急情况，比如乘客突发抽搐、孕妇临盆、儿童窒息......车应该怎么做？它会自动报警吗？会绕开红灯吗？有权利「擅自加速」吗？</p>
  <p>乘客的身体数据是否应该被系统监测？监测到什么程度算越界？又是谁来定义「危险」？</p>
  <p>Waymo远程团队这次能及时发现异常，是因为系统检测到了「姿态剧烈变化」。</p>
  <p>但如果乘客是独自坐车并昏迷呢？如果穿着厚衣服遮挡了动作呢？这些都没有真正的答案。</p>
  <p>自动驾驶正在把「非交通事件」推入一个灰色地带，而无人车的责任边界、能力边界、伦理边界，都还远未厘清。</p>
  <p>生命也再次证明了，人类的节奏，永远不会向技术的节奏低头。</p>
  <p>Waymo可以提前预测拥堵、自动避开施工、计算出最快路线，但它永远预测不了一个孩子什么时候降生。</p>
  <p>这就是自动驾驶无法修复的最温柔的「Bug」。</p>
  <h2><strong>自动驾驶时代的荒诞图鉴</strong></h2>
  <p>Waymo车里的这一幕，其实反映了一个更大的问题：</p>
  <p>我们把世界交给AI，它总会被「人类的混乱」打个措手不及。</p>
  <p>旧金山街头，孩子直接骑到了外卖机器人身上，而机器人只能继续按程序移动，完全不知道自己已经成了人类的玩具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_04bf658cec334452ae88b57c69b896ed@46958_oswg222641oswg1024oswg951_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>算法在预测情绪时经常失灵。人们随便一句无伤大雅的抱怨，也能让AI误判为严重的心理危机。</p>
  <p>而像「机器人接生」这种桥段，更是完全不在任何硅谷PR手册的FAQ列表里。</p>
  <p>事实上，无人车遇到的离谱状况，远比Waymo的官方案例多得多。</p>
  <p>在酒驾执法行动中，警方曾经试图把无人车当成「可能的醉驾对象」拦下，结果发现根本没人坐在里面，只能报警联系公司。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2698972c862c4373a3f3e2ed0703d4a9@46958_oswg85404oswg1024oswg768_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">圣布鲁诺警察局的警员发现这辆无人驾驶汽车在红绿灯处当着警察的面非法掉头</p>
  <p>有路人看到一群Waymo停在路中央，实际上是软件更新导致短暂同步卡顿；</p>
  <p>还有人在深夜把无人车当成移动KTV，整个车厢被音响震得像夜店。</p>
  <p>科技在努力把世界压缩成一条清晰、线性、可预测的曲线。</p>
  <p>但人类的故事，本来就是跳跃式的、情绪化的、充满失控味道的。</p>
  <p>AI越进步，越容易无意间撞上这些「计划外的瞬间」<strong>。</strong>&nbsp;代码里也没有定义的温柔、荒诞和意外。</p>
  <p>AI的时间是平滑的、数学化的，是可优化的曲线。</p>
  <p>而人类的时间却是突然的，是跳跃的，是会被情绪、疼痛、天气、交通堵塞随时打断的。</p>
  <p>技术想让世界越来越可靠、越来越稳定，可生活的本质，从来不是稳定，而是突如其来的改变。</p>
  <p>自动驾驶会越来越聪明，但人类的混乱与温度，也会一直存在。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8c5037eb9b8642f997a21e1986e5e377@46958_oswg81833oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Waymo的后座成了临时产房，硅谷所有的算法、传感器、路线规划都静静退到了一边。</p>
  <p>科技能把道路铺得笔直，却永远预测不了生命什么时候降临。</p>
  <p>无人车可以自动驾驶，但人类的故事，从来不是自动的。</p>
  <p>它带着意外、带着疼痛，也带着一种无法被简化成流程的温度。</p>
  <p>也许未来某一天，Waymo真的会把「突发分娩应急流程」写进产品文档里。</p>
  <p>可生命的节奏和力量，永远不会因为一段代码而改变。</p>
  <p>参考资料：https://x.com/TechCrunch/status/1998978439110603018&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/kJf786Nf_Ei0SGyvUeU2SQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：倾倾&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257529218308</id>
            <title>超越GPT-5、Gemini Deep Research，人大高瓴AI金融分析师，查数据、画图表、写研报样样精通</title>
            <link>https://www.36kr.com/p/3612257529218308</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257529218308</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:50:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>能自动查数据、写分析、画专业金融图表的AI金融分析师来了！</p>
  <p>最近，中国人民大学高瓴人工智能学院提出了一个面向真实金融投研场景的多模态研报生成系统——<strong>玉兰·融观</strong>（Yulan-FinSight）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7bfea04bb94847c69da4961a2825bbcb@46958_oswg446663oswg1080oswg535_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>面对用户的研究需求，FinSight能够自动拆解任务，从互联网和金融数据库中搜集包括股价、财报、新闻在内的<strong>多源异构数据</strong>，并生成包含“发展历程”、“核心业务架构”、“竞争格局”等章节的<strong>万字图文报告</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_33659d329ba645fdbc45562d1f53b36e@46958_oswg181916oswg1080oswg574_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>该系统也在<strong>AFAC 2025 金融智能创新大赛挑战组</strong>的1289支队伍中夺冠，并在多项评测中超越了GPT-5 w/Search、OpenAI Deep Research与Gemini-2.5-Pro Deep Research，展现出接近人类专家的金融分析与写作能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a0fa9a2298cd478986af65efa07d2f15@46958_oswg46846oswg1080oswg361_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>下面来看详细内容。</p>
  <h2><strong>为什么通用AI做不好金融研报？</strong></h2>
  <p>在研究者看来，问题的关键并不在于模型“不会写字”，而在于金融行业的研究报告本身是一项<strong>高度结构化、强逻辑、强可视化</strong>的专家级工作，涉及多个流程。</p>
  <p>相比通用问答、检索或文本生成任务，金融投研对数据整合能力、分析深度以及表达形式均提出了更高要求。</p>
  <p>具体而言，现有通用AI系统主要面临三方面挑战：</p>
  <p><strong>1、领域知识与数据割裂：</strong></p>
  <p>通用搜索系统难以有效整合股价、财务报表等结构化金融数据与新闻、公告等非结构化信息。由于缺乏统一的数据表示与多智能体协作分析机制，系统往往只能对单一信息源进行浅层处理，难以形成系统性的金融洞察。</p>
  <p><strong>2、专业级可视化能力缺失：</strong></p>
  <p>金融研报高度依赖图表来传递高密度信息，但现有模型多只能生成静态图片或简单折线图，难以支持多维对比、事件标注等专业金融可视化需求，图文之间也缺乏严格的数据一致性约束，例如，图文无关或图文信息矛盾与冲突。</p>
  <p><strong>3、缺乏“迭代式研究”能力：</strong></p>
  <p>绝大多数系统仍采用固定的“先检索—后生成”流程，研究路径一旦确定便难以调整。</p>
  <p>相比之下，人类分析师往往会根据中间发现不断修正研究重点，而这种基于中间结果的动态策略调整能力，正是现有通用AI系统普遍欠缺的部分。</p>
  <h2><strong>FinSight的核心思路：像金融分析师一样工作</strong></h2>
  <p>为突破上述限制，FinSight并未简单地“堆模型”，而是从认知流程入手，模拟人类金融专家的工作方式，并提出了三项关键技术创新。</p>
  <h3><strong>核心架构：代码驱动的可变内存智能体架构</strong></h3>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b63682d7329b4ebb993012325bce847f@46958_oswg359272oswg1080oswg611_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>FinSight的底层采用了一种全新的、名为<strong>Code-Driven Variable-Memory</strong>（CAVM）的多智能体架构。</p>
  <p>如图所示，现有Agent 架构本质上仍受限于对话式记忆范式，即以消息或任务进度等历史作为状态载体。这一范式在任务复杂度与流程长度增长时，容易暴露出表达能力与可控性的结构性瓶颈。</p>
  <p>CAVM将这一范式重构为代码驱动的变量记忆空间。系统不再以自然语言对话作为协作媒介，而是将数据、工具与中间推理结果统一映射为可读写的程序变量，由多个<strong>Code Agent</strong>通过共享变量空间完成协同推理。</p>
  <p>通过将“记忆”从消息序列提升为可操作的变量结构，CAVM 使复杂任务得以被显式建模、持续修正与模块化组合，为<strong>长时程、多流程</strong>的专家级推理提供了必要的结构支撑。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_dcff242f7e39449d9ff4b5d567fbc429@46958_oswg185178oswg846oswg632_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>在这一设计中，数据、工具和智能体被统一抽象为可编程变量空间：</p>
  <p>财务报表、行情数据、新闻文本作为数据变量</p>
  <p>搜索、分析、绘图等能力作为工具变量</p>
  <p>不同功能的Agent通过Python代码进行调度与协作</p>
  <p>这种“以代码为中枢”的设计，使系统能够高效处理大规模异构金融数据，并支持复杂的多流程任务协作。&nbsp;</p>
  <h3><strong>视觉突破：迭代式视觉增强机制</strong></h3>
  <p>针对金融图表生成中普遍存在的专业性与可信度问题，研究者们提出了<strong>Iterative Vision-Enhanced Mechanism</strong>，将绘图过程建模为一个可迭代优化的视觉生成问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b890901e59734d91a36304e6ca3fde3e@46958_oswg130918oswg1080oswg462_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>该机制采用了<strong>Actor–Critic 协作范式</strong>：</p>
  <p>文本大模型作为<strong>Actor</strong>，负责生成可编译、可执行的绘图代码，充分发挥其在代码生成与逻辑控制上的优势；而视觉语言模型则作为<strong>Critic</strong>，直接对图像进行视觉层面的审视，从数完整性与整体美观性等维度提供反馈。</p>
  <p>这一设计的关键在于<strong>优势互补</strong>：语言模型擅长编码与思考，却难以获取真实的视觉反馈；视觉模型具备强大的感知与判别能力，但在复杂代码生成上能力受限。</p>
  <p>通过将二者解耦并置于闭环中，系统在<strong>test time</strong>通过多轮“生成—评估—修正”实现持续优化，使绘图质量随迭代次数自然提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_cf8bae62349343718f1e33201615fd82@46958_oswg165534oswg705oswg512_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>最终，系统能够稳定生成包含双轴对齐、事件标注以及复杂结构的专业金融图表，如图所示，将原本一次性生成的静态结果，转化为一种<strong>test-time scaling</strong>的过程。</p>
  <h3><strong>两阶段写作框架：先分析，再成文</strong></h3>
  <p>在写作层面，FinSight并不试图一次性生成完整的长篇研报，而是将研报写作重构为<strong>“分析—整合”</strong>的两阶段过程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_0503fb07a6464e02beccb44b951002aa@46958_oswg119272oswg784oswg648_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>首先，系统生成一组<strong>“分析链”</strong>（Chain-of-Analysis，CoA）：每条分析链对应一个明确的子任务（如公司历程、财务分析、竞争对手分析、风险因素等），在局部范围内完成证据收集、关键判断与核心结论提炼。</p>
  <p>之所以需要这一步，是因为一份研究报告往往由多个子问题耦合构成，若直接端到端生成长文，很难兼顾所有的分析准确性和深度。</p>
  <p>随后，系统以这些CoA作为“骨架”，将分散的洞察在全局层面进行组织与编排，生成大纲并分章节逐步写作：在保证章节结构与论证链条连贯的同时，把文本叙述、数据引用与图表呈现进行对齐，最终合成为一份逻辑自洽的长篇报告。</p>
  <p>这种<strong>“先分析、后写作”</strong>的策略有效避免了长文常见的逻辑松散问题，使报告在篇幅超过2万字时仍保持结构清晰、论证深入。</p>
  <p>为了进一步保证长篇研报中的事实准确性与图文一致性，作者在写作阶段还引入了一种<strong>生成式检索</strong>（Generative Retrieval）&nbsp;机制。</p>
  <p>不同于传统“先检索、后生成”的后处理做法，该方法将检索过程嵌入写作本身：模型在生成具体段落时，会根据当前的分析链与写作上下文，动态生成数据和图片的索引标识符，再通过后处理统一嵌入。</p>
  <p>这样一来，引用准确性和图文一致性得到了最大的保证。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_9553889edba64471b75d606a95366c6f@46958_oswg780249oswg1080oswg1083_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△</p>
  <p>通过这种方式，FinSight能够在长篇写作过程中持续对齐文本叙述、数据来源与可视化结果，避免常见的事实错配与图文脱节问题，从而在报告篇幅不断扩展的情况下，依然保持整体逻辑与证据链的稳定性与一致性。</p>
  <h2><strong>实验结果：全面超越现有Deep Research系统</strong></h2>
  <p>作者们在涵盖公司研究与行业研究的高质量基准测试上，对FinSight进行了系统评估。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7289b76c9d9541ce9ebb92a9df876807@46958_oswg257358oswg1080oswg440_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>结果显示，FinSight在事实准确性、分析深度与呈现质量三项核心指标上均显著优于Gemini-2.5-Pro Deep Research与OpenAI Deep Research，综合评分达到<strong>8.09</strong>。</p>
  <p>在可视化维度上，得益于迭代式视觉增强机制，FinSight获得<strong>9.00</strong>的评分，明显领先对比系统，体现出对专业金融图表生成能力的有效提升。</p>
  <p>而迭代式绘图的效果分析同样惊艳：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_e9929d477a324dd3a207e22e7d9c9dea@46958_oswg169246oswg1080oswg371_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在长文本生成场景中，系统生成的研报平均长度超过20000字，包含50余张图表与结构化数据引用，且随着篇幅增长，报告质量保持稳定，未出现显著退化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1a804390e3f0425c8afac96546732344@46958_oswg276565oswg1080oswg541_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，在AFAC 2025金融智能创新大赛中，FinSight在来自企业与高校的1289支参赛队伍中<strong>排名第一</strong>，获得挑战组赛题四冠军，进一步验证了其在真实场景中的实用性与鲁棒性。</p>
  <p>研究者认为，FinSight并非仅是一个金融工具，而是展示了Agent架构在高复杂度垂直领域的潜力。</p>
  <p>通过统一数据、工具与智能体，并引入视觉与写作的多阶段闭环，AI系统<strong>首次</strong>在金融投研这一“专家密集型”场景中，展现出接近人类分析师的工作能力。</p>
  <p>这一范式的意义不止于金融。</p>
  <p>它表明，在那些高度依赖专业知识、长时程推理与多模态表达的“专家密集型”场景中，AI 系统不再只是信息汇总器，而开始承担起类似人类专家的工作方式：</p>
  <p>分解问题、验证假设、修正结论，并最终形成可被审阅与追溯的完整成果。</p>
  <p>从这个角度看，<strong>FinSight更像是一个起点</strong>。</p>
  <p>随着Agent架构不断成熟，未来的科研分析、法律研判、医疗决策等复杂领域，或将逐步迎来以专家级AI Agent为核心的新一代生产力形态。</p>
  <p>论文及项目作者：中国人民大学高瓴人工智能学院：金佳杰、张宇尧、许一孟、钱泓锦、朱余韬、窦志成</p>
  <p>论文链接：https://arxiv.org/abs/2510.16844</p>
  <p>代码链接：https://github.com/RUC-NLPIR/FinSight</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/F7l6bVXzhe7Ihc7ThM47sQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：FinSight团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257612006403</id>
            <title>第一批拿12.8万月薪的实习生已经出现，AI人才抢夺战真的好激烈</title>
            <link>https://www.36kr.com/p/3612257612006403</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257612006403</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:49:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>好震惊，好意外，现在一份4–6个月的AI相关实习，月薪已经接近14万人民币了！</p>
  <p>而且<strong>这个价格不是个例</strong>——</p>
  <p>OpenAI、Anthropic、Meta、Google DeepMind等巨头，都为实习、Fellowship、Residency这类短期岗位，开出足以对标全职研究员的价格。</p>
  <p>Business Insider最新披露的一组数据显示，目前AI相关实习和研究型短期项目的月薪，已经普遍来到7000–18000美元区间，折合人民币约4.9-12.6万元。</p>
  <p>换算成年薪水平，是不是<strong>已经明显超出大多数行业对“实习生”这一角色的传统认知</strong>……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b1209f9a6ea04639984f1c41be558495@46958_oswg99889oswg232oswg224_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>真·AI人才的生活，我的梦（没错已经开始白日做梦了）。</p>
  <p>书归正传。</p>
  <p>继大厂、巨头为成熟的AI人才大动干戈，甚至扎克伯格为了挖OpenAI的人亲自洗手作羹汤端到想挖的人嘴边过后，<strong>这场纷争终于开始波及那些还没有正式毕业、甚至刚刚进入研究路径不久的人。</strong></p>
  <h2><strong>水涨船高的AI实习工资</strong></h2>
  <p>在薪酬层面，实习生、学生研究员、驻留项目，已经可以和全职研究岗站在同一水平线上。</p>
  <p>我们先展开来看看硅谷那边的具体情况。</p>
  <h3><strong>OpenAI</strong></h3>
  <p>OpenAI发起了一个<strong>周期为6个月的驻留计划</strong>。</p>
  <p>参与者以全职员工身份加入研究团队，直接参与前沿模型和系统研究。</p>
  <p>公开信息显示，该项目工作地点在旧金山，月薪约为18300美元（约合12.8万）。</p>
  <p>最重要的是，项目结束后，计划参与者有可能转正。</p>
  <p>不管是工作强度还是薪酬，都已经可以和OpenAI本身的正式岗位媲美，只不过有一个“6个月”的期限罢了。</p>
  <h3><strong>Anthropic</strong></h3>
  <p>Anthropic的<strong>AI Safety Fellow项目</strong>有异曲同工之妙。</p>
  <p>这个为期4个月的全职研究型人才计划在伯克利或伦敦办公，核心目标是推动AI安全方向的公开研究产出。</p>
  <p>Anthropic披露，往届的AI Safety Fellow项目中，有超过80%的成员产出了论文，有的成果还以其它形式公开。</p>
  <p>参与者不仅可以获得每周3850美元（约合2.7万元）的津贴，还能按月使用约15000美元（约合10.5万）的算力支持。</p>
  <p>从投入成本来看，这个补贴已经不能算是传统意义上的实习补贴了，其实就是专项经费的old school说法。</p>
  <h3><strong>谷歌</strong></h3>
  <p>谷歌的<strong>Student Researcher项目</strong>则覆盖了更大范围的博士生群体。</p>
  <p>这个项目采用年薪制，根据地区和经验不同，基础薪酬在11.3万到15万美元之间，也就是79万到105万左右。</p>
  <p>谷歌方面表示，这个项目主要是为了给Google Research和Google DeepMind等团队补充新鲜血液，</p>
  <p>发现了吧……</p>
  <p>虽然项目形式上仍然被定义为“学生研究员”，但从工作内容和薪酬水平来看，这项目已经很难再与普通学生兼职或短期实习划等号了。</p>
  <h3><strong>Meta</strong></h3>
  <p>上述趋势同样体现在Meta的<strong>Research Scientist Intern项目</strong>中。</p>
  <p>Research Scientist Intern是一个12周到24周的研究型实习，研究方向覆盖NLP、生成模型、CV等核心领域，月薪大概在7650美元到12000美元之间，据说还有更高的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_c05aa32a2fcc4c63bcd8a0f9963cfc25@46958_oswg32641oswg168oswg126_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>是所有AI实习生项目都提升了吗？我们不得而知。</p>
  <p>但根据已经有的信息来看，顶尖实习生的薪酬已经又攀爬了（不只）一个台阶。</p>
  <p>Anyway，对于有明确研究背景的候选人来说，不管从薪酬来看还是从倾斜的资源来看，以上这类项目都绝对足以等同于和一份AI领域的正式工作。</p>
  <h2><strong>这种情况不只发生在国外</strong></h2>
  <p>这种变化并非只存在于海外巨头之间。</p>
  <p>虽然公开披露的数据相对有限，但<strong>国内市场上也显现出隐隐抬头的趋势</strong>。</p>
  <p>就拿最近的一则新闻来说——</p>
  <p>最近，<strong>字节</strong>给20位博士颁发了2025年字节跳动奖学金，这些人覆盖大模型、机器学习、多模态、AlInfra、机器人、Alfor Science、硬件等多个研究领域。</p>
  <p>相比往届，这一次的获奖名额增加了，奖学金还比以前翻了一倍（为10万现金+10万专项学术资金补贴），又还给每位获奖同学的导师提供10万元奖励。</p>
  <p>奖学金获得者清华计算机科学与技术系的张金涛在小红书称赞“字节大气”，还透露出一点额外的消息：</p>
  <blockquote>
   <p>字节报销了他从伯克利Sky Lab往返北京的差旅费。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_d40905a5d9ff4de592a57c1b3f7d68c7@46958_oswg444428oswg1080oswg776_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不光是字节这么大手笔，近几年，阿里云、腾讯、百度等在实习生和学生研究员层面的项目规模持续扩张，覆盖方向也从传统工程岗位，逐渐延伸到基础模型、系统架构、算法研究等更偏研究型的领域。</p>
  <p>以<strong>腾讯</strong>为例。</p>
  <p>今年4月，腾讯宣布启动史上最大规模的就业计划，三年内将新增 28000 个实习岗位，并同步提高实习转正比例。</p>
  <p>仅在今年一年内，腾讯就计划接收10000名实习生，其中六成为技术类岗位。</p>
  <p>（2025年就要过去了，也不知道腾讯的计划落实得怎么样了）</p>
  <p>腾讯方面的解释很直接：一切都基于大模型加速落地这一背景。</p>
  <p>变化不是只有亿点点。</p>
  <p><strong>阿里云</strong>给出的信号同样明确。</p>
  <p>上半年2026届实习招聘启动后，公司明确表示这是近年来规模最大的一次AI人才校园招聘，其中AI相关岗位占比超过80%，覆盖大语言模型、多模态理解与生成、模型应用以及 AI Infra 等方向。</p>
  <p>这种集中度本身已与传统“多业务平均分配”的实习模式拉开了距离。</p>
  <p><strong>百度</strong>这边，早在今年3月就向在校生开放了3000多个暑期实习岗位，其中87%与AI相关。</p>
  <p>综合上述信息可以发现，虽然国内大厂付给实习生方的具体薪资水平并未披露，但在岗位占比、技术集中度以及长期转化预期上，国内市场也开始向同一个方向靠拢。</p>
  <h2><strong>巨头在“买”什么样的实习生？</strong></h2>
  <p>当短期项目的成本被不断推高，一个绕不开的问题是，这些公司究竟在寻找什么样的人？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_395426013ac8408c84f345ea0ba1f1b4@46958_oswg64804oswg218oswg222_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从各类项目的申请要求和历史参与者背景来看，<strong>最核心的能力是可验证的研究产出能力</strong>。</p>
  <p>这种能力通常体现在论文、方法论创新、或在复杂问题上的系统性推进经验上。</p>
  <p>很多项目<strong>明确强调，希望候选人能够在项目周期内完成具有公开价值的研究成果</strong>。</p>
  <p>同时，这些公司也在寻找能够独立推进长期、复杂问题的人。</p>
  <p>无论是模型架构、安全性研究，还是系统层面的优化，这些问题更依赖研究者自身的判断和持续投入。</p>
  <p>上述的短期项目们，不少被设计为全职强度——很大程度上，一大部分原因是为了观察候选人在这种环境下的表现。</p>
  <p><strong>更长远的考量，则在于潜力</strong>。</p>
  <p>我们可以在许多项目在描述中看到，诸如“希望参与者未来能够成长为核心研究员或技术方向负责人”这种话术。</p>
  <p>说白了，这类实习岗位虽然周期还是短，但它就不是传统意义上的实习，也就是补充人力或承担基础任务的那种。</p>
  <p>公司对这些实习生的定位也和常规实习生不同。</p>
  <p>背后真实目的是经过系统性筛选，考核这群人对问题的理解深度、研究品味以及长期投入某一方向的意愿，然后<strong>提前开始培养和绑定AI技术人才</strong>。</p>
  <p><strong>短期研究项目，正在成为企业提前下注人才的一种方式，同时也是一套隐形的精英筛选机制</strong>。</p>
  <p>这种方式比直接高价挖成熟人才风险更低，也比单纯依赖简历和面试更加可靠。</p>
  <p>在这样的逻辑下，实习生被当作“顶尖期货”来对待，也就不难理解了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b798f782cdf64a9ca009906ae21e97b8@46958_oswg39194oswg182oswg122_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过AI人才的培养和筛选路径明显前移这个趋势，对资源和资金没那么宽裕的初创公司就不那么友好了。</p>
  <p>他们获取顶尖人才的难度开始上升——而且可能是只是刚刚开始。</p>
  <p>大厂砸钱砸资源，岂是一般初创公司能够与之相抗衡的呢？</p>
  <p>参考链接：</p>
  <p>[1]https://www.businessinsider.com/top-paying-ai-internships-fellowships-residencies-openai-anthropic-meta-google-2025-12</p>
  <p>[2]https://www.xiaohongshu.com/explore/6927412f000000001902688c?app_platform=ios&amp;app_version=9.14.2&amp;share_from_user_hidden=true&amp;xsec_source=app_share&amp;type=normal&amp;xsec_token=CBoPjgHC6p1qNs6Sqx0OQ6V4QZkPpFIpH9gQdgKyh3f84=&amp;author_share=1&amp;xhsshare=WeixinSession&amp;shareRedId=NzxHOEQ6OTw6Pjw3Sj81SD1HQUk5R0lK&amp;apptime=1766715420&amp;share_id=3af983a0c03a440a9c3e2f72094e59c5&amp;wechatWid=9c1aa40191ada137b15ba1a8b9204956&amp;wechatOrigin=menu</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/E13AuvGTCFQwfADfenJKFA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：衡宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257575470339</id>
            <title>英伟达成美国大模型开源标杆：Nemotron 3连训练配方都公开，10万亿token数据全放出</title>
            <link>https://www.36kr.com/p/3612257575470339</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257575470339</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:49:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>英伟达在开源模型上玩的很激进：</p>
  <p>“最高效的开放模型家族”Nemotron 3，混合Mamba-Transformer MoE架构、NVFP4低精度训练全用上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_cfb0745865424db4ae6405af2120e17a@46958_oswg445342oswg720oswg900_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且开放得很彻底：</p>
  <p>不仅开放模型权重，还要把超过10万亿token的训练数据、预训练和后训练软件、训练配方全部公开。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_8bbc0a7f504c4c7f937c0a2fdc969329@46958_oswg44843oswg1080oswg314_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与其他开源模型相比性能有竞争力，且速度快1.5-3.3倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_75140db87e844e06a9a33736dded2ded@46958_oswg99627oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>把Mamba和Transformer混着用</strong></h2>
  <p>Nemotron 3在架构层面追求推理效率的最大化。</p>
  <p>传统Transformer的自注意力机制需要对不断增长的KV Cache做线性扫描，序列越长，计算开销越大。</p>
  <p>英伟达的解决方案是大量使用Mamba-2层替代自注意力层——Mamba层在生成时只需要存储固定大小的状态，不受序列长度影响。</p>
  <p>以Nano型号为例，整个模型主要由交替堆叠的Mamba-2层和MoE层构成，自注意力层只保留了少数几个。</p>
  <p>论文给出的层排布模式是：5个Mamba-2+MoE的重复单元，接3个同样结构的单元，再来1个包含注意力层的单元，最后是4个Mamba-2+MoE单元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a7170bbc299a472aa074cc3c0d603faa@46958_oswg110094oswg1080oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在8k输入、16k输出的典型推理场景下，Nemotron 3 Nano 30B-A3B的吞吐量是Qwen3-30B-A3B的3.3倍。序列越长，优势越明显。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_c6fe663ab3ba43f8ad4fa6d2755bd8ca@46958_oswg84148oswg1080oswg416_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与此同时，模型在长上下文任务上的表现并没有打折扣。</p>
  <p>论文展示了一组RULER基准测试的结果：在100万token输入长度下，Nemotron 3 Nano基座模型拿到了68.2分，而在同样条件下训练的Nemotron 2 Nano 12B只有23.43分，出现了断崖式下跌。MoE混合架构在长度外推上的鲁棒性明显更好。</p>
  <h2><strong>LatentMoE：在潜空间里做专家路由</strong></h2>
  <p>针对Super和Ultra这两个更大的模型，英伟达提出了LatentMoE架构，在潜在空间中进行专家计算。</p>
  <p>MoE层在实际部署时会遇到两类瓶颈：</p>
  <p>低延迟场景下，每次只处理几十到几百个token，此时从显存读取专家权重成为主要开销。</p>
  <p>高吞吐场景下，一次处理数千token，此时专家间的all-to-all通信成为瓶颈。两种情况下，开销都与隐藏维度d线性相关。</p>
  <p>LatentMoE的做法是：先把token从原始隐藏维度d投影到一个更小的潜在维度ℓ（通常是d的四分之一），在这个低维空间里完成专家路由和计算，最后再投影回原始维度。</p>
  <p>这样一来，每个专家的权重加载量和通信量都降低了d/ℓ倍。省下来的计算预算被用于增加专家数量和每个token激活的专家数。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_71b718346772464cb0d7f122c84dfb6b@46958_oswg173033oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>标准MoE用128个专家、激活6个；LatentMoE用512个专家、激活22个。</p>
  <p>两者的总参数量和激活参数量几乎相同（都是8B激活、73B总参），但LatentMoE在所有下游任务上都取得了更好的成绩——MMLU-Pro从48.30提升到52.87，代码任务从51.95提升到55.14，数学任务从78.32提升到80.19。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_970b977841cc4b5ca159ca8d6541f587@46958_oswg50034oswg1080oswg384_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>需要注意的是，路由门控网络、共享专家计算以及非专家层仍然保留在原始维度，因为这些部分对瓶颈的贡献很小。</p>
  <h2><strong>用NVFP4训练250亿token</strong></h2>
  <p>Super和Ultra还采用了NVFP4格式进行训练，这是英伟达在低精度训练上的又一次探索。</p>
  <p>NVFP4是一种4位浮点格式，采用E2M1的元素格式（2位指数、1位尾数），配合16元素的微块缩放和E4M3格式的块缩放因子。在GB300上，FP4的峰值吞吐量是FP8的3倍。</p>
  <p>论文显示，团队已经用NVFP4格式稳定训练了高达25万亿token。与BF16训练相比，Nano模型的损失差距控制在1%以内，8B激活参数的更大模型差距进一步缩小到0.6%以内。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2776ac307b0140a99cda5bffbc1a532b@46958_oswg139016oswg1080oswg391_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在MMLU、GSM8K、HumanEval等下游任务上，NVFP4训练的模型与BF16版本的准确率曲线几乎完全重合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_74938f43584d408d8dbe38e237d3512c@46958_oswg174134oswg1080oswg549_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过并非所有层都适合量化到NVFP4。团队发现Mamba输出投影层在量化后会出现高达40%的flush-to-zero现象，因此保留在MXFP8精度；QKV投影和注意力投影保留在BF16以维持少量注意力层的保真度；网络最后15%的层也保持高精度以确保稳定性。MTP层和潜在投影由于对推理时间影响很小，同样保留在BF16。</p>
  <h2><strong>多环境强化学习一把训到底</strong></h2>
  <p>Nemotron 3的后训练采用了多环境强化学习，覆盖数学推理、竞赛编程、指令遵循、软件工程、搜索、对话、通用工具使用、长上下文等多种任务。</p>
  <p>与之前分阶段训练不同能力的做法不同，这次英伟达选择同时训练所有任务。</p>
  <p>论文指出，这种同步训练方式更稳定，更不容易出现reward hacking，也避免了分阶段训练常见的能力退化问题。</p>
  <p>AIME25数学分数从80提升到90，LiveCodeBench从65提升到72，τ²-Bench工具使用从40提升到50左右，全程呈稳定上升趋势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_4fe407b2e0644e028a470b70e88b5053@46958_oswg199909oswg1080oswg441_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>高效的推理吞吐量在这里发挥了重要作用。</p>
  <p>大规模RL需要生成海量rollout样本，Nemotron 3的混合架构相比其他开源模型有显著优势。</p>
  <p>团队还采用了异步RL架构来解耦训练和推理，并利用多token预测加速rollout生成。训练算法方面使用GRPO配合masked importance sampling来处理训练策略和rollout策略之间的差异。</p>
  <p>整个后训练软件栈以Apache 2.0协议开源，包括NeMo-RL（可扩展RL训练）和NeMo-Gym（RL环境集合）两个仓库。</p>
  <p>此外，Nemotron 3还支持推理时的思维预算控制。</p>
  <p>用户可以指定思维链的最大token数，当模型达到预算时，追加一个标记即可让模型基于部分思维链生成最终回答。</p>
  <p>论文给出了准确率与平均生成token数之间的权衡曲线，这为实际部署中的效率-精度平衡提供了细粒度控制。</p>
  <p>论文地址：https://arxiv.org/abs/2512.20856</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/OEtDlmYgkD37DzAEdtR5nQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：梦晨，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612292341449730</id>
            <title>2025年，这十个科技突破再次革新我们对世界的认知</title>
            <link>https://www.36kr.com/p/3612292341449730</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612292341449730</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:49:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_58904d08801148e28a7220bea7e8bedd@46958_oswg37573oswg640oswg364_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：界面图库</p>
  <p>2025年，是联合国教科文组织定义的“国际量子科学与技术年”，也是我国“十五五”规划承前启后的时段。</p>
  <p>在这一年，计算范式更迭。“DeepSeek时刻”带来的“Aha Moment”让我们反思算力，量子计算的技术突破层出不穷；从诺贝尔物理学奖到硬科技的产业界，这个世界似乎正在挥别那个堆砌晶体管数量的时代。</p>
  <p>材料不断翻新，继而重塑着我们对于物质世界的感知：脑机芯片滑入大脑皮层，空芯光纤刷新长距离通信，金属材料挤压至埃米级的“二维”世界，μ子的理论模型与现实世界精确耦合，抽象的物质极限正被技术一一兑现。</p>
  <p>人类生存的图景也随之摇身一变。这一年，钢材首度达到“近零排放”阈值，中国“人造太阳”得以预演核聚变堆运行的未来，贝努小行星的样本则直指地球的过去，人类文明的生存坐标正被重新校准。</p>
  <p><strong>以下是界面新闻盘点的2025年度十大科学技术突破。</strong></p>
  <h2><strong>DeepSeek-R1：大模型的“中国方案”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_cd7e9e38f15047b2966f29674529f111@46958_oswg20769oswg580oswg330_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>深度求索（DeepSeek）在2025年1月20日发布的DeepSeek-R1模型，基于Deep Seek-V3的基础模型，以强化学习为核心驱动训练推理能力，并免费开源。</p>
  <p>该模型在o1类推理模型的基础上，更多地依赖“强化学习”，模型使用为自己创建和调整的奖励系统，从自身行动中获得反馈。在Math-500等基准测试中，R1以极低的算力成本实现了媲美OpenAI o1的推理能力。Nature杂志将DeepSeek创始人梁文锋列为2025年度十大人物，评价其“让复杂的逻辑推理变得触手可及”。</p>
  <h2><strong>超导量子电路与宏观量子隧穿：确证量子科技基石</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a96d41f125b94295b77e55bfe48cf3ec@46958_oswg443767oswg566oswg566_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>10月，诺贝尔物理学奖花落量子科技，表彰了超导量子电路技术为现代计算变革奠定的宏观基石。John Clarke、Michel H. Devoret与John M. Martinis因在上世纪80年代利用含约瑟夫森结的电路，首次观测到宏观量子隧穿与能级离散而获此殊荣。</p>
  <p>这一发现打破了经典与量子世界的传统界限，证明了由数亿原子组成的宏观电路系统也能像微观粒子一样被精确操控。该突破催生了“人造原子”与超导量子比特（Qubit），构成了今日谷歌、IBM等科技巨头构建量子计算的物理学原点。</p>
  <h2><strong>通用量子计算机Helios：高精度量子计算叩响商用大门</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_326b736f645e4fd79cf617f60fba94be@46958_oswg62460oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为量子计算领域离子阱路线的领军企业，Quantinuum于11月5日发布了第三代量子计算机Helios。Helios包含98个物理量子比特，单量子比特门操作的保真度达到 99.9975%，双量子比特门操作的保真度在所有量子比特对之间平均为99.921%，并能提供48个经过纠错的逻辑量子比特，是目前全球精度最高的通用商用量子计算机。</p>
  <p>Helios实现了接近2：1的物理-逻辑比特转换率（远高于行业平均的几十甚至上百比一）被加州大学洛杉矶分校教授Prineha Narang评价为“独特且令人印象深刻”。 配合其研发的Guppy编程语言，Helios的问世或标志着量子计算开始真正具备解决商业问题的能力。</p>
  <h2><strong>超薄高带宽脑机接口BISC芯片：给大脑植入“无线宽带”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ff0f3b9d5be243ef976549671aa470fa@46958_oswg155723oswg1080oswg396_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>哥伦比亚大学联合斯坦福等团队于12月8日发布的BISC芯片，为人类大脑植入了前所未有的“无线数字宽带”。该成果发布于国际权威期刊Nature Electronics，通过将65536个电极、电源及射频模块极致集成于一枚厚度仅50µm、体积3mm³的柔性CMOS芯片上，彻底颠覆了传统脑机接口的物理形态。</p>
  <p>该芯片能如贴纸般滑入大脑皮层表面，并通过体外中继站建立UWB链路，实现高达100Mbps的数据吞吐量。这一飞跃不仅解决了高分辨率信号无法实时传输的痛点，更将海量神经数据直接送入AI模型，为全植入式癫痫监测、高自由度神经假肢及双向脑机交互提供了核心数据通道。</p>
  <h2><strong>新型空芯光纤：刷新信号传输损耗纪录</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_aae6b92bb1474460a84218f7769841fe@46958_oswg247759oswg1080oswg401_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由微软支持的Lumenisity研究团队宣布其发现了一种具备前所未有的传输带宽和超低衰减性能的微结构光波导。成果于9月1日发布在国际权威学术期刊Nature Photonics上，这种新型空芯光纤在1550nm波长（通信常用波段）下的实测损耗仅为0.091dB/km，且在长达66THz的频宽窗口内，损耗均保持在 0.2 dB/km 以下。</p>
  <p>与传统的实心玻璃纤芯不同，这种创新光纤采用“空气纤芯”，通过周围精心设计的玻璃微结构来引导光线传输。此外，该技术在理论上仍有进一步降低损耗的空间，并支持在拥有更宽带放大器的波段下工作，标志着长距离通信及高能激光远程传输领域有望迎来一个新的时代。</p>
  <h2><strong>“埃米级”二维金属制备术：对金属原子的“降维打击”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ba125dd9545e48469b05792fa2c5e941@46958_oswg188083oswg1080oswg257_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>3月，中国科学院物理研究所张广宇团队发表在国际权威期刊Nature上的论文显示，其开发了一种“原子制造的范德华挤压法”，将金属材料厚度推向了埃米（Å）级极限，约为头发丝直径的二十万分之一。针对单层铋（Bi）的输运和拉曼测量显示，其具有优异的物理性能，例如全新的声子模式、增强的电导率、显著的场效应以及巨大的非线性霍尔电导率。</p>
  <p>原子级薄的二维金属曾长期被学界认为是“不可能完成的任务”，这一工作为实现二维金属、合金以及其他二维非范德华材料建立了一条有效途径，为广泛的新兴量子器件、电子器件和光子器件提供应用前景。</p>
  <h2><strong>μ子g-2实验高精度结果：标准模型暂时屹立不倒</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1faa0b75d6234c8a93ea6b224a9f6e84@46958_oswg200187oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>6月，备受期待的费米国家加速器实验室（FNAL） μ 子 g-2 实验最终结果公布，其测得的 μ 子异常磁矩与修正后的理论预测完全吻合。最新的测量结果与2021年及2023年发布的结果高度一致，更将测量精度提升至前所未有的127ppb（一千万分之一点二七），超越实验最初设定的目标（一千万分之一点四），给出了当前最精确的μ子反常磁矩测量结果。</p>
  <p>尽管理论计算的最新结果削弱了μ子反常磁矩中可能存在的“新迹象”，但此次实验的高精度结果可为未来标准模型的扩展提供基准；标准模型又挺过了一项挑战。</p>
  <h2><strong>近零碳排放绿色钢铁 SSAB Zero™：更可持续的能源经济先声</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_d69d6bcb1e9f492a8527caa20f704199@46958_oswg147422oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>9月23日，瑞典钢铁巨头SSAB宣布其SSAB Zero™钢材成为首个达到国际能源署（IEA）近零排放阈值并满足“先行者联盟”（FMC）采购标准的产品。依托美国爱荷华工厂，该产品融合无化石电力、生物质能源与HYBRIT®技术路线的氢还原铁，从化学反应根源斩断了碳排放。</p>
  <p>GE Vernova（通用电气能源业务分拆后成立的独立公司）当日宣布将其即刻引入陆上风电塔筒供应链，这标志着“绿氢+绿电”冶炼模式已正式跨越概念验证鸿沟，为全球能源基建提供了首个可规模化复制、具有清晰减排路径的绿色范本。</p>
  <h2><strong>中国“人造太阳”EAST：创造“亿度千秒”世界纪录</strong></h2>
  <p>1月20日，位于安徽合肥的全超导托卡马克核聚变实验装置（EAST）首次实现1亿摄氏度1066秒稳态长脉冲高约束模等离子体运行，再次创造了托卡马克装置稳态高约束模运行新的世界纪录。</p>
  <p>千秒量级是聚变反应实现稳定的重要基础。但运行时间越长，约束等离子体的难度就越高。此次实验超越千秒，意味着人类首次在实验装置上模拟出未来聚变堆运行所需的条件，验证了聚变的工程可行性。</p>
  <h2><strong>小行星贝努含有生命物质：探秘前生命时期的地球</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_f51745480c2e46e1874a6837bf8bb66d@46958_oswg100721oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此前，Nature与Nature Astronomy刊登的多项重磅研究揭晓了NASA OSIRIS-REx任务带回的贝努（Bennu）小行星样本的深度分析结果。科学家在其中检测到了构建生命所需的14种氨基酸、核碱基及含钠磷酸盐。</p>
  <p>日本东北大学发布于权威期刊Nature Geoscience 12月的最新研究显示，在OSIRIS-REx 航天器采集的贝努样本的提取物中鉴定出多种生物必需的糖类，包括核糖（RNA 的糖组分）和葡萄糖（代谢底物）。这些糖类的发现补全了生命关键成分的清单，表明包含生命所需全部三大组分的物质，可能已经被散播到了前生命时期的地球及其他内太阳系行星上。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_ofr6n0e5QmfkceHVM07UQ" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，作者：周末&nbsp;林鑫龙，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612257773487113</id>
            <title>训练时间爆砍80%，港大快手联合打造了一个AI炼金师：专挑“有营养”数据，20%数据达成50%效果</title>
            <link>https://www.36kr.com/p/3612257773487113</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612257773487113</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 11:48:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>想象一下，如果让一个大厨用发霉的食材、过期的调料来做菜，即使厨艺再高超，也做不出美味佳肴。AI训练也是同样的道理。</p>
  <h2><strong>一、数据就像食材，质量决定成品</strong></h2>
  <p>现在的AI图像生成模型，如Stable Diffusion、FLUX等，需要从网络上爬取数百万张图片来学习。但这些图片质量参差不齐：有些模糊不清，有些内容重复，有些甚至只是广告背景图。用这些“食材”训练出来的AI，自然效果不佳。</p>
  <p>由香港大学丁凯欣领导，联合华南理工大学周洋以及快手科技Kling团队共同完成的这项研究，开发出了一个名为“炼金师”（Alchemist）的AI系统。它就像一位挑剔的大厨，能从海量图片数据中精准挑选出最有价值的一半。</p>
  <p><strong>更让人惊喜的是：</strong></p>
  <ul>
   <li>用这一半精选数据训练出的模型，竟然比用全部数据训练的表现还要好</li>
   <li>训练速度快了 <strong>5倍</strong></li>
   <li>只用20%的精选数据，就能达到50%随机数据的效果</li>
  </ul>
  <h2><strong>二、让AI学会“自我评判”</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2a8f2af8d49649d6a50e35a2ef94a99c@46958_oswg220281oswg830oswg373_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>2.1 传统方法的局限</strong></h3>
  <p>传统的数据筛选方法就像用筛子筛米粒，只能按照单一标准过滤：</p>
  <ul>
   <li>只看图片清晰度</li>
   <li>只看文字匹配度</li>
   <li>只看美学评分</li>
  </ul>
  <p>这些方法的问题在于：<strong>它们不知道哪些数据真正有助于AI学习</strong>。</p>
  <h3><strong>2.2 炼金师的智慧</strong></h3>
  <p>“炼金师”更像是一位经验丰富的美食评委，它能同时考虑多个维度：</p>
  <ul>
   <li>不仅看“菜品”的卖相</li>
   <li>还要品尝口感</li>
   <li>甚至考虑营养搭配</li>
  </ul>
  <p>核心思想：让AI学会观察自己的学习过程</p>
  <p>炼金师训练了一个专门的<strong>评分员模型</strong>，这个评分员就像资深的艺术老师，能够判断每张图片对整个学习过程的价值。</p>
  <p><strong>评判标准：</strong></p>
  <p>✅如果一张图片能让AI模型学到新知识并快速改进→<strong>好数据</strong></p>
  <p>❌如果一张图片让模型学了半天也没什么进步→<strong>无用数据</strong></p>
  <p>这就像观察学生做习题时的表情和进步速度，来判断这道题是否适合他们。</p>
  <h2><strong>三、最简单的不一定最好</strong></h2>
  <h3><strong>3.1 意外的真相</strong></h3>
  <p>研究团队发现了一个<strong>违反直觉</strong>的现象：</p>
  <p><strong>那些看起来最“简单”的图片，比如纯白背景的产品图：</strong></p>
  <ul>
   <li>虽然能让AI快速收敛</li>
   <li>但对提升模型能力帮助不大</li>
   <li>就像一直做最简单的加法题，虽然不会出错，但对提升数学能力没有帮助</li>
  </ul>
  <p><strong>相反，内容丰富、稍有挑战性的图片，才是真正的“营养品”</strong></p>
  <h3><strong>3.2 科学验证</strong></h3>
  <p>研究团队追踪了不同评分区间图片的训练动态：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_0435cbd5d9b240e4a770009171340872@46958_oswg56688oswg876oswg224_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_15ac75eef80541ed97fb0e2411909bde@46958_oswg179651oswg830oswg437_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>四、技术亮点：偏移高斯采样策略</strong></h2>
  <p>基于上述发现，团队提出了“偏移高斯采样”（Shift-Gsample）策略。</p>
  <h3><strong>4.1 传统方法vs炼金师</strong></h3>
  <p><strong>传统Top-K方法：</strong></p>
  <ul>
   <li>简单选择评分最高的数据</li>
   <li>❌但这些数据往往过于简单，缺乏营养</li>
  </ul>
  <p><strong>炼金师策略：</strong></p>
  <ul>
   <li>✅避开评分过高的“简单”数据</li>
   <li>✅重点选择中等偏上评分的“有营养”数据</li>
   <li>✅保留少量简单和困难样本，维持数据多样性</li>
  </ul>
  <p>这就像制定健身计划：</p>
  <ul>
   <li>❌不选择过于轻松的运动 （没有锻炼效果）</li>
   <li>❌不选择过于困难的运动 （容易受伤）</li>
  </ul>
  <h3><strong>4.2 多粒度感知机制</strong></h3>
  <p>为了更好地评估数据质量，炼金师还设计了<strong>“多粒度感知”</strong>机制：</p>
  <ul>
   <li><strong>个体层面：评估单张图片的质量</strong></li>
   <li><strong>群体层面：考虑整批数据的搭配</strong></li>
  </ul>
  <p>就像营养师不仅关注单个食材的营养价值，还要考虑整餐的营养搭配。</p>
  <h2><strong>五、实验结果：数据说话</strong></h2>
  <h3><strong>5.1 主要成果对比</strong></h3>
  <p><strong>在LAION-30M数据集上：</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_068baadd81454c29b0e23ca8d0ce0c56@46958_oswg73006oswg870oswg266_img_png?x-oss-process=image/quality,q_100/format,jpg/interlace,1" /></p>
  <p><strong>关键发现：</strong></p>
  <ul>
   <li>用50%精选数据超越100%全量数据</li>
   <li>用20%精选数据达到50%随机数据效果</li>
   <li>训练速度提升 <strong>5倍</strong></li>
  </ul>
  <h3><strong>5.2 跨模型通用性</strong></h3>
  <p>炼金师在不同规模、不同架构的模型上都有效：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2e804e85a21940ddbaa51ee0265f5acd@46958_oswg209753oswg625oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>5.3 跨数据集适应性</strong></h3>
  <p>在不同类型数据集上的表现：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_e4adbe9df18d4b208db9742bc4f527d6@46958_oswg131914oswg621oswg331_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>HPDv3-2M数据集</strong>（真实+合成混合）：</p>
  <ul>
   <li>20%保留率：FID从35.55→ <strong>32.27</strong> ✅</li>
   <li>50%保留率：FID从20.21→ <strong>18.15</strong> ✅</li>
  </ul>
  <p><strong>Flux-reason-6M数据集</strong>（纯合成推理数据）：</p>
  <ul>
   <li>20%保留率：FID从23.66→ <strong>22.78</strong> ✅</li>
   <li>50%保留率：FID从19.35→ <strong>18.59</strong> ✅</li>
  </ul>
  <h2><strong>六、可视化分析：眼见为实</strong></h2>
  <h3><strong>6.1 数据分布特征</strong></h3>
  <p>研究团队对筛选后的数据进行了可视化分析：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_939932f1543e4c5ca595899ca21c7657@46958_oswg444323oswg647oswg361_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>0-20%高分区域</strong>（简单但营养不足）：</p>
  <ul>
   <li>白色或纯色背景</li>
   <li>简洁的产品图</li>
   <li>视觉干净但信息量有限</li>
  </ul>
  <p><strong>30-80%中分区域</strong>（最有价值的“金中间”）：</p>
  <ul>
   <li>内容丰富</li>
   <li>主题明确</li>
   <li>动作清晰</li>
   <li><strong>炼金师重点选择区域</strong>⭐</li>
  </ul>
  <p><strong>80-100%低分区域</strong>（过于混乱）：</p>
  <ul>
   <li>噪声图片</li>
   <li>多对象混乱场景</li>
   <li>视觉密集区域</li>
   <li>内容不清晰</li>
  </ul>
  <h3><strong>6.2 训练动态对比</strong></h3>
  <p><strong>训练稳定性对比：</strong></p>
  <p>炼金师选择的数据展现出：</p>
  <p>✅稳定持续的性能提升</p>
  <p>✅更快的收敛速度</p>
  <p>✅更少的训练波动</p>
  <p>随机选择的数据则表现出：</p>
  <p>❌早期训练波动大</p>
  <p>❌性能提升缓慢</p>
  <p>❌需要更多epochs才能收敛</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7921a2288bd841a594411ce3661c20b6@46958_oswg229315oswg366oswg840_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>七、技术深度：元梯度优化框架</strong></h2>
  <h3><strong>7.1 双层优化问题</strong></h3>
  <p>炼金师的核心是一个<strong>双层优化框架</strong></p>
  <p><strong>外层优化</strong>：学习如何评分</p>
  <ul>
   <li>目标：找到最优的评分策略</li>
   <li>评判标准：验证集上的性能</li>
  </ul>
  <p><strong>内层优化</strong>：训练代理模型</p>
  <ul>
   <li>目标：用加权数据训练模型</li>
   <li>权重由评分器决定</li>
  </ul>
  <h3><strong>7.2 元梯度更新机制</strong></h3>
  <ul>
   <li>系统通过观察两个模型的表现差异来更新评分：</li>
   <li>评分更新∝代理模型的验证集损失</li>
  </ul>
  <p><strong>核心思想：</strong></p>
  <p>如果一个样本让验证性能提升→提高其评分</p>
  <p>如果一个样本只降低训练损失但不提升验证性能→降低其评分</p>
  <h2><strong>八、Q&amp;A环节</strong></h2>
  <h3><strong>Q1：炼金师如何判断哪些图片数据更有价值?</strong></h3>
  <p><strong>A：</strong>炼金师通过观察AI模型在学习过程中的“反应”来判断数据价值：</p>
  <p>✅好数据：能让模型学到新知识并快速改进</p>
  <p>❌差数据：让模型学了半天也没进步</p>
  <p>这就像观察学生做题时的表情和进步速度，来判断题目是否合适。</p>
  <p><strong>技术细节</strong>：</p>
  <ul>
   <li>监控训练损失变化</li>
   <li>追踪梯度动态</li>
   <li>对比验证集性能提升</li>
  </ul>
  <h3><strong>Q2： 为什么用一半数据训练出的模型比用全部数据还要好?</strong></h3>
  <p><strong>A：</strong>因为<strong>并非所有数据都有价值</strong>，关键在于质量而非数量。</p>
  <p><strong>类比说明：</strong></p>
  <ul>
   <li>教孩子画画时，精选5000张优质作品</li>
   <li>比给他看10000张杂乱涂鸦更有效</li>
  </ul>
  <p><strong>科学原理：</strong></p>
  <p><strong>1.冗余数据消耗资源但不提升性能</strong>：如重复的简单样本、模糊不清的噪声图片</p>
  <p><strong>2. 有营养的数据促进真实学习</strong>：如内容丰富的中等难度样本、多样化的场景和对象</p>
  <p><strong>3. 避免过拟合</strong>：若只用简单数据会导致模型“死记硬背”，还应使用适当难度的数据培养泛化能力</p>
  <h3><strong>Q3： 炼金师的数据筛选方法能在其他AI模型上使用吗?</strong></h3>
  <p><strong>A：</strong>可以！研究显示这种方法具有<strong>良好的通用性和跨模型适用性</strong>。</p>
  <p><strong>验证范围：</strong></p>
  <p>✅不同数据类型：</p>
  <ul>
   <li>网络爬取数据 （LAION）</li>
   <li>高质量合成数据 （Flux-reason）</li>
   <li>人类偏好标注数据 （HPDv3）</li>
  </ul>
  <p>✅不同模型架构：</p>
  <ul>
   <li>STAR系列 （40M→0.9B参数）</li>
   <li>FLUX系列 （3B参数）</li>
   <li>从头训练 vs LoRA微调</li>
  </ul>
  <p>✅不同模型规模：</p>
  <ul>
   <li>用小模型 （0.3B） 筛选数据</li>
   <li>成功提升大模型 （0.9B） 性能</li>
   <li>评分成本可忽略不计</li>
  </ul>
  <p><strong>原理：</strong></p>
  <p>数据质量是本质属性，不依赖特定模型</p>
  <p>就像好食材适合各种烹饪方法</p>
  <p>经验丰富的教练选择的训练方法，既适合业余选手也适合专业选手&nbsp;</p>
  <p><strong>Project Page：</strong>https://kxding.github.io/project/Alchemist/</p>
  <p><strong>Github：</strong>https://github.com/KlingTeam/Alchemist/</p>
  <p><strong>arXiv：</strong>https://arxiv.org/abs/2512.16905</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/vMhEjEXbX9PTtziGumP_AQ" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：Alchemist团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612177250660866</id>
            <title>宁德时代再签大单，32只锂电概念股“蠢蠢欲动”</title>
            <link>https://www.36kr.com/p/3612177250660866</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612177250660866</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:54:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，锂电池板块热度持续攀升。</p>
  <p>消息面上，宁德时代与韩国电解液制造商Enchem签订5年大单，合同规模约达1.5万亿韩元，约合72.68亿元人民币，是Enchem成立以来最大规模的单一客户订单。</p>
  <p>12月26日早盘，碳酸锂主力合约盘中强势突破13万关口，一度涨超8%，创2023年11月以来新高。</p>
  <h2><strong>头部厂商持续斩获大单</strong></h2>
  <p>随着全球能源转型加速，锂电池产业正经历从规模扩张到质量提升的关键转折期。</p>
  <p>行业层面，截至2025年，全球已有超过130个国家提出碳中和目标，动力电池作为交通电动化核心，储能电池作为可再生能源规模化利用关键，迎来确定性增长。国际能源署（IEA）预测，到2030年全球电动汽车保有量将突破3亿辆，配套动力电池需求将超过3,000GWh，年均复合增长率保持在25%以上。</p>
  <p>技术层面，过去十年，锂电池成本下降近90%，能量密度提升超三倍。行业共识认为，2026-2030年锂电池成本仍有20%-30%下降空间，主要通过材料创新、工艺优化和规模效应实现。同时，钠离子电池、固态电池等下一代技术将在2027年后逐步进入商业化导入期，开启新一轮技术竞赛。</p>
  <p>中研普华产业研究院报告显示，2025年全球锂电池市场规模预计超过1.2万亿元人民币，其中动力电池占比约70%，储能电池占比快速提升至20%以上。</p>
  <p>从整体电池产业来看，国金证券认为，锂电供给确立穿越过剩周期，库存周期结束两年去库阶段，正式转入“主动补库”的繁荣期，基本面呈现2024年触底、2026年有望明显复苏。随着头部企业稼动率打满，行业由“内卷价格战”转向“联合挺价”，推动价格触底回升，产业链利润分配正向具备高壁垒、高集中度的上游“硬瓶颈”材料环节转移，最终实现全行业的量利双升。</p>
  <p>今年以来，锂电产业链大单呈爆发状态。以宁德时代为例，公开数据显示，公司年内已拿下300GWh以上储能订单，相比2024年93GWh的储能系统出货量，已翻至少3番。2021-2024年，宁德时代已连续4年储能电池出货量位居全球第一。</p>
  <p>市场最新消息显示，宁德时代旗下的江西枧下窝锂矿将在2026年2月农历新年后全面恢复运营。宜春市作为“亚洲锂都”，拥有丰富的锂云母资源。枧下窝矿区的供应能力直接关系到宁德时代乃至全球新能源汽车的供应链稳定。</p>
  <p>其他锂电池巨头如亿纬锂能、国轩高科、中创新航等相继披露了大额采购协议，涵盖磷酸铁锂、正负极材料、电解液、铜箔、隔膜等关键环节，这些订单动辄数十亿甚至数百亿元，协议期限多为3至5年。</p>
  <p>11月底，龙蟠科技与楚能新能源签署补充协议，约定2025年至2030年采购130万吨正极材料，以当时市场价估算合同总金额高达450亿元。</p>
  <h2><strong>年内已诞生6只翻倍股</strong></h2>
  <p>同花顺数据显示，根据申万三级行业分类，A股锂电池板块一共有31家上市公司。</p>
  <p>从地域分布看，广东省11家，占比35.5%；江苏省4家，占比12.9%；浙江省 3家，占比9.7%；安徽省、湖北省、江西省各有2家；福建省、湖南省、吉林省、辽宁省、上海市、四川省、重庆市各有1家。</p>
  <p>从业绩表现看，2025年前三季度，上述31家上市公司营收合计为5168.87亿元，同比增长14.24%；净利润合计为592.81亿元，同比增长39.23%。其中，有28家公司的净利润为正，占比90.3%；有26家公司营收同比增长，占比为83.9%。</p>
  <p>其中，宁德时代的营收和净利润在31家公司中均稳居第一。前三季度，宁德时代实现营收2830.72亿元，同比增加9.28%；归属于上市公司股东的净利润490.34亿元，同比增加36.20%。</p>
  <p>从二级市场表现看，截至12月25日收盘，今年以来，一共29家上市公司年内股价实现上涨。其中，涨幅超过50%的有15家公司。</p>
  <p>铜冠铜箔（301217.SZ）、德福科技（301511.SZ）、嘉元科技（688388.SH）、震裕科技（300953.SZ）、天宏锂电（920252.BJ）、鹏辉能源（300438.SZ）6家公司年内股价已经成功实现翻倍。</p>
  <p>12月23日，震裕科技公告称，公司拟向不特定对象发行可转换公司债券，募集资金总额不超过18.8亿元，用于锂电池精密结构件扩产项目、人形机器人精密模组及零部件产业化项目（一期）、电机铁芯扩产项目（一期）以及补充流动资金。其中，锂电池精密结构件扩产项目计划总投资10.38亿元，拟使用募集资金7.52亿元。</p>
  <p>公开资料显示，震裕科技主营业务涵盖精密级进冲压模具、电机铁芯、锂电池精密结构件等，产品广泛应用于家电、新能源锂电池、汽车等领域，合作客户包含多个行业头部企业。2025年前三季度，公司锂电池结构件实现收入超过42亿元，同比增长接近50%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_1963b794ed41491a9665a05aed98c8ab@5727534_oswg104958oswg617oswg729_img_jpg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>本文来自微信公众号“览富财经网”，作者：览富财经网，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612218491438088</id>
            <title>金属暴涨潮下投资众生相：有人惊险解套、有人暴赚200%，牛市还能追吗？</title>
            <link>https://www.36kr.com/p/3612218491438088</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612218491438088</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:53:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“金价还在涨，我真的看不懂了。”电话那头，黄金投资者徐雨的声音带着一丝困惑与庆幸。今年10月入场的她，刚刚经历了从亏损到回本、再到小赚1000元的过山车行情。</p>
  <p>12月25日圣诞节，全球贵金属市场休市。就在前一日，现货黄金价格首次突破每盎司4500美元大关，盘中最高触及4525.83美元/盎司。至此，黄金年内涨幅已超过70%。</p>
  <p>这不是黄金的独角戏，一场全面而猛烈的贵金属牛市正以雷霆之势席卷全球。白银、铂金、钯金同步狂飙，年内涨幅均超100%。</p>
  <p>12月24日，白银首次站上72美元/盎司，铂金突破2377美元/盎司，钯金逼近1960美元/盎司，最高纪录不断被改写。Wind数据显示，按当天最高价计算，年内白银、铂金、钯金的涨幅分别高达惊人的151.61%、163.05%和115.72%。</p>
  <p>南开大学金融发展研究院院长田利辉对时代周报记者分析称，本轮贵金属集体走强，核心在于“三重共振”：一是美联储降息周期开启，美元指数回落，美元资产吸引力下降；二是地缘政治风险持续发酵，中东局势、俄乌冲突等导致避险需求激增；三是全球去美元化加速，多国央行持续购金，中国、印度等国央行购金量创历史新高。</p>
  <p>然而，面对历史高位，投资者心态分化：有人回本后选择观望，有人坚定长持不动，也有人凭借杠杆实现翻倍收益。盛宴之下，是继续追高，还是落袋为安？</p>
  <h2><strong>金价“狂飙”，投资者心态分化</strong></h2>
  <p>12月24日，现货黄金在创下4525.83美元/盎司新高后回落，收盘报4479.42美元/盎司。COMEX黄金期货亦在触及4555.10美元/盎司后收于4505.40美元/盎司。</p>
  <p>中信期货分析指出，金价冲高回落受美国超预期GDP数据带动美元反弹影响，但地缘风险、央行购金及降息预期将持续支撑，下行空间有限。</p>
  <p>机构对前景颇为乐观。高盛预计，到2026年12月金价将涨至4900美元/盎司；摩根大通则认为，中国保险巨头的新需求可能推动金价在2026年底触及5055美元/盎司。</p>
  <p>国内金饰价格随之水涨船高，周大福、周生生等品牌足金饰品报价一度突破1400元/克。</p>
  <p>12月25日，周大福、周生生等多家品牌金饰价格回落至1395-1398元/克左右，较前一日单克价下滑约12-16元。其中周大福、六福珠宝、老凤祥、潮宏基、谢瑞麟、金至尊等品牌足金金饰价格报1398元/克，周生生、老庙黄金报1397元/克，周六福报1395元/克，菜百首饰报1360元/克，中国黄金报1300元/克。</p>
  <p>临近年末，时代周报记者注意到，在北京朝阳合生汇，周六福、周大福、菜百首饰、周生生、中国黄金、老庙黄金、潮宏基等品牌推出克减130元的活动，部分货品低至5折。</p>
  <p>不同商场门店优惠力度也不同，中国黄金通州万达门店销售人员告诉时代周报记者：“目前正在做圣诞和元旦的活动，优惠力度是克减120元，一口价商品打八折，老顾客可以打七五折。”此外，中国黄金华贸门店销售人员告诉时代周报记者，当前该门店的优惠力度是克减150元。</p>
  <p>面对一路高涨的黄金饰品价格，大多数消费者望而却步。与此相比，黄金投资者的心态却呈现出较大分化。</p>
  <p>“从今年10月开始投资黄金，正赶上黄金牛市”。北京00后徐雨告诉时代周报记者，她主要购买黄金ETF，“因为买入方便，可以每天看到收益损失”。</p>
  <p>十月初入市的她，刚进场就经历了市场剧烈波动，“之前投了2万，因为10月底开始的波动亏损后撤出了一部分，现在只剩1万多。黄金最近大涨，我刚回本，还赚了1000块”。面对金价新高，徐雨选择暂停投入，保持观望，“波动太大，不落袋为安也不敢说真赚了”。</p>
  <p>与徐雨不同，魏灵的投资策略则显得更为稳健。她自2022年起为抵御通胀开始购金，主要投资实物金条与首饰。“2024年买的100克，成本约每克680元，现在已经赚了3万元左右。”魏灵表示。</p>
  <p>目前，魏灵在黄金投资方面已投入约20万元，占其总资产20%。尽管10月份时以每克979元购入的50克一度亏损，但近期大涨已让其回本。“选择持有，不关注短期因素。黄金的货币属性决定其长期（以十年计）总是上涨的。”她表示。</p>
  <p>李娜的投资组合更为多元，包括积存金、首饰和投资金条。“从前年开始投资，最初开始买黄金是因为喜欢戴黄金首饰”。目前，她总共投入约10万元，占个人总资产的40%左右。</p>
  <p>“其实不应该占比这么高，风险太大了。”李娜表示，目前的收益率约40%，都卖出去的话，能赚四万元左右。</p>
  <p>面对高位，她采取“部分获利了结+持有底仓+回调加仓”的灵活策略。“已将短期获利部分约30%仓位减仓锁定收益；保留70%底仓长期持有”。李娜设置了明确的加仓区间，她表示，“若金价回调至4250-4300美元/盎司，会用积存金分批补仓”。</p>
  <h2><strong>白银、铂金、钯金涨超100%，有投资者暴赚200%</strong></h2>
  <p>在黄金闪耀之际，白银、铂金、钯金的表现更为凶猛。</p>
  <p>截至12月24日收盘，现货白银报71.87美元/盎司，盘中曾涨至72.70美元/盎司，创历史新高。COMEX白银期货报71.875美元/盎司，也在盘中刷新历史高位，至72.750美元/盎司。若按当日最高价计算，年内现货白银、COMEX白银期货分别涨151.61%、135.56%。</p>
  <p>“直接投资白银期货，交易灵活，杠杆能放大收益。”在北京从事金融工作的路鸣，道出了专业玩家的路径。2024年，他开始关注贵金属，2025年8月察觉到白银“逼仓”等增量逻辑后，便将重心从黄金转向白银。路鸣将个人账户20%-30%的期货仓位配置于白银，目前累计投入约100万元左右，盈利超过200%。</p>
  <p>然而，即便经验丰富，面对巨大涨幅也要保持警惕。“近期计划逐步减仓”，路鸣判断，白银可能还有逼仓行情，因此选择部分获利了结，剩余仓位继续持有。路鸣表示，“未来仍关注贵金属大周期下不同品种机会。后续降息逻辑可能使黄金更强，铂金、钯金也值得关注”。</p>
  <p>事实上，钯金、铂金近期表现同样优秀。截至12月24日收盘，现货铂金报2256.73美元/盎司，盘中曾涨至2381.53美元/盎司，突破2008年所创历史最高位2300美元/盎司；现货钯金报1726.84美元/盎司，盘中最高触及1959.68美元/盎司，创下历史新高。按当日最高价计，年内现货铂金、现货钯金已分别上涨163.05%、115.72%。</p>
  <p>紫金天风期货贵金属研究员刘诗瑶对时代周报记者表示，本轮贵金属集体走强主要基于三重逻辑驱动：一是美联储降息预期持续构成直接利好；二是市场对美联储在数据缺失时降息的决策独立性产生担忧，强化避险需求；三是提前定价2026年美国中期选举年可能出现的财政扩张与债务风险。</p>
  <p>“从品种表现看，白银、铂金等涨幅显著超越其工业属性范畴，主要跟随黄金的金融逻辑波动，呈现出贵金属普涨格局，其中白银因历史弹性特征涨幅尤为突出。”刘诗瑶指出。</p>
  <p>面对创纪录的价格，投资者追高进场风险几何？田利辉建议，普通投资者应避免追高，贵金属波动剧烈，杠杆交易风险极高。应慎重控制贵金属在投资组合中的比重，作为避险资产而非核心配置，关注白银工业需求变化，如光伏用银需求因价格高企可能受到抑制。投资需理性，切忌被“翻倍”诱惑冲昏头脑。</p>
  <p>（徐雨、魏灵、李娜、路鸣等为化名。）</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjEyODE4MA==&amp;mid=2653339044&amp;idx=4&amp;sn=70594f7b58c237a520b01a7e3f5db515&amp;chksm=bc76c64c23b329e35e558d4b1bc55d1889d677156406714eca5e45b0c10ac9da7d28e7a90198&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“时代周报”（ID：timeweekly）</a>，作者：王苗苗，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612186689270531</id>
            <title>2025年A股IPO收官：111家企业募资1253亿元，近半投向科创领域</title>
            <link>https://www.36kr.com/p/3612186689270531</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612186689270531</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:53:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年即将收官，A股IPO（首次公开募股）格局初定。</p>
  <p>截至12月26日，2025年A股发行上市家数共计111家，同比增长11%；首发募资总额达到1253.24亿元，同比增长86.07%。募资增速远超数量增速，反映出今年IPO市场“少而精”的特征。</p>
  <p>业内人士表示，纵观过去五年，A股IPO市场已完成从“规模扩张”向“质量优先”的转型。在经历2021年高位运行后，市场通过阶段性调整实现了结构优化，标志着已进入一个更加成熟的发展阶段。</p>
  <h2><strong>全年111家企业IPO募资1253亿元</strong></h2>
  <p>2025年，A股IPO市场在稳监管与优结构背景下实现温和增长。截至12月26日，A股共有111家企业首发上市，募资总额为1253.24亿元。</p>
  <p>2025年，A股IPO平均募资额相较于2024年增加4.55亿元，同比增长67.51%。IPO企业募资规模主要集中在10亿元以下的区间，其中募资金额在5亿元以下的企业有42家，募资金额在5亿元至10亿元的企业有40家，募资金额在10亿元至30亿元的企业有21家。此外，募资金额在30亿元至50亿元、50亿元至100亿元、100亿元以上的企业分别为6家、1家、1家。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b152b1afc2e646cd9e55697be74d901e@5727534_oswg19314oswg705oswg422_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2025年，A股十大IPO共募集资金561.65亿元，占全年募资总额的44.82%，募资额同比增长197.52%。这一显著增长主要源于下半年超大型项目的落地，其中华电新能（600930.SH）于7月上市，以181.71亿元的募资额领跑，直接拉高了前十大IPO的整体募资规模。</p>
  <p>紧随其后的是摩尔线程（688795.SH）和西安奕材（688783.SH），分别以80.00亿元和46.36亿元的募资额位列第二和第三位。其中，摩尔线程是国内稀缺的全功能GPU研发企业，其募资主要投向新一代自主可控AI训推一体芯片等硬科技研发项目；西安奕材则专注于12英寸硅片研发生产，产品覆盖AI芯片、存储等领域，两者均体现了资本市场对高科技及战略性新兴产业的重点支持。</p>
  <p>从整体市场特征来看，2025年A股IPO呈现“少而精”的特点，超大型项目密集落地，成为募资规模大幅增长的核心动力，这与A股从“规模扩张”向“质量优先”的转型方向高度契合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_86f193520b1a47dd9ea4995672ef3782@5727534_oswg288284oswg1344oswg670_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得关注的是，年内IPO终止审查企业共计99家，同比减少335家，降幅达到77.19%。终止数量的大幅回落，反映出监管审核标准趋严，企业申报更加审慎，“带病申报”现象减少，同时也体现出市场生态持续优化。</p>
  <h2><strong>近五成IPO募资投向科创领域</strong></h2>
  <p>在板块分布上，科创板上市企业共有18家，合计募资353.05亿元；创业板上市企业有32家，合计募资245.05亿元，北交所上市企业有25家，合计募资72.04亿元；沪市主板上市企业有23家，合计募资432.28亿元；深市主板上市企业有13家，合计募资150.82亿元。</p>
  <p>从科创属性维度来看，创业板与科创板合计上市企业50家，合计募资598.1亿元，分别占全年上市数量和募资总额的45.05%、47.72%。接近五成的募资投向科创领域，展现出资本市场服务科技创新的核心定位。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_3623ac4417ca4475a642bb4dbd72b2b3@5727534_oswg102142oswg1146oswg708_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在行业分布上，电子行业成为今年IPO的“双料冠军”，共有19家企业上市，合计募资337.44亿元，分别占全年上市数量和募资总额的17.12%、26.93%。从募资额TOP5行业来看，电子（337.44亿元）、汽车（229.25亿元）、公用事业（181.71亿元）、电力设备（118.56亿元）、医药生物（90.66亿元），占全年募资总额的76.41%。这一分布特征与国家战略导向高度契合，工业、科技类行业成为IPO市场主力，彰显资本市场对新质生产力发展的支撑作用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ca205b3403494a898e554e18c143cc2d@5727534_oswg91811oswg554oswg414_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体来看，今年IPO企业主要集中在电子、电力设备、汽车、机械设备、医药生物、基础化工等行业，分别有19家、18家、16家、13家、10家、10家。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b4593f2ecf7443cd9c0ce569d2d819dd@5727534_oswg31141oswg725oswg468_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>A股打新收益创三年新高</strong></h2>
  <p>从首日涨幅来看，今年IPO新股上市首日平均涨幅达到256.77%，为近三年来最佳表现。中签投资者在股票上市首日，回报率超发行价两倍半。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_01d171646fce45fe80da01487709344f@5727534_oswg452260oswg1138oswg3144_img_jpeg?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>具体来看，上市首日涨幅在300%以上的个股共有34只，其中大鹏工业（920091.BJ）首日涨幅达到1211.11%，排名榜首，三协电机（920100.BJ）、沐曦股份（688802.SH）紧随其后，首日涨幅分别达到785.62%、692.95%。此外，江南新材（603124.SH）首日涨幅606.83%，广信科技（920037.BJ）首日涨幅500%，分别位居第四和第五位。</p>
  <p>值得关注的是，随着沐曦股份的上市，再度刷新了年内A股IPO单签赚钱纪录。若以收盘价计算，投资者中一签盈利高达36.26万元，超过了摩尔线程（24.31万元），成为A股全面注册制以来最赚钱新股，也是近十年最赚钱新股。</p>
  <p>业内人士表示，“肉签”股多为市场热门的概念股，其频繁出现的原因是今年新股普遍具备强科创属性，被市场寄予厚望。此外，发行价控制相对合理，为股价上涨预留了空间。</p>
  <p>本文来自微信公众号“览富财经网”，作者：览富财经网，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612182446097409</id>
            <title>全员涨薪潮</title>
            <link>https://www.36kr.com/p/3612182446097409</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612182446097409</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:52:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>这是喜闻乐见的一幕。</p>
  <p>昨天（12月25日），京东发布2025年终奖公告：京东全集团92%的员工拿满甚至拿到超额年终奖，年终奖总投入同比增幅超过70%，京东采销更是“<strong>上不封顶</strong>”。</p>
  <p>不久前，字节跳动也宣布2025年奖金投入提升35%，调薪投入上涨1.5倍。几乎同一时间，比亚迪、宁德时代等超级巨头纷纷开始给员工涨薪。</p>
  <p>想起不久前，中央经济工作会议列出了明年经济工作的重点任务，第一条就提出——制定实施城乡居民增收计划。无疑，企业主动给员工涨工资、发奖金，立竿见影。</p>
  <p>“希望这股涨薪的风，也能早点吹到我这儿。”临近年底，打工人们有了新盼头。</p>
  <h2><strong>京东字节宣布：涨工资！</strong></h2>
  <p>大厂们开始卷工资了。</p>
  <p>从京东说起。其实早在去年9月，京东就发布了20薪升级计划，宣布自2024年10月1日起京东零售集团和职能体系将用两年时间实现20薪，其他部门也将随后陆续启动加薪。</p>
  <p>根据该加薪计划，今年京东年终奖继续大幅上涨，已升级部门今年实现19薪，同时更有业务单元提前实现20薪。此外，一线员工年终奖仍将在年前发放。</p>
  <p>整体上，<strong>京东2025年的年终奖总投入同比增幅超过70%，预计将创下行业今年最大涨幅</strong>。具体来看——</p>
  <p>今年升级为19薪的部门内：</p>
  <p>年度绩效A+的员工将获得10倍月薪年终奖，即全年22薪；</p>
  <p>年度绩效A的员工将获得9倍月薪年终奖，即全年21薪；</p>
  <p>年度绩效B+的员工将获得7倍月薪年终奖，即全年19薪。</p>
  <p>今年提前实现20薪的部门内：</p>
  <p>年度绩效B+的员工即可拿满8倍月薪年终奖，即全年20薪；</p>
  <p>年度绩效A+将直接获得12倍年终奖，全年24薪。</p>
  <p>更让人羡慕的是，京东采销今年将实现平均25薪，并且“上不封顶”。</p>
  <p>这已是京东过去一年多第七次提高员工薪酬激励。值得一提的是，京东今年布局外卖业务时，率先给全职骑手缴纳社保，推动行业迈进“五险一金时代”。</p>
  <p>字节也放大招。12月19日，字节跳动发布全员信宣布：增加奖金（含绩效期权）投入，2025全年绩效评估周期相比上个周期提升35%；大幅增加调薪投入，较上个周期提升1.5倍；提高所有职级薪酬总包的下限（起薪）和上限（天花板）。</p>
  <p>对此，字节跳动在邮件中解释称，行业正面临新的机遇和挑战，公司希望更好地激励和保留优秀人才，同时也更好地吸引全球优秀人才加入公司，<strong>做到“什么时候加入都不晚”。</strong></p>
  <p>纵观互联网大厂圈，字节的薪资一向诱人。根据其在社交平台发布的多个热招岗位，如“海外商业化-算法专家”月薪最高可达8万元，“智能编辑技术专家”月薪最高7万元，校招大模型算法工程师岗位的月薪达到6万元，相当霸气。</p>
  <p>当然，这背后是一场硝烟四起的人才争夺战。并且，火药味已经越来越浓了。</p>
  <h2><strong>涨薪潮来了</strong></h2>
  <p>这股风还吹到了智能制造领域。</p>
  <p>先是宁德时代。一份宁德时代发布的《2026年1—6级员工薪资调整通知》显示，宁德时代决定自2026年1月1日起，对1-6职级员工——也就是<strong>生产线操作工、技术员等一线基层员工的基本工资上调150元</strong>，其他薪资结构保持不变。</p>
  <p>消息一出便迅速冲上热搜，有网友调侃“杯水车薪”，但也有网友认为“蚂蚱腿再少也是肉，总比没有强”。</p>
  <p>除涨薪外，宁德时代还发布春节坚守岗位奖励计划：2026年春节期间，出勤满足条件即可获得额外奖励至少3200元，适用范围包括宁德时代及国内独资分、子公司电池、材料制造基地下沉十大部门、中心MEVEOPNJG1-10级员工。</p>
  <p>市值1.7万亿元，宁德时代赚钱能力惊人。单看2025第三季度，其营收1041.85亿元增长12.90%，净利润185.49亿元增长41.21%。<strong>粗略计算，“宁王”日赚约2亿元</strong>。</p>
  <p>比亚迪也来了。最近，互联网社交平台流传着比亚迪对技术研发人员实施涨薪的消息——调薪幅度500元至3000元不等，最高涨薪4500元。对此，比亚迪方面回应称“涨薪属实”，但并未透露涨薪幅度以及涉及人员数量。</p>
  <p>还有市值超2700亿的药明康德。据业内流传，药明康德2025年已完成两次调薪：4月按个人绩效实施差异化年度加薪，11月底落地化学业务平台特殊调薪，覆盖90%正式员工，平均调薪比例超12%。</p>
  <p>羡煞打工人的是，昨天药明康德发放了2025年“阳光普照奖”——<strong>每人2500元，全员覆盖、不问岗位、不谈绩效</strong>。据说，这是这家生物医药巨头的老传统，今年比往年还多了500元。</p>
  <p>如此来看，从科技、制造到新能源、医药，巨头们不约而同地表态涨薪，信号隐隐约约。</p>
  <h2><strong>涨薪背后：鼓励大力消费</strong></h2>
  <p>风向标早已出现。</p>
  <p>这里先提一提大背景。长期以来，我国居民收入占比GDP的比例相对偏低，只有40%左右，而发达国家在70%左右，全球平均水平也有60%左右。再来看消费水平，2025年前三季度最终消费支出对经济增长贡献率达53.5%，虽较往年有所提升，但与发达国家仍有差距。</p>
  <p>扩大内需消费，成为一场至关重要的战役。</p>
  <p>今年12月11日落幕的中央经济工作会议，明确提出“制定实施城乡居民增收计划”。细细读下来，这次的表述与往年相比有着明显不同，一方面今年不再只是中低收入群体，几乎覆盖了所有人群。另一方面，相较于去年提出的“推动”，今年则是“制定实施”，这意味着将从方案制定走向具体落实。</p>
  <p>数日后，《求是》发表了《坚定实施扩大内需战略》，对于居民增收计划提出了更具体的表述，“实施城乡居民增收计划，<strong>提高居民收入在国民收入分配中的比重，提高劳动报酬在初次分配中的比重。”</strong></p>
  <p>显然，增加居民收入，最直接、最有效的办法就是涨工资。以此，进一步释放中国居民的消费潜力，让大家更富裕，更敢消费，从而形成内外需更加均衡的增长动力。</p>
  <p>做好、做大“蛋糕”的同时，也要进一步分好“蛋糕”。根据人社部数据，2025年以来已有20多个省份上调最低工资标准：第一档月最低工资标准均超过了2000元。其中，上海以2740元领跑全国。同时，超过2500元的还有北京、天津和广东，深圳最低工资标准单列公布，为2520元。</p>
  <p>另一边，以京东、字节、宁德时代、比亚迪等为代表的超级巨头，已率先开了个好头。毕竟，居民富裕了，消费能力上去了，才能拉动了内需。</p>
  <p>一切才刚刚开始。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247707663&amp;idx=1&amp;sn=33da16864879a5986f74678e70135dfa&amp;chksm=edfdcce3946ae507869a4aed332f533eda91f682fad64c8f801b35eedc547336ae427e0c3e1c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：周佳丽，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612182536930311</id>
            <title>12个月，他们投向医疗30亿</title>
            <link>https://www.36kr.com/p/3612182536930311</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612182536930311</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:52:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年已近尾声，若要回顾今年创投圈的关键时刻，创新药高涨一幕无法略过。</p>
  <p>回想前两年，医疗行业经历估值回调，医疗投资一度趋于沉寂。市场情绪悲观之际，启明创投主管合伙人胡旭波却和团队做出重要决策——继续重点投资创新药和器械领域，尤其是有重大临床突破潜力的领域。</p>
  <p>现在回头看，当初的决定看起来是个正确的选择：今年，创新药板块成为明星，港股盛况更是历历在目——IPO钟声不断，十倍股频现，指数一度飙升逾100%。甚至有投资人将2025年称为“医药翻身之年”。</p>
  <p>“这只是开始。”行至年终，胡旭波与投资界聊起中国医疗创新的起起伏伏。他相信，中国创新已迈入关键节点，正从局部单点突破向大规模全面突破迈进。以年初DeepSeek出圈为代表，中国创新历经了从跟进到自我革新的阶段，未来工程化能力还将持续提升；创新药领域正从部分技术平台、产品线的突破，向整个体系突破迈进，医疗器械领域的创新企业则凭借突破性的临床设计和显著供应链优势稳步开始全球化发展。未来5-10年，更多具有高度原创性的研发成果有望在中国的实验室诞生，并为全球医药创新做出贡献。</p>
  <h2><strong>出手医疗创新最重VC</strong></h2>
  <p>回顾2025年，启明创投在医疗创新领域投资了超30个项目，出资超30亿元，其中部分投资是2024年下半年决策——启明创投的医疗投资历来是一张晴雨表。</p>
  <p>印象深刻的包括康诺思腾。这是一家诞生于中国香港的创新型手术机器人独角兽企业，创始人欧国威曾在香港中文大学任教，后于2019年创办康诺思腾（Cornerstone Robotics），专注于研发能够对标进口品牌的新一代国产腹腔镜手术机器人。</p>
  <p>带着做中国手术机器人的创业抱负，欧国威率队的康诺思腾于2024年开始步入商业化，完全掌握机械架构、电气架构、软件架构、复杂算法以及视觉影像等核心技术，自主搭建手术机器人底层技术平台。一路走来，其身后也集结了一众VC/PE，融资超30亿元。当中，启明创投是最早一批投资康诺思腾的投资人。</p>
  <p>那是2020年，一通在酒店大堂的远程电话让胡旭波坚定了投资的决心。欧国威对手术机器人领域的深入理解及其“改变全球手术机器人格局”的愿景，与启明创投对市场前景的判断相契合——无论是国内尚未饱和的需求，还是国际新兴市场的潜力，都预示着广阔的空间。就这样，启明创投于2020年坚定出手，并一路陪伴至今。</p>
  <p>今年11月，康诺思腾完成约2亿美元的超募融资，吸引了包括港投公司、全球战略投资者及主权基金在内的多方参与，老股东启明创投等继续加持。这已经是启明创投连续五轮投资康诺思腾。</p>
  <p>几天后，启明创投还将迎来一个重要IPO——英矽智能，一家总部在香港、研发中心在上海的AI新药研发企业。启明创投是英矽智能的早期投资人之一，并在后续多轮融资中持续加注。英矽智能发展早期，启明投资团队就开始协助支持公司建立起新药研发领导团队，并让AIDD的AI能力和药物研发能力真正开始有机融合。</p>
  <p>手握全球进展最快AI药物——Rentosertib（ISM001-055），英矽智能即将于今年12月30日在港交所IPO上市，有望成为今年港股最大的Biotech IPO。按照每股24.05港元的发行价计算，英矽智能将通过本次IPO募集至多约23亿港元，IPO市值超130亿港元。</p>
  <p>这也意味着，启明创投医疗版图又将落袋一个百亿IPO。</p>
  <h2><strong>越是市场悲观，越是笃定出手</strong></h2>
  <p>久违地，医疗行业热闹了起来。</p>
  <p>回想2021年，中国医药行业在一场狂欢后急转直下，此后便是漫长的冬天。期间，一级市场大多数投资机构将重心转移到其他领域，出手医疗极其谨慎，甚至是避而不投。在部分投资机构内部，医疗投资人也一度处于相对边缘的位置。</p>
  <p>“那时候，我们始终告诉自己，要深入到第一线，积极与企业家和创业公司沟通交流，验证我们所关注的创新的实际价值。”行业最低谷时，启明创投医疗创新投资团队并未停下脚步，反而保持了密切的行业接触，几乎覆盖了中国95%以上的创新公司。</p>
  <p>直到2024年上半年，胡旭波的判断逐渐清晰：启明创投所坚持的——<strong>推动中国创新服务于全球市场——是可行且值得投入的</strong>。尽管当时医疗投资依旧冷清，启明创投看到的是中国创新被低估的历史性机会，胡旭波也在内部多次强调，必须把握时间窗口，果断投资那些产品与团队都令人信服的企业。</p>
  <p>在这样“非共识”的决策下，启明创投成为那段时期在医疗领域投资最为活跃的VC之一，在创新药和医疗器械领域投入了大量资金，自2024年5月至2025年5月的<strong>12个月内投入近40亿元人民币，可能是当时全球医疗基金里投资金额最大的中国VC基金</strong>。</p>
  <p>今年以来，随着全球资本对中国创新资产进行重新评估，加之企业自身通过产品成果、授权合作与全球布局释放积极信号，行业整体呈现回暖态势。“我们还是有点幸运，我们坚持的投资理念和方向在一个合适的时间点得到了初步的确认。”胡旭波感慨道。</p>
  <p>回顾今年以来，A股与港股市场中市值达到千亿规模的创新药企已增至近10家。此间，港股创新药板块表现尤为突出，成为上涨集中的领域，相关指数一度累计涨幅超过100%，十倍股集中涌现。赚钱效应传导，港交所门口排满了等待上市的创新药企，仅11月就有近10家公司递交上市申请。截至当前，2025年成功在港股IPO的生物科技公司数量已较去年翻了一倍。</p>
  <p>这当中，国际投资人的态度转变尤为关键，此前主战场在纳斯达克的机构，2025年开始重新配置中国创新药资产。背后原因在于，<strong>中国创新药企业的产品开始真正意义上被业界尤其是全球制药创新体系认可。</strong></p>
  <p>“尤其是去年下半年开始，有一批中国创新药企业的临床数据很惊艳。业界发现，原来中国公司能做得这么好，海外药企龙头纷纷开始跟中国创新药企业合作。”胡旭波分析本轮回暖时指出。</p>
  <p>他认为，如果有更多大型国际投资机构和专业投资人将资金配置于中国的创新药企业，先进入港股，未来或许进一步扩展至A股，这将有助于构建一个更加健康、可持续的生物医药产业生态。</p>
  <h2><strong>穿越周期，中国医疗创新永不落幕</strong></h2>
  <p>医疗投资下一阶段的叙事是什么？</p>
  <p>据最新数据，2025年全球大型药企通过许可引进（license-in）的新药项目中，大概率有40%左右来自中国的优秀生物医药创业公司。而2019年，这一数字是0。</p>
  <p>这里有一个背景，即全球最大的跨国药企，有一部分新药通过内部研发获得，另外很大一部分新药是通过外部的协作，包括从中小生物研发机构、生物研发企业购买专利。过去中国是license-in，是海外先进医药的主要承接国。但现在情况变了，<strong>中国已经成为license-out（对外授权）的主要发源地。</strong></p>
  <p>行至当下，中国医疗创新的全球影响力正在提升，密集发生的超级BD交易是最好的印证。在胡旭波看来，BD不仅带来现金流，也证明中国创新企业具备与全球头部药企合作的能力，更向市场证明了中国创新药的价值。BD交易构建了全球化创新生态——<strong>中国提供优质资产，国际药企提供商业化渠道，形成双赢格局。</strong></p>
  <p>在此过程中，中国正在形成独特的创新双循环：一方面用工程化创新快速降低新药可及性门槛，另一方面用源头创新构建长期技术壁垒。</p>
  <p>因此，持续布局中国药企出海，早已成为启明创投的核心投资主题之一。团队也从数年前开始，有意识地帮助被投企业构建全球化的能力，包括定期与海外大公司保持交流，连续四年组织启明创投医疗创新合作伙伴开放日（Partnering Day）活动，为启明创投投资企业和全球头部药企搭建交流合作平台，帮助了超百家（次）全球头部药企和投资企业开展了数百场1对1会议。</p>
  <p>除此之外，启明创投内部也设立专门的团队，协助投资企业了解全球医疗注册体系和出海规则等，帮助企业走向全球。投资界拿到一组数据——截至2025年10月，<strong>启明创投投资企业已签署30项与跨国药企及海外生物科技公司的BD交易，可披露交易总额197亿美元。</strong></p>
  <p>“很多企业已经发展到能在全球市场上与最优秀的公司同台竞争的水平。”谈及中国药企的未来，胡旭波表示，“10年前，我还不敢说很多中国公司能走向全球，但现在可以了，只不过要求更高了。”</p>
  <p>他也指出，许多中国公司规模仍较小，要参与海外市场，将面临诸多挑战——包括文化适应、对全规则的了解、组织结构的支撑，以及资金实力等。“并非所有企业都能走到那一步，前方的道路必然充满挑战。”</p>
  <p>起起伏伏，中国医疗投资市场经历了过去一个周期的寒冬，今年终于有了暖意，正如大家普遍感受到医疗行业拐点的到来。走出低谷，这一波行情将持续多久？</p>
  <p>胡旭波的心态是谨慎乐观：“未来的路还很长，我们当前始终保持着兢兢业业的状态，深入调研每一家企业。启明创投所投的医疗公司，我们都希望它具有全球影响力——<strong>无论是新药还是器械，都不应仅局限于中国市场，而应能在海外创造价值</strong>。当然，这也绝非易事。”</p>
  <p>医疗创新历来被喻为一场耗资巨大、周期漫长的马拉松。于医疗投资人而言，这无疑也是一场漫长的修行。或许正如胡旭波所说，一切才刚刚开始。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247707663&amp;idx=2&amp;sn=a4f3afe57bf60db7f3a9225b8e0bfe2f&amp;chksm=ed9fc39352976d2189126a621fd638972974b8ca6ee475237b7efa9d1d03c4ad3de38751f438&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：周佳丽，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612215125684737</id>
            <title>ChatGPT 和传统搜索引擎，在一条钢丝上越走越近</title>
            <link>https://www.36kr.com/p/3612215125684737</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612215125684737</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:51:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>奥特曼此前曾多次公开表示，在AI回复中加入广告让他感到不安，他认为这是企业的“最后手段”。</p>
  <p>可是在现实面前，奥特曼选择了低头。</p>
  <p>在ChatGPT最新的安卓测试版1.2025.329代码中，赫然出现了“ads feature”、“search ad”、“bazaar content”等广告相关的字符串。</p>
  <p>这些代码片段虽然只有十几行，但足以说明OpenAI正在为ChatGPT植入广告做技术准备。</p>
  <p>诚然，广告会为OpenAI带来巨大的收入。</p>
  <p>但是这样一来，AI搜索长期建立的结构化、纯净无广告等标签将会荡然无存。如何在广告以及优质输出内容之间找到平衡点，已然成为了2026年所有大模型企业的共同难题。</p>
  <h2><strong>01</strong></h2>
  <p>广告即将成为OpenAI的最大收入来源之一。</p>
  <p>根据OpenAI披露的数据，公司在2025年上半年的支出就达到25亿美元，照此以往，到2029年时，公司将烧掉1150亿美元。</p>
  <p><strong>即便ChatGPT的周活跃用户目前接近9亿，但其中只有约5%的用户付费订阅。</strong></p>
  <p>按照OpenAI的定价，ChatGPT Plus每月20美元，ChatGPT Pro每月200美元，按5%的付费率计算，这些订阅收入也远不足以覆盖成本。</p>
  <p>为了填补这个财务黑洞，OpenAI制定了免费用户变现计划。根据公司内部预测，2026年开始，免费用户的人均年度营收将达到2美元，到2030年这个数字将增长到15美元。</p>
  <p>最直接的变现方法就是广告。而OpenAI希望通过广告业务，到2030年实现总营收中20%来自广告相关收入。</p>
  <p>奥特曼在最近的访谈节目中也调整了说法，称广告“虽然令人不适，但并非完全不可接受”。这种态度的变化，与其说是理念转变，不如说是现实妥协。</p>
  <p>从OpenAI内部讨论的情况来看，其广告形式与传统搜索引擎有着本质区别。奥特曼称之为“意图导向的变现”，核心是将广告转化为“对话式推荐”，而不是简单地在搜索结果中插入广告链接。</p>
  <p>这种模式的运作方式是：当用户询问“最好的跑鞋推荐”时，AI会在提供专业建议的同时，自然地推荐某个付费品牌。</p>
  <p>据The Information报道，推荐不会生硬地标注“这是广告”，而是融入对话流程，比如“根据你的训练强度，Nike的Pegasus系列可能很适合，它的缓震技术能有效保护膝盖”。OpenAI可能通过购买分成或收取“优先进入推荐逻辑”的费用来实现盈利。</p>
  <p>OpenAI在内部制作了多种广告展示原型，用于模拟不同的呈现方式。其中一种方案是在ChatGPT主回复窗口的侧边栏显示赞助信息，并明确标注“包含赞助结果”。这种设计参考了谷歌搜索的广告展示方式，但试图让广告看起来更像“补充建议”而非传统的页面广告。</p>
  <p>OpenAI的另一种方案是在用户点击进一步信息时，在页面侧边展示广告。</p>
  <p>比如用户询问巴塞罗那旅行建议，ChatGPT会先推荐圣家堂等景点，这个推荐本身不是赞助内容。但当用户点击圣家堂的介绍链接时，会看到一个包含多家付费旅游服务商赞助链接的弹窗。</p>
  <p>这种“二次触发”机制的目的是避免用户在首次对话中就感受到商业推广的压力。</p>
  <p>OpenAI还在探索“生成式广告”模式。AI不是简单展示广告商提供的文案，而是根据用户的具体需求和对话语境，自动生成定制化的推荐内容。</p>
  <p>比如同样推荐一款跑鞋，对马拉松选手会强调耐久性和支撑性，对新手则会强调舒适性和性价比。OpenAI认为这种动态生成的广告内容理论上能带来更高的转化率。</p>
  <p>OpenAI内部员工在评估这些方案时，他们的核心争论点在于“如何在不引发用户反感的情况下展示广告”。</p>
  <p><strong>同时团队内部也达成了一种共识，那就是广告绝不能打断或干扰自然对话节奏，所有广告曝光都应设定在对话推进至一定深度后触发。</strong></p>
  <p>这个原则意味着免费用户不会在每次对话中都看到广告，只有当对话内容明确指向消费、出行或产品决策时，广告才会出现。</p>
  <h2><strong>02</strong></h2>
  <p>2025年11月，OpenAI推出了Shopping Research功能，将ChatGPT变成个人购物助手。用户可以语音或文字描述购物需求，AI会提出针对性问题，然后提供完整的购买建议，包括产品链接和价格对比。</p>
  <p>OpenAI在推出这个功能时明确表示，目前不收取任何佣金或联盟营销费用，商家也不能付费影响排名。但业内普遍认为这只是暂时的策略。Shopping Research使用了专门训练的GPT-5 mini模型，能够读取产品页面、规格表和可信评论，这个基础设施完全可以无缝对接广告系统。</p>
  <p>OpenAI已经与Walmart、Target、Etsy等零售商建立合作关系，用户可以在ChatGPT中搜索和购买这些平台的商品。虽然现在是免费流量导入，但一旦广告系统上线，这些合作关系就能立即转化为付费推广渠道。</p>
  <p>在2025年黑色星期五期间，ChatGPT带来的电商网站流量同比增长28%，Cyber Monday当天AI带来的零售网站流量增长670%。如果OpenAI能在这些流量中插入广告，即便转化率只有传统电商的一半，收入也将非常可观。</p>
  <p>然而，为了抵御其对购物入口及广告收入的冲击，亚马逊在临近圣诞节时，屏蔽了ChatGPT、 Meta、谷歌等多家公司的AI爬虫，阻止其抓取商品信息。</p>
  <p>同时，亚马逊推出了自研的AI购物助手Rufus，以守住平台的入口，应对AI搜索带来的变革。</p>
  <p>为了进一步探索广告业务，OpenAI从谷歌挖来了广告业务高管希瓦库马尔·文卡塔拉曼（Shivakumar Venkataraman），他曾负责谷歌搜索广告的多个核心项目。</p>
  <p>此外，OpenAI还在LinkedIn上发布了多个与广告相关的职位，包括广告工程师、广告产品经理和广告策略分析师。</p>
  <p><strong>这些动作都表明，广告对OpenAI来说已经不是要不要做的问题，而是怎么做的问题。</strong></p>
  <p>推动OpenAI做这个决定的，除了成本压力，还有竞争压力。谷歌在2025年宣布将在Gemini中引入广告，计划2026年正式推出。这给OpenAI带来了直接威胁。如果竞争对手都在通过广告降低用户成本并增加营收，OpenAI很难独善其身。</p>
  <p>Perplexity AI已经推出了“赞助回答”功能，在搜索结果中明确标注赞助内容。虽然这个功能引发了一些用户不满，但也证明了AI搜索广告的可行性。OpenAI显然不想在这场竞赛中落后。</p>
  <p>从市场规模来看，全球数字广告市场年产值超过1万亿美元，其中谷歌和Meta占据了大部分份额。如果OpenAI能通过ChatGPT切入这个市场，哪怕只拿到5%的份额，也将带来每年500亿美元的收入，足以支撑公司的长期运营。</p>
  <p>但OpenAI也面临着用户信任的挑战。一旦AI的回答开始掺入商业利益，用户如何判断这个建议是基于客观分析还是广告商的付费？当ChatGPT推荐某款产品时，用户会怀疑这是因为产品真的好，还是因为品牌付了钱？</p>
  <p>这个问题没有答案。</p>
  <p>OpenAI现在正试图在"智力中立"与"财务自救"之间走钢丝。如果这个平衡失败，ChatGPT可能会从“AI助手”变成“推销产品的聊天机器人”。</p>
  <h2><strong>03</strong></h2>
  <p>但不可否认的是，AI搜索正在蚕食传统的关键词搜索。</p>
  <p>传统搜索引擎的市场份额正在以肉眼可见的速度流失。根据highervisibility发布的2025年搜索行为研究报告，谷歌在通用信息搜索领域的份额从2025年2月的73%降至8月的66.9%，半年时间下降了6.1%。</p>
  <p>中国市场的变化更加剧烈。百度的移动端搜索市场份额从2021年的94.72%下降到2025年第三季度的58.6%。</p>
  <p>QuestMobile的数据显示，百度的媒介地位指数跌至第九位，排在抖音、淘宝、微信、快手、小红书之后。而且百度2025年第三季度的在线营销收入同比暴跌18%，这已经是连续第六个季度下滑。</p>
  <p>然而这些用户并不是不再搜索了，而是把搜索行为转移到了AI工具上。</p>
  <p>QuestMobile发布的《2025年中国AI终端生态发展研究报告》显示，截至2025年10月，AI移动端用户规模已达7.2亿，占中国网民总数的50%。AI搜索请求日均突破28亿次，其中商业查询占比41%。</p>
  <p>德国数字行业协会bitkom对1000名用户的调查显示，50%的受访者有时会通过AI聊天查找信息，而不是使用传统搜索引擎。在16-29岁人群中，5%完全依赖AI搜索，11%主要使用AI，20%使用AI与传统搜索引擎的比例相当。</p>
  <p><strong>也就是说，超过三分之一的年轻人已经把AI作为主要或唯一的信息获取方式。</strong></p>
  <p>更能说明问题的是零点击率的变化。零点击代表用户搜索完关键词后，不进行任何页面跳转，转而直接下一次搜索或者关闭页面。</p>
  <p>SparkToro的数据显示，谷歌搜索的零点击率已达58.5%，移动端更是高达77.2%。这意味着超过一半的搜索不再产生点击，用户在看到搜索结果和摘要后就离开了。传统搜索引擎最核心的广告模式正在失效。</p>
  <p>AI搜索带来的转化率更高。大模型搜索转化率指的是用户从发起搜索到最终需求被直接满足的比例。ChatGPT的转化率是谷歌搜索的6倍，用户更愿意信任AI给出的直接答案。</p>
  <p><strong>这种转变背后是AI搜索解决了传统搜索长期存在的核心痛点。</strong></p>
  <p>传统搜索只提供链接列表，用户需要点开十几个网页逐一查看，不同网站信息质量参差不齐，相互矛盾，用户需要自行辨别真伪。一个简单问题往往需要花费很长时间拼凑完整答案，"搜索→点击→阅读→返回→再搜索"的循环让用户苦不堪言。</p>
  <p>AI搜索直接给出完整答案，省去了筛选链接、逐一点击、拼凑信息的过程。根据OpenAI联合哈佛大学的调查《How People Use ChatGPT》，将近35%的用户将“获得直接答案”列为使用AI搜索而不是谷歌搜索的首要原因。</p>
  <p>AI搜索支持多轮对话，这进一步丰富了搜索结果。第一次提问不清楚时，用户可以立即追问、补充条件、调整方向，像与真人对话一样逐步明确需求，而非反复修改关键词重新搜索。AI能记住上下文，形成连贯对话，而传统搜索每次都把用户当作"新用户"处理。</p>
  <p>《AI搜索用户行为研究》显示，72%的AI搜索会话包含2轮以上对话，其原因是这种交互方式更符合人类自然的思维习惯。而在传统的关键词搜索中，并不存在"连续"这个概念，每一次搜索都只有当前的关键词。</p>
  <p>用户更看重的是，AI给出的答案不受商业利益驱动，没有竞价排名的困扰。传统搜索引擎的广告模式长期以来饱受诟病，百度搜索结果前几页被竞价排名广告占据，真实信息被淹没，用户需要滚动数屏才能找到非广告内容。</p>
  <p><strong>虽然AI也可能出错，但至少不是“谁付费谁排前面”。</strong></p>
  <p>语音交互方式的便利性也是重要因素。移动端打字速度慢、容易出错，长问题输入体验极差，而语音输入速度是打字的3-4倍，特别适合复杂问题表达。Geokeji的研究显示，AI搜索应用中58%的用户使用语音输入，而传统的关键词搜索，即便拥有语音输入功能，使用率仍然不到20%。</p>
  <p>语音搜索的平均问题长度是文字搜索的2.3倍，因为语音输入更便利，用户能够更完整地表达自己的需求，提高了搜索的准确性。在开车、做饭、带娃、运动等场景中，双手被占用时，语音搜索成为唯一选择。这些高频场景让用户养成了"遇事直接说"的新习惯。</p>
  <p>Gartner预测，2026年全球搜索引擎访问量将骤降25%。这不是简单的市场份额转移，而是一场交互方式的革命。</p>
  <p>从"打字输入关键词"到"语音描述完整问题"，从“筛选十几个链接”到“获得一个直接答案”，从“单次查询”到“多轮对话”，传统搜索引擎赖以生存的“关键词匹配+竞价排名”模式，正在被基于大语言模型的"语音对话+直接答案"模式快速取代。</p>
  <p>所以，传统搜索公司和ChatGPT一样，也处在两难之中。适应新的交互方式，那原本行之有效的商业模式就注定遭到破坏；但继续留在舒适圈吧，这个圈子的规模又肉眼可见越来越小。在这个新技术革命将来未来的转型期，他们只能自相矛盾、首鼠两端，但同时又坚定地走在钢丝上，钢丝对面，就是同样彷徨的ChatGPT。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/783XbwQStUY67vJ8om_xOw" rel="noopener noreferrer nofollow" target="_blank">“直面AI”</a>，作者：苗正，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612155215328002</id>
            <title>国产GPU，“围剿”英伟达</title>
            <link>https://www.36kr.com/p/3612155215328002</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612155215328002</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:19:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果说两年前的“H800禁售令”引发的是中国客户恐慌性的囤货狂潮，当英伟达再次交出一份全球营收创新高但中国区占比滑落至10%警戒线的财报时，市场的情绪已经从恐慌转为了冷漠。</p>
  <p>面对华尔街分析师关于“特供版芯片在中国市场订单不及预期”的尖锐追问，这位身穿标志性皮衣的CEO罕见地陷入了沉默。他试图用“复杂的监管环境”来搪塞，但所有人都听出了潜台词中的无力感。</p>
  <p>当为了合规而自我阉割的特供版芯片，在性能上被国产“新贵”们逼平，在价格上又因高昂的供应链成本而居高不下时。那个曾经只要在PPT上画出一张卡，就能让中国互联网巨头提着现金排队的时代，已经彻底终结了。</p>
  <h2><strong>精准的刀法与失衡的性价比</strong></h2>
  <p>英伟达再次推出针对中国市场的特供芯片H20时，其算盘打得极其精明：通过降低芯片的峰值性能以符合美国出口管制要求，同时保留高速互联带宽和CUDA生态的兼容性。在英伟达看来，这是中国客户在“算力饥渴”下的唯一解药。</p>
  <p>市场用脚投出的票，却给了这种傲慢一记响亮的耳光。为了满足美国对“算力密度”和“互联带宽”的双重限制，H20几乎被“阉割”得面目全非。这就导致H20在实际的大规模训练集群中，其有效算力甚至不如两年前囤积的H800。</p>
  <p>从技术逻辑上看，AI大模型的训练确实依赖高带宽，但推理和微调场景对算力密度的要求同样严苛。H20为了合规，将算力“阉割”到了H100的20%甚至更低，但其晶圆面积、封装成本并没有显著下降。</p>
  <p>这就导致了一个极其荒谬的TCO模型：中国客户需要购买比过去多出三倍甚至五倍数量的显卡，租用更大的机房空间，消耗更多的电力，搭建更复杂的网络拓扑，仅仅是为了达到两年前一张A100卡就能解决的算力水平。</p>
  <p>对于精打细算的中国互联网大厂和智算中心运营商来说，这笔账怎么算都是亏的。所以H20的渠道价格就开始出现松动，从最初预期的1.2万—1.5万美元高位，一路下探至10万元人民币左右，甚至在某些大单采购中出现了比昇腾910B还要低的价格倒挂。</p>
  <p>英伟达仿佛陷入了一个死循环：为了合规，必须降低性能；为了维持高毛利和应对复杂的供应链合规成本，价格无法大幅下调；而性能下降、价格坚挺的结果，就是彻底将中低端市场和推理市场拱手让人。</p>
  <p>这种局面的出现，并非英伟达技术不行了，而是竞争参照系变了。摩尔线程是这群新贵中最具代表性的一员。如果不说它是国产，你甚至会以为它是英伟达的某个“中国分部”。摩尔线程极度强调“全功能GPU”的概念。</p>
  <p>不仅能做AI计算，还要能做3D图形渲染、视频编解码。这种策略极其聪明地切入了英伟达的腹地，它不仅想替代A100/H100，还想替代RTX系列。在2024年到2025年的窗口期，摩尔线程的“夸娥”万卡集群解决方案开始在业界崭露头角。</p>
  <p>它解决了一个核心痛点：对于那些不想被生态完全绑定，又买不到满血英伟达的中型企业和科研机构来说，需要一个架构上更接近传统GPU、迁移成本更低的替代方案。摩尔线程的MUSA架构在设计之初就考虑了对CUDA代码的兼容性，大大降低了开发者的迁移门槛。</p>
  <p>其市值已悍然站上3000亿元人民币大关，成为“国产GPU第一股”在科创板站稳了脚步。摩尔线程从受理到过会仅用时88天，也创下了科创板的“闪电纪录”，对于一家成立仅5年的公司而言，这种“跑步上市”的盛况，在A股历史上极为罕见。</p>
  <p>与此同时，壁仞科技在港交所的招股进入最后冲刺阶段，拟募资额接近50亿港元。翻开招股书，这些“独角兽”的财务报表依旧是“鲜血淋漓”，基石投资者名单中也不乏顶级国资与险资的身影。</p>
  <h2><strong>国产算力不再仅仅是“备胎”</strong></h2>
  <p>二级市场给予的高估值，透支的是未来十年的预期。投资者赌的不仅是某一家公司的技术，更是赌在中国这个全球最大的半导体消费市场中，必然会诞生一到两家能与英伟达分庭抗礼的巨头。</p>
  <p>从昇腾910C在核心训练集群的规模化部署，到DeepSeek等头部大模型厂商公开为国产算力站台，中国芯片厂商不再是“备胎”，而是真正坐上了牌桌。对于面临巨大盈利压力的云厂商来说，继续迷信英伟达，就是对股东不负责任。</p>
  <p>字节跳动、阿里巴巴、腾讯等互联网巨头，在2025年的算力采购策略上表现出了惊人的一致性。不约而同地将英伟达的存量高端卡集中用于极少数超大模型的预训练，而在占据算力消耗80%以上的推理和微调环节，激进地引入国产算力。</p>
  <p>字节跳动在2025年的推荐算法集群中，非英伟达芯片的占比更是首次突破了40%。推荐算法可以说是字节跳动的利润奶牛，敢于在核心业务上动刀，说明国产芯片的稳定性已经通过了最严苛的实战考验。</p>
  <p>如果说商业逻辑的转变是水面上的波澜，那么制造环节的惊心动魄则是水面下的暗流。美国商务部在今年进一步收紧了对华出口HBM的限制。不仅是顶级的HBM3e，连基础版本的HBM3也被列入了严控范围。</p>
  <p>这对于试图追赶英伟达的国产GPU厂商来说，无异于釜底抽薪。没有HBM，高端GPU就是一块废硅。国产GPU厂商开始学会“看菜吃饭”，既然买不到最好的HBM，那就通过架构创新来弥补。</p>
  <p>摩尔线程和壁仞科技在2025年推出的新一代产品中，普遍采用了更大的片上SRAM缓存和优化的显存压缩算法，以降低对显存带宽的依赖。这种“穷人家的孩子早当家”的设计思路，虽然在极限性能上不如英伟达的暴力堆料，但在实际工程应用中却展现出了极高的效率。</p>
  <p>通富微电、长电科技等国内封测巨头，在国产2.5D封装技术上也取得了实质性突破。尽管良率初期惨不忍睹，但依靠国内庞大的市场需求进行“暴力迭代”，到了2025年第三季度，这一数字已经被拉升至40%—60%的区间。</p>
  <p>虽然与台积电90%以上的成熟良率相比仍显稚嫩，但这已经跨越了“商业化量产”的盈亏平衡点。这意味着，国产大芯片不再是实验室里的展品，而是可以源源不断流向数据中心的工业品。</p>
  <h2><strong>从“能用”到“好用”</strong></h2>
  <p>长期以来，英伟达最坚固的壁垒并非GPU本身，而是CUDA。那个让无数开发者“不得不爱”的软件生态，曾被认为是国产芯片不可逾越的天堑。这个庞大、复杂且极其好用的软件生态，像毒品一样让全球的开发者欲罢不能。</p>
  <p>在中国，过去十年的AI繁荣也是建立在CUDA之上的。因此，英伟达曾自信地认为：只要CUDA还在，中国客户就逃不出我的手掌心。但当“买不到”成为常态，依赖CUDA就变成了一种巨大的经营风险。</p>
  <p>对于中国企业而言，如果底层的算力基座构建在随时可能被切断的CUDA之上，那么上层的万丈高楼皆为虚幻。这种安全意识的觉醒，促使整个行业开始联手构建属于中国自己的软件标准。</p>
  <p>而这道天堑被填平的速度，超出了所有人的预期。以摩尔线程和壁仞为代表，通过兼容CUDA代码，降低迁移成本。摩尔线程的MUSA在2025年开发者大会上展示了惊人的兼容性，数万行代码的迁移时间被压缩到了小时级。</p>
  <p>在2025年，绝大多数算法工程师不再需要手写底层的CUDA算子。通过编译器技术的突破，开发者只需关注上层的Python代码，底层的适配工作由编译器自动分发到不同的后端，无论是Nvidia GPU，还是Ascend，亦或是海光DCU。</p>
  <p>技术层面的“去CUDA化”正在加速。百度飞桨、阿里通义千问、腾讯混元大模型，都在底层代码层面做了大量的适配工作。通过编译器优化、算子库重写以及自动转换工具，在主流的大模型训练和推理任务中，这种差距已经被缩小到了“可接受”的范围。</p>
  <p>这种“去底层化”的趋势，极大地降低了国产芯片的迁移门槛。更重要的是，围绕CANN形成了一个庞大的开发者社区。在GitHub和Gitee上，针对昇腾芯片的模型适配代码库数量在2025年呈现出指数级增长。</p>
  <p>除了在大模型训练端的厮杀，国产GPU开始渗透进渲染、数字孪生、云游戏等边缘市场。摩尔线程的“夸娥”千卡集群在数字人渲染上的应用，证明了GPU不仅仅只有AI这一条路可走。</p>
  <p>海光信息在2025年财报中也披露，其DCU产品在通算领域的生态兼容性已达到95%以上。</p>
  <p>当软件不再是瓶颈，硬件的性价比优势就会被无限放大。在占据市场90%份额的成熟模型训练和推理场景中，CUDA的“神谕”地位已经动摇。</p>
  <p>当然我们必须清醒地看到，“碎片化”依然是国产GPU的顽疾。海光有DCU，摩尔线程有MUSA，壁仞有BIRENSUPA……每一家都有一套自己的编程模型。对于下游软件开发商来说，适配这七八套系统简直是噩梦。</p>
  <p>2025年下半年，行业内开始出现整合的呼声。虽然物理层面的合并尚早，但软件层面的互通标准，例如OpenCL的某些国产化变体开始被提上日程。谁能统一这个破碎的江湖，谁就是下一个时代的盟主。</p>
  <p>2024年英伟达在中国市场的份额一度高达80%以上，而到了2025年底，这一数字被压缩至60%左右。这丢失的20%，是被“四小龙”硬生生啃下来的，但是对于这些芯片新贵而言，IPO敲钟的那一刻，才是真正残酷淘汰赛的开始。</p>
  <p>本文来自微信公众号“深观商业”，作者：深观商业，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612127193330180</id>
            <title>当AI开始制造神曲，腾讯音乐们还剩什么？</title>
            <link>https://www.36kr.com/p/3612127193330180</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612127193330180</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:19:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>把歌手挤下榜单的AI音乐，正在悄悄占领你得耳朵。</p>
  <p>每天通勤路上，酷狗音乐的资深用户田乐习惯性点开榜单，挑一首“新歌榜”或“飙升榜”里的作品当作背景音。但最近，他越来越觉得哪里“不对劲”。</p>
  <p>“歌词都很工整，甚至有些对仗工整得不自然；旋律像在哪儿听过，但完全记不住；更关键是，声音没什么情绪。”田乐说，他试着点击歌手名查看详情，结果大多是查无此人的“空号”，甚至一天能发布十几二十首歌。</p>
  <p>“我不是音乐专业，但我的直觉是这些歌是AI写的。”他的直觉正在成为一类人的共同体感，现实也验证了这一趋势。</p>
  <p>今年3月，程序员Yapie用DeepSeek模型与Make Best Music工具，只花了数小时，就完成了《七天爱人》的词曲创作。这首基于“暗恋到分手”的提示词生成的歌曲，上线网易云音乐后，播放量迅速突破200万，评论超4600条，跻身飙升榜、赏音榜，与毛不易、陈奕迅的作品同框。</p>
  <p>十八线音乐人拼尽全力无法战胜AI的调侃评价成为现实。《七天爱人》的版权最终售出数万元，将流量真实变现。这说明一件事，<strong>AI不再只是玩具，它正在改变音乐行业的商业逻辑。</strong></p>
  <p>在不被告知的情况下，大众已很难分辨一首歌是否出自AI。但对于音乐平台而言，这种模糊性正冲击其商业模式。一个供需关系正在变化：AI的创作效率，正将音乐曲库推向理论的“无限大”，而人类的消费时间与注意力，却始终是刚性有限的。</p>
  <p>AI迫使音乐平台的竞争逻辑，从过去“谁拥有最多版权”的资源竞赛，转向“谁能更有效分发播放量”的运营战争。决定平台未来走向的，不再是内容多少，而是注意力的分配效率。</p>
  <h2><strong>01&nbsp;赌出下一首跳楼机</strong></h2>
  <p>“当行业规则开始变化，先感受到冲击的，往往是从业者。”独立音乐人诺亚对「市象」说，他的创作已离不开Suno。“如果说两年前是恐惧和排斥，现在只想怎么用得更好。”</p>
  <p>这并非个例。2024年，Suno开始被广泛讨论。它生成的不是旋律片段，而是包含人声、歌词、编曲的一整首歌。这种创作方式，将音乐制作的门槛从“需要年限积累”降到了“只需要想象力”。</p>
  <p>其更新速度也在不断加快。Suno最新发布的V5模型，在音色、咬字、情绪等方面接近真实人声。它还推出了Suno Studio，内置多轨编辑功能，开始成为诺亚这样专业音乐人手中的一个效率工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_ab5735989b754a3e987dbc00695e7369@26875_oswg72777oswg1080oswg509_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>“它帮我节省了大量时间。”诺亚说。<strong>持续使用后，诺亚得出了结论：如果平台不加以限制，AI音乐才是最容易上榜的。“这不意味着AI做得更好，而是它更懂什么样的旋律洗脑、什么歌词易传播。AI比人类更懂‘榜单算法’。”</strong></p>
  <p>这个判断的背后，是音乐传播方式的变革。在短视频成为主阵地的时代，“流量即价值，爆款即成功”就算在音乐行业也已成共识。</p>
  <p>抖音数据显示，年曝光超十亿次的歌曲达6208首，且一首歌若能在抖音冷启动成功，达到周曝光超2500万，其在全网流媒体的播放份额占比可达35%-40%。短视频几乎定义了当下音乐爆款的形态，并裁决着它们的流行周期。</p>
  <p>AI音乐碎片化、高适配的特性，与短视频BGM需求完美契合，能迅速形成“创作-传播”的滚雪球效应。一首AI生成的“神曲”，可激发海量二创，其互动数据又被抖音算法实时捕捉，加速推荐，反哺歌曲热度。这种由大数据驱动的高效“测试-反馈”闭环，效率远超传统宣发。</p>
  <p>更底层的变革在于生产力。诺亚透露，已有公司在批量生产AI音乐，将其视为一场“概率游戏”。<strong>“AI实现了批量化、低成本生产。单曲成功率再低，凭借巨大基数，爆款出现的概率也被大幅提升，它们想赌出下一首《来财》或者《跳楼机》。”数量，本身已成为一种竞争优势。</strong></p>
  <p>虽然平台均设有AI审核规则，但审核成本也随Suno们的进化而陡增，且“人类使用多少AI算AI作品”的界限日益模糊。“平台或许能阻止小白蒙混，但阻止不了音乐人深度使用AI。”诺亚说。</p>
  <p>效率层面，人类已无胜算。AI的日产量可达上万首，人类唯一能做的，是制定规则。这意味着，AI带来了近乎无限的内容供给，但首页推荐位、用户注意力、播放量却是绝对的有限资源。曲库从1亿首膨胀到10亿首，对用户无意义，对平台则意味着筛选成本与分发压力的暴增。</p>
  <p>平台的终极考题或许正是在无限的供给中，如何分配有限的注意力？这不仅是技术问题，更是平衡听众体验、创作者权益与商业利益的复杂决策。</p>
  <h2><strong>02&nbsp;腾讯音乐们的“旧瓶装新酒”</strong></h2>
  <p><strong>内容产业的核心矛盾，始终是“供给过剩”与“注意力稀缺”。历史上，每一次渠道革新，像是流媒体取代唱片、Spotify横空出世等都创造了巨大价值，其本质是提升了内容与注意力的匹配效率。</strong></p>
  <p>面对AI掀起的“无限供给”海啸，国内平台展现出截然不同的应对姿态。</p>
  <p>腾讯音乐选择“开放通道，关闭收益”。它开辟AI音乐快速上传通道，将内容池迅速做大，但明确表示AI作品暂无收益。这像是一种“开源节流”的防御策略。一方面，避免海量AI内容过早冲击以“周杰伦们”为核心的、昂贵的版权变现体系，另一方面，试图牢牢掌握AI内容入库与商业化的最终定义权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_11e09856ba554871b2f198e2c42a4cd7@26875_oswg37226oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网易云音乐则扮演一种类似精品店的角色。它对上传者设定“露脸清唱”“提交工程文件”等审核条件，试图在源头阻断AI批量上传的可能。这种策略强调平台对“音乐品味”和“社区调性”的主动塑造，而非简单地扩张内容池。</p>
  <p>尽管策略不同，但这两家平台的出发点一致：它们的核心价值建立在版权稀缺之上。订阅付费模式能成立，是因为音乐的生产曾高度依赖歌手、唱片公司与专业制作流程；用户愿意为歌曲付费，是因为平台提供的是一份“正版内容的集中许可”。</p>
  <p>而AI，正在从根本上松动这个模型。用户不再需要等待艺人发片，可以直接用Suno生成一首当下想要的歌曲。</p>
  <p>起码就目前AI音乐“野蛮生长”的阶段而言，AI生成的音乐不依赖任何唱片公司、版权机构或商业授权（当然其中的版权争议还会持续存在），而背后的大模型公司其实也没有什么动力去限制版权，毕竟更多的生成才能收取更多的Token费用。</p>
  <p>当一首歌曲绕过了传统的生产机制，那么平台也无法围绕“版权”修筑竞争护城河。</p>
  <p><strong>“TME们的核心价值从来不是‘做音乐产品’，而是‘管理版权’。”</strong>诺亚认为。如果AI音乐能够以足够高的效率批量生产出媲美真人歌手的作品时，传统的版权价值将快速滑落。而过去十年围绕版权构建起来的商业秩序，也将随之失效。</p>
  <p>这种担忧不仅出现在中国。在全球范围内，旧体系的拥有者们已经试图为这场洪水划定新的河道。近期，美国三大音乐著作权集体管理组织ASCAP、BMI与加拿大的SOCAN，共同宣布将统一AI创作歌曲的登记规则，正式接纳“部分由AI生成、部分由人类创作”的作品进行版权注册。</p>
  <p><strong>这一动作的本质，是想让AI音乐这坛新酒，再装回这些传统版权巨头的旧瓶子里。</strong>它们试图将AI生成内容纳入其既有的法律与商业框架，确保无论一首歌的“基因”来自人还是机器，其价值的流转最终仍需经过传统的渠道进行计价与分配。</p>
  <p>目前来看，这场全球性的防御战效果如何，还是未知数。它可能为AI音乐建立合法的商业化出口，也可能因其复杂的规则而延缓创新速度。对于腾讯和网易而言，国际上的这一动向既是参考，也是压力。它们既需思考如何在自己的地盘上应对AI的冲击，也需观望全球规则的重塑将如何影响整个产业的利益格局。</p>
  <p>当传统平台的护城河受到冲击时，另一种完全不同的游戏规则正在被验证，就是被传统平台视为“搅局者”的汽水音乐，它没有历史包袱，似乎它从根源上就是为了驾驭无限供给而设计的。</p>
  <h2><strong>03&nbsp;字节的“定义权”战争</strong></h2>
  <p>在AI带来的无限供给面前，腾讯和网易的策略本质仍是“管控”：前者控制商业化出口，后者设定品味门槛。而汽水音乐的策略则截然不同。它不试图控制内容，而是试图定义“什么能火”。</p>
  <p>攻守之间，是各自对游戏规则底层逻辑的不同理解。</p>
  <p>AI音乐时代，单曲的版权价值不断被稀释，真正稀缺的是“流行的通道”，也就是分发所绑定的注意力。<strong>汽水音乐试图掌握的，不是音乐的归属权，而是下一首神曲形成路径的定义权。</strong></p>
  <p>音乐在汽水体系中的角色，不是作品本身的价值，而是短视频流量引擎的燃料。平台将流量倾斜给更易激发互动和二创的作品，用实时数据反馈定义热度排序。汽水不再是内容的管理者，而是流行歌曲的制造者。</p>
  <p>这套体系的运转从一个简单的动作开始：用户将一首AI生成的、节奏鲜明的片段用作短视频BGM。发布后，点赞、使用、分享数据被算法实时捕捉，一首歌能否流行，在几小时内就能得到市场最直接的反馈。</p>
  <p>成功者会触发海量二创，形成滚雪球效应，其热度又通过“前往汽水音乐听全曲”导流回音乐平台。这种“发布、测试、爆火、反哺”的闭环，是缺乏短视频场景的腾讯、网易这样的传统平台里需要漫长的周期来完成，但在字节的生态里，是以天甚至小时计的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_b37ea594db2a4745861cf06aefd58476@26875_oswg72816oswg1080oswg441_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另外在AI生产力层面，即时性是字节为“短视频配乐”这个场景量身定制的AI能力。不同于追求通用性的音乐大模型，内部如Seed-Music等项目，核心目标是解决一个具体问题：如何让AI生成的音乐，更贴合视频的情绪、节奏和转场。</p>
  <p>从自身最核心业务需求倒推出来的研发，让产出的工具与内容，与抖音创作者的需求天生契合。它生产的不是艺术歌曲，而是一段能精准点燃画面情绪的素材，正如开头提到的那首《七天爱人》。</p>
  <p>在这个高效的内部循环里，发现、创作、传播、消费的链条，在一个体系内被打通。AI音乐生成未来可以直接嵌入抖音的创作流程，视频的爆火又为汽水音乐带来用户。</p>
  <p>汽水音乐的商业模式，也天然适配这一逻辑。它采用“免费听歌+广告解锁”的运营模型，延续了字节系如番茄小说、红果短剧一脉相承的注意力变现方式。在AI带来的海量供给面前，平台无需承担高额版权支出，运营边际成本大幅下降。</p>
  <p>近期，汽水音乐在官网的一系列动作，更是将这场“定义权”之争推向了明面。它通过官方教程引导用户“无逢迁移网易云歌单”，不仅对标产品体验，更直接拆解用户转移的技术壁垒。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_de4da9db9b2742fca391f060b91d6766@26875_oswg125892oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在音乐平台的用户资产中，歌单是最具粘性的用户喜好和内容沉淀。这个动作恰恰说明在版权因AI供给而贬值的未来，汽水似乎更有自信能够为用户提供最无缝的体验、最低的决策门槛，掌握珍贵的分发权。</p>
  <p>当其他平台仍在思考如何“容纳”AI音乐时，字节的体系已在高效地消化和利用AI音乐，为其整个内容生态供能。</p>
  <p>不过当算法热衷于推广《跳楼机》这类易于传播的“电子快餐”，像周杰伦、陈奕迅作品那样的“细糠”是否会被淹没而消失？对此，诺亚倒不这么认为。“这是一种对新事物的抗拒和杞人忧天式的担心，优秀的歌曲不可能消失，真正会发生的是，未来的周杰伦和陈奕迅们也开始用AI写歌。”</p>
  <p>在他看来，AI对行业最深刻的改造，或许不是淘汰，而是“工具化”的全面渗透。顶尖音乐人将利用AI快速尝试旋律变奏、优化编曲细节、甚至探索新的音色组合，将重复性劳作交给机器，从而更专注于创意与情感的“神韵”。</p>
  <p>诺亚的想法不无道理，或许这并非妥协，而是在新的生产力浪潮中，保持领先的理性选择。“相较于坚持孤身一人逆流游泳，驾驭浪潮，才是更可能到达彼岸的方式。”</p>
  <p>商业世界的转折点，往往以旧势力与新玩家的和解为标志。AI音乐初创公司Suno估值已超200亿美元，用户量千万级。曾对其提起诉讼的华纳音乐、环球音乐集团均已撤诉，并转向战略合作，内容涵盖曲库授权、声音肖像及合规框架。</p>
  <p>在不可避免的AI音乐生态中，或许所有平台都需重新寻找自己的位置。</p>
  <p>（文中人物为化名）</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/f9hXVif4FF7ywClyZ8f6Ag" rel="noopener noreferrer nofollow" target="_blank">“市象”</a>，作者：王铁梅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612136338670848</id>
            <title>买美元理财的人，本金都亏了？</title>
            <link>https://www.36kr.com/p/3612136338670848</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612136338670848</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:19:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“买美元理财近1年，不仅亏了全部收益，本金还亏了近1000元。忍痛结汇了，亏损就当交学费了。”在北京工作的田峰（化名）告诉中新经纬。&nbsp;</p>
  <p>25日，离岸人民币兑美元升破7.0大关，创2024年9月底以来新高；在岸人民币兑美元最高升至7.0053，距离“破7”仅一步之遥；美元指数也跌破98。像田峰一样在今年初高位换汇并购买美元理财的投资者，正面临汇兑损失吞噬利息收益甚至本金的困境。&nbsp;</p>
  <h2><strong>“折腾一年，亏损近千元”</strong></h2>
  <p>今年2月，家住上海的侯先生在东亚银行办理了一笔美元定期存款业务。侯先生坦言，彼时美元走势相对强势，叠加人民币存款利率持续下行，在了解到美元存款的相关产品后，便决定入手。&nbsp;</p>
  <p>“当时我用20万元人民币换美元，购汇汇率为7.297（即1美元可兑换7.297元人民币），选择的一年期美元定存产品年利率为4.4%。眼看这笔存款马上就要到期了，人民币兑美元汇率已经回升到7附近。”侯先生说道。&nbsp;</p>
  <p>东亚银行手机App显示，12月26日10时20分左右，该行美元现汇买入价（即客户将美元卖给银行时银行的报价）为6.9752。相较购汇成本，侯先生持有的美元账面贬值约4.41%。也就是说，汇率的损失已抵消了这笔美元存款的利息收益。“目前存款还有两个月到期，届时再看看汇率会不会回升。”侯先生表示，如果没有回升，会继续持有，购买美元理财产品。&nbsp;</p>
  <p>另一位投资者田峰在这个月将手中的美元全部兑换成了人民币，从年初至今，这笔投资共亏损987.02元。&nbsp;</p>
  <p>田峰表示，今年1月，他通过工商银行手机App购汇11000美元，交易汇率为7.3608，共支付人民币80968.8元。之后，他买入了一只美元理财产品，当时该产品成立以来年化收益率达5.1%。&nbsp;</p>
  <p>工商银行手机App显示，截至2025年12月23日，该产品近一月年化收益率为3.6%，近一年年化收益率4.17%。&nbsp;</p>
  <p>田峰称，不仅收益率不及预期，今年以来美元指数也在持续走低。9月，他将其中的5600美元理财卖出并结汇，成交汇率是7.1324，兑换人民币39941.44元。12月中旬，他将剩余的5672.16美元也进行了结汇，成交汇率只有7.0591，兑换人民币40040.34元。&nbsp;</p>
  <p><strong>“折腾一年，还亏了将近1000元。”</strong>田峰感叹道。&nbsp;</p>
  <p>中国外汇投资研究院研究总监李钢在接受中新经纬采访时表示，不少投资者只看到了美元存款和理财的名义收益率，却忽视了汇率波动带来的“隐性风险”。当人民币出现升值时，即便美元资产本身有4%左右的利息收益，也可能被汇率损失完全抵消，甚至出现账面亏损。&nbsp;</p>
  <h2><strong>人民币汇率如何走？</strong></h2>
  <p>2025年人民币兑美元汇率整体呈先抑后扬、震荡走强的走势。年初人民币汇率承压，离岸人民币兑美元汇率在2025年4月一度贬破7.40，之后触底反弹，今年下半年稳步升值。11月下旬以来，人民币兑美元加速升值，12月25日离岸升破7.0关口至6.996，创逾一年新高。截至12月26日发稿时，今年以来，在岸人民币兑美元累计升值约4%，离岸人民币兑美元升值约4.5%。&nbsp;</p>
  <p>据中国人民银行官网，中国人民银行货币政策委员会2025年第四季度例会于12月18日召开。会议认为，增强外汇市场韧性，稳定市场预期，防范汇率超调风险，保持人民币汇率在合理均衡水平上的基本稳定。&nbsp;</p>
  <p>李钢指出，今年人民币兑美元升值，并不是单一因素推动，而是多重力量叠加的结果。首先，从外部环境看，<strong>美联储货币政策已经进入明确的转向阶段，市场提前定价未来降息路径，美元指数整体走弱，为非美货币提供了升值空间。</strong>其次，中国经济在年内呈现“弱复苏但稳预期”的特征，出口韧性、经常账户顺差以及跨境资金流动改善，对人民币形成基本面支撑。第三，年内市场对人民币的情绪发生了明显修复，前期过度贬值预期被逐步纠正，结汇需求上升，也放大了阶段性升值幅度。&nbsp;</p>
  <p>民生银行首席经济学家温彬12月25日在微信公众号“民银研究”撰文指出，近期人民币升值加快主要受如下几方面因素支撑：一是美元指数走弱，二是出口保持韧性，三是人民币资产吸引力提升，四是监管引导汇率升值见成效。&nbsp;</p>
  <p>对于后续人民币汇率走势，温彬预计，国外方面，美元指数在降息周期下或呈弱势走势，国内方面，出口对汇率的支撑作用或减弱，但证券投资的支撑作用会进一步增强。预计2026年人民币汇率大部分时间或将保持在6.9-7.3区间双向波动。&nbsp;</p>
  <p>英大证券首席经济学家郑后成在微信公众号“郑后成宏观研究”上发布的文章中认为，在经历长达2年半左右的“筑底”阶段后，<strong>人民币汇率大概率在2026年迎来升值的“主升浪”</strong>。&nbsp;</p>
  <p>“综合中美两国宏观经济基本面的相对变化，中美两国利差收窄的走势，以及美元指数的下行趋势，叠加考虑人民币汇率3到4年左右的周期性，我们认为2026年人民币汇率大概率稳步升值。参照以前两轮人民币汇率升值的经验，本轮人民币汇率升值进程有可能延续至2027年，升值的终点可能触及6.20-6.30这一区间。”郑后成表示。&nbsp;</p>
  <p>在李钢看来，明年人民币汇率大概率呈现“宽幅波动中的双向调整”，而不是单边升值或贬值。从中期看，美联储进入降息周期、美元中枢下移，有利于人民币稳定甚至阶段性偏强运行；但与此同时，全球经济不确定性仍在，地缘政治、贸易政策变化也会带来扰动。因此，人民币更可能在一个合理区间内（波动中枢可能较今年上移）双向波动，政策层面仍将以“防止单边预期、自主可控”为核心目标。<strong>对企业和投资者而言，应逐步适应人民币汇率弹性成为常态，而不是押注方向。</strong></p>
  <p>对投资者而言，李钢建议：第一，不要简单用利率高低来决定币种配置，必须将汇率波动纳入整体收益评估；第二，外币资产更适合作为资产配置的一部分，用于分散风险，而非短期博取收益；第三，如果没有明确的外币负债或外币支出需求，盲目集中配置单一外币，反而容易在汇率波动中承受不必要的风险。&nbsp;</p>
  <p>文中观点仅供参考，不构成投资建议，投资有风险，入市需谨慎。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NDU5OTAzMA==&amp;mid=2247599995&amp;idx=1&amp;sn=62eaf245c77d8830cb4c0803ef82ecd1&amp;chksm=e85b03fd1a376851771af2960abc02292b27939f5b68ec394f42211bed51ba32cdf422e9a5c8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“中新经纬”（ID：jwview）</a>，作者：魏薇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612158628512771</id>
            <title>Meta公布“超级智能”新进展：无需人类，软件Agent即可自我训练</title>
            <link>https://www.36kr.com/p/3612158628512771</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612158628512771</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:18:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近年来，基于大语言模型（LLMs）的软件工程智能体发展迅速，但其训练数据和训练环境仍高度依赖人类知识和人工策划，本质上是在复现人类开发轨迹，难以自主发现新的问题结构与解决策略，这从根本上制约了智能体迈向超级智能的能力。</p>
  <p>基于此，来自Meta、伊利诺伊大学厄巴纳-香槟分校的研究团队提出 Self-play SWE-RL（SSR），作为软件工程智能体训练范式的第一步。该方法对数据假设的要求极低，<strong>仅需访问包含源代码和已安装依赖项的沙盒化代码仓库，无需任何人工标注的问题或测试用例</strong>。</p>
  <p>研究表明，智能体可以从真实世界的软件仓库中自主获取学习经验，<strong>有望催生在系统理解、解决全新问题以及从零开始自主创建软件等方面超越人类能力的超级智能系统</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_33df569f69fa4311899f592bfcbf9519@000000_oswg110739oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://arxiv.org/pdf/2512.18552</p>
  <h2><strong>Self-play SWE-RL 框架</strong></h2>
  <p>SSR 的设计原则是<strong>减少对代码库先验知识的依赖</strong>，以提升方法的通用性与可扩展性。它不依赖于特定环境的预配置，智能体要通过与环境的交互，自主探索测试的运行方式并理解其结构。该极简输入设定使 SSR 几乎无需额外配置即可应用于不同代码库，显著降低了使用与迁移成本。</p>
  <p>SSR 的核心是<strong>通过自博弈式的迭代循环，使智能体在不断生成与解决 Bug 的过程中实现自我提升</strong>。在 SSR 中，同一 LLM 策略被划分为两个协同演化的角色，分别是智能体 Bug 注入与智能体 Bug 求解，二者共享参数但承担不同任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_652027c17ca341ff8897f04bae42339b@000000_oswg34422oswg1080oswg261_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图| SSR 的总体框架</p>
  <h3><strong>1.智能体 Bug 注入</strong></h3>
  <p>智能体 Bug 注入通过<strong>让模型扮演“破坏者”构建起自驱动的进化闭环</strong>。</p>
  <p>在这一过程中，首先生成包含 Bug 补丁和弱化测试的 Bug 构件，将抽象错误转化为标准化的练习题；随后，运用“删除关键代码”或“回滚历史修复”等复杂生成策略，从真实工程逻辑中制造出极具挑战的高质量难题；为了确保逻辑严密，系统利用“逆向变异测试”进行严格的一致性验证，剔除无关干扰并确保错误可复现；最后，通过动态奖励机制将任务难度维持在“跳一跳才够得着”的区间，并将修复失败的尝试转化为高阶缺陷循环利用，从而在无需人类标注的情况下，驱动智能体在博弈中不断实现自我超越。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_27f1f56385ea4c9785c048abd9f4b8c1@000000_oswg226305oswg1080oswg364_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图| 智能体 Bug 注入中“删除关键代码”和“回滚历史修复”的策略</p>
  <h3><strong>2.智能体 Bug 修复</strong></h3>
  <p>智能体 Bug 修复通过在沙盒中应用缺陷补丁并重置 Git 历史来构建防作弊的代码现场，确保模型无法走捷径。随后，以弱化测试的逆向补丁作为任务提示，取代人类的文字描述，迫使代理纯粹基于代码逻辑定位问题。在修复过程中，智能体通过“推理与工具调用”的交互循环，在模拟环境中自主进行补丁尝试与验证。最终，系统通过回滚原始测试文件的评估机制进行严苛复核，确保生成的 Bug 在真实测试下依然有效，从而完成从理解考题到提交正确答案的闭环。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_aa2a1b27b2b04674afc3652ab8e8e9a8@000000_oswg52206oswg1080oswg140_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图| 智能体 Bug 修复的流程</p>
  <h2><strong>实验结果</strong></h2>
  <p>研究人员在 SWE-bench Verified 与 SWE-bench Pro 上，对基础模型、基线强化学习方法以及 SSR 进行了系统比较。</p>
  <p>实验结果表明，即使在完全不接触任务描述和测试数据的情况下，SSR 仍能在训练过程中持续实现性能提升，验证了 LLM 仅通过与真实代码库交互即可增强其软件工程能力。更重要的是，SSR 在整个训练轨迹上始终优于基线 RL，说明<strong>由模型自主生成的任务相比人工构造的数据，能够提供更具信息量和有效性的学习信号</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a709e3f525db43b494bf61bdf113e3df@000000_oswg134469oswg1080oswg387_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图| 训练过程中的基线比较</p>
  <p>研究人员比较了完整的 SSR 与仅进行 Bug 注入或仅进行 Bug 修复的两种变体。</p>
  <p>实验结果表明，完整的自博弈框架性能最优，而单一注入或修复训练均表现不足，前者缺乏从修复过程中的学习，后者受限于静态任务分布。相比之下，自博弈通过同时生成与修复 Bug，使任务分布随训练动态演化，持续提供更丰富的学习信号，从而实现稳定的性能提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_5d9c880de6014a37b4bb5ec67f67b0a1@000000_oswg111864oswg1040oswg296_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图| Self-play Swe-RL的消融研究</p>
  <h2><strong>不足与未来展望</strong></h2>
  <p>尽管 SSR 在减少人工依赖、实现自我提升方面展现出潜力，但仍处于早期阶段。当前方法依赖显式测试作为判定器，存在奖励投机的潜在风险。同时，验证机制主要基于单元测试，难以覆盖真实软件工程中的高层目标与复杂语义。此外，Bug 注入与修复角色共享同一模型配置，尚未系统探索模型规模、结构差异及角色分离对自博弈学习的影响。</p>
  <p>此外，研究人员还探索了若干未取得理想效果的方向，例如，自然语言 issue 生成受限于模型能力与奖励设计，难以保证质量与多样性；仓库专用训练因数据多样性不足未能带来收益；而训练不稳定性则成为限制 SSR 进一步扩展的重要瓶颈。</p>
  <p>展望未来，SSR 为自博弈驱动的软件工程智能体打开了多个研究方向，包括通过种子机制控制错误分布、合成更复杂的多步软件任务，以及设计适用于长周期软件开发的高效训练范式。尤其是在<strong>奖励稀疏、决策链条极长的真实工程场景中，如何引入更密集、结构化的反馈，将是释放自博弈潜力、迈向更高层次智能的关键</strong>。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247601592&amp;idx=1&amp;sn=4af68c6b92aa7f7d9439d963b141d056&amp;chksm=cee9d74e58f57813b21a5a973c6638c03f96e26c635ab573d77423890533b44e65a72a823faf&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“学术头条”（ID：SciTouTiao）</a>，整理：潇潇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612165190255621</id>
            <title>2025年AI的温柔转身：从颠覆行业到生活“缝补匠”</title>
            <link>https://www.36kr.com/p/3612165190255621</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612165190255621</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:04:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>站在2025的年尾回望，这一年的AI世界恍如一场快进的科技叙事。</p>
  <p>年初， DeepSeek凭借高效推理迅速出圈，Meta则持续深耕开源生态；在算力受限的环境下，中国模型厂商用惊艳的算法优化能力，交出了令人瞩目的答卷。</p>
  <p>9月云栖大会上，阿里云重磅发布Qwen3系列，万亿参数级别的Qwen3 Max正式亮相，明确将其定位为“AI 时代的 Android”，拉开了生态竞争的序幕。</p>
  <p>到了年末，巨头们的角逐进入白热化，AI 行业完成了从单点技术突破到全生态构建的关键一跃。大模型赛场从单纯比拼参数，转向追求极致效率；智能体则告别概念演示，迈入规模化落地的新阶段。</p>
  <p>而当行业巨头在生态赛道上激烈角逐时，AI技术也早已悄悄渗透到生活的肌理。</p>
  <p>Nano Banana的AI生图让“一句话唤醒创意画布”成为全民触手可及的日常，灵光的 “全民开发”生态让普通人零门槛搭建专属闪应用，年末豆包手机的登场，更让智能体验无缝融入掌心。</p>
  <p>那些曾刷屏热搜的技术突破，如今想来竟已沉淀出时光的质感，仿佛一场热闹的技术盛宴过后，AI终于放慢了追逐概念的脚步，稳稳走进了普通人的日常。</p>
  <h2><strong>从屏幕到脚步：AI让视障者与世界无缝相拥</strong></h2>
  <p>70岁父亲因脑血管疾病偏瘫失语后，毛强的日子就陷在了一场无休止的“猜谜游戏” 里。</p>
  <p>老人微微抬一下手，他就得凑近了猜：是渴了想喝水？还是觉得屋里冷？又或是电视声音太吵？猜错的瞬间，父亲憋得满脸通红，急得一下下拍着轮椅手柄的样子，总让毛强心里发酸。</p>
  <p>直到2025年的冬日，一款叫“灵光”的AI应用，轻轻缝补好了这道沟通的裂缝。</p>
  <p>毛强用灵光AI手搓了一个极简的“小话筒”，几个色彩鲜艳、字号巨大的按钮清晰标注着“上厕所”“想睡觉”。当老人颤抖的指尖落在按钮上，清脆的合成语音便替他说出了藏在心里的话。那一刻，毛强悬了许久的心，终于落了地。</p>
  <p>毛强的经历并非孤例。这份由AI编织的温暖，并非只停留在一户家庭的客厅里。根据灵光官方数据：上线仅1个月，用户已成功创建1200万个闪应用。</p>
  <p>“你是我的眼，带我领略四季的变换；你是我的眼，带我穿越拥挤的人潮……”这段流传甚广的歌词，在 2025 年的全球语境下，正在从一种文学修辞转变为扎实的技术现实。让这份温暖照进现实的，正是斩获2025年度文化影响力奖的App——Be My Eyes。</p>
  <p>这款由视障人士汉斯·约根·维伯格（Hans Jørgen Wiberg）为解决自身需求而开发的工具，截至去年12月，已覆盖全球上百个国家，汇聚了超过820万名明眼志愿者与74万名视障用户。</p>
  <p>Be My Eyes在2025年最大的质变在于全面尝试接入了GPT-4o。在此之前，视障用户需要等待志愿者接听视频，而现在，日常决策的效率被大大提高。</p>
  <p>在官方发布的宣传视频中，一名盲人打开应用，不再是等待哨声响应，而是直接与GPT-4o对话。他转动摄像头，AI便用极其自然的人声详细告诉他眼前的景象：“你左手边是一件深蓝色的羊绒衫，右手边是浅灰色的，灰色这件领口稍微有一点褶皱。”</p>
  <p>通过这种实时的视觉描述，用户能够瞬间做出决策，而不必担心深夜打扰到远在另一个时区的志愿者。</p>
  <p>同样的温暖也出现在深圳黄木岗交通枢纽。2025年12月13日，智能导盲犬“小蒜”正式试点。它集成了视觉语言大模型与3D体素神经网络，视障乘客通过口头指令即可激活路径规划。</p>
  <p>“它就像我的眼睛，”体验者郭女士说。而另一位体验者看重的是它的专注：“它不会被火腿肠香味勾走，也不会因为别的狗吠而分神。” AI在这里缝补了公共交通中的“最后一公里”，让视障人士能像普通人一样从容地穿过地铁迷宫。</p>
  <p>目前，深圳地铁已在黄木岗枢纽13、14出口旁的垂直电梯处设置了服务点。这种通过“视觉语言大模型”驱动的导盲服务，正在填补人工引导无法覆盖的24小时空白。它并没有“重塑”交通，它只是让一个看不见的人，能像普通人一样从容地迈出家门。</p>
  <h2><strong>跨越城乡边界，AI让公平之光照进课堂与病房</strong></h2>
  <p>在2025年，豆包推出的AI英语外教Owen已经悄然陪伴了超过700万人次在线练习口语。这是一个极具张力的场景：在偏远的山区，一个留守儿童对着屏幕里耐心、永远不会疲倦的Owen大声朗读单词；而在城市的另一端，一个报不起高昂补习班的孩子，同样拥有了一位24小时随叫随到的专属“私教”。</p>
  <p>在贵州石阡困牛山红军学校，希沃（Seewo）提供的一个小小的算力“盒子”，正在让普通教室变身为实时响应的AI空间。它不再需要老师去手动录入烦琐的成绩数据，课后自动生成的深度反馈报告，能精准指出每个孩子的薄弱环节，帮助乡村老师像特级教师一样优化教学策略。</p>
  <p>在甘肃会宁的黄土地上，快手公益捐建的数字教室则在缝补孩子们关于“梦想”的想象力。利用可灵AI的生成能力，乡村里的孩子第一次将脑海里的画作变成了流动的动画，甚至亲手编写代码指挥无人机掠过麦田。</p>
  <p>截至2025年底，已经有超过1.4万名像会宁学子一样的乡村学生，通过这类数字教室第一次触碰到了大模型时代的前沿科技。</p>
  <p>医院里的资源缺口，也被AI慢慢补齐。浙江的医院里，AI医生分身能在线解答老人的高血压用药疑问，还能提醒定期复查的时间。</p>
  <p>蚂蚁的阿福，能回答健康医学疑问，能解读报告，还能生成运动打卡计划。它像医生朋友、私人营养师、运动教练，一对一与用户对话，做到一人一策、量身定制。</p>
  <p>中国电信贵港分公司与贵港市人民医院携手打造的贵港市AI医学影像远程诊断云平台，更让偏远患者受益。来自数十公里外乡镇卫生院的CT影像，能瞬间呈现在三甲医院的专家眼前。至今已完成3000例辅助诊断，真正实现“数据多跑路，群众少奔波”。这些不显眼的小功能，成了很多家庭的“定心丸”。</p>
  <p>这就是2025年AI最真实的切片。AI正化作温柔的“缝纫工”。用精准的算法、贴心的设计，将偏瘫老人的沟通裂缝、视障人士的出行阻碍、乡村孩子的教育鸿沟，一一缝补进更顺畅、更从容的日常图景里。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU5MTczNjIyNA==&amp;mid=2247608589&amp;idx=1&amp;sn=4644909965bf1cd1e79a2a088f3a5eb4&amp;chksm=ff64b662e82ad99a34f1b0c1cf5d6f717b913cc889019b1d730defa20234fab97bdc4cc6fd5e&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“Tech星球”（ID：tech618）</a>，作者：任雪芸，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612186454721798</id>
            <title>模拟芯片涨价，已是实锤</title>
            <link>https://www.36kr.com/p/3612186454721798</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612186454721798</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 10:03:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“最高涨30%！”，<strong>亚德诺半导体</strong>（ADI）的一纸涨价通知，彻底击碎了行业对“模拟芯片是否回暖”的最后一丝疑虑。当头部玩家相继按下调价按钮，这场从2025年下半年开启的涨价潮，已然从零星信号演变为确定性趋势。</p>
  <h2><strong>模拟双雄，相继调价</strong></h2>
  <p><strong>TI</strong>（德州仪器）和ADI作为全球模拟芯片领域的双雄，下半年来纷纷释出涨价信号。</p>
  <h3><strong>TI，打响涨价连环枪</strong></h3>
  <p>今年6月，TI正式启动覆盖3300余款料号的全球性涨价计划，此次涨价并非仅针对中国区，而是一次全球性的价格调整。据内部邮件及代理商确认的涨价目录，此次调价呈现金字塔式分布：约<strong>9%</strong>的料号涨幅突破<strong>100%</strong>，主要集中于停产料号或极低利润产品；<strong>55%</strong>的料号涨幅落在<strong>15%-30%</strong>区间；另有<strong>30%</strong>的料号涨幅低于<strong>15%</strong>。</p>
  <p>值得注意的是，信号链产品为本轮涨价的核心标的，其中ADC（模数转换器）、运算放大器等关键品类部分型号涨幅超100%，远超市场预期。而前期因价格战降价幅度较大的隔离芯片、LDO（低压差线性稳压器）及DC-DC转换器等产品，则以20%左右的涨幅符合行业预期。</p>
  <p>国际投行伯恩斯坦的研报印证了这一数据，其指出TI在6-7月间对多款模拟器件实施了高达30%的工艺价格上调，部分数据转换器产品价格甚至翻倍。</p>
  <p>随后在8月，TI开启新一轮涨价潮，型号涉及6万多个产品料号，幅度远超第一波，重点涉及工控类、车载类、以及消费电子与通信设备等相关芯片产品，还覆盖&nbsp;LDO(低压差线性稳压器)、DC-DC(直流&nbsp;-&nbsp;直流转换器)、数字隔离、隔离驱动等品类。如果说6月是聚焦低毛利老料号的试探，那么8月便是针对全品类大规模提价。</p>
  <h3><strong>ADI，开始调价</strong></h3>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_f8409b5e6cf4425b86551957f5dad6d4@000000_oswg576091oswg1080oswg908_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近日，ADI也向客户正式发出了涨价通知，计划于2026年2月1日起对全系列产品实施价格调整。与以往“一刀切”的涨价模式不同，ADI此次采取了针对不同客户层级及料号的差异化调价方案。据公司内部消息及业内人士透露，普通商用级产品涨幅普遍在10%-15%之间，工业级产品涨幅约15%，但其中近千款军规级MPNs产品（后缀/883）的涨幅或将高达30%。</p>
  <p>根据ADI的涨价通知，新的价格体系将适用于所有未发货的订单。对于已经发货的订单，则仍按原价执行。这一安排旨在减少对现有合同和客户关系的冲击，同时确保价格调整的平稳过渡。</p>
  <p>两家巨头的涨价动作，早已在近期财报中埋下伏笔。</p>
  <p>2025年上半年，模拟双龙头TI和ADI营收分别达85.17亿美元、50.63亿美元，同比增长13.82%、8.38%，远超此前业内预期。TI表示订单水平已恢复到正常复苏期的预期水平。</p>
  <p>随后在Q3，ADI营收为&nbsp;28.8&nbsp;亿美元，同比增长24.7%，高于分析师预测的&nbsp;27.7&nbsp;亿美元。得益于其工业领域的需求增长，ADI实现了良好的订单预订趋势和订单积压量的增长，因为制造商们在面对美国关税政策的变化时提前发货。具体到数据方面，工业部门的营收占公司总销售额的&nbsp;45%，达到&nbsp;12.9&nbsp;亿美元。ADI预测Q4营收为&nbsp;30&nbsp;亿美元，上下浮动&nbsp;1&nbsp;亿美元，高于分析师预测的&nbsp;28.2&nbsp;亿美元。</p>
  <p>TI Q3营收达47.42亿美元，同比上升14.2%，环比增长6.6%；净利润13.64亿美元，同比持平，环比增长5.3%；从终端市场来看，工业领域依旧是公司增长主力，本季度同比上升约25%；汽车市场则延续稳健态势，同比高个位数增长；通信设备市场表现尤为强劲，同比增长超过45%，这意味着数据传输及基站相关器件需求显著反弹。不过，TI对第四季度指引偏谨慎，预计营收42.2–45.8亿美元，环比下降约7%。</p>
  <h2><strong>此次涨价，聚焦那些产品？</strong></h2>
  <p>从市场表现来看，工业控制、汽车电子、AI相关及通信领域的核心芯片率先走出低谷，这三大领域也是上述两家公司的核心战场。</p>
  <h3><strong>工业控制，需求激增</strong></h3>
  <p>目前，工业自动化正经历从“单机控制”向“智能边缘+集中调度”的范式转变，PLC（可编程逻辑控制器）、工业网关、传感器融合系统对高精度模拟前端芯片的需求急剧上升。其中，高精度ADC、隔离运放及RS-485/Can总线接口芯片成为本轮涨价的先锋品类，部分料号涨幅突破30%。</p>
  <p>在新一代分布式控制系统（DCS）中，对温度、压力、振动等物理量的采集精度要求已普遍进入16位甚至24位ADC范畴，带动TI的ADS系列、ADI的AD7124等高端ADC持续满载。与此同时，功能安全标准的普及也使得隔离类器件需求激增——数字隔离器、隔离电源、隔离ADC等成为关键组件，不仅单价提升，配套用量亦显著增加。</p>
  <h3><strong>汽车芯片，重点战场</strong></h3>
  <p>在汽车电动化、智能化、网联化趋势下，新能源汽车中的BC、BMS、电机控制 驱动、车载影音娱乐、车载照明等都带动了对模拟芯片持续的需求。其中车规级PMIC、BMS（电池管理系统）隔离芯片等品类均为本轮涨价浪潮的重点。</p>
  <p>BMS隔离芯片是新能源汽车的核心安全器件，负责实现电池包与整车控制器的电气隔离，保障充电与放电过程的安全稳定，随着动力电池能量密度提升与快充技术普及，对其精度与耐压性能的要求不断提高，推动高端产品需求增长。TI也在8月第二波涨价中重点上调BMS隔离芯片的价格。</p>
  <p>车规级PMIC广泛应用于汽车智能座舱、自动驾驶、车身电子、仪表及娱乐系统、照明系统等场景。按产品，PMIC主要可分为AC/DC、DC/DC、LDO、驱动芯片、电池管理IC等。随着域控制器架构普及，LDO与多相DC-DC转换器需满足功能安全要求，TI的TPS7A系列、ADI的LTpower系列产品成为主流设计首选。由于晶圆产能仍集中在8英寸产线，扩产难度大，导致代工厂如世界先进（VIS）、稳懋（Win Semiconductors）的模拟专属制程排单紧张，进一步支撑价格坚挺。</p>
  <h3><strong>通信市场，值得押注</strong></h3>
  <p>通信市场方面，5G基站的建设带动基站射频前端、电源管理与接口芯片需求回升。特别是光模块升级至800G后，对TI与ADI提供的限幅放大器（Limiting Amplifier）等模拟组件提出更高带宽与更低功耗要求，相关料号价格保持稳定甚至小幅上调。</p>
  <p>Q3，TI通信设备市场表现尤为强劲，同比增长超过45%，环比增长10%，数据传输及基站相关器件需求显著反弹，部分受益于AI训练网络扩张与高速互联器件需求增长。TI表示已将数据中心列为重点投入方向之一，认为该市场将在2026年及以后贡献更大份额。</p>
  <h2><strong>台系模拟IC设计，看法两极化</strong></h2>
  <p>部分&nbsp;IC&nbsp;设计厂商坦言，若头部大厂顺利上调产品价格，中小厂商面临的压价压力或将得到一定缓解。但更多从业者指出，模拟&nbsp;IC&nbsp;品类繁杂，ADI、TI&nbsp;此番涨价的产品，与中小厂商深耕的应用领域和目标市场未必直接重叠，对整体市场价格走势的影响暂时有限。</p>
  <p><strong>致新、茂达、通嘉、伟诠电子</strong>等中国台湾&nbsp;IC&nbsp;设计企业，长期聚焦PMIC、UDB-PD&nbsp;芯片及马达驱动芯片赛道。作为模拟&nbsp;IC&nbsp;领域的风向标，TI&nbsp;与&nbsp;ADI&nbsp;的价格波动，始终牵动着市场对这批中国台湾厂商后市表现的预判。不过台系厂商早已明确表态，产品定价需结合具体品类与应用场景具体分析——“<strong>TI&nbsp;和&nbsp;ADI&nbsp;能涨价，不代表台系厂商就能跟风”</strong>。</p>
  <p>对中小厂商而言，还需综合权衡多重现实挑战：自身技术实力与产品可靠性能否比肩大厂、如何抵御新晋玩家低价抢单的冲击、以及在市场份额与利润空间之间如何取舍，这些因素都将对其定价策略产生关键影响。</p>
  <p>中国台湾模拟&nbsp;IC&nbsp;厂商直言，TI&nbsp;调价向来以自身经营需求为核心，无需过多顾及同业竞争态势；而此次&nbsp;ADI&nbsp;跟进调整价格，或许正折射出整个&nbsp;IC&nbsp;设计行业正面临着日益加剧的成本压力。值得注意的是，当前成熟制程的晶圆代工成本并未走高，后端封测环节也保持平稳，产业链上游的直接成本压力并不算大。由此可见，驱动美国头部大厂调整定价策略的核心因素，更多源于宏观环境变化与各细分应用市场的供需格局差异。</p>
  <h2><strong>国产模拟，攻坚时刻</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_e2240cdcafa44cda97914c51c6defd01@000000_oswg262670oswg714oswg851_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从图表数据看，TI&nbsp;与&nbsp;ADI&nbsp;在华收入占比呈现&nbsp;“先升后分化”&nbsp;的趋势。</p>
  <p><strong>2017-2021年，</strong>中国市场对国际大厂的快速绑定使得TI&nbsp;在华收入占比从&nbsp;44%&nbsp;升至&nbsp;55%，ADI&nbsp;从&nbsp;17%&nbsp;升至&nbsp;24%，核心驱动是中国电子制造业的全球产能集中。<strong>2022-2024年</strong>，TI&nbsp;与&nbsp;ADI&nbsp;在华收入占比实现“分化”，受地缘政治与半导体供应链安全影响，TI&nbsp;在华收入占比从&nbsp;55%&nbsp;断崖式下跌至&nbsp;19%。</p>
  <p>值得注意的是，9月13日，商务部发布公告，对原产于美国的进口相关模拟芯片发起反倾销调查。此次调查重点关注的产品也多在上文提及。具体而言，自本公告发布之日起，商务部对原产于美国的进口相关模拟芯片进行反倾销立案调查，本次调查确定的倾销调查期为2024年1月1日至2024年12月31日，产业损害调查期为2022年1月1日至2024年12月31日。调查范围为，原产于美国的进口相关模拟芯片，其主要用途为相关模拟芯片中使用40nm及以上工艺制程的通用接口芯片（Commodity Interface IC Chip）和栅极驱动芯片（Gate Driver IC Chip）。</p>
  <p>据江苏省半导体行业协会提交的申请文件，相关美国生产商包括四家，分别是TI、ADI、<strong>博通、安森美</strong>。该协会提交的初步证据显示，2022年-2024年，申请调查产品自美进口量累计 增长&nbsp;37%，进口价格累计下降&nbsp;52%，压低和抑制了国内产品销售价格，抢占了国内产业的市场份额。本次反倾销调查预计将进一步弱化以&nbsp;TI&nbsp;为代表的海外头部厂商对国内模拟&nbsp;IC&nbsp;厂商的压制。</p>
  <p>目前，国产模拟芯片则呈现“结构性国产化&nbsp;+&nbsp;高端滞后”&nbsp;的特征。</p>
  <p>高端模拟芯片市场仍由国际大厂牢牢掌控，比如TI、ADI&nbsp;在车规电源管理&nbsp;IC、高精度&nbsp;ADC、隔离式栅极驱动器等核心品类中，市占率均超过&nbsp;90%。这一格局背后的壁垒体现在三个维度：一是<strong>可靠性认证周期长</strong>，AEC-Q100&nbsp;车规认证需&nbsp;3-5&nbsp;年，国产厂商难以快速切入主流供应链；二是<strong>工艺壁垒高</strong>，模拟芯片的精度、功耗等核心性能，高度依赖制造工艺的定制化支撑，但国内模拟芯片行业“设计&nbsp;-&nbsp;制造”&nbsp;协同不足的问题，正成为高端国产化的核心制约。国内模拟芯片厂商以&nbsp;Fabless&nbsp;模式为主，国产晶圆代工厂商的BCD、BiCMOS&nbsp;等模拟工艺，与<strong>台积电、格罗方德</strong>存在代际差距；三是<strong>生态绑定深</strong>，国际大厂与特斯拉等头部客户的联合开发模式，进一步巩固了其在高端场景的先发优势。</p>
  <p>国产厂商的突破集中在细分高端赛道，比如<strong>纳芯微</strong>已实现车规级隔离芯片的批量交付；<strong>思瑞浦</strong>推出16通道高精度ADC—TPAFE51760。圣邦股份全品类覆盖5200余款产品，车规级DC-DC转换器已进入小鹏、蔚来供应链。此外，中国还涌现出一大批优秀的模拟芯片公司，比如<strong>艾为电子、矽力杰、晶丰明源、杰华特、富满微、赛微微电</strong>等。</p>
  <p>自我国针对进口芯片实施流片地认证相关规则后，国内部分模拟芯片产品市场报价已出现上调。当前海外相关贸易政策存在不确定性，下游客户转向国产产品的意愿显著提升，越来越多终端厂商开始主动寻求国产方案，这一趋势尤其利好工业、汽车领域占比较高的模拟芯片企业。技术层面，模拟芯片依赖成熟制程工艺，国内企业已完成多料号的研发与量产工作，产品矩阵覆盖信号链、电源管理、射频等主要细分品类，且在性能与稳定性上逐步实现突破。叠加本土供应链的完备性优势，国产模拟芯片的市场替代潜力有望进一步打开。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkxMjIyNzU0MA==&amp;mid=2247804865&amp;idx=1&amp;sn=51374e2c250cc6497f96cb6503586fb7&amp;chksm=c08c53cab6a6eced9ee96786764ef4edff49fcb3c3f30f340a767e090842e020f5c79e406496&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“半导体产业纵横”（ID：ICViews）</a>，作者：丰宁，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612176869475332</id>
            <title>京东的200次「向前一步」</title>
            <link>https://www.36kr.com/p/3612176869475332</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612176869475332</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 09:54:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>今年双12期间，李欣在京东为新家购置了一把椅子，收货后发现尺寸与家里的桌子配不上。当她点开“退换/售后”页面时，意外发现除了可以换同款的不同颜色、型号外，还出现了“店铺爆款”和“平台热卖”商品，甚至有个单独的选项，可以直接选到购物车商品，她一眼就看到了此前加购的人体工学椅。每件商品下方，具体价格和“预计单件到手价补（退）”的金额都清晰呈现。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_7a12cfbe15774ad7b09810c4d037c4f8@1267484143_oswg29508oswg602oswg695_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第二天，旧椅子被取走，新椅子也同步发货。李欣说，“没想到现在换货可以这么方便、人性化。”</p>
  <p>李欣不知道的是，类似“差价换”这种惊喜体验的细节提升，京东在2025年实现了200多个。这并非一次偶然，而是一场持续数年、仍在深入的“静默战争”的一部分。</p>
  <p>近日，36氪与京东平台服务的多位项目负责人、商家进行了对话。我们发现，常为电商人说到的“供应链”一词，<strong>在京东内部的注解已经远不限于狭义上的“选品采购”、“物流配送”等环节，而是深入到了零售从售前到售后的每个环节。</strong>他们甚至将其延伸为“服务供应链”的概念——京东不只运送货物，更是希望为用户提供“确定性”的购物体验。</p>
  <h2><strong>一场关乎“体验痛点”的歼灭战</strong></h2>
  <p>“差价换”的发心，源于一个“天真”的提问。</p>
  <p>在京东内部一次关于体验案例的复盘会上，“热门商品换货无货”的问题被摆上台面。用户想换，仓库没货，常规操作是安抚、补偿、引导退货。讨论陷入流程优化的窠臼时，有人问：“为什么不能让用户换点别的？我们有那么多货，万一用户找到了更合适的选择呢？”</p>
  <p>这个想法并非凭空而来。在日常海量的用户声音挖掘中，项目团队发现，“我补差价，换那个行不行？”类似诉求常常出现。同期，京东内部面向全体员工征集的“惊喜服务”创意投票中，“差价换”的构想脱颖而出，让团队对这类需求的存在有了更大的确定性。</p>
  <p>然而，从“天真一问”到真正上线，远非在页面上增加几个选项那么简单。</p>
  <p>“只拿前期推动各业务部门共识这件事儿来说，当用户可能从A店铺换到B店铺，意味着原订单的销售额会‘流失’，商家不好协调，内部跨部门如何转移订单也是个问题，要沟通的细节很多。起初大家为此争论得不可开交。”项目负责人梦昭（化名）告诉36氪。</p>
  <p>最终推动“差价换”项目落地的，是一个更宏观的判断：如果一次不畅的换货体验导致用户退货并永远离开，其损失远大于在平台内完成一次订单的流转。与一单生意的得失相比，用户的体验更加重要。</p>
  <p>这不是京东第一次在“换货”上挑战行业常规。自2007年自建物流之初，京东便推出“上门换新”服务。十几年过去，完全跟上这一服务的平台依然寥寥。某种意义上，如今的“差价换”，是京东服务基因里“敢为人先”的又一次演进。</p>
  <p><strong>如果说“差价换”是针对“换货难”痛点的一记精准点射，那么京东开展的“服务无死角”项目，则是一场系统性的阵地排查。</strong></p>
  <p>2024年9月，京东正式启动“服务无死角”项目，目标是从被动响应投诉，转向主动扫描全链路中所有影响体验的“毛刺”。这些“死角”通常具备一个共同特征：不阻断流程，却伤害用户体验。</p>
  <p><strong>在京东的办公区，“决策时不要忘了用户”的标语随处可见。这不仅是口号，更是机制——2025年，京东修复了超200个“服务死角”。</strong></p>
  <p>这些对“体验痛点”的歼灭，表面看是成本的增加，但京东在其中看到了更深层的商业逻辑。“差价换”项目团队发现，<strong>让用户做一个“补20元差价”的决策，远比让他做一个“重新花120元购买”的决策要容易得多。</strong>前者决策门槛极低，而后者需要重新评估需求、比价、占用资金，这都可能是导致用户放弃买单的原因。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_99a4083b76094262afe8ff09a519b0af@1267484143_oswg36974oswg800oswg533_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从后台数据来看，“差价换”目前的售后满意度，远高于“普通换货”，而这种满意度实际上也进一步反哺商家,形成“高满意度-流量倾斜-生意增长”的良性循环。同样其他“服务无死角”的举措，也都为商家带来了生意增长。某种程度上，这是商业世界对于回归需求本源的一种奖励。</p>
  <p><strong>京东集团创始人、董事局主席刘强东曾说，“京东集团的所有业务只围绕着供应链展开。”如今，对零售后端体验环节的持续优化，已被明确纳入京东“超级供应链”的能力图谱。而这条“服务供应链”，正试图将“后端的麻烦”，转化为“前端的优势”。</strong></p>
  <h2><strong>把“包邮区”画到地图边缘</strong></h2>
  <p>在传统的电商商业模型里，有一道清晰的经济分界线：偏远地区，由于订单分散、人口密度低、物流线路长，配送成本高昂，往往被默认为“不划算的市场”。商家在这里设置高昂运费或直接不支持发货，消费者则忍受着选择匮乏与购物车里的“运费惊吓”。</p>
  <p><strong>京东决定挑战这个“常识”，起点是新疆。</strong></p>
  <p>新疆的广阔地域和独特的物流网络，使其成为检验供应链能力的终极考场。京东给出的解法，是系统性的“集运”模式：消费者下单后，商家只需将商品发往京东指定的西安中转仓，此后跨越数千公里的“后半程”配送，由京东物流统一完成，京东会对这段运费进行全额补贴。</p>
  <p>本质上，这是京东将其重资产投入近二十年建成的全国性物流主干网络与区域仓配能力，进行极致的“能力外溢”和精密调度。通过干支线的无缝衔接、中转仓的集货效应，将长距离、高成本的零散末端配送，整合为可控、高效、规模化的确定性服务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_69e988e46c7b4915b33f9943b554f750@1267484143_oswg959462oswg1080oswg671_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>数据证明了价值——<strong>新疆地区上线集运包邮服务后，订单量同比增长超过100%。</strong>这个数字揭示着：所谓的“不划算”，有时是因为供给的缺失压抑了真实的需求。</p>
  <p>新疆的成功，也给了京东“偏远地区包邮”项目战略扩张的信心。</p>
  <p><strong>2025年11.11期间，京东宣布将“偏远地区包邮”服务扩展至西藏、内蒙古、甘肃、宁夏、青海五地，实现偏远地区包邮全覆盖。</strong>这不是简单的区域增加，而是将一套已验证的系统性解决方案，进行规模化复制。其背后的价值主张清晰而坚定：打破地理带来的消费不平等，让无论身处何地的用户，都能获得同样可信赖的商品与服务。</p>
  <p>市场的反馈迅速而真实。对90后某护肤品店主薇薇（化名）来说，此前，一单发往新疆的快递，运费常高达三四十元，“我是个体代销，这几乎吃光了我的利润”，她不得不对偏远地区订单设置运费或直接关闭交易，“很多时候不是不想包邮，而是包不起。”</p>
  <p>接入京东的集运服务后，薇薇的成本结构彻底改变。2025年11.11以来，其店铺来自青海、西藏、甘肃、新疆等地的订单量同比增长超过300%。</p>
  <p>钱芳丽是上海进凡贸易有限公司旗下imomoto品牌的负责人，选择第一时间成为“新疆包邮”的参与者后，imomoto在新疆地区的销量提升44%，GMV增长24%。</p>
  <p>今年，京东“包邮区”扩围，钱芳丽仍然是第一批参与者。“这不仅是销量增长，更是品牌认知和市场竞争力的提前布局，对品牌长期建设是天大的好事。”她说。</p>
  <p>在京东的“服务供应链”中，“差价换”优化的是单点决策链路，“偏远地区包邮”重构的则是区域商业的基础设施。尺度不同，但内核一脉相承：通过打造确定性的极致体验，去激活那些真实存在却被掩盖的存量需求，亦或开拓新的增量市场。</p>
  <h2><strong>“信任”是最短的商业路径</strong></h2>
  <p>无论是解决200个体验痛点，还是将“包邮区”推向地图边缘，支撑这些行动的，是京东一套植根于组织肌理的“听诊”系统。</p>
  <p>每天，海量的用户声音通过客服听线被收录；技术团队对商品评价进行文本分析，量化“不爱吃”、“尺寸不准”等关键词；各品类的采销、服务运营，则凭借行业深耕，洞察那些非标的痛点。</p>
  <p>这些信息流汇聚在一起，形成了驱动“服务供应链”运转的初始数据。而确保数据能被重视并转化为行动的，是京东内部反复强调的决策逻辑——<strong>刘强东要求京东的任何业务决策都要从“战略三问”出发：“你的客户是谁？你能为他们创造什么价值？你的核心竞争力是什么？”</strong></p>
  <p>穿越复杂商业计算、回归价值本源的出发点，也让京东与商家间构建起更深层的“信任”。</p>
  <p>去年6月，一家床垫品牌电商部负责人小维（化名）收到京东采销的提议——开通“免费试睡”。会议室里，团队的声音一边倒，“拆了塑料保护膜，再退回来，这床垫还怎么卖？”</p>
  <p>作为一家在多个平台运营的品牌，小维深知行业规则：试睡可以，但绝不能破坏床垫薄膜。更何况，彼时正值价格战内卷最激烈时期。京东提出的“支持拆膜试睡”，在他们听来，无异于一道“亏损通知书”。</p>
  <p>京东采用的方式不是施压，而是“风险共担”：试运行阶段，京东依托自身的物流网络与履约能力，先行承担因试睡不满产生的逆向配送成本，并对退回商品的折价、报废、仓储等成本提供补贴。这份契约，将双方的博弈关系，转变成了共同提升体验边界的同盟关系。</p>
  <p>解除了后顾之忧，小维的团队开始全力优化“试睡”服务的每一个细节，比如通过入京东自营仓和京东物流实现床垫“次日达”、对换新的用户做到“取旧送新”的无缝衔接……戏剧性的反转很快上演：顾客的决策链路明显缩短，店铺转化率提升了30%，订单量增长超过50%，而最让人担心的“拆膜退货率”，远低于团队最初的恐慌性预估。一条高赞评价写道，“敢让人拆开睡100天，是对自己产品有多自信？就冲这份底气，我赌了。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_e177f30c4c094096a56e6dd2657b8ebc@1267484143_oswg271141oswg1080oswg2086_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>“这根本不是我们最初想象的‘洪水猛兽’。”小维告诉36氪，“一次‘豪赌’般的服务升级，成了我们最强的增长引擎，更是带动了品牌全生命周期的回报提升。”</p>
  <p>当下，电商的竞争已深入“信任密度”的腹地。价格、流量、功能的优势都极易被模仿，唯有建立在无数真实体验之上的、系统性的“可信赖感”，最难被复制。这需要不计算一城一池得失的长期主义。</p>
  <p><strong>京东的“服务供应链”，正是这种长期主义的实践。它将售后从成本中心，重塑为增长引擎；将物流优势，转化为普惠的消费基础设施；将用户的一个个“痛点”，锻造为“信任货币”。</strong></p>
  <p>当“确定性”本身成为最具吸引力的产品，当“信任”成为平台生态里流通最广的硬通货，京东长期“重押”的服务，便进化为了一个驱动健康增长的“价值系统”：极致体验深化信任，信任驱动增长，增长反哺更优体验。</p>
  <p>这或许就是京东在每一个“不划算”的细节里，想要达到的本质目的。这条由“服务”参与构筑的“超级供应链”，已成为京东在当下最独特也最难以被撼动的生态位。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612152513266691</id>
            <title>蒸馏、GEO、氛围编程 2025年度“AI十大黑话” 能听懂几个？</title>
            <link>https://www.36kr.com/p/3612152513266691</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612152513266691</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 09:14:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年，AI领域的发展令人目不暇接，一系列新概念不断涌现并重塑着行业格局。《麻省理工科技评论》评出十大年度AI热词。 读懂这些词，或许也就读懂了2025 年我们如何被AI改变。</p>
  <h2><strong>1. 氛围编程</strong></h2>
  <p>三十年前，苹果联合创始人 史蒂夫·乔布斯 提出：每个人都应该学习编程。而今天，编程正在被重新定义。OpenAI联合创始人安德烈·卡帕西所提出的“氛围编程（Vibe Coding）”，它不是一种新语言，而是一种新方式：人只需用自然语言表达目标和逻辑，具体代码由AI自动完成。</p>
  <p>在氛围编程中，开发者只需要告诉AI：想做一个什么样的应用、需要哪些功能、整体的体验应该是什么感觉；AI则负责生成代码、调整细节，并在反复对话中不断迭代。</p>
  <h2><strong>2. 推理模型</strong></h2>
  <p>2025年，“推理”被反复提及，逐渐成为AI讨论中的核心词汇。这一热度背后，对应的是推理模型的崛起：这类大语言模型通过多步拆解与连续推演，开始处理更复杂的问题。</p>
  <p>自OpenAI发布o1和o3系列推理模型后，DeepSeek迅速跟进。如今，主流聊天机器人均已引入推理技术，在数学和编程竞赛中达到了顶尖人类专家水平。但关于AI是否真正具备“推理”能力，也再度引发了人们对智能本质的思考。</p>
  <h2><strong>3. 世界模型</strong></h2>
  <p>大语言模型很会“说话”，却并不真正理解世界。它们能生成流畅的文字，却常常缺乏基本常识，甚至在简单的物理问题上犯错。为弥补这一缺陷，AI 研究正转向一个关键方向——世界模型（World Model）：让 AI 不只学习语言，而是理解现实世界的因果关系、物理规律与时间演化，从而判断什么是合理的，并预测接下来会发生什么。</p>
  <p>无论是谷歌DeepMind的Genie 3，李飞飞团队的Marble，还是杨立昆离开 Meta 后专注的新研究方向，本质上都在通过预测视频演化或构建虚拟环境，让AI在模拟与试错中掌握世界运转的基本规律。</p>
  <h2><strong>4. 超大规模数据中心</strong></h2>
  <p>随着AI对算力的需求激增，科技巨头们正以前所未有的规模，建设专门为AI服务的“超级数据中心”。例如，OpenAI与美国政府合作推动的“星门”项目，计划投入5000亿美元，在全美建设史上最大规模的数据中心网络。</p>
  <p>然而，这些庞然大物的背后也引发了诸多社会忧虑：它们惊人的能耗可能推高当地居民的电费，短期内难以完全依赖清洁能源，且能为社区创造的长期就业岗位有限。这正在成为技术狂奔与民生利益之间一个日益突出的矛盾点。</p>
  <h2><strong>5. 泡沫</strong></h2>
  <p>目前，AI正在成为资本最拥挤的赛道之一。以 OpenAI、Anthropic 为代表的公司估值持续攀升，但现实是，多数仍处于高投入、尚未建立稳定盈利模式的阶段。投资人押注的是 AI 将开启下一轮财富浪潮，但这项技术最终能释放多大的现实价值，仍有待时间验证。</p>
  <p>不过，和当年的互联网泡沫相比，如今顶尖的AI公司收入增长迅猛，并且背后站着微软、谷歌这样资金雄厚、实力强劲的科技巨头，这为它们提供了稳定支撑。</p>
  <h2><strong>6. 智能体</strong></h2>
  <p>“智能体”可能是眼下AI圈里最火也最说不清的概念了。虽然各家都在宣传自家AI能像“智能助手”一样自主完成任务，但到底什么才算真正的智能体行为，整个行业还没有统一的标准。即使现在的AI还难以在复杂多变的环境中稳定、可靠地工作，这并不妨碍“智能体”成为产品宣传中最热门的标签之一。</p>
  <h2><strong>7. 蒸馏</strong></h2>
  <p>2025年年初，DeepSeek发布的R1模型向我们展示了“蒸馏”技术的巧妙之处。它让小模型学习大模型的精髓，用极低的成本就实现了接近顶级模型的性能。这让行业看到，打造强大的AI模型，未必只能靠堆砌昂贵的算力。高效的算法设计，同样能带来新的可能。</p>
  <h2><strong>8. AI垃圾</strong></h2>
  <p>“AI垃圾”已成为公众熟知的词汇，特指为博流量而批量产生的劣质AI内容。如今，“垃圾”更演变为一种后缀，被用来形容各种缺乏实质、空洞乏味的事物，如“工作垃圾”、“社交垃圾”。这背后，折射出人们对AI时代内容质量与真实性的普遍反思。</p>
  <h2><strong>9. 物理智能</strong></h2>
  <p>相比语言和推理能力，AI在现实世界中的行动能力仍是很大的短板。虽然现在机器人在特定任务上学习更快了，自动驾驶的模拟也越做越逼真，但不少打着“智能家庭助手”旗号的产品，其实背后还得靠人远程操控。</p>
  <p>为了提升这种能力，已经有机器人公司开始花钱向普通人征集做家务的视频。这正说明，要想让AI真正理解并适应我们生活的物理世界，仍然前路漫长。</p>
  <h2><strong>10. GEO</strong></h2>
  <p>随着AI越来越多地直接给出答案，人们获取信息的方式正在发生改变。传统的搜索引擎优化（SEO），正在让位于一种新的玩法——生成引擎优化（GEO）。</p>
  <p>过去，品牌和内容创作者拼的是网页在搜索结果中的排名；而现在，问题变成了：当用户直接问AI一个问题时，AI给出的那段答案里，会不会提到你的品牌、你的观点，甚至引用你的内容。在这种规则下，内容提供者要么学会被AI引用和吸收，要么就可能逐渐从视野中消失。</p>
  <p>本文来自<a href="https://news.qq.com/rain/a/20251226A040N800" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：金鹿，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612094884049409</id>
            <title>2025AI应用大爆发，2026普通人有什么机会？</title>
            <link>https://www.36kr.com/p/3612094884049409</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612094884049409</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 08:56:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <h2><strong>中国AI奋起直追，但收入差距仍不小</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_fc6784aa9bc546369bd275cc5968acea@5252769_oswg82613oswg1080oswg449_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>今年以来资本市场一直在争论AI有没有泡沫，因为当前整个AI产业利润分配存在严重失衡，英伟达几乎攫取了市场近九成的利润，下游很多应用开发和模型训练企业需支付天价算力成本，却难以实现盈利。</strong>这种“头重脚轻”的利润结构，让应用层缺乏足够资金投入创新，整个生态难以形成健康的正向循环，也让投资者对AI的商业价值产生质疑。</p>
  <p>但AI应用市场并没有那么不堪，企业 GenAI 支出从 2024 年的115 亿美元跃升到 2025 年的 370 亿美元，年增约 3.2 倍，约占全球 SaaS 市场6%。从行业宏观视角来看，过去 6 个月 AI 产业的迭代速度远超去年，正站在技术周期的关键拐点，模态融合成为核心趋势——去年，以单模态为主，VLM 等视觉理解模型占比偏低，LLM（大语言模型）是绝对主流；今年，多模态调用量占比持续攀升，生图、生视频能力增长迅猛——尤其下半年以来，模型的“Function Call”请求量爆发式增长。</p>
  <p>在C端其实也有不小的增长，据Appfigures 估算，2025 年全球用户在 ChatGPT 移动应用上的支出约为 24.8 亿美元，较 2024 年的 4.87 亿美元同比增长 408%。在 2023 年（ChatGPT推出首年），相关收入约为 4,290 万美元，此后一年增幅超过10 倍，再叠加 2025 年的扩张，形成高速复合增长轨迹。&nbsp;</p>
  <p>ChatGPT 用了 31 个月达到 30 亿美元消费者支出；作为当前收入最高的短视频应用，TikTok 达到同一水平则花了 58 个月。主流流媒体服务中，Disney+ 和 HBO Max 分别用了 42 个月和 46 个月才实现同样规模的用户付费。指责AI应用发展停滞了，肯定是不对的，但AI应用的分化更为明显了。</p>
  <p><strong>全球 AI 应用商业化已形成清晰梯队，通用大模型凭借规模优势占据第一梯队，垂类应用则以 “适配具体场景、降低行业成本” 为核心，在 AI 编程、多模态、AI 搜索等领域快速起量，2B/2P 商业模式确定性强，2C 端则展现高增长弹性。</strong></p>
  <p>第一梯队的商业应用领先优势明显：以通用大模型主导，OpenAI 遥遥领先OpenAI 以100 亿美元 ARR 位居全球第一，2023-2025 年预期收入复合增长率（CAGR）达 260%，核心驱动力是 C端产品 ChatGPT—— 其贡献超 60% 收入。</p>
  <p>另一大模型厂商 Anthropic 以 40 亿美元 ARR 位列第二，收入增速虽快（2024 年底至 2025 年 7 月增长 3 倍），但以 B 端 API 调用为主（占比 70%-75%），客户包括 AI 编程工具 Cursor、软件开发公司 GitLab 等，增长弹性低于 OpenAI 的 C 端驱动模式。</p>
  <p>而国内应用目前处在第二梯队之间（ARR 1-10 亿元）：垂类应用成主力，AI 编程 / 多模态 / 搜索落地最快垂类应用因场景明确、降本效果显著，成为商业化第二梯队的核心构成。</p>
  <p>在体系化和生态化竞争的驱动下，应用落地层面呈现出百花齐放的格局，从7月到11月，超过200款AI应用面世，其中，AI应用插件、PC网页端、AI原生APP占比分别达到81.5%、10.7%、7.8%；应用方向上，深度洞察用户个性化需求与场景痛点的垂直应用成为突破口，例如，AI图像处理、AI专业顾问、AI效率办公、AI社交互动、AI文案写作占比分别达到24.9%、18.5%、6.8%、5.9%、5.9%。</p>
  <p><strong>但如果以全球热度和日均消耗Token来看，字节跳动旗下产品Dola(豆包海外版)和另一家中国公司DeepSeek分别以4700万和3900万MAU位列全球第四和第五，中国应用并没有完全掉队，甚至在海外市场也有一席之地。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_842083cc4bc24dc0abffd588d635fe33@5252769_oswg27564oswg960oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在全球前 50 个生成式AI App中，有 22 个产品是由中国团队开发的，但只有 3 个产品主要在中国使用。其中，照片与视频类应用高度集中，美图一家就贡献了五个产品：Photo &amp; Video Editor、BeautyPlus、BeautyCam、Wink 和 AirBrush。字节跳动也是App的重要参与者，旗下拥有：豆包和 Cici（通用大语言模型助手）、Gauth（教育科技应用）和Hypic（照片/视频编辑工具）。</p>
  <p>总的来看，还是老问题导致的中美AI收入差距过大，美国市场存在成熟的软件付费生态，用户更愿意长期为闭源软件付费。美国主要的科技巨头 OpenAI、Google 构建了明确的长期路线，聚焦通用智能底层逻辑探索。谷歌、微软、AWS 更是形成了从芯片、框架到云服务的全栈闭环，通过硬件与软件的垂直整合“滚雪球”。所以中美应用之间出现十倍乃至百倍的收入差距也就不难理解了。</p>
  <h2><strong>不看榜单跑分，看落地</strong></h2>
  <p><strong>今年海内外AI的核心变化，已经很明确：从“概念炒作”进入“价值兑现”。</strong></p>
  <p>知名投资人朱啸虎直言，“GPT-5‘千呼万唤始出来’，但说实话大家都很失望。”他认为，Transformer架构下的通用人工智能（AGI）能力上限已经基本能看到，在核心智力上的提升空间非常小，更多的是在用户体验和成本上进行优化。核心问题在于数据瓶颈和推理天花板，盲目加大模型参数和数据量，不仅不会提升智力，反而可能损害性能。</p>
  <p>从行业观察来看，笔者认为也确实如此，这一年里，不再是单纯卷模型能力。 DeepSeek 用极致的成本效率击穿了算力与规模的神话；GPT-5 将“推理”从能力升级为系统能力，重新定义了什么是通用模型；Gemini 3 强势回归，证明顶级模型竞争远未结束；Qwen3 则在开源生态中持续扩张，开始影响更广泛的开发者与产业链。与此同时，AIGC 全面爆发，图像、视频生成第一次真正从“展示能力”走向“被用户大量使用”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a59ecd3851514651abfe6746cec01137@5252769_oswg280465oswg960oswg614_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>今年以来，让 Agent 实际投产、落地应用的最大障碍已经不再是成本问题了，而是「质量」。如何让 Agent 输出可靠、准确的内容，仍然是最难的部分。</strong></p>
  <p>硅谷的一家VC Menlo Ventures指出一个有趣的现象是，万人以上的大型企业中，已经有 67% 将 Agent 投入生产，24% 正在积极开发并计划部署；而在百人以下的小公司，这个比例是 50% 和 36%。这说明，大型企业凭借平台、安全和基础设施等方面的资源优势，能更快地将 Agent 从试验品变成稳定可靠的生产力工具。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_39ebcd415e754375ba21c8ee448e3682@5252769_oswg181423oswg1080oswg1028_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>三分之一的受访者将质量视为主要瓶颈。这里的质量问题，指的是 Agent 的准确性、相关性、输出结果的一致性，以及在维持适切语调、遵循品牌或政策规范方面的能力。</p>
  <p>延迟（20%）则成为第二大挑战。当 Agent 被用于客服或代码生成这类实时交互场景时，响应速度直接决定了用户体验的好坏。这也反映出团队必须在「效果」和「速度」之间做出权衡，功能更强、步骤更多的 Agent 虽然能产出更高质量的结果，但响应速度往往也更慢。</p>
  <p><strong>总体来看，Agent目前还是仅限于编程和客服等高人力成本场景，降本效果显著但增收还不够明显。无论是企业还是员工个人，率先使用的会先享受技术溢价，这在招聘领域已经开始成为必备技能要求。</strong></p>
  <p>有一些 AI SaaS企业已经前瞻性的洞察了很多真实且不被满足的AI需求。比如我们之前讲过的企业筷子科技，其CEO陈万锋认为智能体可控性更强，且具备定制性和广泛性。 他认为它基本上能达到行业里70-80分的人的水准，一个普通的中小商家，想招行业里70-80分水准的人，我认为大概率招不到。而这部分客户过去是大厂很难看得上，也不愿意花费太多精力来维护的。这部分客户还有一个问题那就是预算有限，能省则省。在陈万锋看来，这个问题并不难解决，有了智能体和托管服务，或许可以通过GMV抽佣的方式，服务品牌商家。</p>
  <p>借助筷子科技的AI工具，广州市一家汽车美容店的运营团队，半小时内生成100多条个性化视频，店员和顾客扫码转发这些视频后，店铺的新客源在那个星期同比增加50%。这家小型汽车美容店的三人团队，每天投入少量时间运营社交媒体账号，利用AI工具帮助产出内容，并进行投放与管理等，获客成本远低于传统模式。</p>
  <p>有些企业的想法则是自己接入开源大模型，来做AI业务定制化，但从效果来看目前跑通的少之又少。这又是为何呢？</p>
  <p>AI落地不是一蹴而就的“颠覆”，而是AI技术与产业需求在互动中逐步校准磨合。AI落地应用需要有个工作流程分割、业务流程重构的过程。把AI擅长的部分交给AI；剩下的部分，不管是由于AI能力限制还是数据积累不足，还需要继续由人完成。人的工作是驾驭AI，黏合流程断点，进行任务和资源分派，以及结果的评估纠正。</p>
  <p><strong>对企业而言，现阶段不必执着于“全流程AI化”，可以选择聚焦“小切口、高适配、高收益”的场景，找到AI与业务相契合的最小可行飞轮，再利用AI编程工具测试、打磨功能，降低落地成本，从而赢得内部支持。</strong></p>
  <h2><strong>AI对于普通人而言有哪些机会</strong></h2>
  <p>今年你或许听过不少关于巨头因为AI大规模裁员的新闻，大部分中小企业也在尝试接入AI，普通人的机会到底在哪？有不少朋友问我，现在个人学AI还有机会吗？普通人是不是现在学晚了？是不是需要懂代码和技术？</p>
  <p><strong>笔者认为当前的AI应用普遍已经来到了“傻瓜级应用级别”，指的是基本可以依靠提示词和内容调试来完成目标任务。但学会AI其实还是挺难的，很多人找不到合适的场景只会一窝蜂的抄袭，更为关键的是你要用AI做什么，你是否懂你要用AI做的生意。</strong></p>
  <p>比如今年以来大火的AI动漫，10月24日至28日，短短五天内，中信、东吴、兴业等10家头部券商相继发布研报，一致看好AI漫剧赛道。芒果、抖音、B站等视频平台竞相入场；阅文集团宣布开放10万部精品IP，并设立亿元专项创作基金；二级市场同样反应热烈，10月31日，中文在线等AI漫剧相关的概念股掀起涨停潮……</p>
  <p>有业内投资人指出，以能直接反映业务“盈利能力”的ROI（投资回报率）为例，目前AI漫剧的全域经营的投流ROI普遍能够达到1.1—1.8倍。这意味着每投入1元投流费用，能带来1.1—1.8元的收入。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_9e605a1953ef4419a0622d014369bb6c@5252769_oswg159219oswg1080oswg1017_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>行业数据显示：AI动态漫的单分钟生成成本，已从纯人工时期的数万元，压缩至千元以内，最低可到600—700元。整部作品的制作成本也降至5万—10万元，仅为传统动态漫的10%—30%。笔者预计未来还会继续呈倍数下降。</p>
  <p><strong>如果我们是一位普通创业者，想以个人身份参与AI动漫创业，那么需要做些什么？</strong></p>
  <p>流程大概应该是这样的，选择适合自己的模型应用，到底是豆包、千问、Deepseek、还是可灵，还是其他。当然也可以一部分用来写文案，一部分用来制作视频，至于哪个更好用则要看你的操作习惯，用豆包更多的会更熟悉豆包的提示词。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_588b8fc7bdd145c0af7c725889bbe892@5252769_oswg129897oswg553oswg346_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>操作的流程基本都差不多，选择故事脚本、确认风格、确认分镜脚本、生成分镜画面、剪辑视频。是不是基本达到了傻瓜式操作？这个时候你还要抱怨不会用吗？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_97b2dd78d0b9419394418a71b9b14dc6@5252769_oswg196493oswg554oswg249_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但如果你只会这些基本操作，是不足以让你在AI上赚钱的。能够留下用户的AI漫剧基本上还是题材新奇和故事好。<strong>AI或许会淘汰一些编剧和导演，但能做好AI视频的，基本还是那些拥有导演思维和编剧思维的人才。</strong></p>
  <p>据界面新闻报道，一部播放量破千万的付费AI漫剧，净利润可达20万至30万元。然而，“吃到肉的终究是少数人”，行业的“马太效应”已经凸显。2025年6-8月的数据显示，累计播放量能突破千万的漫剧仅占12%，而多达64%的作品播放量不足100万，多数都成了分母。</p>
  <p>此前笔者讲过如何用AI做投资<a href="https://mp.weixin.qq.com/s?__biz=MzAwMTg1MjAyNw==&amp;mid=2247488527&amp;idx=1&amp;sn=53741a62dc6ccd43106950bf033aa660&amp;scene=21#wechat_redirect" rel="noopener noreferrer nofollow" target="_blank">中国AI模型远超美方模型，靠AI赚钱的时代到来了吗？</a>的案例，道理其实也大同小异，懂AI更要懂投资才行，否则只会被AI带偏生产同质化的垃圾内容。当然，如果你觉得你怀才不遇，或者足够勤奋愿意试错，可以用AI尝试各种赛道都不为过。</p>
  <h2><strong>写在最后</strong></h2>
  <p>不要去抱怨目前的AI性能不够或者不够好用，在全球性热度和资本的长期投入之下，其成本降低，性能好用只是时间问题。</p>
  <p>GPT-4已经从60美元/百万token降至GPT-5.1的1.25美元，而国产模型GLM-4.6更是将成本压至0.3美元/百万token。对消费者而言，固定价格的端侧设备，能运行的AI模型参数量每88天翻一番——今天旗舰机才能实现的功能，明年千元机或许就能轻松胜任。</p>
  <p>能够被AI改善利润的行业，首先不能是在走下坡路和内卷的夕阳行业，这样情况下行业普遍用AI只会加剧内卷。过去都喜欢谈互联网+，那么AI+带来的一定不只是降本，更关键的地方在于增效。手机之后的下一个时代产品，不应该还是一块更好用的屏幕，我们期待AI应用时代应该带来更多的机遇，而非相反。</p>
  <p>参考资料：</p>
  <p>LangChain Agent 来源：Founder Park</p>
  <p>企业级AI市场快速爆发 来源：Growth Croissance</p>
  <p>全球AI应用商业化到了哪一步 来源：中信建投证券</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/o37B0sJuNXQKNShk5LsEMw" rel="noopener noreferrer nofollow" target="_blank">“首席商业评论”</a>，作者：做镜观天，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612036332794376</id>
            <title>茉酸奶，卖掉了创始人</title>
            <link>https://www.36kr.com/p/3612036332794376</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612036332794376</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 08:47:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>是什么，能让<strong>创始人彻底离开自己亲手创办十余年的公司</strong>？</p>
  <p>创业第11&nbsp;年，茉酸奶迎来关键人事更迭：创始人赵伯华同时卸任法定代表人、总经理、董事、财务负责人等全部职务，并退出股东行列；联合创始人、现任董事长顾豪随即接任法定代表人，持股比例提升至&nbsp;57.14%，成为绝对控股股东。</p>
  <p>从工商信息来看，这是一场<strong>干净利落、没有“过渡期”的权力交割</strong>。</p>
  <p>于是，市场的第一反应，自然是去寻找“触发点”。</p>
  <p>离开的原因，或许是<strong>新股东的入场</strong>？</p>
  <p>一个被频繁提及的解释，是资本的变化。2023&nbsp;年入股茉酸奶的乳业巨头君乐宝，曾在今年&nbsp;10&nbsp;月清仓退出，但却在赵伯华卸任的同一节点再次返场，以&nbsp;21.43&nbsp;万元持股&nbsp;42.86%。这种“先退再进”的操作，时间点过于敏感，很难不引发外界关于股东博弈的联想。</p>
  <p>另一种解释，则指向<strong>经营层面的压力</strong>。</p>
  <p>数据显示，至本月中旬，茉酸奶全国门店数量为1166家，与巅峰期的1682家相比，减少了516家。门店收缩、价格下调、对品控的重新强调，都在提醒外界，<strong>这家公司正从激进扩张阶段回撤</strong>。</p>
  <p>但如果仅仅用股权结构或经营数据来解释赵伯华的离开，或许仍然流于表面。</p>
  <p>当回看茉酸奶这些年的发展路径，会发现答案并不指向某一次资本进出，也不完全归因于某一轮业绩起伏。赵伯华离开的，也并不是一个已经失败的品牌。</p>
  <p>或许，真正让赵伯华选择出走的，并非一时得失，而是茉酸奶自身的演变——早已和他当年在上海临港开出的那家小店，渐行渐远。</p>
  <h2><strong>牙医卖甜饮</strong></h2>
  <p>创始人的退出固然显得“刺眼”，但对赵伯华而言，这场撤退并非一时兴起，更像是早已写进剧本的结局。</p>
  <p>2014年，赵伯华在上海临港大学城附近开出了第一家门店，当时的品牌还叫“茉莉酸奶”。鲜果加酸奶的组合，踩中了大学生的消费偏好。根据公开报道，大约在2014年底至2015年初，茉莉酸奶更名为茉酸奶，并于2015年开始在上海各区陆续铺设直营门店。</p>
  <p>尽管茉酸奶走的是一条“比奶茶更健康”的路径，但再健康也是一杯含糖饮料。而<strong>在创业之前，赵伯华是一名牙医</strong>：理论上，他的职业背景应当与“少糖”“控糖”站在同一阵营。从劝人少吃糖的牙医，到投身含糖饮品赛道的创业者，这种跨界，颇具反差感。</p>
  <p>更有意思的是，<strong>2019年，上海另一位牙医同行看中了赵伯华的生意</strong>，选择加盟茉酸奶。他就是茉酸奶目前的第一大股东顾豪。</p>
  <p>相比赵伯华，顾豪的反差感更为强烈。在结束牙医生涯后，他也没有选择与“健康”相关的行业，更是直接投向了甜品赛道。随后，顾豪开始在餐饮领域寻找更多可能性，先后涉足咖啡、烧烤和火锅，但始终未能掀起太大水花。</p>
  <p>直到2019年，他加入茉酸奶，这段多次试水的创业经历，才算真正找到落脚点。</p>
  <p>彼时的茉酸奶，全国门店数量仅有7家。作为对照，同样处在创业第五年左右：喜茶的门店数已超过600家，霸王茶姬突破500家，奈雪也达到了155家。放在整个现制饮品赛道里，<strong>赵伯华显然是一个相当“慢”的创业者</strong>。</p>
  <p>转折点出现在2020年。顾豪进一步以联合创始人的身份正式加入茉酸奶。两人很快达成分工共识：<strong>赵伯华继续专注产品研发，顾豪则负责组建团队、推动扩张，各自回到自己更擅长的位置。</strong></p>
  <p>尽管同样是从牙医转行餐饮的创业者，但顾豪的风格明显更加进取。在他的主导下，<strong>茉酸奶的节奏开始发生变化</strong>。</p>
  <p>2020年，茉酸奶的开店数量增长至30家，较此前翻了不止两倍。即便从绝对数量看，依然难以与头部品牌同台竞争，但考虑到当时线下消费整体承压，这样的克制的扩张速度，反而显得合理。</p>
  <p>真正的加速发生在2021年底。茉酸奶开放加盟，直接改变了增长曲线。到2022年，其门店数迅速攀升至280家，相比2021年的45家，增长超过6倍。</p>
  <p>茉酸奶开始进入了发展的快车道，显然这并非赵伯华所长。这一年开始，赵伯华逐步淡出了台前：有报道称，<strong>自2022年起，他已开始退出公司的日常经营管理。</strong></p>
  <p>与此同时，顾豪的角色则愈发清晰。2022年3月，他开始持股茉酸奶；同年6月，进入董事会。到了2023年，随着线下消费的复苏，茉酸奶在当时的饮品市场中异军突起，门店数量迎来高峰，一举冲至1309家。</p>
  <p>年底，<strong>茉酸奶迎来了大股东——乳业巨头君乐宝</strong>，持股30%，顾豪持股比例则由45%将为40%，而赵伯华选择继续“撤退”：持股比例从原来的55%将为30%，</p>
  <p>如果站在当时的时间节点回看，没能亲自站上这轮爆发式扩张的高点，赵伯华的撤退似乎“走早了”。</p>
  <p>但进入2024年再回头看，赵伯华的撤退，反而显得意味深长。</p>
  <h2><strong>离场的不止创始人</strong></h2>
  <p>当起甩手掌柜的赵伯华，或许比任何人都更懂得“<strong>提前离场</strong>”的价值。但作为一个长期专注产品、并不急于做规模扩张的创始人，他未必愿意看到，自己一手创办的茉酸奶，最终陷入2024年那样的局面。</p>
  <p>时间回到快速扩张的<strong>2023年，茉酸奶便已经由于定价问题而掀起争议</strong>。茉酸奶在官方公众号发布了一份新品“猫山王榴莲奶昔”的定价问卷，给出了68元、88元和108元三个选项。结果，茉酸奶并未有预期那般的高端形象，反而引来大量吐槽，“酸奶刺客”的标签迅速传播。</p>
  <p>价格高低，本质上是市场选择的问题，消费者可以用“不买单”表达态度；<strong>但当争议从价格延伸至产品质量与食品安全，性质便完全不同了</strong>。进入2024年，这条红线被反复触碰。</p>
  <p>2024年3月，上海市消保委对茉酸奶芒果奶昔的成分提出质疑，要求其说明额外脂肪的来源；两天后，茉酸奶被曝出使用冰激凌原浆制作酸奶并登上热搜，<strong>其长期强调的“健康属性”随即遭到广泛质疑</strong>。</p>
  <p>5月，新京报发布调查报道，指出北京四家茉酸奶门店<strong>使用过期40多天的原料</strong>。不少消费者也在社交平台反馈：“喝完拉肚子”“使用烂香蕉”“榴莲果泥发酸”等问题集中出现。直接后果是，北京区域月销量暴跌42%，全国月销量下滑18%。</p>
  <p>6月，北京海淀区市场监管局对10家茉酸奶门店立案查处，多家门店因食品安全问题被警告，其中伊藤洋华堂门店因使用过期原料被罚款7万元，创下行业内食安处罚纪录。7月底，又有消费者投诉部分门店服务态度恶劣，品牌形象进一步受损。</p>
  <p>8月，茉酸奶宣布全面升级为“无植脂末、无氢化工艺”的奶基底，试图通过产品调整挽回信任。但风波并未就此平息：当月仍有多起投诉称，消费者饮用后出现急性肠炎或过敏反应；部分门店被指未按备注出餐、洒漏严重且态度敷衍。到了12月，又连续三天被投诉饮品中出现头发、虫子及其他不明异物。</p>
  <p><strong>一系列食品安全问题叠加，直接将茉酸奶的口碑推至谷底</strong>。自9月底起，全国范围内开始出现明显的闭店潮。进入冬季后，有消费者调侃称“冰沙奶昔加上原料不明，这大冬天里简直是‘窜稀套餐’”，而闭店速度也明显加快。到11月，全国累计闭店数量已超过760家。</p>
  <p>业绩下滑之下，加盟商的压力也集中爆发。部分加盟商曾前往茉酸奶总部维权；有加盟商回忆称，当时总部请来了安保公司维持秩序，而<strong>顾豪并未现身，这也让不少人怀疑其在刻意回避问题。</strong></p>
  <p>一位已闭店的茉酸奶加盟商透露，在去年媒体曝光门店使用过期食材问题后，顾豪便很少公开露面，“我猜顾豪是怕自己的名声被搞臭了，名声毁了的话，以后做其他品牌，加盟的人就不会很多”。</p>
  <p>彼时的顾豪，或许多少会理解，甚至羡慕早已离场的赵伯华。</p>
  <h2><strong>加盟扩张止步</strong></h2>
  <p>不过，正如加盟商所料，顾豪做起了新品牌。</p>
  <p>有加盟商回忆，顾豪曾在公司内部多次提到，<strong>要为茉酸奶寻找“第二增长曲线”</strong>。自2024年起，茉酸奶先后孵化了三个子品牌：主打酸奶碗与酸奶产品的 Gooolden，奶茶品牌优尼波巴（Uniboba），以及定位为“茉酸奶2.0”的 MoreYogurt 牧场奶仓。</p>
  <p>在主品牌口碑持续承压的背景下，这些新品牌显然被寄予了分散风险的期待。但从结果来看，这条路径并不顺利：</p>
  <p>Gooolden 已在全国范围内关停；优尼波巴目前全国约有56家门店，但部分门店开业不足一年便已闭店；牧场奶仓今年也已有2家门店关停，全国在营门店仅剩9家。</p>
  <p><strong>新品牌推进受阻的同时，管理层也持续震荡。</strong></p>
  <p>自2024年起，茉酸奶集团的CEO、品牌负责人、运营负责人、HR负责人等多个核心岗位相继更换。据业内流传，去年8月上任的CEO金国超，已于今年2月初离职，在职时间不足6个月。组织层面的不稳定，进一步放大了品牌调整期的不确定性。</p>
  <p>当内部试错成本不断抬升，茉酸奶也开始将目光投向外部寻找新增量。有前加盟商透露，今年茉酸奶已在推进加拿大、新加坡等海外市场的相关布局，希望通过出海打开新的增长空间。</p>
  <p>与此同时，<strong>价格与加盟政策，也在悄然发生变化</strong>。</p>
  <p>据南都湾财社报道，2023年7月，茉酸奶的价格带约为20-43元；到2024年3月，下探至18-34元；而近期，其价格小幅收缩至18—30元。价格下移，某种程度上也反映了品牌在市场端的妥协。</p>
  <p>价格调整背后，是加盟门槛的明显降低。据报道，目前茉酸奶的加盟费已下调约50%。而以往一家加盟店的落地成本通常在七八十万元，如今已大幅降至30万元左右，并允许加盟商收购二手设备、加盟费分期支付，以缓解前期资金压力。</p>
  <p>值得注意的是，<strong>在放低加盟门槛的同时，茉酸奶终于开始在加盟政策中强化对门店的管理</strong>。门店开业后，总部会安排人员定期检查食品安全与清洁度并进行评分，若评分达到80分以上，可减免下一年度的加盟费。这一规定多少带有“亡羊补牢”的意味。</p>
  <p>毕竟，茉酸奶在2024年集中爆发的一系列口碑问题，正是发生在快速扩张之后、门店管理明显滞后的阶段。</p>
  <p>有餐饮开店博主分析认为，经历2024年的口碑滑坡后，茉酸奶并未彻底没落，说明其供应链能力和产品基础，依然使其在现制饮品市场中占有一席之地，在酸奶这一细分赛道中占据头部。但在现制饮品行业整体增速放缓的背景下，并不建议此时贸然加盟。</p>
  <p>根据弗若斯特沙利文的报告，中国新式茶饮市场的复合增长率，已从2017—2022年间的24.9%，骤降至2024年的6.4%，预计2025—2030年仅为8%—10%。<strong>行业已经进入存量博弈，“头部吃肉、尾部喝汤”的分化在今年上半年进一步加剧。</strong></p>
  <p>显然，降价、重提品控、放缓扩张，并非战术选择，而是茉酸奶在竞争白热化后的必然回撤。规模的代价，终究会在某个阶段以另一种方式被清算。此时的顾豪，或许也终于意识到，当年那位强调节奏与边界的创业伙伴，并非过于保守。</p>
  <p>而<strong>赵伯华已经选择重新出发</strong>。多方消息显示，这位已淡出茉酸奶的创始人，近期再度创业，转身进入火锅赛道。尽管媒体多次尝试采访，但他选择了婉拒。</p>
  <p>火锅同样是一个高度拥挤、竞争残酷的行业。但对赵伯华而言，这未必是一场简单的跨界。更像是一次回归初心——回到2014年，在上海临港大学城开出第一家小店时，那个对规模保持克制、对产品高度专注的自己。</p>
  <p>在消费创业这条路上，快并不一定更远；而那些被忽视的“慢”，往往才是真正的护城河。</p>
  <p>参考资料：</p>
  <p>南都鉴定评测实验室《高管频繁变动、门店总数锐减！获君乐宝增持后，茉酸奶如何突围？》</p>
  <p>餐饮见闻《高峰1600家店！创始人突然全面离场，这个品牌怎么了？》</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/1vHbuTsWYiicLPhA9O_A0g" rel="noopener noreferrer nofollow" target="_blank">“金角财经”</a>，作者：Chester，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3612074260841728</id>
            <title>黄仁勋200亿美金接盘Groq，中东王爷和特朗普都笑了</title>
            <link>https://www.36kr.com/p/3612074260841728</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3612074260841728</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 08:46:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_2e522aff3bdf40638632a1929f2853a2@46958_oswg1026049oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：Groq的营销戏码——在行业会议活动上租了一头Llama</p>
  <p><strong>北京时间 12 月 25 日，Groq 披露与 NVIDIA 达成 200 亿美元的技术许可协议。&nbsp;</strong></p>
  <p>主要包含三项重要内容：</p>
  <p>1、NVIDIA&nbsp;并非法律意义上收购Groq&nbsp;，而是达成了一项非独占的技术授权协议，NVIDIA 将可以使用 Groq 的硬件与架构设计许可。</p>
  <p>2、Groq 的 CEO Jonathan Ross（Google 最早 TPU 团队的成员），以及 Groq 几乎所有重要的核心成员，都会加入 NVIDIA。</p>
  <p>3、Groq将继续作为一家独立公司存在，保留其核心知识产权，并继续运营。</p>
  <p>这里值得注意的是：NVIDIA 将收购 Groq 的全部<strong>实体资产</strong>，但<strong>不包括其知识产权；</strong>Groq的<strong>人</strong>看起来是被收购的主要资产；Groq这家公司并没有被收购，还会作为<strong>独立的公司</strong>继续运营之前的主要业务。</p>
  <p>媒体传出的消息说这笔交易的总价值约为&nbsp;<strong>200 亿美元</strong>。</p>
  <p>200 亿美元足以买下全球顶尖晶圆代工厂格芯（GlobalFoundries）的全部股份，也相当于&nbsp;四分之一Intel的市值。NVIDIA 愿意支付如此巨额的对价，却只拿到了一个‘非独占’的许可？</p>
  <p>联想到不久前 Intel 拿下 SambaNova 的棋局，值得对这件事情深度思考。事实上，本质上基于超长指令架构（VLIW）的所谓LPU，其<strong>架构授权本身并不值200亿美金，但是Groq交易动作背后的意义远超200亿美金。</strong></p>
  <p><strong>近来AI泡沫论、Google TPU、Broadcom、产品出口受限、甚至美国国内要求对AI强监管的呼声，都在对Nvidia的市值提出挑战。</strong></p>
  <p>黄仁勋通过极高对价的资本动作向华盛顿与中东盟友交出一份沉甸甸的“战略投名状”，意在利用资本博弈深度对接白宫的 AI 利益版图，从而换取核心产品在全球市场的出口豁免权与联邦级监管红利，进而维持在AI基础设施的垄断地位与高增长。</p>
  <p>本文基于对基于超长指令架构的AI芯片产品进行技术架构详细拆解，分析为何Groq不值这个价钱，并结合资本方及融资动态、梳理最近白宫围绕Nvidia重要动作的时间线，尝试一窥这场巨额非典型收购背后的复杂棋局。</p>
  <h2><strong>01 Groq&nbsp;讲的故事，资本很买账</strong></h2>
  <p>Groq 成立于 2016 年，其核心产品最初名为 TSP（张量流处理器），后随着 Transformer 架构成为主流，更名为 LPU（语言处理单元），也称 GroqChip 1。</p>
  <p>这款芯片于 2019 年发布。Groq 的 CEO Jonathan Ross 曾是 Google TPU 项目核心成员。与 Google TPU 采用 8 路 VLIW 脉动阵列不同，Groq 采用 144 路 VLIW 大规模设计，由 GlobalFoundries 代工，在成本和规模扩展上更具优势。</p>
  <p>产品方面，Groq 原计划 2025 年推出基于三星 4nm 工艺的第二代芯片，2026 年规模化部署，但至今未见踪影。</p>
  <p>融资方面，Groq 已累计融资 18 亿美元，包括 2024 年 6.4 亿美元 D 轮和 2025 年 7.5 亿美元 E 轮（估值 69 亿美元）。2025 年 2 月，Groq 获沙特 15 亿美元承诺资金用于扩展 AI 推理基础设施，当时已有 1.9 万颗芯片部署在沙特。</p>
  <p>那么，Groq 的产品有什么特殊之处？</p>
  <p>答案是 Memory（内存）。Groq 最显著的特点是：没有外接 DDR 或 HBM，只使用片上 SRAM。</p>
  <p>这带来极快的访问速度，但劣势明显：每颗芯片仅 230MB 存储容量。即便是 Llama 7B 这样的小模型也需要 2 个机柜，部署 70B 模型则需要 10 个机柜、超 100 千瓦功耗，而其他 AI 芯片最多一台一体机即可。（详见腾讯科技2024年2月20日分析文章）</p>
  <p>这样的代价换来的是：在单用户推理场景下性能极其出色，Token 生成速度达到市场最快一档。因此 Groq 主打“规模化部署下的高推理速度”这一卖点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_a7e5ef495df846ef875c602240e818d3@46958_oswg265113oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：高推理速度对比图</p>
  <p>需要明确：Groq 不是 TPU 翻版，也不是传统 ASIC。除了内存设计，其架构也截然不同。Groq 采用 144 路全覆盖 VLIW 架构，可准确描述为：极宽 VLIW、完全静态调度、单线程确定性执行、无乱序/分支预测/投机执行、数据流高度可预测。这表明 Groq 更接近“超大规模硬实时 DSP/Dataflow Machine”。</p>
  <p>Groq 在 AI 计算中有哪些优势？</p>
  <p>首先，极低且可预测的推理延迟，Token 输出极快。这是 Groq 最大优势。其架构无动态调度干扰、无缓存缺失随机延迟、无 Warp 分歧性能损耗、无内核启动开销，因此 token latency 和 tail latency 都极小。在单请求体验和实时推理场景中极具吸引力。</p>
  <p>第二，极高的能效理论上限。无复杂控制逻辑，芯片大部分面积用于计算，没有长期常开的调度单元，算力能耗比理论值非常漂亮。</p>
  <p>第三,确定性系统行为，对系统工程极其友好。每个 cycle 的执行已知，无运行时调度抖动，性能不因输入分布变化而漂移，这对系统设计和运维非常友好。</p>
  <p>但这些优势成立的前提极其苛刻：必须把计算静态地、近乎完美地填满 144 个并行执行块。这要求模型结构高度规则、算子形态稳定、内存访问可预测、调度空间可被人工穷举。</p>
  <p>真实场景并非如此理想，因此需要极强的软件来弥补。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_9112e5400df24ee1b22b033af2124be6@46958_oswg263656oswg1080oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02&nbsp;真实的Groq芯片架构</strong></h2>
  <p>上面提到Groq的芯片根本不是TPU，而是类似于DSP的架构，其在AI计算中的优势要求很苛刻。更值得玩味的一点是，Groq近几年特别避讳说自己的架构是超长指令架构，这又是为什么呢？</p>
  <p>超长指令字（Very-Long Instruction Word，VLIW）是一种相当“异类”的计算机体系结构，它与 CPU 和 GPU 在设计理念上非常不同。</p>
  <p>在过去的几十年里，VLIW 一直在一些细分市场中表现出色，比如DSP和MCU领域。而随着AI的兴起，以及对AI算力芯片需求的大爆发，VLIW 开始再次伟大“复兴”（Make VLIW Great Again！）。</p>
  <p>之所以许多人关注并利用VLIW 这种架构，是因为它能够实现<strong>结构简单、设计优雅、高效率、低延迟</strong>的芯片硬件。但其代价也很大，它几乎把负担和期望全部压在了编译器和软件栈身上，很多时候甚至需要用户亲自手写（汇编）代码。</p>
  <p><strong>AI计算芯片（通用芯片与专用芯片，泛化能力）</strong></p>
  <p>在AI芯片领域，对模型的泛化能力决定了是否可以被真实地部署到生产环境中，而这就与编译器存在着紧密关系。简单来说，芯片硬件决定了性能的上限，而编译器决定了芯片能发挥出多少性能，以及可以支持多少种模型。</p>
  <p>在AI计算中（本文都是以推理计算为例），AI模型是由复杂的数学算子（卷积、矩阵乘法等）组成的计算图。由于芯片（VLIW 或 GPU）只认底层的二进制指令，因此就需要编译器来负责把高级语言（PyTorch/TensorFlow）写的模型，翻译成芯片能听懂的指令。但是对于 VLIW 这种静态架构，编译器还要多做一项任务，也就是精确安排哪个计算单元在哪个纳秒处理哪个数据。</p>
  <p>正是因为这最后一个任务，成了所有VLIW架构的AI芯片编译器的噩梦。</p>
  <p><strong>编译器和工具链</strong></p>
  <p>我们用Groq和Nvidia的GPU来举例说明编译器对于模型的泛化能力的影响、进而对是否可以大规模商用部署所起到的决定性作用与极限挑战。</p>
  <ul>
   <li>GPU，是强硬件架构，泛化能力由硬件冗余和编译器共同支撑。</li>
   <li>GPU硬件内置了复杂的调度器，能自动处理一些乱序和并行任务。编译器的压力相对较小，只需要把算子优化好即可。</li>
   <li>这类芯片天然泛化能力强，因为即使编译器不是最完美的，硬件也能靠“蛮力”自动查漏补缺。</li>
  </ul>
  <p>Groq，基于VLIW，算是强软件架构，泛化能力和编译器的强大程度息息相关。</p>
  <p>芯片硬件本身非常简单（甚至没有调度逻辑）。如果出现了一个全新的模型结构（比如从 CNN 变成 Transformer），硬件动不了，只能靠编译器去重新拆解计算图，寻找新的并行方式。</p>
  <p>如果编译器不够聪明，无法把复杂的模型逻辑映射到简单的硬件上，芯片的泛化能力就会很差，只能跑特定的几种模型。</p>
  <p>也正因如此，<strong>Groq几乎不使用VLIW架构这个字眼，而是用TSP</strong>，后来更是用LPU这个非常蹭大模型眼球的名称，就是希望将软件面临的问题不要被太注意。</p>
  <p>即使在最初（2020年）其介绍产品的这篇论文中，在“ARCHITECTURE OVERVIEW”这个小节，也只是使用了“144 independent instruction queues (ICUs) ”这个表达，通篇没有VLIW这个词。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_bad08c53764f42f1bad903057a607cd0@46958_oswg71906oswg1077oswg389_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也就是说，考虑到那个年代模型的零碎，Groq从一开始就在向外界隐藏（或者说淡化）致命的弱点，<strong>就像现在绝大多数所谓AI芯片公司一样，对大规模商用部署讳莫如深，目标仅仅是用自己的Demo（展示机）来提升估值。</strong></p>
  <h2><strong>03&nbsp;VLIW的AI芯片产品周期</strong></h2>
  <p>事实上过去这些年，有许多公司尝试着用VLIW来做（AI）芯片，比如Movidius、高通的Hexagon、Google的TPU、TI的DSP，其中DSP做的很不错，但做AI芯片，都绕不开编译器的问题。</p>
  <p>这众多项目中，只有 Google 在<strong>自家选定的的应用场景下</strong>、在<strong>8-wide</strong>规模上把编译器做得很好。而 Groq 是 144-wide，难度不是线性上升，而是巨量级上升。</p>
  <p>因此在这个领域的创业公司做AI芯片产品，大概率就会是这么一个套路：</p>
  <p>1.&nbsp;硬件团队做出漂亮架构，算出理论吞吐、能效、面积优势，找投资人拿钱；</p>
  <p>2.&nbsp;现实落地阶段会发现不仅难泛化，且无法做到当初预期的性能，毕竟把模型映射到宽 VLIW 的调度问题实在太难；</p>
  <p>3.&nbsp;这个时候就会手动调优某一特定模型，然后利用特定模型手动调优出的性能，继续找投资人拿钱；</p>
  <p>4.&nbsp;但如果模型迭代太快，编译器团队就会压力倍增，需要更多的人手来手动处理，这又会要求融更多的钱来招更多的高成本的软件工程师；</p>
  <p>5.&nbsp;随着融资轮次的增加，编译器和市场团队会无路可走，产品与市场负责人或者继续承压，或者当作背锅侠走人；</p>
  <p>6.&nbsp;而采用VLIW的这家企业，真正的目标实际上是要靠尽快被并购（在国内运气好了赶上政策还可以上市）来套现；</p>
  <p>对于成熟的资本市场而言，对其他 AI 芯片初创公司的信息非常明确：要么当某大厂的合作伙伴，要么成为收购目标，要么作为竞争者被砸钱砸到出局。</p>
  <h2><strong>04&nbsp;独特的视角：人员流动方向</strong></h2>
  <p>如果你现在去看Groq论文中的第一作者，Dennis Abts，会发现他在 2022 年 10 月加入了 Nvidia。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_524258cd91724ad790465f289eee847e@46958_oswg129670oswg791oswg793_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：Dennis Abts加入Nvidia</p>
  <p>这位曾在大名鼎鼎的Clay工作的大佬，在Groq正是软、硬件协同设计的负责人。2022年的夏秋之际，正是大模型爆发的前夜，AI还是处在ResNet、Yolo、BERT、UNET、双塔等&nbsp;CV、NLP和搜推应用中数目繁多的模型与场景中，对于一家AI芯片来说，软件栈对于这些大量的主流模型的适配是无法逃避的工作，如果要支持快速迭代的适配，编译器就不得不面对动态调度的需求，这对Groq（的Dennis）来讲几乎是不能完成的任务。如果需要向投资人交差，主动或背锅离开就是必然的了。</p>
  <p>我稍微花了点时间去搜索，除了Jonathan Ross作为创始人还在之外，其中有许多为已经离开，去往NV、Google、Amazon等企业。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_9b1806b8661143dc8280278e2c2dbd66@46958_oswg280137oswg1080oswg2688_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>05&nbsp;套现的交易？</strong></h2>
  <p>正如上面所述典型套路，此类公司（在海外）的终局就是被收购，这不过是将相关人等的解套。然而，这次的并购正如Groq其芯片架构一样，挂羊头卖狗肉。</p>
  <p>真实的并购交易需要监管审批，<strong>而这只是一笔技术授权交易，并不需要证券、反垄断等监管机构的审批。</strong>但如果稍微动点脑子就会发现，在结果层面，它<strong>看起来已经非常接近一次并购了。</strong></p>
  <p>这也是铺天盖地的新闻报道，标题几乎都是按照收购来写的原因。</p>
  <p>近年来很多类似交易都遵循同一种模式，全球最大的科技公司用大额资金与“有前途的”初创公司达成协议，拿走它们的技术与人才，但又刻意避免在形式上完成收购。他们假装这只是受限的 IP “收编式挖人（acquihire）”。</p>
  <p>设想一下，假设真有这么一家芯片公司，也想获得 Groq 的 IP 授权。那么问题来了：技术支持从哪里来？核心成员并入NV的情况下，后续还有没有持续演进的技术路线图？还是说，公司买到一个“没有未来开发团队的 IP 包”也是可以接受的？</p>
  <p>前面提到，最近一轮的融资是在今年9月，投资者包括贝莱德、纽伯格伯曼、三星、思科，以及Altimeter和1789 Capital。特别需要注意的是，对，特别需要注意，<strong>特朗普的大儿子是1789 Capital的合伙人</strong>。</p>
  <p>更进一步，这对沙特主权财富基金来说是可以一场大胜，在此之前，其对Groq的投入，基本上都转化成了在当地的算力建设，而本次的交易，又实现了超额的资本收益。赢两次，双赢。</p>
  <p>有没有一种可能，这笔法律上不构成并购的交易，在今年9月份已经谈妥？</p>
  <h2><strong>06&nbsp;Nvidia的考量</strong></h2>
  <p>但是，花费200亿美金，Nvidia图什么？</p>
  <p>从产业角度分析，可以牵强附会多种利好与协同。</p>
  <p>推理成为主战场后，客户开始按Token的综合成本重新定义性价比，这种在某些场景下极致性能的VLIW芯片也许可以成为Nvidia的侧翼，从而让手上也有一条“非 GPU”路线可以塞进同一个平台叙事里。再考虑到Groq已经尝试了芯片公司运营AI云的商业模式，NV借此机会暗渡陈仓进入这一业务，并通过这一模式配合英伟达的市场与资本运作，也尚未可知。</p>
  <p>但，这并不能解释为何会值200亿美金。更蹊跷的是，这个200亿美金的交易对价，并不在Groq的新闻稿中，而是由CNBC最先透露。</p>
  <p>最合理、且符合实际的解释，就是这本质是一出资本套现戏码，既和NV和AI产业的资本局有关，也可能和黄教主在游说白宫（甚至是特朗普）达到某个战略目标有关。</p>
  <p>近来AI泡沫论、GoogleTPU、Broadcom、产品出口受限、甚至美国国内要求对AI强监管的呼声，都在对Nvidia的市值提出挑战。</p>
  <p>黄仁勋同时在白宫两条线游说：一条是反对更严对华&nbsp;（以及其他受限制国家，此前也包括沙特）AI 芯片出口法案（如 GAIN AI 法案未被纳入国防法案）；另一条就是反对州级 AI 严监管、争取联邦统一框架，两者共同目标都是为英伟达争取更大的全球与本土市场空间。</p>
  <p>NV通过这笔交易进一步向沙特示好。美国AI巨头，都将中东当作算力布局中最为重要的区域，此前一段时间，该地区也在受限列表上。而随着豁免的批准，Nvidia可以借助于自身和Groq原有的布局、以及这笔交易向沙特交的“投名状”，更好地开展业务。</p>
  <p><strong>看一下时间线：</strong></p>
  <p>2025年夏天，特朗普试图在“大而美法案One Big Beautiful Bill”中塞入一条“联邦优先、冻结州级 AI 法规 10 年”的条款，结构参议院投票结果为 99 票反对、1 票赞成，条款被否决。</p>
  <p><strong>2025年9月，Groq进行了最后一轮融资，1789 Capital（小特朗普）入股</strong>，老股东跟投。</p>
  <p>2025 年 11 月 19 日：美国商务部正式宣布，授权沙特政府支持的 AI 公司 Humain 和阿联酋的 G42 购买先进 AI 芯片，每家最多可购 3.5 万枚英伟达 Blackwell GB300 或性能相当的 AI GPU，这标志着美国首次公开批准大规模向沙特出口当前一代顶级 AI 芯片。</p>
  <p>2025 年 12 月 8 日，特朗普在其社交媒体账号上发文宣布，在“确保国家安全”的前提下，允许英伟达向中国及其他获批客户出口 H200，随后白宫与商务部等部门开始就具体许可和“白名单”审查流程落地。</p>
  <p>2025年 12 月 11 日，特朗普签署名为“确保人工智能全国政策框架”的行政命令，通过行政手段推进联邦优先思路，被视为绕开国会僵局、在监管上“联邦接管 AI 治理”的一步。</p>
  <p>若联邦成功压制“最严厉”的州级 AI 法规，英伟达等 AI 基础设施供应商在美国的客户（云厂商、互联网平台、大模型公司）合规负担会减轻，间接支撑这些客户继续高强度采购 GPU/AI 芯片，对英伟达业务构成正面支持。有利于提振对英伟达未来收入与投资周期的预期，进而可以继续支撑甚至抬高股价。</p>
  <p>2025年12月24日，Groq宣布了这笔对价200亿美金的交易。</p>
  <p>中美这两大在AI领域下重注的经济体，近来不约而同地为AI芯片创业企业救场。AMD收购Untether AI的员工团队；传言Intel近乎达成对Sabanova的收购；Nvidia非典型地收购了Groq；而在东方大国，科创板近来挂牌两家，元旦新年后一周时间港交所再迎来两家。</p>
  <p>当Google和Broadcom吹响了TPU的号角，AMD催肥了CUDA兼容的土壤，东方已然破晓！</p>
  <p>资本东风迎面吹来，科创板与港交所的钟声嘹亮；向西吹去，并购的落槌声此起彼伏。</p>
  <p>历史不会重复，但会押着相同的韵脚。无论西东。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/kIRMEfLe8L7ZVCJC2H17JA" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，作者：姚金鑫（J叔），36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3611984546706178</id>
            <title>2025年即将过去，带你重温科技圈发生的12件大事</title>
            <link>https://www.36kr.com/p/3611984546706178</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3611984546706178</guid>
            <pubDate></pubDate>
            <updated>Fri, 26 Dec 2025 08:00:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>时间过得很快，一转眼2025年就要过去。回首2025年，科技圈发生各种大事小情，让人眼花缭乱。其中，一些重大事件不仅对企业自身发展是一大突破，更对行业变革产生深远影响，你不容错过。</p>
  <p>站在2025年尾声，不妨以月为单位，复盘每个月科技圈发生的一件大事，这12件大事也许能唤醒你的记忆。原来2025年月月有精彩，并对2026年充满期待！</p>
  <p><strong>1月：DeepSeek一夜爆红</strong></p>
  <p>今年春节被DeepSeek霸屏，它用高超的算法、开源技术路线、极低的成本，一举打破了科技巨头用算力构建起的高墙，也让AI平民化成为现实。1月最后一周，DeepSeek在短短7天内新增1亿用户，累计用户达1.25亿（含Web、App，未去重），表现极其炸裂。</p>
  <p>DeepSeek火爆出圈后，倒逼国内外同行在春节火力全开、加班加点，国产芯片、软硬件公司、云厂商紧急加入DeepSeek“朋友圈”，以形成软硬件协同，提升竞争力。同时，DeepSeek“国运级别的科技成果”“摧毁英伟达的算力神话”等溢美之词，给海外资本市场带来剧烈扰动，导致1月27日美股芯片股集体崩盘。</p>
  <p><strong>2月：京东杀入外卖市场</strong></p>
  <p>京东外卖的杀入，使美团、饿了么（现更名为“淘宝闪购”）长期主导的外卖市场终于迎来新的变量。凭借品质外卖、给全职骑手缴纳五险一金、2025年5月前入驻全年免佣金等利好政策，京东外卖迅速崛起，上线90天内，日订单量即突破2500万单，入驻商家超200万。</p>
  <p>当然，京东外卖在搅动外卖市场格局的同时，也打开了即时零售的新世界大门，京东、美团、阿里上演“三国杀”。在大手笔烧钱的加持下，今年暑假，即时零售市场的炮火震耳欲聋，淘宝闪购、美团外卖日订单量高峰均突破1亿。在这场大战中，美团处于守势，京东、阿里则处于攻势，它们鏖战不仅为了抢占市场份额，更事关未来“本地生活入口”的定义权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_730519e8fd034c8abd3d2059c5a14148@46958_oswg42279oswg500oswg468_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>3月：雷军意外带火周云杰</strong></p>
  <p>今年3月，海尔掌门人周云杰意外走红，准确来说是被小米掌门人雷军带火的。原因是他们一起走上代表通道，被网友P出各种搞笑的神图在网上疯传，周云杰看后直言自己也被逗笑了。一时之间，周云杰成为各路媒体争相采访的对象，以至于让鲜少见过如此大阵仗的他有点招架不住。</p>
  <p>同时，网友纷纷喊话周云杰赶快开通个人账号，而他主打一个听劝。没过多久，果然开通抖音和微博账号，并带动一众海尔高管起号。值得一提的是，周云杰开通微博账号时，雷军还表示欢迎。其实，两位大佬有很多共同点：都是学霸、知名企业家，也都很听劝。</p>
  <p><strong>4月：大厂争相推出外贸扶持计划</strong></p>
  <p>面对国际市场波动与国家提振消费的号召，国内大厂纷纷行动起来，推出外贸扶持计划。比如，腾讯、抖音集团分别推出“外贸新征程助跑计划”、“外贸优品专项扶持计划”，前者助力国货转销东南亚，后者则助力外贸企业转内销。阿里国际站自4月初开始飞赴全球各地找销路，并上线专门的AI选品工具，而淘宝天猫启动的“外贸精选”专项计划，则致力于帮助外贸商家快速拓展国内市场。</p>
  <p><strong>5月：小米玄戒O1正式发布</strong></p>
  <p>今年5月，小米自主研发设计的3nm旗舰芯片——玄戒O1正式发布，首发搭载在小米15S&nbsp;Pro、小米平板7Ultra上。众所周知，芯片行业的特点是重投入、长周期、难度大，玄戒O1历时4年研发，投入2500多人和135亿元，并汲取松果的惨痛教训，才得以小有所成。雷军深知造芯之艰难，制定了长期持续投资的计划：至少投资十年和500亿，稳打稳扎、步步为营。</p>
  <p><strong>6月：李云飞与杨学良隔空互呛</strong></p>
  <p>今年6月，在中国汽车重庆论坛上，比亚迪品牌及公关处总经理李云飞与吉利控股高级副总裁杨学良隔空互呛，火药味十足。当时，李云飞犀利地指出，有些企业就是又坏又蠢，讲个产品都要拉踩，有些时候不是不想回应，是懒得回应。一天后，在同一场合，杨学良毫不客气，对比亚迪贴脸开大，“今年同行抛出了拉踩论，又蠢又坏论，算不算贼喊捉贼呢？”</p>
  <p>这还没完，真正的高潮来了，他再度提起“常压油箱”风波，直言这是典型的违法犯罪事件，到底谁对谁错、谁真谁假，一定要有一个公开的结论，不能不了了之。杨学良特意强调，吉利做的拆解测试，与长城举报的内容信息完全一致。对于“常压油箱”风波，以及彼时舆论热议的“车圈恒大”话题，李云飞没有选择回避，而是在微博上大大方方回应，强势回击吉利、长城，但很快便删除。据说是王传福直接下的决定，让李云飞“忍一时，和为贵”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_949bbb47136d4f0caec26cfc127d63ec@46958_oswg35036oswg750oswg426_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>7月：理想i8对撞测试引发争议</strong></p>
  <p>7月底，理想汽车首款纯电SUV理想i8上市后风波不断，尤其是与乘龙卡车对撞测试引发轩然大波，质疑测试结果离谱甚至造假的不在少数。尽管涉事三方理想、中国汽研、东风柳汽均在第一时间发声，但由此引发的争议并未消散，反倒愈演愈烈。比如，卡车头掉下来有点违反常理，理想方面却只字不提个中原因。</p>
  <p>再比如，中国汽研为什么买二手卡车来测试，而不是买全新卡车？又是否对乘龙卡车的车况进行详细检查？直到8月6日，三方发布联合声明，其中理想、中国汽研均公开致歉，替被躺枪的乘龙卡车澄清事实、消除误解，这场风波才到此结束。不久后，理想掌门人李想请部分货运师傅们吃饭，在谈及对撞测试时表示，“多少让很多乘龙卡车用户有点不开心，有冒失但无意冒犯！”</p>
  <p><strong>8月：罗永浩的十字路口上线</strong></p>
  <p>今年8月，罗永浩主持的深度播客节目——罗永浩的十字路口正式上线，嘉宾包括李想、何小鹏、刘谦、刘靖康等人，视频平均时长超过3小时，主打深度交流，内容涵盖创业思考、行业趋势及AI技术前沿，一上线便成为爆款。罗永浩表示，视频播客才是未来，节目效果符合预期，如果效益特别好会考虑增加更新频率。</p>
  <p>他还透露，自己与企业接触时发现，对方最愿意掏钱买的是上播客的名额。但罗永浩的十字路口不是花钱能上的，这条线守得很死，“我清楚，一旦开了这个口子，团队的价值观就会‘往脏了去’，这队伍就没法带了。”当然，播客高流量就会有高收益，目前罗永浩的十字路口已与瑞幸等多个赞助商合作，实现产品露出。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_c69575f4b113424ca088cb3b4931320e@46958_oswg58381oswg650oswg488_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>9月：iPhone&nbsp;17系列卖爆了</strong></p>
  <p>9月手机圈的主角注定只属于苹果，全新iPhone上市成为万众瞩目的焦点，今年带来的iPhone 17系列也不例外。新机于9月10日发布，9月19日正式开售，市场表现超出预期，简直卖爆了！据知名数码博主“数码闲聊站”爆料，iPhone 17系列上市1个月，即截至10月19日，累计激活530万±，实时破600万。</p>
  <p>其中，iPhone 17 110万±，iPhone 17 Pro 167.6万±，iPhone 17 Pro Max 252万±。显然，这无疑是个非常炸裂的成绩，有些国产安卓旗舰一年也卖不了这么多，而苹果只用了短短一个月便达成。说白了，国产厂商在发布会上再怎么卖力diss iPhone，都掩盖不了苹果无比强大的既定事实，追赶注定任重道远！</p>
  <p><strong>10月：旗舰机混战打响</strong></p>
  <p>随着9月底天玑9500、第五代骁龙8至尊版两款旗舰芯片发布，由此拉开新一轮旗舰机混战。其中，国庆前夕发布的小米17系列打头阵，真正的重头戏在国庆后。vivo、荣耀、OPPO、红魔、iQOO、realme、努比亚、一加等玩家轮番登场，带来各自的当家旗舰，使10月的手机市场格外热闹。</p>
  <p>不过，话说回来，不管各家旗舰在发布会上如何吊打甚至碾压对手，终究要在市场上分出胜负，即用销量说话。母系旗舰中，小米一马当先，vivo、OPPO紧随其后；子系旗舰中，iQOO表现最为抢眼。当然，这只是一时的胜负，把眼光放长远，在市场格局成型之前，仍存在较大变数，这直接关乎各家的高端化前景。</p>
  <p><strong>11月：阿里千问开启公测</strong></p>
  <p>11月中旬，阿里全新推出的AI应用“千问”正式开启公测。阿里对其寄予厚望，希望打赢AI时代的未来之战，成为国民级应用。或许你会好奇，面对DeepSeek、豆包、元宝已抢占先机，姗姗来迟的千问是否还有机会？当然有，目前国内AI To C市场正处于起步阶段，所有台面上的玩家都有机会，更何况千问还有两大杀手锏：</p>
  <p>一是技术优势，Qwen大模型的持续升级是关键支撑，Qwen3-Max性能已超越GPT5、Claude Opus 4，跻身全球前三，最强模型为智能体AI的精准服务提供基础；二是场景优势，千问定位于一个会聊天能办事的个人AI助手，在阿里生态的加持下，可以助力其打开能办事的想象空间，接入地图、外卖、订票、办公、学习、购物、健康等各类生活场景。基于此，公测一周下载量便突破1000万次。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251226/v2_564b409f683a43d480f5d92008713583@46958_oswg14372oswg600oswg553_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>12月：豆包AI手机引发广泛关注</strong></p>
  <p>12月初，字节跳动与努比亚联合推出的“豆包AI手机”引发广泛关注。其核心卖点在于对日常App的自动化操作，包括点外卖、订机票、比价购物，AI还能代替回复微信消息、操作小程序游戏等。推出后一度一机难求，二手平台更是炒到最高9999元，火爆程度可见一斑。</p>
  <p>不可否认，豆包AI手机的探索具有积极意义，让整个行业和普通大众看到AI手机的一个形态，对生态的促进也有推动作用，但也引发关于数据授权、隐私保护与系统安全的讨论。其实，围绕AI手机的落地，业内已出现两条截然不同的技术路线之争：一条是以豆包AI手机为代表的GUI Agent范式，另一条则是谷歌、苹果等厂商倡导的&nbsp;Agent to Agent（A2A）范式。未来到底哪条技术路线会占上风，让子弹先飞一会！</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/PrzWTLJQVRgxWulhUmWjXw" rel="noopener noreferrer nofollow" target="_blank">“龚进辉”</a>，作者：龚进辉，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>