<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3533023048128902</id>
            <title>京东失去自信力了吗？</title>
            <link>https://www.36kr.com/p/3533023048128902</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3533023048128902</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 12:38:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_de65e5a8e50344d78b5436d97bacf7c4@6270888_oswg35985oswg600oswg251_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <blockquote>
   <p><strong>不论叫做「二选一」，还是「主动比价」，都让人再次注意到巨人的蹒跚</strong></p>
  </blockquote>
  <p>京东认为，自己并没有「二选一」的行为。&nbsp;</p>
  <p>今年「双十一」来得早，国庆假期刚过，京东已经启动本年度「双11全球好物节」，也是几大购物平台中最早起跑的。&nbsp;</p>
  <p>但很快，有媒体指出京东有「二选一」的行为，比如要求双11期间商家在抖音等其他平台直播时，不得抽奖、发放优惠券或打出价格优惠标识等，而商家一旦被发现「违规」，将面临数百万元到数千万的高额处罚。&nbsp;</p>
  <p>京东没有发布官方的回应，先是有「前京东采销负责人」在社交平台力挺老东家，说这是「正常比价是为用户谋福利」，认为有人在给京东扣帽子。&nbsp;</p>
  <p>之后有媒体引用「京东内部人士」，称京东是在「主动比价」，「本质是为消费者构筑价格防护墙」，所以不是「二选一」，这是在曲解语义。&nbsp;</p>
  <p>不过，很难说外界的质疑只是「曲解」。根据相关部门的解释，「禁止平台内经营者在其他竞争性平台开店和参加其他竞争性平台促销活动」都属于限制市场竞争的「二选一」，而京东也的确限制相关商家参与抖音电商等平台的促销。&nbsp;</p>
  <p>「二选一」这一概念广为人知，也与京东有关。&nbsp;</p>
  <p>在京东与阿里激烈竞争的年代，京东便因为阿里强迫商家二选一而提起诉讼并获得胜利，而阿里几年前遭遇反垄断的重罚，「二选一」也是原因之一，上述关于「二选一」的解释便来自这次的处罚决定。&nbsp;</p>
  <p>那时候，京东还站在道德的高地上，它也不愿意轻易下来。在上半年的「外卖大战」里，京东也曾经以「二选一」来指责美团限制外卖骑手的选择。&nbsp;</p>
  <p>所以，很能理解为何京东宁愿换个说法，也不想担下「二选一」的名头。只是，<strong>不论是「二选一」，还是「主动比价」，看起来都像是焦虑之下的应激反应，激烈，笨拙，却不能解决实际问题。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_541d36e5012b49419ed0ca409bb3ad28@6270888_oswg43784oswg840oswg560_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>京东如何走到这一步？</strong></h2>
  <p>京东似乎失掉自信力了，不仅体现在这次的应对中，也体现在今年以来的一些矛盾措施里。&nbsp;</p>
  <p>今年三月，外卖大战开始之前，京东推行「春晓计划」，通过降低门槛、流量扶持等方式，极力吸引数以百万计的中小商家入驻，说想构建一个开放、繁荣的第三方平台生态。&nbsp;</p>
  <p>「生态」的本质是开放与共生，而「墙」的本质是封闭与防守。&nbsp;</p>
  <p>京东通过「价格防护墙」的强硬姿态，试图建立一个封闭、可控的价格体系来保护其核心市场份额，这是一种典型的防御性、控制性思维。&nbsp;</p>
  <p>一家企业不可能在同一时间、用同一种战略，既去砌墙，又去种树，这样的分裂，恰恰是丧失自信的在位者最典型的行为特征：<strong>既想通过严密的控制来找回安全感，又恐惧于封闭可能带来的僵化与衰亡。</strong></p>
  <p>于是在两种完全相悖的路径之间摇摆不定，最终只会向市场传递出混乱的信号，并疏远其赖以生存的合作伙伴。&nbsp;</p>
  <p>京东是如何走到这一步的？&nbsp;</p>
  <p>不少人的分析，认为与上半年外卖大战的失利有关。这些观点里，外卖大战让京东花费了巨额补贴，而最终缺少资金继续投入到「双十一」，于是只能用「主动比价」的方式来应对。&nbsp;</p>
  <p>这可能是事实，不过还可以顺着往下再说一层。&nbsp;</p>
  <p>外卖大战刚开始时候，我曾分析，三家公司的意图各不一样，而京东的目标有两个：&nbsp;</p>
  <p>业务上，京东需要用更低的成本获取高频流量，以带动其电商主业；&nbsp;</p>
  <p>组织上，京东要用一场盛大的战争迎接创始人归位，也让京东重新找回战斗力，最终走出刘强东口中「失落的五年」。&nbsp;</p>
  <p>京东步步紧逼，制造了巨大的竞争压力，迫使阿里巴巴不得不提前并加码应战。&nbsp;</p>
  <p>我们能看出那时京东的自信，内外部的人都会评论，感觉之前的东哥和京东回来了。在核心电商业务增长乏力的背景下，京东以外卖业务向外界、也向自己证明：其引以为傲的核心能力（物流履约）依然具有强大的「进攻性」和「可复制性」，足以在新战场开疆拓土。&nbsp;</p>
  <p>不过，这场被寄予厚望的进攻很快就遇到失败。&nbsp;</p>
  <p>京东用于电商的「重骑兵」式仓配体系，完全无法适应外卖「30 分钟」的即时性「巷战」需求。巨额的补贴投入并未换来可持续的市场份额，反而严重拖累了公司利润，导致股价大幅下挫 。这次失败，向京东管理层证明了一个残酷的现实：向外扩张的路，走不通了。&nbsp;</p>
  <p>于是，在 6·18 期间还意气风发的京东，到了双十一时候已经成了防守者，进攻受挫，而追兵将至。&nbsp;</p>
  <h2><strong>在错误的战场，使用错误的武器</strong></h2>
  <p>今年，抖音电商今年对外的动作少，对内则一直在做业务调整，并大举发力家电业务。家电需求与利润都很好预测，像是一艘电商货船的压舱石，确保前行稳定。&nbsp;</p>
  <p>家电也是京东起家的商品，也塑造了京东最初的业务与文化形态。&nbsp;</p>
  <p>回到公司起点，我们可以简单地把淘宝理解成线上的「四季青」，大家来这里是摆摊卖各类非标品，比如衣服、饰品甚至销量极高的成人用品；京东则是线上的「数码港」，自己就是商家，来这儿的也都略略懂行，也需要更好地配送和售后。&nbsp;</p>
  <p><strong>阿里和京东以不同的方式制定了中国电商的规则，让中国人可以信任电商。阿里的核心是支付宝体系，而京东的核心是自建物流体系。</strong></p>
  <p>自建物流是物理世界的「重资产」壁垒，也转化成京东在用户体验上的绝对优势。京东用「多、快、好、省」四个字定义了品质电商的标准，其中，「快」和「好」是其灵魂。&nbsp;</p>
  <p>极致的物流速度和可靠的售后服务，共同塑造了京东自营模式的核心价值，引领着消费者的选择。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_bfe40683062846109054f742a062a5b7@6270888_oswg154611oswg1000oswg750_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>京东也理所当然地享有因卓越服务而产生的品牌溢价。当一件商品在京东和天猫之间存在小幅价差时，京东次日达的便捷、正品保障的安心以及退换货的无忧体验，足以构成消费者选择京东的决定性理由。&nbsp;</p>
  <p>不过，我们先不说经济环境引起的消费者对价格更敏感，但从京东而言，在服务上构建的壁垒也越来越薄。&nbsp;</p>
  <p>「次日达」在 2010 年是一场革命，但在 2025 年，当整个行业的物流效率都在提升，它已接近成为「行业标配」。&nbsp;</p>
  <p>京东的「自信」在很长一段时间里变成了「自满」，它沉迷于优化其庞大的物流机器的成本与效率，却停止了在「服务」本身的「价值创新」。当用户体验不再有质的飞跃时，消费者对服务溢价的支付意愿自然会下降。&nbsp;</p>
  <p>而且，京东先前的庞大优势，也逐渐成了「组织惯性」，阻碍京东进一步向前。&nbsp;</p>
  <p>刘强东本人也承认，京东组织变得「庞大臃肿低效」，存在严重的「大公司病」。事实上，在拼多多之前，京东已经接入了抖音生态；在抖音电商成为一级部门之前，京东也有过自己的直播，并在 2023 年也再次获得重视。&nbsp;</p>
  <p>京东的反应并不慢，但最终总是会走上先前的路子。我们现在熟悉的京东，依然是一个穿着红色衣服的「小哥」，骑着电瓶车或者三轮车，有礼貌地敲门送货。&nbsp;</p>
  <p>和十年前没有任何区别。&nbsp;</p>
  <p>京东内部的业务部门也是如此。有从京东来到抖音电商的朋友告诉我，在京东，做活动几乎只有一种方式：发券。在他们看来，如果没能吸引消费者，那一定是券发得不够。&nbsp;</p>
  <p>所以她很为抖音电商感到惊讶，因为后台有着极其细致的标签，甚至可以分析出消费者下单前后几分钟里的行为，并以此来与商家和运营做沟通和复盘。&nbsp;</p>
  <p>从这一角度来说，<strong>京东以「主动比价」的方式来应对抖音电商，并把抖音电商的「破价」看做最需要应对的事情，本身也是路径依赖的体现。</strong></p>
  <p>在京东看来，商品价格是一个可以被管理的、相对静态的参数。&nbsp;</p>
  <p>为了实现「全网最低价」的管理目标，它有权通过后台系统直接修改价格。这完全符合其作为「货架管理者」的角色认知。&nbsp;</p>
  <p>然而，在抖音的生态里，那个引发争议的「低价」并非一个孤立的数字，它是「内容」的一部分，是特定场景的产物。它可能诞生于一场长达数小时的直播，是主播与品牌方在数百万观众面前反复拉扯，最终达成的一个戏剧性结果。&nbsp;</p>
  <p>这个价格的背后，捆绑着粉丝的情感、现场的气氛和限时抢购的紧迫感。它是一个动态的、充满叙事性的事件，而非一个静态的、可供比对的标签。&nbsp;</p>
  <p>当京东试图用后台指令去「管理」这个由内容和情绪创造出来的价格时，它犯了一个根本性的品类错误。它无法理解，也因此无法掌控这个新对手的运作逻辑。&nbsp;</p>
  <p>京东就像一个严谨的图书馆管理员，试图用杜威十进制分类法去整理一个喧闹的、充满即兴表演的狂欢节。这种深层的错配感，导致其所有应对措施都显得笨拙、失当，且往往适得其反。&nbsp;</p>
  <h2><strong>「比价」的恶性循环</strong></h2>
  <p>一个自信的行业领导者，通常会扮演其商业生态的「建设者」和「赋能者」。因为它知道平台的繁荣与生态内合作伙伴的健康发展休戚与共。刘强东早年提出的「三毛五理论」，即主张品牌方应保留大部分利润以投入创新，正是这种自信的「建设者」心态的体现。&nbsp;</p>
  <p>然而，<strong>当领导者丧失自信，其行为模式会迅速从对外建设转向对内消耗。</strong>在巨大的外部压力下，它不再将生态伙伴视为共同成长的盟友，而是视为可以用来抵御风险、转嫁压力的「人质」或「变量」。平台与商家之间，从一个正和博弈的共生关系，退化为一个零和博弈的存量争夺。&nbsp;</p>
  <p>京东与品牌的冲突，带来的不仅是商业上的两难，更是对京东最宝贵资产——信任——的侵蚀。&nbsp;</p>
  <p>当价格争议升级为关于「主动比价」的法律和舆论风波时 ，京东长期以来建立的「值得信赖的合作伙伴」形象便开始出现裂痕。&nbsp;</p>
  <p>这恰恰给了竞争对手可乘之机，抖音电商得以将自己塑造为尊重商家自主经营权的「利他」平台——事实上，在抖音电商早期的招商话术里面，便会告诉商家，你们来这儿，多一个曝光渠道，哪怕不在抖音成交，也能增加你们在淘宝、京东的销售。&nbsp;</p>
  <p>京东的防御行为，最终只起到了疏远盟友、成就对手的反效果。&nbsp;</p>
  <p>更进一步看，京东将「价格防护墙」作为面向消费者的核心叙事，实际上是在把消费者作为武器来保护自己的利益。&nbsp;</p>
  <p>京东试图通过将自己定位为消费者利益的捍卫者，来为自己与品牌方的冲突提供合法性。这种策略短期内或许能赢得部分消费者的好感，但长期来看，它对生态的腐蚀是致命的。&nbsp;</p>
  <p><strong>京东的「主动比价」，在平台、品牌和消费者之间植入了不信任的种子，将三方本应是合作共赢的关系，扭曲为平台联合消费者向品牌方施压的对抗关系。</strong>它教育消费者变得更加多疑，不再相信品牌价值，只相信赤裸裸的价格。&nbsp;</p>
  <p>这最终会把情感、服务等都变成标价的商品，加速整个市场的商品化，彻底摧毁京东自己曾经赖以生存的服务溢价和品牌信任，使其在求低价而不得的泥潭中越陷越深。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_528a0c42ecae41e58204b96591052587@6270888_oswg156126oswg1080oswg495_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>真正的自信力，绝不可能从对竞争对手价格的斤斤计较中找回，而只能从对自我核心价值的深刻反思与重塑中重建。&nbsp;</p>
  <p>十年前，智能硬件创业兴起，京东也顺势推出了众筹业务，一度成为行业龙头，那时候的京东，无疑还有着理想主义色彩，试图去孵化生机勃勃的热带雨林，或许显得混乱无序，但恰恰是这种多样性和不确定性，孕育了未来的期望。&nbsp;</p>
  <p>如今的京东，更像是在造一座「人工林场」，基于买卖来思考其中究竟该有什么树木，为了保证现有高大树木的产出和存活，管理者会系统性地清除林下的灌木和杂草。整个林场看起来整齐划一，但却丧失了生命力和抵御未来风险的韧性。&nbsp;</p>
  <p>京东的病根，在于它已经从一个充满活力的「产品型公司」，僵化为了一个庞大而低效的「流程型公司」。它的一切都围绕着「成本、效率、体验」这个旧平衡，擅长「管理」一个既定流程，却丧失了「创造」一个全新产品的能力。&nbsp;</p>
  <p>京东需要从「流程思维」中摆脱出来，去审视自己最强大的资产（供应链），并回答一个全新的问题：&nbsp;</p>
  <p>「我如何能利用这些数据、仓库和配送员，为消费者设计出一个可感知的、可交互的、甚至可付费的「信任产品」？」&nbsp;</p>
  <p>这个「信任产品」不再仅仅是「更快地送货」（流程优化的结果），而是可以主动向消费者展示商品从何而来、由何构成、经过何种检验的可追溯数字档案；是超越行业标准的质保承诺；是对符合可持续发展标准的产品提供的认证和流量倾斜。&nbsp;</p>
  <p>这本质上是一场组织思维的革命：<strong>从在「价格」这个自己并不占优的维度上被动防御，转向在「信任」这个自己拥有深厚积淀的维度上主动进攻和创新。</strong></p>
  <p>通过将「可验证的信任」打造成一个真正的「产品」，京东才能真正治愈「内部空心化」的慢性病，摆脱对竞争对手的路径依赖，从而在新的电商时代，重新从内部长出属于自己的、不可动摇的内核自信。&nbsp;</p>
  <p>它需要一场刮骨疗毒式的自我革新，而不是一次饮鸩止渴式的价格围堵。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/z1wkUaQbQh0m7FFma1F8NQ" rel="noopener noreferrer nofollow" target="_blank">“洒家君泽”</a>，作者：洒家君泽，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532943217940873</id>
            <title>亚马逊和谷歌的广告战争，开始打到云上了</title>
            <link>https://www.36kr.com/p/3532943217940873</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532943217940873</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 12:28:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>10月31日，亚马逊发布25年第三季度财报：其旗下云计算业务AWS收入实现近三年来最快增速，这带动公司对下一季度的销售额预期高于市场预估，从而在盘后交易中股价大涨约 14%。</p>
  <p>在分析师电话会上，CEO Andy Jassy表示：“从目前的增长势头来看，我相信我们能够在接下来的时间里保持这样的发展节奏。我认为我们在多个领域都具备持续增长的潜力。”<strong>他指出，这其中包括广告业务和零售销售。</strong></p>
  <p>就在10月23日，AWS推出了一项名为RTB Fabric的新服务。根据官方的解释，它是一个面向实时竞价（RTB）广告场景的云托管产品，核心就是缓解广告技术公司在跨平台连接中常见的性能瓶颈，其中之一就是延迟问题。</p>
  <p>这一举措被认为是AWS在广告营销行业上的一个重要举措。</p>
  <p>因为在程序化广告世界里，竞价必须在极短的时间内完成：当用户打开一个App或网页，后台会立刻触发一次广告竞价：不同广告商同时出价，系统要在几十毫秒内选出最高价并返回结果。</p>
  <p>问题在于，广告公司分布在不同的云上、不同国家、不同系统里，信号在传输时绕来绕去，速度就会产生延迟，进而影响广告主的投放效率。</p>
  <p>简单来说，RTB Fabric就是亚马逊在公有云的基础上，专门为DSP、SSP、adx等广告技术公司铺了一张低延迟的云服务。这些公司不再需要自己去搭建复杂的点对点连接，只要接入这张网，就能在 AWS 的基础设施上完成广告请求的传输和竞价。</p>
  <p>从亚马逊的描述来看，这项服务主打“个位数毫秒级延迟”与最高可达 80% 的网络成本优化，并整合了包括 Amazon Ads、GumGum、Kargo、MobileFuse、TripleLift 等合作方在内的链路资源。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c6a64c2a757a4853b5794f66510a0ea2@5081058_oswg9303oswg792oswg343_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>过去人们对亚马逊广告业务的关注往往聚焦在Amazon Ads上，这一次对广告行业的举措，出手的是AWS。虽然与Amazon Ads分属不同部门，不过目标指向如出一辙：谷歌。</p>
  <p>其实，大厂之间的广告竞争，暂时可以分为两层来看：</p>
  <p>第一层是我们最熟悉的，也是广告行业最“显眼”的部分——平台之间的较量。</p>
  <p>广告产品、投放工具、闭环能力、预算承接……所有和广告主、代理商直接打交道的环节，都在这层发生。这一层拼的是转化效率、数据能力，还有对投放链路的掌控力。</p>
  <p>但还有另一层，不那么为人所见，却同样关键——更基础的广告“云”层。</p>
  <p>它服务的不只有广告主和代理商，还有负责“搭系统”的广告技术（Ad Tech）公司。这个层面比拼的是更基础的东西：算力调度、延迟控制、跨平台连接能力，以及数据传输的稳定性。</p>
  <h2><strong>01</strong></h2>
  <p>我们先看第一层。</p>
  <p>在广告市场，谷歌依然具有巨大的统治力，也因此不断成为反垄断审查的对象。所以谷歌很明显是守擂的一方，而亚马逊依然处于推进阶段。</p>
  <p>谷歌几乎主导了 RTB（实时竞价）的底层协议。</p>
  <p>这到不是说谷歌定了RTB的规则，行业里早已有 IAB（互动广告局）制定的 OpenRTB 标准。</p>
  <p>但是因为谷歌在整个广告链路里占据了太多关键节点、占据着绝对性的市场份额——从流量入口到交易通道，再到通信协议，它几乎都在场，所以市场里的行业标准依然不可避免地被谷歌生态“校准”了方向。</p>
  <p>因为当广告主想和最大的流量源、最大的买方平台（DV360）、最大的移动系统（Android）建立连接时，就必须确保——自己的请求格式、数据字段、加密方式、连接节奏，都能在谷歌的系统里跑通。</p>
  <p><strong>十多年下来，整个RTB世界已经在谷歌的协议和传输逻辑上，沉淀出巨大的惯性。</strong></p>
  <p>当然了，理论上广告公司可以不走谷歌那条“默认高速”，但要付出代价。</p>
  <p>要么自己修路——也就是去和各大媒体、平台做直连，在主要城市部署服务器、拉专线、做多区域备份和隐私合规。那是一笔真金白银的投入，还有人力投入。如果无法在市场上形成规模，这样的基础设施建设往往得不偿失。</p>
  <p>另一种做法是“<strong>借非谷歌的路</strong>”。可以对接多个第三方交易所（如 Magnite、PubMatic、OpenX 等），或者使用一些开源中间层（如 Prebid、APS），再加上零售媒体和 CTV（联网电视）平台的流量，<strong>绕过谷歌的高速，走一条更分散的省道</strong>。</p>
  <p>听起来确实更灵活，选项更多，但实际操作远没有这么轻松：每家系统的对接标准都不同，用户身份体系也不兼容（有的用 UID2，有的用 RampID，还有的全靠自家第一方ID）。<strong>广告请求虽然能发出去，但协议五花八门，数据结构不统一，连用户是谁都要重新翻译一遍</strong>。</p>
  <p>结果就是，“省道”虽然没收费站，但<strong>不够直、不够快、也不够稳</strong>。广告公司得花大量精力维护接口，做跨平台的统一识别和频控管理。<strong>碎片化是自由的代价，也是效率的挑战</strong>。</p>
  <p>亚马逊选择架桥铺路，自己做基建。</p>
  <p>对那些不愿将自己的广告系统搭建在谷歌生态上的公司来说，RTB Fabric的出现提供了一个现实可行的替代方案。</p>
  <p>它的大概逻辑是这样的：</p>
  <p>它不改OpenRTB所谓的交通规则，是把在 AWS 上的伙伴拉到同一条托管快道上。只要双方同云同区，非谷歌路径也能跑出高速的平顺感。</p>
  <p>这样广告请求可以不经过谷歌的协议链路，也能完成实时竞价。你只要用我的接口，自动获得和谷歌差不多的传输速度，但更便宜、更开放。</p>
  <p>从对谷歌的影响看，结合美国司法部（DOJ）对谷歌广告的反垄断起诉，就有了更清晰的对比视角：</p>
  <p>DOJ 反垄断是在“<strong>监管层面</strong>”拆谷歌广告业务的塔，AWS 是在“<strong>技术层面</strong>”松谷歌广告的地基，多少有点釜底抽薪的意思。两者的结果其实相通：<strong>都在削谷歌对广告系统的控制力。</strong></p>
  <h2><strong>02</strong></h2>
  <p>在云市场，双方攻守易型：亚马逊是主导方，谷歌是更进取的一方。</p>
  <p>根据 Synergy Research Group 的二季度数据，AWS 是全球云基础设施服务领域的绝对领导者，市占30%，谷歌占比13%。</p>
  <p>广告技术公司历来是 AWS 的大客户，正如在分析师会议中对广告业务的提及，在AWS的官网行业分类里，广告与营销业务是11大垂类行业之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3a16dd15eadc4b8484bdd57c1d5d6968@5081058_oswg275891oswg1080oswg1258_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在云计算的诸多行业中，广告科技公司可能是最早一批“全栖云端”的使用者——他们需要极高的计算吞吐能力、实时的数据处理、以及对全球节点的弹性调度，而这些，AWS恰好擅长。</p>
  <p>从AWS的官网看，过去十年间，不少包括雅虎DSP、the trade desk等公司几乎都把AWS视作默认选项，有的处于稳定定，有的出于与谷歌广告业务的竞对关系。</p>
  <p>不过这种“默认”，开始在过去几年被撼动。</p>
  <p>从整个云市场来看，谷歌在二季度的增速达到32%，AWS只有17%。三季度财报显示，AWS收入同比增长20%，高于市场预期的17.95%。（Synergy Research Group数据）</p>
  <p>GCP在广告行业的渗透，谷歌向潜在客户抛出的计算积分（credit）极其慷慨，直接抵扣费用，变相“补贴”迁移成本——这让不少广告技术公司开始认真考虑“搬家”。</p>
  <p>“过去三年里，谷歌下手相当狠。”一位参与RTB Fabric测试计划的广告技术公司高管对行业媒体digiday说。</p>
  <p>他认为，AWS推出RTB Fabric，很大程度上就是对谷歌云攻势的一次回击。“因为很多广告技术公司已经转向使用GCP”。</p>
  <p>就10月中旬的时候，广告集团WPP与GCP签署了一项协议：双方合作关系将继续延长五年，WPP承诺投入4亿美元用于谷歌技术和云服务。</p>
  <p>广告行业是一个特殊的垂直领域——数据密度高，时延要求极致，一次竞价需要毫秒级完成，一场活动可能动用数十亿条请求。</p>
  <p>在这个语境下，“云”就是一种直接影响竞价效率、广告收益的关键变量。</p>
  <p>AWS 的优势过去是“通用性”和“稳定性”，而无论是计算补贴、客户绑定，还是与广告集团的深度捆绑，谷歌云在用一种近乎“贴身肉搏”的方式向广告技术公司争夺份额。</p>
  <p>OpenX 的工程高级副总裁Joel Meyer，OpenX与谷歌的GCP的多年合作伙伴。</p>
  <p>他对媒体digiday说：AWS推出的RTB Fabric 显示出云计算在当前广告技术格局中的价值——在这个需要快速反应、快速上线新方案的行业背景下更是如此。</p>
  <p>“他们正在努力简化 RTB 领域中存在的种种复杂性……如果这个方案成功，我认为它将迫使谷歌也推出类似的产品。”他认为，“云计算的本质，就是降低创新门槛——无论是扩展 AI 解决方案，还是实现实时集成，而 RTB Fabric 其实正是推动这一目标的最新一步。”</p>
  <h2><strong>03</strong></h2>
  <p>谷歌手里有全球最完整的广告系统，从广告主、投放平台，到媒体资源，几乎每一个环节都有布局。它还有谷歌云平台GCP 这个全球前三的云服务商，技术能力一流。</p>
  <p>按理说，它也可以修出一条“广告专用的云高速”，像亚马逊这次做的RTB Fabric一样。</p>
  <p>这里的问题是，谷歌一直是广告市场老大，为什么没有先一步做出类似fabric的产品？</p>
  <p>答案可能是：现在不方便做。</p>
  <p>谷歌正在被盯得很紧，特别是在美国和欧洲，反垄断的官司一个接一个。这个时候，如果它再推出一个“所有广告都跑在我这条云轨道上”的服务，不管初衷是什么，都会被外界看成是在进一步巩固垄断地位。</p>
  <p>想想，之前要取消cookie的时候，谷歌就推出了隐私沙盒的方案，英国的反垄断机构就立刻开启了事前审查机制，最终沙盒方案在6年后搁浅。</p>
  <p>在这种“风口浪尖”的阶段，谷歌的策略只能保守一点，少惹麻烦。</p>
  <p><strong>还有一个是不同生态位，做出的不同战略选择。</strong></p>
  <p>对数字广告来说，精准是目的，速度是手段。</p>
  <p>这几年谷歌广告把更多火力放在“算得准”的一侧，而不是跑得快。</p>
  <p>谷歌这些年在模型与测量、Ads Data Hub、隐私计算与归因工具，目标是让广告主更聪明地花钱。</p>
  <p>不过谷歌并不是不做速度与网络：它只是<strong>没有把“RTB 低时延”产品化。</strong></p>
  <p>换句话说，谷歌更多依赖通用云+个案工程去追速度，而不是把“快”变成一个独立、标准化的商品卖点——这正好给了AWS一个切入口。</p>
  <p>从目前来看，我们很难说谁对谁错。</p>
  <p>在广告领域，谷歌和亚马逊的生态位本就不同，打法自然也各有逻辑。</p>
  <p>谷歌是行业的领导者，这一地位使它更倾向于维护现有秩序，强化生态闭环，确保平台收益最大化。在它的系统里，即便开放接口，真正的优先权也掌握在自己手中。</p>
  <p>而亚马逊，则是一个仍在扩张中的挑战者。</p>
  <p>它的广告业务并不是独立存在，而是深度嵌入在零售、内容、数据、物流等更大一盘棋中。它更关注“全链路”的掌控——从用户触点、转化行为，到最终的订单与履约。</p>
  <p>这让它的策略更具侵略性，也更务实。</p>
  <p>所以我们看到的，不是谷歌做不到，而是它一方面投鼠忌器，一方面在当下生态位上的自然选择。</p>
  <p>总之，谷歌和亚马逊两种路线，一种是制定规则，一种是重新定义问题。</p>
  <h2><strong>04</strong></h2>
  <p>对于整个广告生态而言，正在发生一种悄然但深刻的变化。</p>
  <p>平台之间的竞争，正从前台的流量争夺、预算分配，延伸至后台的云服务。在数字广告这个技术高度密集、传输极度敏感的行业中，“谁掌控了链路”，往往也意味着“谁掌控了规则”。</p>
  <p>正如鲁迅所说，地上本没有路，走的人多了，也便成了路。</p>
  <p><strong>RTB Fabric能不能跑出一条新路，关键不在技术规格，而在行业意愿。</strong></p>
  <p>广告技术公司是否愿意把竞价请求交由AWS调度？是否愿意放弃对协议链路的自主掌控，把“方向盘”交给一家平台型公司？这不是工程问题，而是信任问题。</p>
  <p>而最现实的矛盾也恰恰源于这一点：<strong>亚马逊，不只是云服务提供者，它自己也做广告。</strong></p>
  <p>AWS 虽然只是“跑数据”的管道，但当这个管道足够宽、足够快，足以承载起整个广告请求的实时传输时，中立的基础设施的定位还成立吗？</p>
  <p><strong>如果一个控制传输链路的公司，同时也有自己的广告业务，那行业是否可能再次走进“谷歌广告垄断”的老路？</strong></p>
  <p>虽然AWS与Amazon Ads在组织架构上属于不同体系，但行业里没有人会天真地认为二者之间是完全割裂的。</p>
  <p>这就是为什么，RTB Fabric在带来“非谷歌选项”的同时，也让行业多了一层新的焦虑。</p>
  <p>对亚马逊而言，这场基础设施的重构，是一次雄心勃勃的布局，也是一场需要耐心的豪赌。</p>
  <p>赌的是行业对谷歌广告生态惯性的松动，也赌他们愿意为一条看似更开放、可控的链路重新下注。</p>
  <p>只有当更多人愿意上车，新的秩序才有可能真正成立。</p>
  <p>否则，它就只是一条速度很快的“备用道”。而主路依旧会在谷歌手中。（作者：刀客doc）</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Zb8KOf5rCGG3kbs7k-IQKg" rel="noopener noreferrer nofollow" target="_blank">“刀客Doc”</a>，作者：刀客doc，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3533002083327110</id>
            <title>OpenAI，3个月亏了818亿</title>
            <link>https://www.36kr.com/p/3533002083327110</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3533002083327110</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 12:13:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0d4098dd5c414167898716db150aef72@46958_oswg148344oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智东西10月31日消息，据The Register报道，微软最新公布的季度财报，有几段文字暗示OpenAI本季度净亏损<strong>115亿美元（约合人民币818亿元）</strong>。&nbsp;</p>
  <p>在其官方收益报告第9页，包含以下段落：&nbsp;</p>
  <blockquote>
   <p>我们对OpenAI Global, LLC（“OpenAI”）进行了投资，并已承诺投资130亿美元，截至2025年 9月30日，已投入116亿美元。该投资采用权益法进行会计处理，我们在OpenAI的收入或亏损中所占份额计入其他收入（支出）净额。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_db5b70cefc2d435b8d749ce9185f6b79@46958_oswg450910oswg1000oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第二句话很重要。这不是按市值计价的会计方法。按市值计价的会计方法是根据市场当前估值（高达1350亿美元）计算投资的假定价值，并在初始投资的基础上增减估值。这是权益会计，OpenAI的收益或亏损会直接影响微软损益表中的净利润。&nbsp;</p>
  <p>接下来，在第33页，出现了以下内容：&nbsp;</p>
  <blockquote>
   <p>本年度净利润和摊薄后每股收益受对OpenAI投资净亏损的负面影响，分别导致净利润和摊薄后每股收益减少31亿美元和0.41美元。上年度净利润和摊薄后每股收益也受对OpenAI投资净亏损的负面影响，分别导致净利润和摊薄后每股收益减少5.23亿美元和0.07美元。&nbsp;</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d84df0af4b454190a385fb402f9fa470@46958_oswg308558oswg1000oswg690_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后，还有一份美国证券交易委员会的文件，其中包含周二OpenAI宣布完成向营利性公司转型的相关信息，其中透露微软现在拥有OpenAI 27%的股份。那么根据权益法，微软理应承担OpenAI 27%的亏损。&nbsp;</p>
  <p>微软称，为了弥补其在OpenAI亏损中所占的份额，它从净利润中扣除了31亿美元（约合人民币220亿元），这意味着OpenAI当季亏损约115亿美元（约合人民币818亿元）。&nbsp;</p>
  <p>微软拒绝就此置评，仅确认这31亿美元的“今年”亏损指的是微软始于7月1日的当前财年，而非自然年。这是季度亏损，而非9个月的亏损。&nbsp;</p>
  <p>对于OpenAI来说，亏损115亿美元是一个巨大的数字，因为据报道，OpenAI上半年的收入仅为43亿美元（约合人民币306亿元）。&nbsp;</p>
  <p>不过考虑到微软仅在上季度就获得了277亿美元（约合人民币1970亿元）的净利润，这笔钱对微软来说不会造成太大的影响。&nbsp;</p>
  <p>OpenAI尚未立即回复置评请求。&nbsp;</p>
  <p>来源：The Register&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/rvyOO1_wQ2NZB0oB3GPA9w" rel="noopener noreferrer nofollow" target="_blank">“智东西”</a>，作者：ZeR0，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532895226682496</id>
            <title>4倍速吊打Cursor新模型，英伟达数千GB200堆出的SWE-1.5，圆了Devin的梦，实测被曝性能“滑铁卢”？</title>
            <link>https://www.36kr.com/p/3532895226682496</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532895226682496</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 12:13:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，开发出 Devin 智能体的知名人工智能公司 Cognition 推出其全新高速 AI 编码模型 SWE-1.5。据介绍，该模型专为在软件工程任务中实现高性能与高速度而设计，现已在 Windsurf 代码编辑器中开放使用。今年 7 月，Cognition 高调收购开发工具 Windsurf。</p>
  <p>同时，Cognition 称，得益于与推理服务提供商 Cerebras 的合作，SWE-1.5 的运行速度最高可达 Anthropic 旗下 Sonnet 4.5 模型的 13 倍。</p>
  <h2><strong>比 Sonnet 4.5 快 13 倍，编码性能近 SOTA&nbsp;</strong></h2>
  <p>“开发者不应在‘思考速度快’与‘思考质量高’的人工智能之间做选择。”Cognition 在官方声明中表示，这一理念是 SWE-1.5 的设计基础。</p>
  <p>据介绍，SWE-1.5 经过专门设计，是一款拥有数千亿参数的前沿规模模型，旨在打破上述权衡困境的同时提供顶尖性能与一流速度。而该模型最显著的特点是其原始速度，这一优势源于与推理领域专业机构 Cerebras 的深度合作：共同部署并优化 SWE-1.5。具体举措包括训练一个经过优化的草稿模型以实现更快的投机解码以及构建定制化请求优先级系统，让端到端智能体交互过程更流畅。</p>
  <p>Cognition 表示，此次合作让 SWE-1.5 实现了极佳的延迟表现，并“还树立了新的速度标准”，使其处理速度最高可达 950 token / 秒，分别是 Haiku 4.5 模型的 6 倍、Sonnet 4.5 模型的 13 倍。”这一性能飞跃能够让开发者保持 “心流状态”，将此前需 20 秒的某类任务完成时间控制在 5 秒以内。Cognition 认为，5 秒是避免陷入 “半异步死亡谷” 的关键阈值。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9d0668033b004ef4a0dc1bd867fb55ed@46958_oswg84140oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当模型运行速度达到最高 950 token / 秒时，此前可忽略不计的系统延迟成为了主要瓶颈，这迫使其重新审视 Windsurf 智能体实现方案中的多个关键部分。为此，Cognition 重写了代码检查（lint checking）、命令执行流水线等核心组件，每一步操作的开销最多降低了 2 秒。“未来，我们计划在这类优化工作上持续投入。”该公司称。</p>
  <p>在 Scale AI 开发的 SWE-Bench Pro 基准测试中，Cognition 的 SWE-1.5 模型取得了 40.08% 的良好成绩，仅次于 Claude 的 Sonnet 4.5（该模型得分 43.60%）。此外，SWE-1.5 致力于提供端到端的用户体验。据透露，该模型在高速运行状态下实现了接近当前最佳水平（near-SOTA）的编码性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4280b8084503476dbe8be2ff0675812c@46958_oswg134945oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Cognition 方面表示，最重要的是，目前他们团队的众多工程师已将 SWE-1.5 作为日常工作工具，热门应用场景包括：深度探索与理解大型代码库；构建端到端的全栈应用程序轻松编辑配置文件，无需记忆字段名称。据悉，目前 Cognition 处于测试阶段的 Codemaps 功能就在由 SWE-1.5 提供支持。</p>
  <h2><strong>基于新一代 GB200 芯片训练，设计全新编码环境&nbsp;</strong></h2>
  <p>支撑这款新模型的是对尖端基础设施的巨额投入。Cognition 透露，SWE-1.5 的训练依托于 “由数千颗英伟达 GB200 NVL72 芯片组成的先进集群”，并声称它可能是 “首个基于新一代 GB200 芯片训练的公开生产级模型”。GB200 在去年推出之时一度被称为“性能怪兽”，与相同数量的英伟达 H100 Tensor Core GPU 相比，GB200 NVL72 在 LLM 推理工作负载方面的性能最多可提升 30 倍、成本和能耗最多可降低 25 倍。</p>
  <p>今年 6 月初，该团队首批获取这批新硬件访问权限时，其固件尚未成熟，这迫使团队从零开始构建更稳健的健康检查系统与容错训练系统。对于专门针对现代软件工程中复杂、多步骤任务微调模型所用到的密集型强化学习（RL）技术而言，这套强大的硬件至关重要。</p>
  <p>在训练方法上，该模型的训练是在 Cognition 定制的 Cascade 智能体框架上，通过端到端强化学习完成的，并借助了由上千颗 GB200 NVL72 芯片组成的集群。</p>
  <p>同时，Cognition 认为，RL 任务中的编码环境质量是影响下游模型性能的最重要因素。为此，他们手动创建了一个数据集，力求还原在 Devin 与 Windsurf 中观察到的、真实场景下任务与编程语言的广泛分布情况。基于开发 Devin 及构建 Junior-Dev 基准测试的经验，其在打造专属评估体系上投入了大量资源。并且，他们与顶尖高级工程师、开源项目维护者及技术负责人团队合作，设计了高保真度的编码环境。</p>
  <p>需要注意的是，SWE-1.5 是其首次尝试借助这类环境提升模型编码能力，该环境中包含三种评分机制：用于可靠验证代码正确性的经典测试（如单元测试、集成测试）、用于评估代码质量与实现思路的评分标准（Rubrics）和借助可使用浏览器的智能体测试产品功能的端到端完整性的智能体评分（Agentic grading）。为确保环境能抵御 “奖励作弊”（reward hacking）行为，他们开发了一套名为 “奖励强化”（reward hardening）的流程 —— 由人类专家尝试寻找绕过评分器的方法。</p>
  <h2><strong>从 Windsurf 的“余烬”中，诞生新战略&nbsp;</strong></h2>
  <p>这款新模型是 SWE 系列模型的迭代产品，而 SWE 项目最初由原 Windsurf 团队在 2025 年 5 月启动，之后 OpenAI 对 Windsurf 的收购计划失败，Cognition 随即介入成为 “接盘方”。如今，通过将 SWE-1.5 直接集成到 Windsurf 集成开发环境（IDE）中，Cognition 正逐步实现一个新愿景。</p>
  <p>SWE-1.5 并非单一模型，其模型本身、推理过程与智能体框架经过协同设计，共同构成一个统一系统，以此同时实现高速与智能。“选择编码智能体，不只是选择模型本身。其周边的协同调度系统，对模型的实际表现也有着极大影响。在开发 Devin 时，我们常常希望能将模型与框架协同开发；而通过此次 SWE-1.5 的发布，我们终于实现了这一目标。“Cognition 在公告中解释道。</p>
  <p>因此，SWE-1.5 的开发过程包含以下核心环节：</p>
  <p>基于领先的开源基础模型，在我们定制的 Cascade 智能体框架之上，于真实任务环境中开展端到端强化学习（RL）训练。</p>
  <p>在模型训练、框架优化、工具开发与提示词工程等方面持续迭代。</p>
  <p>必要时从零重写核心工具与系统，以提升速度与准确性（当模型速度提升 10 倍后，很多环节都会变成瓶颈。）。其计划在这一领域持续推进，相关改进也将助力 Windsurf 中其他所有模型的性能提升。</p>
  <p>高度依赖内部真实场景的 “内部测试使用”（dogfooding）来指导调优决策，这种方式能让其围绕用户体验对智能体与模型进行调优，而通用奖励函数无法实现这一点。</p>
  <p>部署该模型的多个测试版本（以 “Falcon Alpha” 为名称），并对性能指标进行监控。</p>
  <p>这一战略让 SWE 系列模型得以快速迭代，而 Cognition 此举似乎也在押注：即便没有推出市场上参数规模绝对最大的模型，这种高度集成的高速体验或也能培养出一批忠实用户。</p>
  <h2><strong>SWE-1.5 vs Composer，大家怎么看？</strong></h2>
  <p>SWE-1.5 发布之际，AI 编码环境工具 Cursor 也推出了其专属高速模型 Composer。两家公司都正通过打造专有模型，构建高度集成、低延迟的开发者体验，并减少对第三方接口（API）的依赖。同时，这两项发布表明人工智能开发者工具市场出现了明确的战略趋同。</p>
  <p>两家公司都在大规模采用强化学习技术。Cognition 利用一款名为 otterlink 的虚拟机管理程序，在数万个并发的高保真环境中运行强化学习推演，这些环境包含代码执行与网页浏览功能。这种方法与 Cursor 所描述的、为自身强化学习训练 “运行数十万个并发沙盒编码环境” 的方式高度相似。</p>
  <p>而该技术路径也凸显出一个共识：要打造真正高效的编码智能体，企业须结合自有定制工具与真实场景对模型进行微调。Cursor 的一位机器学习研究员这样解读该策略：“如今，要实现高效工作，至少需要具备一定水平的智能；若能将这种智能与速度结合，效果会非常出色。”</p>
  <p>两者的另一相似之处在于透明度的缺失。Cognition 与 Cursor 均对其新模型的基础架构守口如瓶，仅提及模型基于 “领先的开源基础模型” 构建。这种保密性使得独立评估难以开展，只能依赖用户对企业内部基准测试的信任。这也引发网友一系列的猜测，有人怀疑 SWE-1.5“使用的开源模型可能是 GLM-4.5，Composer &nbsp;也是一样的情况”。</p>
  <p>值得一提的是，据公开介绍，Composer 的生成速度达到每秒 250 个 token，而 SWE-1.5 的处理速度最高可达 950 token / 秒，是前者接近 4 倍。</p>
  <p>目前，已有一批开发者试用了两款模型。AI 专家兼博主 Simon Willison 在测试 SWE-1.5 后表示：“这款模型确实感觉非常快。与 Cerebras 合作进行推理，是一步非常明智的举措。”然而，也有用户在使用两款模型后称，“SWE-1.5 虽然速度快，但没能解决一个问题；而 Cursor 2.0 的 Composer-1 模型却一次性解决了该问题（在 5-codex 连接失败的情况下）。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_306e6c4ffb014d5a9337d83480e8fcdf@46958_oswg68170oswg785oswg310_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，还有用户反馈，“（SWE-1.5）它在处理小型任务时表现确实不错。但比如在尝试完成某项任务时不仅失败了，还搞砸了所有东西（出现了无效的差异编辑），而 GPT-5（低推理版本）一次就成功完成了。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3d65eebeb6884f698c88598651930d61@46958_oswg167395oswg784oswg331_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>参考链接：</strong></p>
  <p>https://cognition.ai/blog/swe-1-5</p>
  <p>https://winbuzzer.com/2025/10/30/cognition-releases-windsurf-high-speed-swe-1-5-ai-coding-model-outpacing-gpt-5-high-xcxwbn/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Jyz1Ig6dfA0lZuB2P3KfRQ" rel="noopener noreferrer nofollow" target="_blank">“AI前线”</a>，整理：华卫&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3533033491602564</id>
            <title>苹果在中国营收依旧下滑，好消息是iPhone 17卖爆了</title>
            <link>https://www.36kr.com/p/3533033491602564</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3533033491602564</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:59:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>&nbsp;</p>
  <p><strong>iPhone 17创纪录&nbsp;</strong></p>
  <p>凌晨，苹果公布了 2025 财年第四季度的财报，营收 1024.66 亿美元，同比增长 8%，创同期历史新高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0587cec76cf54c5f90303dc6fd8590cf@000000_oswg71688oswg1024oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这份强劲的成绩单超过市场预期，苹果股价大幅上涨，这也是苹果十五年来第三次在财报公开后股价出现上升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d7780adc6c1a4bed930009b6dedbb89c@000000_oswg332994oswg1024oswg774_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>大卖的 iPhone 17，尴尬的 iPhone Air</strong></h2>
  <p>大家最关心的，肯定是今年诚意满满的 iPhone 17 系列究竟有没有「卖爆」。</p>
  <p><strong>苹果 CEO 蒂姆 · 库克也在电话会议中透露，iPhone 收入创历史新高，iPhone 17 系列的需求「远超预期」，门店客流量显著增长，消费者反响非常强劲，创下九月季度升级用户数量的新纪录。</strong></p>
  <p>值得一提的是，财报的数据只截取到 9 月 27 日，iPhone 17 系列只开卖了 10 天不到，因此主要的销量贡献，还是来自老 iPhone，<strong>销售额达到 490 亿美元，高于去年同期的 462 亿美元，依旧低于华尔街预期的 502 亿美元。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_271b12e9c3b444c1969a479e9e46a378@000000_oswg25614oswg720oswg405_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>库克则将原因归咎于供应限制，不管是 iPhone 16 还是 iPhone 17，处于供应紧张状态苹果正在努力完成所有订单。</p>
  <p>因此要看 iPhone 17 具体卖得怎么样，还要等下个季度的财报。接下来将进入海外的节日周期以及中国的购物季，iPhone 17 的销量进一步大涨，<strong>库克估计下个季度将成为苹果有史以来营收和 iPhone 销量最高的季度。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9ec7096fd0b748f5a05bf7cceb56e5ef@000000_oswg70657oswg1024oswg650_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲ 图源：Reuters</p>
  <p>最近关于 iPhone Air 的销量表现有不少传闻，分析师郭铭錤爆料这个超薄型号产量削减 80%，预计将在今年年底之前停产。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_80b8cd9e589b458f9411ac09f9d079a1@000000_oswg30210oswg720oswg405_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>有分析师在电话会议上就相关问题直接向库克提问，库克坚持了苹果「不单独公布 iPhone 机型销量」的传统，并表示自己确实有意回避这个问题。</strong></p>
  <p>库克还补充，目前苹果的产能受限主要集中在「高端与入门两端」。</p>
  <p>但在苹果的规划中，iPhone Air 从来不属于「销量担当」，这台集成了大量科技的超薄手机，利润空间本身也要小于 iPhone 17 和 iPhone 17 Pro。</p>
  <p>就像是国产折叠手机，iPhone Air 的重点更多是「刷存在感」、「秀肌肉」，是苹果技术的一块试验田。</p>
  <p>况且，作为一台带苹果 logo 的手机，iPhone Air 的销量也不会差到哪里去——即使是缺乏关注的 iPhone 16 Plus，在 2024 年两个半月内出货量也超过 500 万台；Counterpoint 数据显示，iPhone 16 Plus 还是今年第一季度全球手机销量第十名。</p>
  <p>目前来看，唯一注定会影响 iPhone Air 全球销量的，可能是中国运营商糟糕的 eSIM 激活流程和严苛的使用政策。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_67cd39e464b6489cbd48695422e50873@000000_oswg160500oswg1024oswg555_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲ 图源：CounterPoint</p>
  <h2><strong>Mac 装机量历史新高，但 iPad 已经卖不动了</strong></h2>
  <p>创纪录的不只有 iPhone，还有苹果收入的第二个大头——服务，总收入 287.5 亿美元，实现 15% 的增长率，也是苹果增速最快的业务。</p>
  <p>该业务板块包括 App Store、Apple Pay、Apple TV、Apple Music 和 iCloud，以及 Google 的授权费用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_2c256fb3b1e64bbbb1b1f11c2fd99260@000000_oswg78834oswg1024oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>和 iPhone 一样，苹果也不会单独公布某项服务的详细数据，不过提到了 Apple Pay 营收创历史新高，活跃人数实现两位数增长。</p>
  <p>除此之外，苹果服务业务在美洲、欧洲、亚太地区以及大中华区都创下了营收纪录。</p>
  <p>在 App Store 在全球范围遭遇反垄断调查的情况下，苹果服务依旧保持了极高的增速，让市场更加放心。比起波动的硬件销量，服务业务具有高额的利润以及用户粘性，逐渐成为苹果重要且稳定的收入来源。</p>
  <p>iPhone 和服务之外的产品销售，则略显平淡。</p>
  <p><strong>其中表现最好的是 Mac 产品线，收入达到 87 亿美元，高于同期 77 亿美元，Mac 的装机量也创下了历史新高。</strong></p>
  <p>最大的功臣是今年 3 月发布的 MacBook Air，这条产品线也已经成为了这几年最受欢迎的苹果产品。</p>
  <p>苹果预计年底季度 Mac 的表现会逊于同期——毕竟去年有新的 iMac 和全系更新的 MacBook Pro，以及火出圈的 M4 Mac mini，而今年年底只有 M5 MacBook Pro 孤军奋战。</p>
  <p>虽然 iPad 也在今年年初推出了 iPad Air 和入门款新品，表现却不温不火，销售额 69.5 亿美元和去年基本持平。</p>
  <p>本季度购买 iPad 的顾客中，有一半是首次购买该产品，可见「挤牙膏」的新 iPad，难以打动老用户们。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_11775a7298e04ffba189df8791d0c313@000000_oswg21781oswg720oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过明年的 iPad Air 与 iPad mini 都有望用上 OLED 高刷屏，终于有点让人期待的劲头了。</p>
  <p>可穿戴和家居产品的季度收入为 90.1 亿美元，低于同期水平，全新的 Apple Watch 系列和 AirPods Pro 3 没有带来明显的带动效果。</p>
  <p>值得一提的是，Apple TV 4K 机顶盒和 HomePod mini 新品已经错过了九月、十月两轮新品发布，爆料称苹果仍计划在年内发布。</p>
  <h2><strong>中国区收入不如预期，但即将逆袭</strong></h2>
  <p>虽然财报数据基本都表现良好，但作为苹果的第二大市场，大中华地区的收入却出现同比下降：季度收入144.93 亿美元，同比下降了3.6%；2025 财年收入 643.77 亿美元，同比下降 3.8%。</p>
  <p>关于苹果中国市场的表现，苹果的回应同样也是「供应限制」，iPhone 在中国依旧处于供不应求的情况。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ed59c728521345c3a8db824057ee8097@000000_oswg81286oswg1024oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，苹果表示中国商店客流量正在增加，加上即将到来的电商购物活动，iPhone 17 也在国内大受欢迎，预计下一季度中国市场的收入就会恢复增长。</p>
  <p>苹果还谈到了「国补」对苹果销售的影响：即使苹果有不少产品价格都高于国补范围，总体来看也取得不错的效果。</p>
  <h2><strong>AI Siri，明年上</strong></h2>
  <p>去年开始，每次苹果的财报会议不会缺席的问题自然是「AI」。</p>
  <p>恰逢 Apple 智能上线一周年，有分析师提问苹果有没有看到 AI 带动产品销量的迹象，而苹果表示没有进行深入调查，但看好 AI 成为产品销售的驱动因素，并期待其成为一个更重要的因素。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_52b4b4c7b85447ad940e494e5e9cf2df@000000_oswg54736oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>关于 Apple 智能接下来的发展，库克表示将继续推进第三方 AI 工具的集成，随着时间推移会与更多人合作，也重申了「正在考虑」AI 领域的收购。</p>
  <p>发布一年来，目前苹果只将 ChatGPT 嵌入到 Siri 之中，据悉内部已经在开发与 Google Gemini 的集成，并且计划与 Anthropic 和 Perplexity 合作。</p>
  <p>AI 版 Siri 也成为了固定的提问内容，库克表示「进展顺利」，有望明年发布。</p>
  <p>设计大变的 iOS 26、诚意满满的 iPhone 17 系列冲淡了外界对于苹果 AI 进度缓慢的关注，但这始终是「房间里的大象」，苹果无法回避。</p>
  <p>可惜的是，这次财报会议上苹果没有对中国 Apple 智能的进度进行回应。此前彭博社爆料，苹果仍然计划在今年年底推出国行 Apple 智能，库克此前访华也被认为是在推进相关进度。</p>
  <p>不过目前的 iOS 26.1 版本仍然不见 AI 踪影，今年留给苹果的时间，也已经所剩无几了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_e56522491a5a44538d3e7aad09224824@000000_oswg18983oswg1024oswg344_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一扫去年财报的持续沉闷，iPhone 17 系列确实是苹果的一针「强心剂」，也说明只要苹果不挤牙膏，产品诚意更足，市场会用脚投票支持。</p>
  <p>而这份亮眼的成绩单甚至可以说只是一个开始。从今年开始，苹果将会开启连续三个「大年」，值得期待的新品陆续推出，有一种经济上行时期的美：</p>
  <ul>
   <li>折叠 iPhone &amp; 全玻璃 iPhone</li>
   <li>OLED + 高刷 iPad Air 和 iPad mini</li>
   <li>全新设计的触屏 OLED MacBook Pro</li>
   <li>首款苹果智能眼镜</li>
   <li>带屏幕的智能家居新品</li>
   <li>带红外摄像头的 AirPods</li>
  </ul>
  <p>这些新品固然让人激动，我还是更期待苹果 AI 究竟能做出一个什么名堂。</p>
  <p>毕竟所有人都知道它是未来的交互，而我们至今还缺少一个将我们带向正确方向的引路人。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&amp;mid=2652430920&amp;idx=1&amp;sn=e2f25b03d7d5d785612a16dd1ca0f5f7&amp;chksm=9a177c0317f4bfe124e7be1ed27ce8f57f1be0463d8a3f46eb7599b0d122a749aa2a7dec53ba&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“爱范儿”（ID：ifanr）</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532894978759817</id>
            <title>90后的白月光，被卖了</title>
            <link>https://www.36kr.com/p/3532894978759817</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532894978759817</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:58:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果要向非游戏玩家简单通俗的介绍EA，那么可以做这么一个比喻：<strong>EA就是游戏行业里的阿迪耐克。</strong>FIFA足球、极品飞车、模拟人生，我说一句EA是80、90后的白月光，应该不算过分。</p>
  <p>今天我们要聊的，就是关于这家老牌游戏公司的造富神话：<strong>据多家媒体爆料，全球最顶级的游戏公司EA（艺电公司）即将以550亿美元（约合人民币3915亿）的价格被私有化，买方为沙特阿拉伯公共投资基金&nbsp;(PIF)&nbsp;所牵头的财团，而一旦交易完成，EA将成为游戏产业史上第二贵的公司，仅次于2023年微软对动视暴雪687亿美元（约合人民币4894亿）的成交价。</strong></p>
  <p>但面对这个即将到来的历史性时刻，人们似乎高兴不起来，<strong>因为EA的卖身不仅带着投资者对游戏产业的看好，也带来了一笔高达200亿美元（约合人民币1423.8亿元）沉甸甸的债务。</strong></p>
  <h2><strong>顶级公司，顶级财团</strong></h2>
  <p>在很多人的金钱观里，最好的生意就是“想办法让人上瘾”。如果再加上合法、低成本、受众多这三个限制条件，那么世界上应该不存在比“游戏”更好的生意，人们也轻而易举地能够找到很多对应的例子。</p>
  <p>比如老少咸宜的经典游戏《俄罗斯方块》，自1984年发布以来，《俄罗斯方块》全球范围内可以被统计到的销量就达5.2亿份，其中仅任天堂Game Boy一个平台上的销量就达到了3500万份，直接带动了Game Boy成为了游戏史上最经典的主机之一，也间接为《宝可梦》《星之卡比》这些经典IP攒下了宝贵的第一桶金，进而开启了任天堂数以百亿美元计的财富神话。</p>
  <p>比如在我国波澜壮阔的互联网产业史上，最先让人们意识到互联网能够带来巨大财富效应、跻身“首富”行列的互联网创业者分别是丁磊和陈天桥——丁磊在2000年和2003年两度成为了中国首富，陈天桥在2005年以盛大网络创始人的身份登顶《新财富》“中国500富人榜”榜首，成为了中国最年轻首富——两家公司都将“游戏”看做最重要的战略板块之一，尤其是丁磊的网易，正是《大话西游》和《梦幻西游》将网易彻底拉出了“停牌危机”。</p>
  <p>更关键的是，消费娱乐产业也是有鄙视链的，很多娱乐方式由于太过“感官化”“表层化”常常被高阶层人群怒斥为“奶头乐”。但游戏似乎是个例外，下至平成废宅上至商业巨擘，纵有无数刺激到普通人难以想象的娱乐方式，似乎都无法拒绝游戏的沉迷。比如马斯克就是著名的《暗黑4》玩家，曾经在个人社交媒体上秀出自己2分45秒完成剧情通关，能够排名全球前20。比如巴西球星内马尔的个人Steam显示，他在《FC25》上游戏时长达到了523小时——同期内马尔仅在本职工作上（也就是沙超赛场）出场42分钟，也就是说他的游戏时间达到了工作时间的747倍。</p>
  <p>好一门神仙生意！</p>
  <p>虽然我们很难直接定义EA就是顶级的游戏公司，但就像阿迪耐克一样，你也很难找到其他的游戏公司能够稳压EA一头。同时就像阿迪定义足球装备、耐克引领跑鞋、篮球鞋一样，EA在很多细分游戏类目中都是定义者般的存在：例如在体育游戏领域，EA的《FIFA系列（现在改名为FC）》《极品飞车》是大量玩家的启蒙；在模拟经营领域，EA的《模拟人生》《模拟城市》拥有无数精神续作；横版塔防类巅峰之作《植物大战僵尸》，来自EA旗下的宝开游戏工作室（PopCap Games）；近年来大火的《双人成行》，在EA Play上首次亮相，由EA Originals负责产品发行。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_53a8639edc584f2389ed6574d512ac19@46958_oswg991361oswg1036oswg580_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">（EA今年的新作《FC26》）</p>
  <p>因此也正如阿迪耐克样，EA凭借超然的行业身位，也获得了超然的财务回报。根据今年5月公布的财报显示，2025财年EA的净收入为74.63亿美元，结余净现金流达到了20.79亿美元，并预计2026财年将继续维持相同的收入规模，净收入大概在76亿至80亿美元之间。作为对比，根据微软公布的2024财年报告，动视暴雪的全年营收为57.2亿美元。</p>
  <p>所以作为一棵四季常青的摇钱树，这么多年来类似“财团有兴趣收购EA”的传闻一直就没有断过。其中最有鼻子有眼的传闻出现在2022年，当时微软即将完成对动视暴雪的收购，带动了整个市场对于游戏资产“抗周期性”的讨论，EA也应景地出现了“被收购”的传闻，传闻中的买方是环球影业和NBC（美国国家广播公司）的母公司康斯坦特以及迪士尼。</p>
  <p>据说，EA当时提出的方案是，康斯坦特的所有者布莱恩·罗伯茨（Brian Roberts）被获准收购多数股权。作为交换，罗伯茨将推动NBC分拆出康斯坦特，与EA合并成一家全新的公司。迪士尼当时则寻求的是一种“比IP授权更有意义的合作”。</p>
  <p>当然可想而知的是，以EA如此的行业地位，想要完成收购变成私有资产，谈判一定会异常艰难，所以以上的这些传闻到最后都不了了之。<strong>而本次能够搞定EA董事会的财团，也远超“投资人”这个狭隘的金融概念，从背景到履历堪称“神仙阵容”：</strong></p>
  <p>这支财团的牵头方沙特公共投资基金（PIF），话事人就是大名鼎鼎的沙特阿拉伯王储、地表最强80后候选人之一、沙特愿景2030计划的总设计师穆罕默德·本·萨勒曼。在本次收购之前，PIF就已经是EA的主要股东之一，持股9.9%。与此同时，PIF还是任天堂、&nbsp;Take-Two（2K仟游）等知名游戏公司的股东。再加上此前PIF资助沙特举办了电子竞技世界杯等多项电竞大型赛事，并计划在2027年举办电竞奥运会，大量媒体在报道本次收购案的时候就会额外加上一句评价——沙特阿拉伯是世界上少有的、将电子竞技定义为“国家级战略产业”进行打造的国家。</p>
  <p>第二大参与方银湖资本（Silver Lake）是全球顶级的PE巨头，在全球知名的PE榜单PEI300中排名第12，自1999年成立以来业绩彪炳，并购的经典案例包括戴尔的私有化、Skype的私有化、赛门铁克（Symantec）的私有化。在本次EA收购案敲定之前，他们在体育娱乐产业中先后投资过大名鼎鼎的城市足球集团（英超豪门曼城的母公司）、美国职业棒球联盟管理公司之一Diamond Baseball Holdings (DBH)&nbsp;、澳大利亚足球联赛A-League。再加上银湖资本被传闻将加入甲骨文牵头的Tiktok收购案，大量媒体认为银湖资本组建“体育娱乐生态”的野心昭然若揭。</p>
  <p>第三大参与方Affinity Partners就不多说了，这家由特朗普女婿贾里德·库什纳（Jared Kushner）掌舵的投资平台拥有什么样的资源，懂的都懂。</p>
  <h2><strong>撬动杠杆，远期埋雷？</strong></h2>
  <p>那么EA为什么愿意卖呢？答案可以用四个字来概括：</p>
  <p><strong>揾食艰难。</strong></p>
  <p>实际上自2022年逐渐走出疫情周期以来，人们开始重返户外，全球游戏产业的增长曲线就开始明显放缓，<strong>饶是EA这样的巨头也不例外，近两年来增长陷入停滞状态，就连备受人们期待的线上游戏业务在整个2024财年也仅仅增长1%。</strong>这样表现一方面让市场对于EA的远期预期愈加悲观——2025年1月22日财报日甚至创下了公司上市以来股价单日最大跌幅，跌幅达到了16.7%——另一方面也让EA自身的运营压力越来越大，以至于在2024年年中及2025年5月EA先后进行了两轮规模不小的裁员。</p>
  <p>更重要的是，<strong>随着下行周期的到来，EA自身产品结构畸形的问题也日益凸显。</strong>前面提到了2025年1月22日，EA出现了上市以来单日最大的跌幅，而造成这一惨剧的最直接原因是他们的业绩严重依赖王牌产品、足球游戏《FIFA/FC》——据《华尔街日报》统计，在过去的5年里《FIFA/FC》贡献了整个EA一半的净预订额——而新作《FC25》的销量远不及预期，直接拖累EA在该财年的净预订额仅为70亿美元至71.5亿美元之间，大大低于之前估计的75亿美元至78亿美元。</p>
  <p>当然，EA也一直在想办法改变这种现状。近年来，EA一直在买买买，收购了大量的潜力工作室以寻找新的爆款。前文提到的《植物大战僵尸》开发者宝开游戏工作室（PopCap Games）、《模拟人生》的开发商Maxis工作室，都是通过这种方式加入的EA大家庭。</p>
  <p>但问题在于并购这件事太消耗成本了。在物色到有潜力的游戏开发商之后，EA不仅要开出一个足以打动团队的价码，还需要针对性地配置相应的发行团队来确保游戏的卖座，这都是真金白银的成本。与此同时，当所有人都知道你喜欢通过“买买买”来寻求战略转型，那么你在市场上也失去了“议价”能力，优质资产的所有者必然敢于喊出高价。2021年EA收购美国手游开发商Glu的案例就将这一困境体现的淋漓尽致：</p>
  <p>2015年腾讯收购Glu15%股份的时候，花费为1.26亿美元，算下来整体估值为8.4亿美元。而2021年EA完成收购的时候，Glu的整体估值已经达到了24亿美元，6年时间暴涨了3倍。</p>
  <p>更恶性循环的是，当“并购”成为了不得不采取的策略，进而不得不占据相当数量的现金流，EA就不得不从其他地方削减开支。前面提到EA的王牌产品《FIFA/FC》今年的销量表现十分惨淡，一个重要的原因就在于为了节约成本，EA决定不再向国际足联支付授权费用，失去了“FIFA”这块金字招牌。讽刺地是，<strong>EA其实预料到了将《FIFA》更名为《FC》将会带来的品牌力损耗，因此在更名后的第一代产品《FC24》发售时投入了相当的营销资源来造势，结果仅仅只取得了与前作《FIFA23》持平的销量。</strong>EA的决策者们因此在今年所幸砍掉了相当的营销预算，用自然推流的方式慢慢地卖《FC25》，最终造就了如今我们看到的窘境。</p>
  <p>所以这样的情况下，找到一根粗壮的大腿，顺势完成退市，减少经营决策的限制，也算是一个比较理智的选择。EA董事长兼首席执行官安德鲁·威尔（Andrew Wilson）逊的表态就很正面：“（接受并购）这一刻是对我们杰出工作的有力认可……展望未来，我们将继续突破娱乐、体育和科技的界限，携手合作伙伴，创造变革性的体验……<strong>我对我们正在构建的未来比以往任何时候都更加充满信心</strong>。”</p>
  <p>但让人担忧的不确定性因素在此刻又来了。虽然EA本次收购将按照2025年9月25日（最后一个完全不受交易传闻影响的交易日）收盘时的股价168.32美元溢价25%进行，EA股东将获得每股210美元的现金，整体交易估值为550亿美元，是一个不错的卖价。<strong>但这其中有高达200亿美元（约合人民币1425亿）是财团们借来的。</strong></p>
  <p>综合目前所有的公开信息，由PIF牵头的财团将以现金的方式完成本次收购，但3家投资方能够拿出的现金为350亿美元左右，剩下的200亿美元由摩根大通提供的债务融资完成，<strong>且交易完成后这200亿美元的债务将直接计入EA的财务报表中，而在此之前EA账面上的债务只有22亿美元</strong>。</p>
  <p>所以对于金融业来说，这笔交易刷新了“杠杆收购”的新纪录——在此之前，人类有史以来最大的杠杆收购案来自德州能源（TXU）在2007年创造的，当时收购总价450亿美元中有130亿美元是债务借来的；对于PIF牵头的财团来说，他们收获了有自我造血能力，未来提升空间不小的优质资产；但对于EA来说，他们莫名地背上了一笔沉重的债务，本就沉重的运营压力现在也变得更加复杂。</p>
  <p>事实上，这种不确定性已经不仅仅是未来的预期了。放眼游戏娱乐行业，被杠杆收购、强加债务之后由盛转衰的案例不胜枚举。全球曾经最大的玩具生产商玩具反斗城（Toys "R" Us）、全美曾经最大的派对产品生产商Party City都是前车之鉴，分析人士指出：“巨额债务负担使公司对销售额和盈利能力的轻微下滑非常敏感，同时，复杂的债务结构又使其难以与债权人重新协商条款……<strong>除非投资人愿意慷慨地将债务减半，那么现在公司马上就能盈利，一切安好。</strong>”</p>
  <p>而对于EA来说，已经有报道称为了更早地还清债务、降低运营成本，财团将推动人工智能越来越多地参与到EA的日常运营中，接管客服乃至一部分开发工作。EA旗下工作室、《龙腾世纪》系列开发商BioWare的团队成员们，已经为“被裁撤”做好了准备，不少人都已经准备好了自己的“简历”以随时进入求职市场。</p>
  <p>在这种氛围下，游戏行业对本次交易普遍反应负面，说“<strong>The EA Sale Is Bad News For Everyone</strong>”。而我作为从《FIFA2002》开始入坑的老玩家，也不时地想到英超豪门曼联，在被犹太商人格雷泽家族通过杠杆收购后，逐渐从开创王朝的足球豪门滑落为只考虑市场影响力、股价表现的“足坛流量王”。</p>
  <p>只能说“负面案例”足够多，也反向帮助EA找出了很多肉眼可见的雷。希望到2027年第一季度交易正式完成的时候，EA能够交出一份漂亮的汇报单，<strong>告诉我们“The EA Sale Is Good News For Everyone”。</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/aDi-EqxdRZS-gLWZUy-whQ" rel="noopener noreferrer nofollow" target="_blank">“投中网”</a>，作者：蒲凡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532840371050624</id>
            <title>从预选赛到突围赛，Robotaxi双雄竞速“第一股”</title>
            <link>https://www.36kr.com/p/3532840371050624</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532840371050624</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:58:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_7e0a18a14cda4eca8f03ec542d939237@15574914_oswg895863oswg965oswg564_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>进入下半年，Robotaxi赛道骤然加速。</p>
  <p>特斯拉启动Robotaxi试点运营，百度“萝卜快跑”先后与Uber和Lyft达成战略合作，小马智行与文远知行这些自动驾驶领域的“熟面孔”，也在资本与商业层面频频发力。</p>
  <p>10月28日，小马智行与文远知行双双在港交所发布招股书，启动全球发售。其中，文远知行拟发行8825万股股份，发售价不超过每股35港元；小马智行拟发行4195.57万股股份，发售价将不超过每股180港元。两家公司均预计于11月6日挂牌交易，一场争夺“港股Robotaxi第一股”的竞赛打响。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_6a1d8d6e1b7a4bf8b2e666074d2b16f6@15574914_oswg27042oswg724oswg306_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同日上市，反映了两家自动驾驶独角兽从技术竞逐延伸至资本赛道的激烈博弈，更预示着行业正从迈向规模化商业落地的竞速时代到来。</p>
  <p>随着商业探索与资本进程双双按下快进键，谁更能率先跑通可持续的商业模式，进而成为Robotaxi赛道的定义者？</p>
  <p>这个问题的答案，不仅关乎万亿规模出行市场的格局，也将影响从汽车制造到智能服务等广泛产业的未来。</p>
  <h2><strong>Robotaxi元年，产业跃升下的价值再分配</strong></h2>
  <p>今年下半年以来，Robotaxi（自动驾驶出租车）赛道一改往日的低调姿态，呈现出集体跃迁的势头。</p>
  <p>行业头部玩家在技术落地、商业合作与资本运作上动作频频，推动整个产业从技术验证阶段全面迈入商业化竞速期。特斯拉在奥斯汀启动无方向盘车辆运营并实现单日2000次服务，百度“萝卜快跑”累计订单突破1100万单，Uber亦加码投资文远知行并推动其中东业务接入平台。</p>
  <p><strong>作为高阶自动驾驶面向C端核心应用赛道之一，Robotaxi的崛起，是一场产业链价值重构，汽车产业价值重心从“硬件定义”向“软件与生态定义”战略性转移。</strong></p>
  <p>也正因此，Robotaxi商业化落地加速，背后有着整个产业链的支撑。这场变革将覆盖芯片、激光雷达、线控底盘等一系列核心硬件领域，并重新塑造整车制造、自动驾驶技术提供商与出行平台之间的利益分配格局。</p>
  <p>在这个过程中，掌握核心算法的自动驾驶技术企业，有望像英伟达在人工智能产业中扮演的角色一样，占据产业链中最具价值的核心节点。所以，在持续的亏损背景下，小马智行与文远知行依然吸引了大量目光。</p>
  <p>作为头部玩家，这两家公司一定程度上反映了高阶自动驾驶发展两条关键路径。</p>
  <p><strong>小马智行深耕本土市场的优势突出。</strong>公司是当前国内唯一一家在北上广深四大一线城市均获得全无人收费运营监管许可的企业。</p>
  <p>同时，小马智行战略布局上更倾向于“深度绑定整车厂+自建车队”的前装量产模式，与丰田、广汽、北汽等车企合作，共同推进第七代自动驾驶系统的规模化落地，凸显了通过车规级硬件整合与控制成本的核心思路。也正因此，公司打造出一支超过680辆自有自动驾驶出租车的车队，累计自动驾驶里程超过4790万公里。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_1c16833fd51e4e478cc42dbe286b95bc@15574914_oswg432821oswg743oswg345_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>相比之下，文远知行选择了“平台化技术输出+全球场景复制”的路径。</strong></p>
  <p>文远知行打造的通用自动驾驶平台“WeRide One”，适配Robotaxi、小巴、环卫车等多种车型和场景，商业模式中包括全部投入商业运营的超400辆“第三方合作车辆”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d9d87c5cfe2e499d89b0ade7d87e02b2@15574914_oswg76976oswg849oswg359_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在市场拓展上，文远知行更借力Uber等全球出行平台，快速将其业务铺开至11个国家的30多座城市，并成为唯一一家旗下产品拥有7国自动驾驶牌照的科技公司，全球市场的行业地位突出。</p>
  <p>自动驾驶企业、车企与科技公司跨界结盟，将这两条路径合而观之，它们几乎覆盖了当前汽车产业智能化转型的两大核心方向。<strong>这也侧面证明了Robotaxi商业化落地将在产业合力下加速。</strong></p>
  <p>在此背景下，小马智行与文远知行的竞争，正在从过去的技术层面，扩大至商业生态与资本耐力的综合较量。在通往Robotaxi规模商业化的道路上，究竟哪一种模式更接近最优解？</p>
  <h2><strong>路线与资本，中国Robotaxi备战漫长战争</strong></h2>
  <p>在探讨谁是“中国Robotaxi最佳方案”时，需要认识到小马智行与文远知行差异化的战略，代表了智能驾驶产业在探索未来出行模式上的两种不同视角和逻辑起点。</p>
  <p><strong>从更深层次看，小马智行更接近“本土汽车产业升级”思维，主打“虚拟司机”，侧重于本土制造产业的升级，然后顺势全球扩张。</strong></p>
  <p>小马智行的核心优势在于本土市场与硬件成本的控制能力。第七代自动驾驶系统据说实现了硬件成本较前代下降约70%的突破，为规模化扩张提供了更多可能。</p>
  <p>然而，这种模式也意味着自身投入更多，前期需要更多车队建设与运营积累的沉淀。简言之，早期研发投入高于文远知行，Robotaxi业务商业化产生的收益尚不如文远知行。根据招股书，2025年上半年，公司总营收仅3543.4万美元，亏损达到9064万美元。小马智行上半年研发支出9651.6万美元，而文远知行同期为8998.8万美元。</p>
  <p><strong>而文远知行选择的全球化路线，营收多元化的同时，在业务拓展初期更能“借力打力”。</strong>2025年第二季度，文远知行Robotaxi业务营收同比大幅增长836.7%，达4590万元，全球化的战略迅速转化为业绩增长数字。但与此同时，这种模式也面临着技术适配复杂性与本地化运营能力的双重挑战。</p>
  <p>“本土优先”的产业升级与“全球抢跑”的场景渗透，是从两个方向向着“全球无人驾驶领军者”的道路赛跑，各有所长，但从长远来看，它们很可能随着技术成熟而逐步相互融合，取长补短。</p>
  <p><strong>从这一点出发，两家公司同步选择回港上市，实质上是一场关于产业资源与战略窗口的争夺战。</strong></p>
  <p><strong>一方面，争夺完善“弹药”储备。</strong></p>
  <p>自动驾驶研发如同一场无底洞式的投入，算法优化、数据采集、车队运营每日都在吞噬巨额资金。尽管两家公司Robotaxi业务收入增速显著，但它们都在亏损中寻求商业化突破。</p>
  <p>截至2024年12月31日止3个年度及2025年前6个月，小马智行亏损分别约为美元1.48亿、1.25亿、2.75亿、0.91亿；同期，文远知行亏损分别约为人民币-12.98亿元、-19.49亿元、-25.17亿元、-7.92亿元。</p>
  <p>而港股市场不仅提供融资渠道，还具备连接内地与全球资本的独特定位。根据招股书披露，小马智行拟募资净额约71.9亿港元，文远知行则计划募集约29.3亿港元，这笔资金将为它们的下一步扩张提供关键助力。</p>
  <p><strong>更为战略性的考量在于，港股作为中国企业出海的桥头堡，既能为企业提供内地资源对接，又可作为进军东南亚等新兴市场的跳板。</strong></p>
  <p>近年来，地缘政治因素促使科技企业寻求多元化资本布局，以增强自身抗风险能力。港股上市正好满足了这一需求，既贴近中国本土市场，又能连接国际资本，为企业的全球化布局提供双重保障。</p>
  <p><strong>展望未来，随着第一梯队玩家完成资本化布局，Robotaxi赛道正从由百度“萝卜快跑”开启的技术验证的预选赛，转入规模化运营的突围赛。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4162d42eb3844081b464e286c9143574@15574914_oswg147055oswg785oswg491_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来的竞争将更加考验企业的综合实力，不仅仅是技术能力，还包括商业模式的健康度、资本运用的效率以及全球化运营的落地能力。</p>
  <p>在这个阶段，单纯的技术领先已不足以确保市场地位，如何将技术优势转化为可持续的商业模式，才是决定谁能在这场长期竞赛中笑到最后的关键。</p>
  <p>真正的竞争才刚刚开始。</p>
  <h2><strong>洞察未来出行，下一个超级生态孵化进行时</strong></h2>
  <p>Robotaxi赛道正在上演类似电动车产业崛起的长期进程。</p>
  <p>回顾电动汽车的发展历程，19世纪80年代至20世纪初产业萌芽，可充电电池技术也是率先应用于出租车、公共汽车等公共出行领域，不过受限续航里程和成本未能持续发展；直到2012年特斯拉Model S发布，首次将电动汽车的续航里程突破500公里，并实现“软件定义汽车”的概念，电动车才进入快速发展的黄金期。</p>
  <p><strong>如今，高阶智驾再次在Robotaxi这一出行领域抢先落地。Robotaxi将引领从“智能驾驶”到“智能出行”的产业变革，即将迎来属于自己的“Model S时刻”。</strong></p>
  <p>这也意味着一场新的产业生态重构开始了。</p>
  <p>与Waymo、特斯拉等国际巨头相比，中国企业在Robotaxi领域已占据更为有利的生态位。中国拥有全球最完整的智能汽车产业链、最多元的应用场景以及最为积极的政策环境。</p>
  <p>从国家战略视角观察，“十五五”规划持续强调科技创新与产业升级，Robotaxi作为人工智能与自动驾驶技术最具代表性的融合应用，恰好契合这一发展方向。企业在技术研发与商业化落地方面取得的进展，关系到我国在全球智能交通竞争中的话语权。</p>
  <p>从产业链看，中国成熟的汽车产业链正在推动关键零部件成本快速下降，以激光雷达为例，成本已降至千元级，为规模化商用奠定了坚实基础。这也是为什么小马智行CEO彭军提到“有望3年后实现公司盈亏平衡”。</p>
  <p>现在，相比盈亏，市场最重视的问题是，<strong>谁能率先爬上规模化商业化的陡坡。</strong></p>
  <p><strong>量的突破，意味着率先建立品牌影响力与市场地位，也往往意味着吃到行业变革的最大红利，正如苹果之于智能手机，特斯拉之于电动车。</strong></p>
  <p>美银最新报告预测，到2040年，自动驾驶汽车市场总规模可能增长至1.2万亿美元，一个全新的黄金赛道正在加速形成，第一个“上岸的螃蟹”有望成为最大受益者。</p>
  <p>更重要的是，出行是连接各类消费场景的纽带。因此，展望未来，Robotaxi带来的价值重构远不止于出行市场本身。</p>
  <p>当自动驾驶真正普及时，车内空间将转变为私密的“第三移动空间”，乘客可将出行时间转化为生产力或娱乐消费场景。这种转变将催生全新的商业形态，连接人工智能、泛娱乐、远程办公等多个领域，创造比传统出行大得多的市场价值。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_081e2d8895e04046a179c246089813a0@15574914_oswg1000227oswg991oswg568_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>小马智行与文远知行同步赴港上市，说明所有参与者都在为这场终极竞赛加紧布局。</p>
  <p>最终，这场竞赛的胜出者有望在下一代泛出行娱乐生态中成长为新的科技巨头。</p>
  <p>本文来自微信公众号“港股研究社”（ID：ganggushe），作者：港股研究社，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532934159129479</id>
            <title>黄仁勋苏姿丰，刚投了个复旦女学霸</title>
            <link>https://www.36kr.com/p/3532934159129479</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532934159129479</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:58:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_43d56170d31643ab99a3ef6fa24cafcc@000000_oswg262475oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>智东西10月31日消息，10月28日，美国AI推理独角兽Fireworks AI宣布完成<strong>2.5亿美元（约合人民币17.75亿元）</strong>C轮融资，总融资额升至3.27亿美元（约合人民币23.21亿元），估值达<strong>40亿美元（约合人民币284亿元）</strong>，相比1年前的5亿美元估值翻了<strong>超7倍</strong>。&nbsp;</p>
  <p>本轮融资由光速创投、Index Ventures和Evantic领投，<strong>红杉资本、英伟达、AMD、MongoDB、Databricks</strong>等现有投资方继续跟投。此次融资分为两部分，即由同一批投资者参与的2.3亿美元（约合人民币16.35亿元）的一级市场融资和2000万美元（约合人民币1.42亿元）的二级市场融资。<strong>此前，Fireworks AI已获红杉资本、英伟达多次投资</strong>。&nbsp;</p>
  <p>Fireworks AI创办于2022年，由首席执行官兼联合创始人、前Meta高级工程总监乔琳（Lin Qiao）带领多位前Meta PyTorch核心成员联合创办，核心业务<strong>是为开发者提供一个平台，帮助他们运行和定制开源模型</strong>。&nbsp;</p>
  <p>值得一提的是，联合创始团队中<strong>有3位是华人</strong>。首席执行官兼联合创始人乔琳（Lin Qiao）本硕毕业于复旦大学计算机科学专业，之后在美国加州大学圣巴巴拉分校（UC Santa Barbara）获得计算机科学博士学位。另两位华人联合创始人分别是前Meta软件工程师Benny Chen和前谷歌高级软件工程师Chenyu Zhao。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_178ebd770c8243d6875a1fbc9b4a7af0@000000_oswg65182oswg1024oswg515_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Fireworks AI华人联合创始人（图源：Fireworks AI）</p>
  <p>Fireworks AI不直接购买或自研服务器硬件，而是基于云端GPU集群搭建基础设施，并通过API向客户提供访问接口。&nbsp;</p>
  <p>其主要客户有全球手机巨头三星、全球知名数字出行平台Uber、全球领先跨境电商平台Shopify和全球最大的自由职业交易市场Upwork等知名企业，年化收入已超过<strong>2.8亿美元（约合人民币19.90亿元）</strong>。&nbsp;</p>
  <p>Fireworks AI将利用新融资招聘150多名新的AI研究人员、工程师、产品和销售及营销员工，以及购置驱动AI模型的GPU。&nbsp;</p>
  <h2><strong>01.华人女企业家创业，估值一年增长7倍</strong></h2>
  <p>Fireworks AI创始团队的阵容堪称豪华。2022年，Meta前高级工程总监乔琳（Lin Qiao）与6位联合创始人在美国加州雷德伍德市创立了Fireworks AI。联合创始团队由6名前Meta PyTorch项目的工程师和1名前谷歌AI工程师组成。在创业前，<strong>乔琳曾在Meta领导超过300名工程师的团队，已经拥有了24年的行业经验。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c190a856a96443ae936f0e4694c9431b@000000_oswg711024oswg1024oswg944_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Fireworks AI创始人团队（图源：Fireworks AI）</p>
  <p>在Meta期间，乔琳<strong>最大的成就是领导PyTorch在Meta数据中心、移动设备和AR/VR设备上的开发和部署</strong>，为Meta系列的应用程序提供支持。目前，PyTorch已成为全球主流的开源机器学习框架之一。</p>
  <p>在PyTorch的成功经验基础上，乔琳带领团队创立Fireworks AI，直击AI应用落地的核心痛点——推理的计算成本和效率，将控制权重新交回开发者手中。</p>
  <p>Fireworks AI成立仅三年，创立当年便完成了种子轮融资，2023年完成A轮融资，投资方包括红杉资本、英伟达、AMD等，2024年，其在B轮融资中估值达到<strong>5.52亿美元（约合人民币39.24亿元）</strong>。而近日完成的新一轮融资让Fireworks AI<strong>估值飙升至40亿美元</strong>，估值<strong>一年增长超7倍</strong>。</p>
  <p><strong>目前，Fireworks AI平台每日处理超10万亿个token，服务超过10000家企业客户。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ab342e372a59451ab38836cfe5d6e157@000000_oswg81453oswg1024oswg440_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Fireworks AI合作伙伴（图源：Fireworks AI）</p>
  <p>相比传统云服务商，Fireworks AI提供的是更低成本、更高性能、且支持定制化开源的大模型。&nbsp;</p>
  <p>Fireworks AI支持数百种前沿开源模型的访问权限，这些模型涵盖文本、图像、音频和多模态领域，支持模型微调、强化学习以及评估。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ee89df98af63449ebb86a580b6e20022@000000_oswg154542oswg1024oswg795_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Fireworks AI的大模型库（图源：Fireworks AI）</p>
  <p>所有功能都建立在其在超高速推理引擎之上，Fireworks AI的官网显示，相较于其他服务提供商，Fireworks AI平台的<strong>性能可提升40倍，成本降低8倍</strong>。&nbsp;</p>
  <p>在功能定价上，Fireworks AI采用了极其灵活的定价方式，包括无服务器推理、模型微调定制和按需部署GPU。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_21f8384a31aa46bc8649ff30d38c5722@000000_oswg162567oswg1024oswg598_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Fireworks AI部分功能定价（图源：Fireworks AI）</p>
  <p>“Fireworks AI的使命是提供最好的工具链，借助生成式AI，帮助应用程序开发者达到最高的质量、速度和成本效益，”乔琳称，“我们并不自行研发专用半导体，而是通过让开发者虚拟访问先进芯片来运行开源AI模型，并帮助他们优化推理过程及定制AI模型。”&nbsp;</p>
  <h2><strong>02.推理市场快速发展，企业仍谨慎采用推理平台</strong></h2>
  <p>这笔融资正值AI行业的竞争重点从训练逐步转向推理。随着ChatGPT等工具使用日常化，AI模型的推理需求也越来越大。英伟达、亚马逊和高通等科技巨头，以及Groq和Cerebras Systems等AI芯片创企，都正在积极推进专用于AI推理任务的芯片产品。&nbsp;</p>
  <p>光速创投合伙人阿努什卡·瓦斯瓦尼（Anoushka Vaswani）称：“回顾推理市场头三年的发展，其规模已从零增长至超过50亿美元（约合人民币354.95亿元）。”&nbsp;</p>
  <p>Cursor首席产品官（Sualeh Asif）称：“Fireworks帮助我们实现了Fast Apply和Copilot++模型的高性能运行。在性能方面，他们超越了我们评估过的其他竞争对手。Fireworks还帮助我们实现了针对特定任务的加速和新的架构。”&nbsp;</p>
  <p>分析人士指出，尽管Cursor等AI公司已经在使用Fireworks AI向用户交付AI模型，由于该平台需要定制化的AI工程支持，<strong>大多数企业客户在采用类似Fireworks AI的平台时还是会更为谨慎</strong>。&nbsp;</p>
  <p>AI工程需要高水平的专业技能，企业必须掌握如何将训练好的模型、数据集和推理平台结合起来。许多企业仍在培养内部技术人员或寻找外部人才来填补这一缺口。&nbsp;</p>
  <p>市场研究和咨询机构Gartner分析师奇拉格·德凯特（Chirag Dekate）称：“目前大约有80%的企业尚未达到这一高级AI工程化阶段。”&nbsp;</p>
  <h2><strong>03.结语：Fireworks AI估值飙升，AI推理市场竞争白热化</strong></h2>
  <p>Fireworks AI估值飙升，反映了AI推理市场的快速增长。当其他公司还在用成本筛选客户时，Fireworks则选择支持开发者，赋予他们自主构建、部署和扩展AI的能力，让他们按自己的方式掌控一切。</p>
  <p>然而，诸如Fireworks AI等推理平台都在共同面对新风险，企业在采用这些平台仍显谨慎，亚马逊、微软和谷歌等大型云服务巨头的加入也正在加剧竞争。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652791640&amp;idx=1&amp;sn=a5860b095469f9d293d288fee0d7590d&amp;chksm=8526c2317c8154008ed7a1de2a00d3fe79738fb4a441bf3556cd47d042145f36988aff80eb66&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：王欣逸，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532969170672772</id>
            <title>夸克的「狡兔三窟」</title>
            <link>https://www.36kr.com/p/3532969170672772</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532969170672772</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:55:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在互联网行业，只要入口发生变化，一切秩序都会被重新改写。 PC时代的入口是浏览器，移动时代入口落在超级应用上，而生成式AI的出现，再次让入口这件事从指尖跃迁到语言，甚至走向更直觉的交互方式。&nbsp;</p>
  <p>入口之争的本质，几乎都不是技术路线之争，往往更多是产品定义的一时决策。当然这个位置一旦失守，就意味着退出主航道。&nbsp;</p>
  <p>长期以来，夸克更多像阿里体系里的一条支线：做浏览器、做搜索框、做网盘 、 做办公学习集合 不一而足，可以说哪里需要就出现在哪里，算是一种难得的工具理想主义。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_00ff602a15d94de0b766afeb67e9f079@000000_oswg241768oswg1080oswg584_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">夸克官网截图</p>
  <p>直到 AI大潮 来临 ，夸克的姿态发生了明显变化： <strong>从原本的工具开始转向阿里AI战略中真正直面C端消费者的核心。</strong></p>
  <p>最具象的信号，是短时间内连出两步骤然升级的动作：推出“对话助手”，和启动夸克AI眼镜预售 —— 一个触及软件入口，一个押注硬件入口。&nbsp;</p>
  <p><strong>这不只是技能树的拓展，而是在试图为未来入口的不同可能性预先占位。</strong></p>
  <p><strong>随着夸克一个月内连出两步，阿里似乎是把Google、OpenAI、Meta的AI野心揉进了同一个产品叙事里。</strong></p>
  <p>不过关问题来了： <strong>夸克这到底是在未来做准备，还是在为阿里之前没能在最初的大模型入口之争占得先机而事后补课？</strong> 就目前来看，似乎尚需一定时间才能看到答案。&nbsp;</p>
  <h2>01 <strong>从“对话”到“眼镜”，夸克为何急于前移入口</strong></h2>
  <p>如果只看动作本身，夸克过去一个月做的事， <strong>其实高度一致地指向入口前移。</strong></p>
  <p>终于了推出对话式AI助手，把入口搜索向自然对话转移；同时押注AI眼镜，则是把硬件入口从手机转向更随身的眼镜。&nbsp;</p>
  <p>这两步看似跨度巨大，一个在软件，一个在硬件，但它们共同表达的是同一件事： <strong>夸克对既有入口体系中的生态占位并不满意，或者说整个阿里的AI战略还需要更简单直白的C端入口。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ab02814f996249239fb3bb9d528343ae@000000_oswg544296oswg1080oswg875_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">夸克AI眼镜</p>
  <p>过去用户在搜索框输入关键词，夸克负责呈现更干净、更准确、更结构化的结果，即便是有AI加成的搜索框，也不会根本改变用户习惯。&nbsp;</p>
  <p>但当用户习惯在自然对话中AI描述模糊需求，再获得成品输出，搜索的必要性就被削弱了。 <strong>用户不是不需要信息，而是不愿再花精力在找信息上，希望直接抵达结果。</strong> 这种习惯的改变，是对搜索入口最直接的冲击。&nbsp;</p>
  <p>所以夸克做对话式AI，当然还是一种顺势而为，毕竟OpenAI对这一波AI浪潮最伟大的贡献，与其说是GPT的大模型能力，不如说是ChatGPT这款应用产品。国内如今热门的AI产品，不论是豆包、元宝、Kimi、Deepseek、文小言无一不是对ChatGPT的精准“致敬”产物。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c42184f176884d17a9f4335f9c2ca20b@000000_oswg148984oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">夸克App截图</p>
  <p>事实证明，用户也的确能够接受这种产品形态，在快速实现产品教育之后甚至已经形成了某种路径依赖。因此，在这种环境之下更应该将本就已经具有相当广泛用户基础和工具属性的产品，进一步升级，这大概也是夸克当下端出对话助手的原因。&nbsp;</p>
  <p>但夸克并未止步于对话式入口，而是同时也开始向硬件入口迈进。 <strong>如果说Chatbot是入口的软件形态升级，那么AI眼镜则是终端硬件的尝试。</strong></p>
  <p>夸克押注AI眼镜，本质上是押未来十年信息不再依附于屏幕，无论手机还是电脑，而是以更自然、更随身的方式伴随用户。&nbsp;</p>
  <p>当然，提前站位并不意味着没有风险。对话入口仍处试验阶段，各家产品形态并未定型；AI眼镜则面临成本、体验、生态和用户习惯等多重变量。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ab5766301af14c58b56ce7e4cb655ad6@000000_oswg101126oswg720oswg976_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">夸克AI生成</p>
  <p>更现实的挑战是， <strong>夸克过去是一支轻量团队，以产品与内容洁净度取胜，如今转向硬件后需承担供应链、生态建设与跨团队协同的压力</strong> ，这对夸克而言是陌生且沉重的节奏。押得早意味着占位，但也意味着可能押错方向，尤其当入口形态仍未出现强共识时。&nbsp;</p>
  <p>换句话说， 夸克的动作看似是两条新路径，其实是一条入口延长线 ， 但这条线能否从技术亮点变成用户习惯，还需要时间验证。&nbsp;</p>
  <p><strong>夸克这一次的变化，不在于做了更多，而在于它首次以入口参与者的身份，而不是搜索升级者的身份出牌。</strong></p>
  <h2>02 <strong>殊途同归之下的夸克，被推着走还是主动上桌？</strong></h2>
  <p>与其将夸克的路径变化理解为突然的路线调整或是应激反应，不如将其视为顺应入口周期变化的前置调整。&nbsp;</p>
  <p>站在行业视角下，它并非孤例。 过去一个月里，OpenAI也宣布推出自家浏览器Atlas，借ChatGPT余威进攻到Google腹地，将“代理”之争进一步白热化。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_dc34e28829c941c583ef2026d06585a7@000000_oswg98331oswg1025oswg921_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更早之前苹果被曝出在内部测试轻量级AI眼镜原型，同样的字节跳动在AI硬件方面也早有动作，自有AI眼镜方案一直也在推进中——这些原本分属不同赛道的公司，开始在入口与终端两个方向上呈现某种同步性。&nbsp;</p>
  <p>这意味着，夸克并不是离群跑偏，反而是踩在了一条更大的趋势线上：当Chatbot成为新的交互范式，当信息入口从检索转向模糊语义，当屏幕不再是信息抵达用户的唯一介质， <strong>不同玩家正从不同起点朝同一个方向汇聚——试图参与定义下一代入口，而不是被入口变化所定义。</strong></p>
  <p>在这一意义上，夸克的动作也需要放进更广的行业动态里理解。 当然除了更长远的战略布局，这背后有没有更紧迫的现实需求呢，大概也是有的。 也是在最近OpenAI不仅推出了自家浏览器Atlas，还宣布在ChatGPT内测试即时结账等电商能力。与此同时，字节旗下的豆包也上线了带商品链接的对话式种草与导购能力。并且像美团、京东等平台也都各自在测试内部的Chatbot直连电商或即时零售的功能。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_08036f3ebfec4464acbdf33c63490686@000000_oswg151739oswg960oswg984_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：豆包</p>
  <p>从这个层面来看， <strong>缺乏一个具有泛用性Chatbot入口的阿里，其AI电商宏图实在缺少最表层的可信度。</strong> 因此 ， 无论其AI底层能力有多强，用AI改造了多少电商中间环节，对最普通消费者而言都是毫无意义的， <strong>当最后别人都能直接通过打几个字说几句话就下单一件商品时，阿里才会面临最大的危机。</strong> 就现阶段来看，原本分属模型、硬件、内容、电商的玩家，正从不同路径逐步逼近同一个目标： <strong>让AI从信息入口延伸为交易与服务入口，即所谓的全面“代理化”。</strong></p>
  <p>夸克的特殊性在于，它原本就处在入口链路中，只是属于旧入口体系的底层环节——浏览器与搜索，以及网盘、文档等等基础工具。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_dac5a8b3984843ea84845ba3b5e17785@000000_oswg303689oswg1080oswg801_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：网络</p>
  <p>当入口从找信息转向用信息，从触屏输入转向自然表达，它的原有位置会被削弱，甚至可能被替代。因此，它比多数玩家更早感受到入口不进则退的结构性压力。这种压力不是市场份额层面的，而是存在感与边缘化风险层面的：如果入口迁移，它会不会直接从牌桌上消失？ 以及作为阿里的AI排头兵，如果在其整个AI电商中发挥更多价值，无疑同样也是现阶段夸克不得不考虑的现实问题。&nbsp;</p>
  <p>从这个角度看， <strong>夸克这次两段跳不是既有长远设计同样也是基于非常现实的竞争考量。</strong> 它意识到，仅靠小而美无法抵御入口迁移带来的结构性风险，因此必须把自己从产品逻辑推向入口逻辑。这不是为了证明自己能做多少，而是为了给自己保留未来参与入口叙事的资格。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9afb6b7e2857463895ff447896fcdaf6@000000_oswg314139oswg1080oswg985_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：夸克微博</p>
  <p>当然，趋势并不代表必然成功。&nbsp;</p>
  <p><strong>入口从来不是靠看对方向取胜，而是靠能否撑到方向成熟。</strong> OpenAI做浏览器，有模型原生优势；苹果做眼镜，有软硬件生态整合能力；字节的豆包本身还是具有极强的产品优势以及抖音生态流量加持。 而夸克要在Chatbot实现突围，同时超前布局硬件终端， <strong>需要补齐的能力显然更多。</strong></p>
  <p><strong>其中一项或许就是产品的专精程度。</strong> 夸克集成的工具可谓市面上独一档，这对于做一款好“代理”或许是好事，但问题在于大众对其的认知真的是AI产品吗？这或许需要也要打上一个问号。 如果吸引不到足够的用户去对话去尝试，那么再好的“代理”能力，再强的模型也发挥不出效果。毕竟如果按照模型能力去判断用户量，通问显然早就应该在第一梯队了，然而现实中有多少用户知道又有多少人愿意日常去用呢。&nbsp;</p>
  <p>毕竟如果去看QuestMobile的报告，AI原生APP规模TOP榜里通义还能排在第十位，但根本就没有夸克的身影。豆包和Deepseek的月活已经直奔两亿而去，腾讯今年不断力推的元宝，目前月活用户也不过才3000万出头。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_a6308876247e4e43b0f2f4d32ae84173@000000_oswg88204oswg800oswg876_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：QuestMobile</p>
  <p>而不少评论常常会引用的AIGCRank《中国AI应用排行榜》，在9月夸克的平均日活数位列榜首，紧随其后的是豆包。其中有一个bug在于， <strong>在夸克集成了“看资源”这一能力的大背景下，其不论日活或月活显然都有很大一部分并非是为AI而去，这显然也是一个无法忽视的现实。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_53fea4d4c7b1478c8d84ee8a3dd87f5b@000000_oswg322534oswg1080oswg1151_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：AIGCRank</p>
  <p>或许接下来夸克 这只大厂体系里的“狡兔”，在找好自己的“三窟”之后，要做的反而是如何“埋窟”， 将其他功能隐身， <strong>进一步强化其AI属性，尤其是在C端用户的认知中去重新定义自己。</strong> 入口价值往往需要在更长远的未来才能兑现。夸克此刻做的，当然不是押宝某一种确定性，而是不给未来留下当做未做的遗憾。当竞争的格局下一次改写时，它至少已经明确站在场内，而不是成为某个事后复盘的旁观者。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0MjM2NTY4Mw==&amp;mid=2247589198&amp;idx=1&amp;sn=6fa5ece52643eb4649fc6d09287e5ef2&amp;chksm=e840dc2458c0378e5f11b09bd0a9699cb5aa55ee16edc14d74541f31f98ec745a33ea5872b41&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“壹娱观察”（ID：yiyuguancha）</a>，作者：大娱乐家&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3533019399166857</id>
            <title>抢首发、卷价格，国产手机上演“十月围城”</title>
            <link>https://www.36kr.com/p/3533019399166857</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3533019399166857</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:51:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>9月26日一早，一则“小米17的预售崩了”消息飞速传播。</p>
  <p>部分友商直接拿到了预售数据，从电商渠道看，小米17系列只有上代的90%，标准版则在80%以下。不及预期的消息很快就化作悲观情绪蔓延至资本市场，当日小米集团（1810.HK）股价一度下跌超过8%。</p>
  <p>外界的恐慌并没有影响小米的节奏，在内部看来电商预售订单下滑完全在意料之内：一是此次线下并未提前展示样机；二是线下预约小米开始收取定金；三是小米有意引导用户前往门店取货。</p>
  <p>也是在当天，小米西南地区某经销商告诉界面新闻，从不同门店的预约情况看，预约量是明显高于去年的，对小米而言，真正决定决定成败的是第一个首销开始的周末。</p>
  <p>9月26日10点首销开始，小米迅速用战报回应了质疑，小米17全系开售5分钟，刷新2025年国产手机全价位段新机系列，首销全天销量、销额纪录。开售5天后，小米17系列销量正式突破100万台，其中Pro/Pro Max版本占销量的80%。</p>
  <p>一场令多方“意外”的首销，小米凭借小米17系列以22.08%的市场份额成为中国智能手机市场的周度冠军，短暂超越了苹果，也拉开了10月新机潮的序幕。</p>
  <h2><strong>小米、OPPO、vivo上演“十月围城”</strong></h2>
  <p>九月底到十月，小米、OPPO、vivo各自发布了今年的旗舰产品，红魔、iQOO、红米、真我、一加等子品牌也紧跟其后。其中一加更是将其数字系列和ACE系列一同发布。</p>
  <p>这些新机的共同点是，较上代产品发布时间皆有提前，直接原因是高通和联发科芯片在9月各自发布了旗舰芯片，与上一代相比其发布时间提前近一个月。</p>
  <p>联发科天玑9500虽早于骁龙8至尊版（Snapdragon 8 Elite Gen5）两天发布，其搭载机型vivo X300系列和OPPO Find X9系列发布节点皆晚于小米17系列。</p>
  <p>一位上游供应链分析师告诉界面新闻，芯片厂商的发布节点往往是根据手机厂家的需求来推进，高通如果把节奏提前，其竞争对手联发科自然也会同步提前，这一点芯片厂商的逻辑是一样的，抢到节奏才能抢到客户。OPPO、vivo没有早于小米发布机器是因为天玑9500虽然早于高通骁龙8至尊版发布，但芯片验证和批量生产没有跟上。</p>
  <p>尽管如此，OPPO并没有放弃与高通进一步深入合作，2025高通骁龙峰会上，高通首次推出“双8系旗舰”策略。其中，骁龙8 Elite Gen5由小米17首发搭载，另一款骁龙8 Gen5作为正代旗舰芯片，由一加官宣全球首发。该芯片采用3nm制程工艺，性能与骁龙8至尊版相近，但更注重能效平衡。</p>
  <p>一加中国区总裁李杰称，这颗芯片是一加跟高通双方联合定义，双方一起做了近两年，接下来会在一加非常重磅的机型上面发布，将于年内上市。界面新闻了解到是这款芯片比原本的计划发布时间是2026年的二季度，现在提前了近两个季度。</p>
  <p>Omdia手机行业研究负责人刘艺璇对界面新闻表示，高通把高端芯片的时间节点提前，是希望跟iPhone17在时间线上拉齐，方便中国的手机安卓厂商直面与苹果在高端上竞争。而高端之外过去两年间也能够看到厂商在做产品规划和海外市场的发布都不再是遵循之前的时间节点，厂商在产品发布时间节点上表现的更加灵活和弹性。</p>
  <p>目前小米仍是高通最大的客户，一直享有高通每代旗舰芯片的首发权。今年小米从改名小米17选择直面苹果显然是有意之举，高通的骁龙8至尊版提前使得搭载天玑9500芯片OPPO、vivo加紧节奏，从这个角度看是小米带了整个市场的“节奏”。</p>
  <p>每年的10月是双十一大促前的关键备货窗口，手机厂商需提前1个月发布新机，预留产能爬坡、渠道铺货和预售预热时间。新机首发价与双十一折扣形成价格组合拳，刺激消费者“早买早享受”或“等促销降价”的决策。</p>
  <p>今年，随着这一轮线下国补的退坡，厂家被迫要用更快的速度来迭代抢占存量用户，即发的越早就越优势。</p>
  <p>这也造就了手机厂商“十月围城”的现象。当然，这背后的本质是中国供应链成熟度、消费节点红利和厂商博弈策略三重共振的结果，也是国产手机厂家不得不做的选择。</p>
  <h2><strong>首销超预期</strong></h2>
  <p>“今年很不好做，整体节奏很快，原本预测苹果会给所有人都带来压力，现在看过来小米、OPPO、vivo首销都在上涨。”某国产手机厂商员工告诉界面新闻，“这个跟我们一开始预判的趋势不一样。”</p>
  <p>面对苹果的压力，国产手机厂商善于用差异化来争夺用户。比如小米17 Pro系列增加了背屏设计。同期发布的OPPO Find X9与vivo X300则通过影像来打差异化，双方都上了200MP长焦、8K视频录制成头部品牌差异化焦点，直接比拼长焦与视频能力。</p>
  <p>次旗舰品牌真我、一加受益于7000mAh+硅碳负极电池成本下探，在新机型上纷纷采用该方案，并搭载120W快充，在细分市场iQOO 15和一加15均强化高帧率和散热配置，争夺电竞用户。</p>
  <p>界面新闻了解到，vivo X300系列首销总量约在9万多台，相比上一代产品X200首销日增长50%。OPPO Find X9线下首销量约在7万至8万台，和小米一样，消费者更倾向于购买配置更高的Pro版，有超30%的增幅，标准版则表现一般。</p>
  <p>此前小米集团总裁卢伟冰接受界面新闻采访时表示，内部完全没有预料到小米17 Pro Max卖得这么好，发售当天晚上就在想产能要怎么提升了。</p>
  <p>值得注意的是，此次各家旗舰机型首销期间，其关注度同步以往也变得更多，当然也不乏质疑的声音。在小米17系列发售的第三天，天风国际分析师郭明錤日发文称，小米手机17系列因为开售不及预期下调订单的20%，若后续无更积极的价格策略或营销活动，17系列总出货量可能会低于15系列的约800万部。</p>
  <p>卢伟冰当日下午发文回应表示，“小米17系列有信心销量会比上代小米15系列更多。”</p>
  <p>另据界面新闻记者了解到，小米已经对小米17系上游订单做了调整，Pro max订单由原来的190万台备货增加至220万台，整体出货规模会维持在1000万台以上。</p>
  <h2><strong>标准版遇冷</strong></h2>
  <p>今年手机市场另一个值得关注的变化是，各家主打产品的标准版销量都不及预期。</p>
  <p>渠道人士殷宪永认为，此次各大国产手机的标准版普遍遇冷的很大原因是因为iPhone 17标准版更具性价比，对各家标准版都造成了影响。</p>
  <p>根据Counterpoint Research发布的《中国智能手机周销量追踪报告》，2025年第四季度开局强劲，苹果是此次销售的主要增长动力。“在上市的前两周，我们看到中国市场iPhone 17基础款的销量几乎是同期iPhone 16基础款的两倍。”Counterpoint分析师Mengmeng Zhang表示。</p>
  <p>今年，iPhone 17标准版售价保持5999元起（256GB存储），与前代iPhone 16（128GB）相比，存储容量翻倍但价格未调整，叠加国补后价格下探到5499元。</p>
  <p>另外，双十一期间，苹果的上一代产品iPhone 16系列降幅超过20%，256GB版本价格可能降至5000元以内，叠加平台券、国家补贴和以旧换新后，最高优惠可达2500元。</p>
  <p>iPhone 16 128GB版本降至4500元时，则直接侵入了国产厂商腹地。</p>
  <p>苹果的降价早在去年三季度已经显现出威力，导致国产厂商3000-5000元主力机型出货量环比下降7%，国产厂商一度被迫降价应对。</p>
  <p>上述手机厂商员工告诉界面新闻，“OPPO、vivo今年在制定操盘策略时沿用了往年的惯例，在Pro版本的定价更加激进，然后标准版跑长期，留出一部分利润来后续调价做准备。”</p>
  <p>据其透露，vivo X300和OPPO Find X9的标准版实际上是涨过价的。“中间一直在纠结，看到小米17系列标准版表现一般后就主动提了200元，算是保利润的考量。”</p>
  <p>近几年，包括小米、OPPO、vivo在内的多家厂商在旗舰产品定义上采用与苹果相似的直屏设计，尺寸接近iPhone，兼容AirDrop协议，适配苹果生态场景（如文件格式兼容、通话录音处理等）。</p>
  <p>这种策略成功吸引了一波愿意买单的客户，但副作用也开始显现。当苹果主动做出改变之后，其他手机厂商就会陷入一个非常被动的局面，哪个版本卖得好，完全取决于对手怎么做。</p>
  <p>今年标准版遇冷也暴露出厂家在完全对标苹果以后产生的问题，即丧失了更多产品的主动权。</p>
  <p>“从格局上讲，目前引领高端的厂商仍然是华为和苹果，在中国市场，他们的位置还是比较难以撼动。”刘艺璇表示。</p>
  <p>本文来自微信公众号<a href="https://www.jiemian.com/article/13577918.html" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，作者：李家琦，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3533020766739585</id>
            <title>抖音、快手重启社交，竟然是OpenAI给的压力太大</title>
            <link>https://www.36kr.com/p/3533020766739585</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3533020766739585</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 11:51:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>社交无疑是国内互联网江湖中，一个永远被追逐的概念。在消停了两年后，抖音和快手这两大短视频平台近期又一次尝试改写这个赛道的格局。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_aeb7133aec6a405d9bc9bd3980f7f3d8@000000_oswg20199oswg313oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>日前，抖音方面悄然升级App中的“日常”模块，新增了醒目的创作入口，支持用户发布图文或视频内容，可设置24小时、3天或7天的限时展示，并支持内容聚合浏览、多态点赞，以及浏览记录查看功能。同时抖音还引入提醒机制，好友发布新动态后头像周围将出现蓝、绿、紫等颜色的色环，用户在查看后色环则会自动消失。</p>
  <p>同时快手则重启了“说说”功能，并推出类似漂流瓶的匿名社交产品“小纸条”。不难发现，这一次抖音和快手试图在App里复刻腾讯的“微信朋友圈”以及“QQ空间”。那么问题就来了，这两大头部短视频平台为何会突然开启社交赛道的探索呢？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_06a1ed0270b04dfaac4c8d3a4ffffa57@000000_oswg36830oswg513oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>数年前以“同城号”为标志，抖音和快手以LBS为锚，引导本地用户在特定兴趣圈子中进行交流和交友，进而开始了他们在社交领域的尝试。特别是彼时正与腾讯交恶的字节跳动，除了“同城圈子”之外，在抖音中还陆续上线了“抖一抖”、“朋友Tab”、“抖音聊天”等不同方向的社交产品。</p>
  <p>当然，与过去二十年间试图挑战腾讯的前辈一样，抖音和快手在社交领域的数次尝试基本都是雷声大雨点小，并没有能够改变腾讯在国内社交市场一家独大的局面。既然如此，抖音和快手依然选择“屡战屡败、屡败屡战”的原因，自然也就并不简单了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_196cb33a16064c20b237d714bd5db832@000000_oswg40499oswg600oswg553_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>让抖音、快手近期几乎是同步重启社交领域探索的原因，其实并非是来自腾讯的压力，真正的导火索极有可能来自OpenAI的Sora2。就在国庆假期前，OpenAI不声不响地迭代了视频生成模型Sora2，在AI视频赛道投入了一颗深水炸弹。而同名App超越ChatGPT与Gemini的首发成绩，更是已经证明了Sora2的走红绝非偶然。</p>
  <p>“寒武纪大爆发”，则是一众海外AI领域从业者对于Sora2的一致评价。与只存在于PPT中的初代Sora相比，这一次的Sora2可谓是货真价值。由于Sora2的物理规律模拟精度显著优化，能够精准呈现出复杂动作与环境交互的真实感，同时还新增了音频生成能力，可自动匹配画面生成环境音、对话及背景音乐，从而实现音画同步的一体化创作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_5c28e832d5b64f828c7a02d08eba57af@000000_oswg20501oswg600oswg274_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在网友进行的“意大利面测试”中，奥特曼吃面条的咀嚼动作以及酱汁飞溅的细节，比两年前威尔·史密斯被嘲讽“像没牙老太太嚼空气”的鬼畜视频要逼真得多。不仅生成的视频摆脱了“AI味”，Sora2还拥有至多25秒长视频的叙事能力，就使得如今已有专业创作者通过其制作了包含完整故事线的AI短视频。</p>
  <p>当年OpenAI在仓促间公开Sora，是为了抢走谷歌Gemini的风头，而这一次OpenAI则是来真的。那么在OpenAI推出了一个“世界编辑器”后，怎么会导致大洋彼岸的抖音、快手应激呢？原因其实很简单，因为Sora2的强大让同名App颠覆了AIGC社交。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3e60f331b8f44837a23ce175f71c4551@000000_oswg34566oswg511oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，Sora App提供了两大核心功能，客串（Cameo）和二次创作（Remix）。通过世界模拟模型（world simulation models），Sora App的用户就能无缝客串任何经典场景，比如在古罗马斗兽场当角斗士、在战场上当将军。甚至用户在看到一个自己喜欢的视频时，还能直接点击Remix按钮，在其基础上进行二次创作，让Sora按照你的意思魔改相关视频。</p>
  <p>Cameo和Remix的加入让用户再一次有了亲身参与社交趋势的可能，这其实就是短视频平台最为恐惧的一点。事实上，抖音和快手上都有一个经典玩法花式模仿秀，即一个题材火了后，很快就能看到一众达人扎堆跟风。可同样都是跟风，专业达人精心制作的内容与素人的随手拍谁更容易被看见，答案不言自喻。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_f9f98b0605324ae98d430a5a82efbe98@000000_oswg38047oswg600oswg578_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>抖音、快手近年来最大的一个挑战，就是素人用户从参与者变为了旁观者，可恰好Sora2的出现就是为普通用户赋能，俨然有了七八年前全民拍视频的趋势。大家不妨试想一下，如果动动嘴就能让自己出现在各种大片中，这时候势必就会有迫切的动力将视频分享出去。</p>
  <p>尽管抖音有即梦、快手有可灵，但架不住做AI视频的厂商更多。Sora2的出现就代表着用户创作阵地的转移，这显然是头部短视频平台绝对不愿意看到的事情，毕竟当初短视频平台的崛起过程中，就吃到了图文创作者向视频迁移的红利。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_bed5cb92bd5f4f409eeb5a2d88039729@000000_oswg27509oswg600oswg282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>现在抖音和快手重启社交其实就是未雨绸缪，毕竟一旦在社交赛道占据一席之地，几乎就等于占据了不败之地。在公众号被短视频平台吸走了流量后，微信能依托社交流量再造一个自己的视频号，就已经说明了社交的魅力，只要人类还是社会动物，社交就永远能带来流量。</p>
  <p>抖音、快手如果现在不尝试做社交来巩固流量池，等到AI视频彻底成熟，恐怕就为时已晚了。</p>
  <p>【本文图片来自网络 】&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649898986&amp;idx=3&amp;sn=9bc3d8bf374da5e7ebb22ed295466d19&amp;chksm=869ea12c80f556379583d0110ff8276544d3a214e4304ea8ac927543feae16ff5545f8dfe932&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532949078645888</id>
            <title>库克：大中华区有望恢复增长 下一财季营收将创历史新高</title>
            <link>https://www.36kr.com/p/3532949078645888</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532949078645888</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 10:57:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>划重点：</strong></p>
  <ul>
   <li>截至2025年12月底的2026财年第一财季，苹果整体营收和iPhone营收均有望创出历史新高。</li>
   <li>大中华区营收同比下降4%，主要因iPhone供应限制；库克称市场活力足，门店客流量显著增长，预计2026财年第一财季恢复增长。</li>
   <li>库克称本季供应受限并非产能问题，而是对 iPhone 16 的产量预估低于实际需求；同时 iPhone 17 系列需求强劲，第四财季末留下了大量未交订单。</li>
   <li>人工智能为App Store带来机遇，已向开发者提供设备端模型，普及后开发者和苹果均有机会受益。</li>
   <li>苹果持续加大AI投入，Apple Intelligence引入实时翻译等功能；私人云计算用于Siri，已投产服务器工厂，预计资本支出增加。</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_2d77578a56c943b4a06ada31806e4015@46958_oswg129777oswg960oswg637_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当地时间10月30日，苹果发布了该公司2025财年第四财季及全年财报。财报显示，受iPhone 17系列手机需求强劲的推动，苹果当季营收与净利润双双超出华尔街预期。</p>
  <p>在截至2025年9月27日的第四财季，苹果净营收为1024.6亿美元，比去年同期的949.30亿美元增长8%；净利润为274.66亿美元，比去年同期的147.36亿美元增长86%；每股摊薄收益1.85美元，较去年同期的0.97美元增长91%。苹果财报同比大幅增长，主要受苹果被欧盟要求补缴102亿美元税款，导致当季净利润大幅下滑的影响。调整后EPS同比增长13%。</p>
  <p>财报发布后，苹果首席执行官蒂姆·库克（Tim Cook）和首席财务官凯文·帕雷克（Kevan Parekh）解读了苹果第四财季财报，并回答了分析师的提问。</p>
  <h2><strong>以下为库克对公司第四财季业务的点评</strong></h2>
  <p>2025财年，公司总营收达4160亿美元，创历史新高；新兴市场与发达市场双双创下历史营收峰值，iPhone也迎来历史最高营收；服务领域则在所有地理区域均实现历史新高。</p>
  <p>在我们追踪的绝大多数市场中，公司均实现营收增长，其中美国、加拿大、拉丁美洲、西欧、中东、日本、韩国、南亚等数十个市场，均创下同期营收新高。新兴市场方面，不仅第四财季营收刷新同期纪录，印度市场更创下历史最高营收。</p>
  <p>这些成果，既体现了客户对苹果产品与服务的高度认可，也彰显了我们对创新的坚定投入。我们对当前产品与服务的强劲表现倍感振奋，同时预计，截至2025年12月底的2026财年第一财季，将成为<strong>公司历史上营收最佳的季度，也将是iPhone营收最高的季度。</strong></p>
  <p>眼下，我们正携有史以来最强劲的产品阵容迈入假日销售季。在人工智能领域的投入持续加大的背景下，我们正将智能融入更多用户喜爱的产品与服务，让每一次体验更具个性化、更强大、更便捷。</p>
  <p>第四财季，iPhone营收达490亿美元，创下同期纪录，同比增长6%。<strong>尽管受强劲需求影响，部分iPhone 16与iPhone 17机型面临供应限制</strong>，但在我们追踪的绝大多数市场中，iPhone仍实现了增长。</p>
  <p><strong>Mac业务在第四财季同样表现强劲，营收达87亿美元，同比增长13%，这一成绩得益于MacBook Air的出色表现</strong>。</p>
  <p>iPad业务第四财季营收为70亿美元。今年9月，我们发布了iPadOS 26——这是近年来最受关注的软件更新之一；近期，我们又推出了性能卓越的M5 iPad Pro，为iPad用户带来更多惊喜，该机型的AI 性能实现了显著提升。</p>
  <p>可穿戴设备、家居与配件业务的第四财季营收达90亿美元。我们通过推出最新Apple Watch产品线，为用户开启了更多可能，也让这款全球最受欢迎的手表变得更加强大。</p>
  <p>与此同时，AirPods Pro 3也获得了用户的热烈好评。借助Apple Intelligence驱动的实时翻译功能，AirPods更为全球用户带来了全新且令人兴奋的体验。</p>
  <p>服务业务方面，第四财季营收达288亿美元，同比增长15%，创下历史纪录。无论是发达市场还是新兴市场，服务业务均实现两位数增长；广告、App Store、云服务、音乐、支付服务、视频等细分领域，也全部创下历史新高。</p>
  <p>在今年的艾美奖上，Apple TV表现亮眼，共斩获22项大奖。其中，《The Studio》以13项大奖领跑，成为艾美奖历史上获奖最多的喜剧系列；《离职》（Severance）则以8项大奖位居所有剧情片之首，为这部里程碑式剧集再添荣誉。</p>
  <p>截至目前，Apple TV制作的内容已累计获得超600项大奖与2800项提名，这离不开优质原创故事的支撑。我们很高兴看到观众发现《多数》（Pluribus）这类新作品，同时持续关注《慢马》（Slow Horses）、《早间新闻》（The Morning Show）等回归热门剧集。</p>
  <p>不久后，Apple TV将成为美国F1车迷的 “赛道日专属平台”，这得益于我们与一级方程式赛车（F1）达成的新合作。此外，年度大片《F1 电影》（F1 The Movie）也将于12月12日登陆Apple TV。</p>
  <p>第四财季，我们还迎来了Apple News上线十周年。作为资讯平台，Apple News为用户提供全球头条新闻访问权限，将数百种出版物呈现在用户指尖。</p>
  <p>零售业务方面，我们正携有史以来最强劲的产品阵容，迎接一年中最繁忙的销售旺季。过去几个月，我们不仅在印度、阿联酋等新兴市场开设了新门店，也在美国、中国等市场拓展了零售网络。</p>
  <p>上个月，我还前往东京，出席了苹果银座店的重装开业仪式——现场人群的热情令人难忘。苹果银座店是我们在美国以外开设的首家门店，此次重返并迎接顾客走进这个全新的美丽空间，对我们而言意义非凡。</p>
  <p>我们持续投资于创新与用户体验，这些投入将塑造我们的未来。例如，我们在美国承诺未来四年投资6000亿美元，重点聚焦先进制造、芯片工程、人工智能等创新领域与战略方向。</p>
  <p>这些承诺建立在我们对美国长期投资的基础之上，目前已支持全美50个州的45万多个就业岗位，以及数千家供应商。以休斯顿为例，我们在当地新建的先进AI服务器工厂已正式投产，近期刚完成首批产品交付；我们正引领构建覆盖全美、端到端的芯片供应链。</p>
  <p>我们正携有史以来最强劲的产品阵容迈入假日销售季，对于未来，我充满期待。</p>
  <h2><strong>以下是答分析师问内容摘要</strong></h2>
  <p><strong>摩根士丹利分析师埃里克·伍德林（Eric Woodring）：</strong>你们认为iPhone 17目前取得成功的主要原因是什么？你认为这是由于老化存量用户进入换机周期，还是本周期中某些特定功能或特性比以往更具吸引力，从而更符合消费者需求？</p>
  <p><strong>库克：</strong>我认为这完全归功于产品本身。我们的产品阵容一如既往地强劲。iPhone 17 Pro是我们迄今推出过的最具专业性的手机，其性能令人叹服，设计也极为出色。iPhone Air手感纤薄轻盈，仿佛随时会飞起。而iPhone 17则提供了极高的性价比，将以往仅限于Pro系列的某些特性引入了消费级产品线。总而言之，这是史上最强大的iPhone阵容，并在全球范围内引起了广泛共鸣。</p>
  <p><strong>摩根士丹利分析师埃里克·伍德林：</strong>能否谈谈在当前阶段管理组件成本通胀的策略？显然，本财季你们同时大幅提升了设备中的内存容量，而内存价格正面临显著通胀压力。那么，你是如何应对本周期这一挑战的？</p>
  <p><strong>帕雷克：</strong>我们拥有一支世界一流的采购团队，他们持续探索成本优化机会。目前在大宗商品领域，我想指出，在内存和存储价格方面，我们观察到轻微的顺风效应，并未出现任何显著问题。</p>
  <p>从毛利率表现来看，我们处于有利位置，本季度毛利率达到47.2%，高于指导范围的上限。我们对下季度的指导范围为47%至48%。因此，我认为我们的成本管理成效显著。在本周期伊始，我们刚刚推出了一系列新产品。这些新产品相对于其前代产品具有略高的成本结构，但团队在随时间推移降低这些成本方面表现出色，我们对材料成本节省的整体表现感到满意。</p>
  <p>梅利厄斯<strong>研究所（Melius Research）分析师本·赖茨斯（Ben Reitzes）：</strong>蒂姆，能否谈谈iPhone在中国的表现，特别是其在12月季度的趋势将如何发展？你是否已扭转局面？你对这一轨迹的预期如何？</p>
  <p><strong>库克：</strong>我刚刚从中国返回美国。中国市场充满活力，门店客流量同比显著增长。iPhone 17系列在那里的反响非常热烈。我们确信，2026财年第一财季（截至2025年12月底）将实现增长恢复，这主要基于iPhone在那里的受欢迎程度。因此，对于目前在那里的早期进展，我感到非常满意。</p>
  <p><strong>美林研究分析师本·赖茨斯：</strong>关于服务业务，其中是否包含任何税款支付，或者与你的某合作伙伴的反垄断裁决解决是否发挥了推动作用，如果有的话，其影响程度如何；抑或这完全是有机增长的优异表现，伴随你提到的诸多因素？</p>
  <p><strong>帕雷克：</strong>第四财季强劲表现并未涉及任何现金相关影响，我想强调的是，这一表现完全由有机因素驱动。我再次重申，本季度服务业务营收创下288亿美元的历史纪录，全年营收突破1000亿美元，以14%的同比增长创下最佳年度表现。这完全是有机增长。我们观察到大多数类别实现了连续加速增长，并创下多项历史营收纪录。但完全没有异常情况，几乎全部为有机增长。</p>
  <p><strong>高盛分析师迈克尔·吴（Michael Ng）：</strong>服务业务营收增长是诸多类别中增长最快的，并且是过去两年中最快的。能否进一步剖析加速的驱动因素。是否有与新iPhone发布相关的交叉销售？是否仅仅是活跃用户基础的增长？苹果一直在推动Apple One和AppleCare One的捆绑销售，能够就此详细说明？</p>
  <p><strong>帕雷克：</strong>我们认为，并非单一因素推动了这一更高表现。你说得对，其增速确实高于过去几个季度。我们的服务组合极为广泛，涵盖多种业务，每种业务均具有不同的增长特征和业绩模式。因此，这些在任何一个季度都可能有所差异。我们的优势再次体现为广泛分布，跨越类别和地理区域，因此我不会将超预期表现归因于任何特定因素。我们对这一结果感到非常满意。</p>
  <p><strong>Evercore分析师阿米特·达里亚纳尼（Amit Daryanani）：</strong>中国市场在第四财季表现较为低迷。能否谈谈导致这一疲软的原因？你认为这更多是一种观望现象，例如iPhone Air直到几周前才上市？是什么导致第四财季的疲软，以及2026财年第一财季更好预期的来源是否仅限于iPhone Air的推出，还是有其他因素？</p>
  <p><strong>库克：</strong>大中华区营收在第四财季同比下降4%。这主要由iPhone驱动，若查看iPhone数据，大部分同比变化源于我前面提到的供应限制。因此，基本上是供应限制导致了这一业绩。我们对当前情况感到非常兴奋，包括客流量同比显著上升以及iPhone 17系列的反响。我们预计本财季将恢复增长。</p>
  <p><strong>美国银行（Bank of America）分析师瓦姆西·莫汉（Wamsi Mohan）：</strong>关于你提到的本财季供应受限评论，鉴于iPhone需求强劲。你是否预计，根据对需求与供应的可见性，到第一财季将不再受限？抑或你仍预计在退出第一财季时可能存在限制？另外，是否有办法量化若无限制，本季度营收本可达到多少？</p>
  <p><strong>库克：</strong>是的，若考察供应限制，目前我们对几款iPhone 17型号仍受限。我们不预测供应与需求何时平衡。我们显然正全力实现这一目标，因为我们希望将尽可能多的产品交付给客户，但今天我不会进行预测。</p>
  <p><strong>摩根大通分析师萨米克·查特吉（Samik Chatterjee）：</strong>蒂姆，你谈及在中国观察到的强劲势头，这也是你对第一财季信心的驱动力。你对该地区智能手机补贴在这一势头中的作用有何看法？你如何评估目前有多少比例的消费者可能在使用这些补贴？能否提供更多见解？</p>
  <p><strong>库克：</strong>补贴发挥了积极作用。补贴涉及多个类别，从个人电脑到平板电脑，再到智能手表与智能手机。它们仅适用于某些价格范围，因此存在最高价格上限，我们的部分产品售价高于该上限，从而不符合补贴条件。但它确实产生了有利影响，而且至少从我们的视角来看，显然正在推动部分消费需求。</p>
  <p><strong>摩根大通分析师萨米克·查特吉：</strong>关于第一财季运营支出的增加，其增幅相当显著。你能否进一步剖析这一数字，具体包括哪些部分？此外，运营支出同比增长似乎超过营收增长。那么，这是未来应预期的趋势吗，即短期内你们可能需投入更多资金？</p>
  <p><strong>帕雷克：</strong>正如我们一贯概述并在上次电话会议中重申，我们正在加大对AI的投资。我们也持续投资于产品路线图。运营支出的主要增长由研发驱动。虽然我们继续以审慎且纪律严明的态度管理公司，但我们也在为长期目标管理业务，并对眼前所有机会充满期待。</p>
  <p>至于运营支出与营收增长的比较，虽然运营支出增速快于营收，但我们已观察到毛利率扩张，因此综合来看，这使我们能够实现健康的运营杠杆，且过去几年营业收入增长总体上领先于营收增长。</p>
  <p>道明考恩<strong>（TD Cowen）分析师克里希·桑卡尔（Krish Sankar）：</strong>我的第一个问题是关于iPhone的限制。是否有办法量化由于这些限制而错失的业务规模？以及来自两个不同地区的iPhone制造是否是造成限制的原因？</p>
  <p><strong>库克：</strong>需要明确的是，限制本身与制造产能无关。是我们对iPhone 16的制造数量预估略低于实际需求。因此，我们本可售出更多。我们未公开估计其程度。然后，对于iPhone 17系列，需求极为强劲，因此我们在第四财季结束时积累了大量积压订单。</p>
  <p><strong>道富银行分析师克里希·桑卡尔：</strong>鉴于聊天机器人与AI注入网页服务的普及，你认为这是否会改变移动应用生态系统中的消费者行为？或者你是否观察到任何此类迹象？这会对App Store产生任何影响吗？</p>
  <p><strong>库克：</strong>我认为人工智能为应用商店App Store带来了机遇。我们已向开发者提供我们的设备端模型，并观察到开发者开始采用它们。因此，我认为随着其普及，开发者和苹果均有机会受益，例如通过向应用添加功能等。</p>
  <p><strong>富国银行分析师亚伦·雷克（Aaron Raker）：</strong>当我们看到你反复强调iPhone 17需求强劲时，我好奇iPhone 17类别中Pro与Pro Max版本之间的组合，与以往周期相比是否有任何可辨别变化？</p>
  <p><strong>库克：</strong>坦白说，现在判断组合尚为时过早。出于竞争考虑，我们不喜欢公开披露这一点。但我们目前尚未知晓组合将如何，因为我们在高端与入门级均存在限制，因此我们将观察随着更多供应到来会发生什么。</p>
  <p><strong>富国银行分析师亚伦・雷克：</strong>能否提供关于苹果私人云计算（Private Cloud Compute, PCC）构建的最新见解，以及我们应如何看待其未来发展？</p>
  <p><strong>库克：</strong>苹果目前已将PCC应用于Siri的多项查询处理，且正持续推进其建设。用于支撑 Apple Intelligence 的服务器工厂已于几周前在休斯顿启动生产，后续将逐步爬坡产能以服务数据中心需求。</p>
  <p>帕雷克：2025年已规划相关资本支出，用于第一方数据中心的PCC环境建设，这将体现在本年度部分资本支出中。</p>
  <p><strong>花旗银行分析师阿蒂夫・马利克：</strong>消费者对iPhone Air的接受度是否能为可折叠手机市场提供参考？二者外形因素是否存在本质差异？</p>
  <p><strong>库克：</strong>二者难以相互替代。我们不便透露具体型号需求，但iPhone市场接受度良好，这也是我们预计本季度实现两位数百分比增长的原因。</p>
  <p><strong>花旗银行分析师阿蒂夫・马利克：</strong>个性化Siri预计明年推出，苹果是否会延续“自研基础模型+合作+并购” 的三管齐下策略？是否有侧重？</p>
  <p><strong>库克：</strong>我们正内部开发Apple基础模型（Apple Foundation Models），已部署于设备端及PCC中，且多个模型处于开发阶段。同时，我们持续关注并购机会，若能推进战略路线图，将积极开展。</p>
  <p><strong>Arete Research分析师理查德・克拉默：</strong>苹果常被视为新技术“快速跟进者”，当前AI 功能是否已成为消费者购买iPhone的实质性因素？创纪录销量是否更多源于iOS用户留存？</p>
  <p><strong>库克：</strong>影响消费者购买决策的因素众多，iPhone 17周期尚早，我们尚未开展深入调研，需时间形成结论。但Apple Intelligence已成为影响因素之一，我们坚信其未来会成为更关键的考量点。</p>
  <p>Arete Research分析师理查德・克拉默：在行业大幅增加AI资本支出、产能稀缺的背景下，苹果是否会调整“自有+第三方数据中心” 的混合模式？M5芯片在Apple芯片体系中作用如何？</p>
  <p><strong>帕雷克：</strong>我们预计AI相关资本支出将增加，例如2025年已规划投资用于PCC环境建设。混合模式兼具优势，我们将持续沿用，不会因行业趋势改变。随着PCC使用量增长，我们会逐步扩充其规模，但混合模式将保持不变。</p>
  <p>本文来自<a href="https://news.qq.com/rain/a/20251031A02N4B00" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，编译：无忌<strong>，</strong>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532949078842243</id>
            <title>AI研究员田渊栋：“AI顿悟”的真相、大模型如何学会压缩世界</title>
            <link>https://www.36kr.com/p/3532949078842243</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532949078842243</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 10:38:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta首席执行官马克·扎克伯格近日批准了一项涉及约600名员工的AI部门裁员计划，这是Meta今年在人工智能领域规模最大的一次调整，主要波及公司核心研发机构。</p>
  <p>时任Meta FAIR团队负责人的田渊栋在社交媒体X上证实：“我和我的部分团队成员也受到此次裁员影响”。Meta FAIR作为“超智能实验室”（MSL）科研体系中的核心支柱之一。田渊栋的离开也引发业界的广泛关注。</p>
  <p><strong>在此消息公布后，田渊栋首次公开露面，接受了腾讯科技特约作者「课代表立正」的独家深度访谈。</strong></p>
  <p>面对行业中的质疑，田渊栋在此做出澄清和“正名” ：他的团队在Meta大模型开发中也做出了大量贡献和重要工作。然而，他们面临的最大的挑战并非技术本身，而是如何说服产品团队。&nbsp;</p>
  <p>随后，访谈重心转向了田渊栋的近期研究成果，着重探讨了有关AI大模型的“顿悟（Grokking）”。&nbsp;</p>
  <p>“Grokking”，这个词源自科幻作家罗伯特·海因莱因，意指对事物本质的深刻理解。大语言模型的高分不意味着智慧。真正的临界点，是它第一次学会“思考”的那一刻。</p>
  <p>今年9月，田渊栋发表了一篇独立论文指出，Grokking不是神秘涌现，而是可计算的能量景观动力学（Energy Landscape）。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_94d240edde2d4832ba4dbd6fc8be44ff@46958_oswg22615oswg960oswg222_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <ul>
   <li>论文标题：Provable Scaling Laws of Feature Emergence from Learning Dynamics of Grokking</li>
   <li>论文链接：arxiv.org/abs/2509.21519</li>
  </ul>
  <p>田渊栋的研究揭示了AI学习的核心突破：在群运算任务中，任务复杂度为M（如词汇量或概念数），传统认为模型需穷举M²种组合才能学会规律，数据需求随M平方增长。而他以严格数学证明，模型仅需O(M log M)个样本即可实现泛化——近乎线性增长。以M=1000为例，以往需百万级样本，而新理论仅约7000个。</p>
  <p><strong>这意味着，AI无需“看遍世界”式的暴力学习，也能像人类一样，从极少样本中顿悟深层结构，为数据受限时代的高效训练提供了理论依据。</strong></p>
  <p><strong>在这场访谈中，田渊栋解读Grokking的研究，揭示了其中AI学习的关键：大模型如何从“记忆式拟合”跃迁到“结构化泛化”的内在机制。</strong></p>
  <p>此外，田渊栋在访谈中透露，AI对这篇论文的贡献也很大，其中的一些思考是他和GPT-5进行对话后产生的。田渊栋调侃道：“这听起来有点像self-play（自娱自乐）。不过在对话的过程中，需要给它一些insight（洞察）和思考，它才会有不一样的输出”。</p>
  <h2><strong>本次访谈的核心观点如下：</strong></h2>
  <ul>
   <li>Grokking揭示了从记忆到泛化的数学机制，从记忆到泛化不是神秘涌现，而是优化动力学：数据不足时“记忆峰”占优，数据增多时“泛化峰”升高，一旦泛化峰略高，参数集体翻越，产生顿悟现象。</li>
   <li>表征学习是所有智能能力的基础。无论是思维链推理，还是直觉判断，其根本都取决于模型如何“表示”与“理解”世界。正如数学归纳法取代穷举那样，真正的飞跃源于表征方式的改变。</li>
   <li>Loss Function（损失函数）只是优化的代理信号，其作用是生成合适的梯度流，引导表征朝正确方向更新。不同损失函数若诱导出相似的梯度结构，就能学到近似的表征。目标函数本身并非目的，而是优化的“可计算代理”。</li>
   <li>黑盒 Scaling 强调堆参数、调配置，短期高效；机制理解则追求解释与结构，长期天花板更高。当数据触顶、样本稀缺时，Scaling Law 失效，唯有机理导向的改进才能突破局限。</li>
   <li>泛化的本质是让模型学会“压缩”世界：从冗余的记忆中提炼出可重复使用的结构。真正的理解有两个标准：一是能在新情形下给出正确答案；二是能将复杂问题还原为简洁、通用的逻辑。当证据与归纳偏置（Inductive Bias）相互强化到临界点时，模型就会“跨峰”，进入泛化状态。</li>
  </ul>
  <p><strong>以下为完整版访谈内容，腾讯科技在不改变原意的情况下进行了精编整理：</strong></p>
  <h2><strong>01、Meta裁员事件后的澄清：为团队正名</strong></h2>
  <p><strong>课代表立正：</strong>最近看到了一些关于你（离开 Meta） 的消息。</p>
  <p><strong>田渊栋：</strong>是的，现在算是比较“自由”吧，可以做任何想做的事情了。</p>
  <p><strong>课代表立正：</strong>恭喜！我是在准备这次访谈的时候才注意到，你已经在 Meta 工作了整整十年<strong>。</strong>当初你加入 Meta 的时候，大概有多少人？</p>
  <p><strong>田渊栋：</strong>我加入的时候大概有一万多人。</p>
  <p><strong>课代表立正：</strong>其实那个时候 Meta 也不算是小公司了。我记得它是2012年上市的？</p>
  <p><strong>田渊栋：</strong>对，现在应该大约近8万人左右。</p>
  <p><strong>课代表立正：</strong>我们今天的访谈可以从你的论文聊起，也可以顺便聊聊最近的一些动向。</p>
  <p><strong>田渊栋：</strong>都可以，我更愿意聊论文。我之所以近期会在 X平台（原Twitter）上发声，是因为看到有人站出来猜测和质疑，是否是因为没有做出公司预期的成果。<strong>对此我必须要为我的团队澄清一下：我们团队做了很多非常重要的工作，不能把责任推到我们身上。这一点必须说清楚。</strong></p>
  <p><strong>课代表立正：</strong>那么，团队在大模型训练的过程中具体发挥了哪些关键作用？</p>
  <p><strong>田渊栋：</strong>我们团队率先发现了预训练模型设计中存在的chunk attention等关键问题，并推动了解决方案的落地，有效提升了long-context RL的稳定性。另外贡献还包括数据集生成和评测，RL基础设施的构建和优化，等等。&nbsp;</p>
  <p>此外，<strong>对于大模型架构中存在的一些设计问题，我们也和公司侧的多个团队进行了深入沟通。一开始沟通很困难，因为他们认为这些问题不严重，甚至觉得根本不是问题。</strong></p>
  <p>虽然我当时是作为研究团队加入 Meta 的，而负责大模型具体开发的团队，自然更相信他们自己的判断。所以我们只能通过大量的实验去验证，用数据和结果来证明我们的判断和洞察是正确的。最终，事实也确实证明这些问题是存在的，他们才真正接受我们的结论。这整个过程，其实就体现了我们团队的重要价值。</p>
  <p>此外，我们也攻克了不少在大模型训练中的不少难题。比如：如何让上下文长度训练 （long context length training） 更加稳定。这个过程解决了训练中常见的 blow up（训练崩溃） 问题。虽然这些技术成果最终没有直接体现在官方版本（official release）中，但它们确实为后续的模型研发打下了坚实的基础。</p>
  <p>可以说，我们团队更像是“幕后英雄”，没有站在聚光灯下，但在关键环节起到了承上启下、夯实底层的作用。</p>
  <h2><strong>02、研究员的核心价值是洞察力，但真正的难点是说服别人</strong></h2>
  <p><strong>课代表立正：</strong>您刚才提到的问题中，我有两方面想进一步了解：</p>
  <p>第一，作为研究团队，你们并没有被完全信任，是因为缺乏训练大模型的直接经验，还是有其他方面的原因？沟通时接触的大模型团队是怎样的？他们自身是否有丰富的大模型训练经历？</p>
  <p>第二，你们在接触到大模型的产品能力后，为什么能迅速发现问题？</p>
  <p><strong>田渊栋：</strong>他们的整体经验确实非常丰富。但在某些实验中出现了程序错误（bug），由此做出了错误判断。我们这边虽然没有直接参与超大模型的训练，但一直在做大模型相关的研究，也发表过不少论文。</p>
  <p>我本人曾做过 Sparse Attention（稀疏注意力）相关的研究，对注意力结构的机制与意义相对熟悉，因此，一看到一些设计细节，就立刻判断出其中的问题。</p>
  <p>当然，这种判断并不是我独有，很多研究者都能察觉问题。<strong>但真正的难点在于如何说服别人。我们需要花很多时间和精力去解释、论证这些问题的存在，通常要等到对方团队在内部自查时也意识到问题的严重性，态度才会开始转变。</strong></p>
  <p><strong>课代表立正：</strong>换句话说，尽管没有直接训练超大模型，但研究过程中的直觉与经验依然能帮助你们快速定位问题、判断偏差并提出修正方向。</p>
  <p><strong>田渊栋</strong>：是的。这就是研究员的核心价值所在：<strong>即便在“数据点稀疏”的情况下，也能推断出关键结论，并将其迁移应用到更复杂的问题上</strong>。相反，如果一个人没有 insight（洞察），只会不断地跑实验、调参数，那这样的工作是非常容易被替代的。研究员的优势在于：在有限信号下识别结构性问题，从而避免大量无效计算与资源浪费。</p>
  <p><strong>课代表立正：</strong>你刚才提到“稀疏的数据点”。这里具体是指什么？是来自不同论文或实验的零散结果吗？</p>
  <p><strong>田渊栋：</strong>可以这么理解。比如说一位新手可能需要跑一万组实验，得到一万个数值，但这些数据是“死”的——缺乏结构性分析与总结。</p>
  <p>而一个有经验的人，看到二十个甚至十个点，甚至只是观察到一部分 training curve（训练曲线），就能判断这个路线是否行得通，从而及时止损并调整方向。</p>
  <p>这也是为什么 AI 研究员通常薪资较高：一个真正高质量的“洞察（insight）”，可能就能节省上百、上千甚至上万张 GPU 卡的试错成本。GPU 当然重要，它能支撑更大规模的实验、带来更多观察机会；但 insight 和算力是互补的。&nbsp;</p>
  <p><strong>课代表立正：</strong>你刚才用了两个词，一个是经验（experience），一个是洞察（insight）。我想深入探讨一下这个问题：你认为到底什么是洞察能力（insight）？有些人认为这是品味（taste），有些人说是直觉（intuition），你怎么看？&nbsp;</p>
  <p><strong>田渊栋：</strong>我们需要通过对话与追问，去观察一个人是如何思考问题的。我举一个例子：在 PhD qualifier（博士资格考试）中，老师们会围绕某个主题（例如偏微分方程）不断追问，直到考生能清晰地解释关键概念之间的联系，并用最简洁的语言表述“两个最核心要素的关系”。</p>
  <p>如果一个人只能背出定义、却说不清其中的原理，比如什么时候 A→B、什么时候 A→C，那说明他还没有形成真正可迁移的 mental model（心理模型）。做研究最忌讳的就是“概念套概念”，而没有掌握它们之间的关系与使用条件。</p>
  <p><strong>当前的大语言模型也普遍缺乏这种能力——在“极少数据”的条件下进行稳健外推。这恰恰是人类仍然在某些认知任务中占据优势的地方。&nbsp;</strong></p>
  <h2><strong>03、“顿悟”如何发生</strong></h2>
  <p><strong>课代表立正：</strong>这也呼应了我想和你对话的初衷——你的研究重点之一正是 Grokking：解释模型如何从“记忆式拟合”跃迁到“结构化泛化”。你的论文就是围绕这一机制展开的。&nbsp;</p>
  <p><strong>田渊栋：</strong>对。Grokking 提供了一条观察“从不可压缩到可压缩表示”的动力学路径（dynamics）。理解这条路径，有助于我们在数据与算力受限的环境中，用更少的样本与更可靠的训练信号，获得可泛化的表示与更强的模型。</p>
  <p><strong>课代表立正：</strong>你刚才提到的“顿悟”并非只是某个具体任务层面的能力，而是更底层的机制：在某个时间点，模型完成了一次表示的重组，就像“学会了”某件事。</p>
  <p>我有关注到你此前的专访，以及我与Denny Zhou在 X平台上关于 chain-of-thought（思维链）的讨论中，也探讨过类似的现象。从理论上讲，如果逻辑链条能够被完整表达，那么 chain-of-thought 应该是可以求解的；</p>
  <p>但现实中，模型往往需要大量数据去逼近解，而人类却能在瞬间抓住要点。这种差异似乎与刚才所说的那种底层机制相关。如果要给这种能力下定义，你会倾向称之为 reasoning（推理能力），还是另有所指？</p>
  <p><strong>田渊栋：</strong>更准确地说，它发生在 reasoning 或其他任务之下的“共同底层”机制，那就是 representation learning（表征学习）。</p>
  <p>随着训练推进，模型的表征会不断演化。一开始更像是死记硬背；但随着足够的积累和联结，结构会突然“贯通”，从而出现类似“读书百遍，其义自见”的转折点。比如说在小学生的教育中，老师可能会先要求他们背诵一些知识，过段时间通过新的知识联结，原本模糊的含义逐渐显现，这就是顿悟的一部分。&nbsp;</p>
  <p><strong>课代表立正：</strong>也就是说，无论是 chain-of-thought 还是直觉判断，其实最终都依赖于“我如何表示、如何理解这个世界”这一底层机制？&nbsp;</p>
  <p><strong>田渊栋：</strong>对。比如，小学生可能解题靠穷举；而进入初高中后，引入了数学归纳法，仅靠简洁的证明就能覆盖无限情形，这种方法背后的“表示”就发生了根本性变化。神经网络的学习关键差异，也正体现在表征方式上。</p>
  <h2><strong>04、两种研究路径：Scaling Law与机制理解，选择更困难的后者</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_e53aced286884c18b9679d4f031f6e71@46958_oswg264442oswg1000oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>指神经网络通过寻找能拟合训练数据的“最短程序”（最简洁的模型），从而实现最好的泛化能力 图片来源：课代表立正&nbsp;</p>
  <p><strong>课代表立正：</strong>&nbsp;Ilya Sutskever在 2016 年 MIT 的演讲里提过两个问题：为什么反向传播能起作用？以及理论上最优的假设空间是否等价于简洁程序（short programs）。那你的意思是不是说——模型原本要走许多路径，但突然找到了更高效的联系，实现了压缩，从而获得更强的泛化能力？&nbsp;</p>
  <p><strong>田渊栋：</strong>&nbsp;对，“压缩”是一个通俗但恰当的说法。不过，目前我们仍不清楚——什么时候可以压缩，什么时候不行。</p>
  <p><strong>这正是研究 Grokking 的意义所在：它提供了一条动力学路径，展示系统如何从“不可压缩”状态过渡到“可压缩”状态。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_eaa5d85d963044df809a31fc94df1ca6@46958_oswg200239oswg960oswg453_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>指AI通过模式匹配（连线）将散乱的信息转化为结构化的知识，从而能够应用已知规律解决未知问题。图片来源：课代表立正</p>
  <p><strong>课代表立正：</strong>&nbsp;这听起来和人类的知识学习非常相似。我们也是通过“信息的连接”形成知识。</p>
  <p>教育心理学认为最重要的是先验知识（prior knowledge）——新的信息只有与旧的经验建立联系，才能形成理解。 但无论在人脑还是大模型中，我们都不清楚这些“连接”究竟是如何形成的。也许理解这一过程，就能抓住下一代模型的关键契机？</p>
  <p><strong>田渊栋：&nbsp;</strong>完全正确。&nbsp;<strong>现在主要有两种研究路径：一种是把系统当成黑盒，用“scaling law（规模定律）”去堆参数、试配置；另一种是“打开机器”，理解其内部机制，然后带着直觉去调参数。</strong></p>
  <p>目前黑盒方法更主流，见效快、成本低；<strong>但要真正理解模型的工作原理，就必须走后一条更艰难的路。</strong></p>
  <p><strong>课代表立正：</strong>&nbsp;为什么黑盒方法更占上风？是不是因为即使我们“打开”了，人类也依然难以判断里面到底发生了什么？</p>
  <p><strong>田渊栋：</strong>&nbsp;是的。这就是为什么要建立一个更高层次的整体理解框架——去统摄不同学习范式的共性。我做 Grokking 这篇论文的目的，正是尝试构建这样的框架。&nbsp;</p>
  <p>短期来看，黑盒路线依然高效；但从长期来看，理解机制的那条路天花板更高。</p>
  <h2><strong>05、Grokking：从记忆跃迁到泛化的数学机制</strong></h2>
  <p><strong>课代表立正：</strong>黑盒路径之所以占主流，也因为即使“打开”模型，人类也很难判断其内部到底发生了什么。因此，能否建立一个足以统摄多种学习范式的“大框架”变得很关键——这也是你们把 Grokking 作为正式论文（paper）发布的原因？</p>
  <p><strong>田渊栋</strong>：对。我们希望通过系统性研究，建立起更大的理解框架，从而为未来的改进指明方向。&nbsp;</p>
  <p><strong>课代表立正：</strong>我再引入一个相关讨论。我们常常从人类学习中汲取灵感。&nbsp;</p>
  <p>现在有两个派系，Rich Sutton 强调，强化学习（Reinforcement Learning, RL）才是更贴近人类的学习方式，因为它拥有明确的目标函数（objective）；而另一派代表（如 Hinton）认为，经验不仅来自物理互动，语言也能有效传递经验。</p>
  <p>这场争论的核心是：人类如何学习？什么是学习？人类是如何生成新知识并 connect the dots 的？你个人更倾向哪种猜想？&nbsp;</p>
  <p><strong>田渊栋：我赞同“通过经验学习”的观点，</strong>但更重要的问题是：“哪种经验更有价值？”有一种观点强调，必须有 embodiment（身体化经验），也就是“行万里路”“亲身体验”“感受情绪”等，才能形成真正深刻的表示；另一种观点则认为抽象概念也可以通过语言传递被学习。<strong>其实这两者并不冲突。我们追求的是高质量的 representation（表征）——这种表征能够支撑预测、支持泛化。</strong></p>
  <p>表征是如何形成的，关键在于输入的丰富性及其结构。直观经验和抽象概念可以混合输入，只要最终能产出高质量、可泛化的表征即可。这个比例不一定非黑即白，可以是一半一半，也可以是三分之一对三分之二，关键在于能否形成有用的认知结构。</p>
  <h2><strong>06、从黑盒试验到机制理解，打开系统才能抬高模型上限</strong></h2>
  <p><strong>课代表立正：</strong>回到“打开模型”这条路，它的现实意义是什么？是更高效率的学习，还是在同样的知识里学到“新的东西”？当数据见顶时，效率的边际价值似乎有限。</p>
  <p><strong>田渊栋：</strong>恰恰相反，数据见顶时更需要对机器的理解。如果训练 token 总量对于大众领域已足够，但对于小众领域样本稀缺，且训练算法“费数据”，模型就容易停留在记忆（memorization）而非泛化（generalization）层面。&nbsp;</p>
  <p>此时仅靠 scaling law（扩展法则）可能就会失效。你可以做 data augmentation（数据增强），但如果你对模型的机理有更深入的理解，或许可以通过改进训练算法或架构本身，在少样本的情况下学到更合适的表示。</p>
  <p><strong>课代表立正：</strong>从大模型的生成过程来看，inference（推理）期间产生的新 token 更像是记忆还是泛化？</p>
  <p><strong>田渊栋：</strong>这要视情境而定，通常是两者的混合。任务种类丰富且覆盖多样组合时，更可能学到稳健的表示并实现泛化。材料越多，见到的组合越广，就越有可能形成对未见组合也有效的表征。<strong>所谓“真正理解”，一方面体现在能对新情形给出正确答案；另一方面则体现在能够将问题还原为更简单、可广泛适用的逻辑。</strong></p>
  <p>这两点加在一起，就构成了我们对“泛化”的一种可操作性定义。相反，若某一领域数据稀缺、结构难以捕捉，模型往往只能“死记硬背”，在训练集上的错误率尚可，但难以推广至新的样本。</p>
  <p><strong>课代表立正：</strong>当 scaling law 在数据受限的情况下边际效益递减，而机理导向的范式能在样本稀缺处提升“可压缩的表示”，是否意味着后者将在“高难度、小样本、结构强”的场景中显示出决定性优势？</p>
  <p><strong>田渊栋：</strong>这是我的判断。<strong>短期来看，黑盒方法扩大规模依旧高效；但从长期来看，打开系统并理解表示形成与迁移的动力学，才有可能真正抬高模型的能力上限。</strong></p>
  <h2><strong>07、从压缩性走向解释力：泛化的终极价值</strong></h2>
  <p><strong>课代表立正：</strong>如何更形式化地解释“从记忆到泛化”的跃迁？很多人将其视为神秘的“emergence”（涌现）。&nbsp;</p>
  <p><strong>田渊栋：</strong>我们可以通过“多峰非凸优化”（multi-modal non-convex optimization）的图景来理解。不同的表征对应着不同的“山峰”（局部最优解）。数据分布决定山峰的高低：当数据不足时，“记忆峰”更高；当数据增多且结构更清晰时，“泛化峰”会升高，“记忆峰”则下降。&nbsp;</p>
  <p>优化过程会趋向更高的山峰；一旦“泛化峰”略高，参数便会集体“翻越”，呈现出“顿悟（grokking）”现象。这是一条清晰的数学路径，并非神秘跳变。</p>
  <p><strong>课代表立正：</strong>是否可以理解为：泛化的正确表征一直潜伏在数据中，只是我们以前未曾发现或未予重视？随着数据点的增多，其价值被凸显，我们才开始重视？</p>
  <p><strong>田渊栋：</strong>可以这样理解，但前提是该结构确实存在，并且数据量足以让它的优势显著到可以“打败”记忆式的解。在证据不足时，“记下来”更划算；而证据充足时，泛化结构因更简洁、更稳健而自然占优。&nbsp;</p>
  <p><strong>课代表立正：</strong>这引出了评价与奖励的问题。预训练阶段主要使用 next-token prediction（下一词预测）；那么在后训练阶段，如何促成更强的泛化？又该如何避免 reward hacking（奖励机制被规避）？&nbsp;</p>
  <p><strong>田渊栋：</strong>预训练的损失函数相对稳定，比如预测下一个词等。而后训练阶段的“玩法”则丰富得多：可以在强化学习（Reinforcement Learning）的训练中设定不同的value/reward（价值/奖励）或 rubric（评分标准）；也可以引入 chain-of-thought（思维链），让中间步骤经得起检验，以此抑制“走捷径”的现象（比如选择题盲猜）。不同方向的优化会分别强化模型的不同能力维度。</p>
  <p><strong>课代表立正：</strong>你提到“优雅（elegance）/压缩”的倾向。这种倾向存在于 reward function（奖励函数）中吗？</p>
  <p><strong>田渊栋：</strong>它更像是训练过程中的隐式偏置（implicit bias）：在众多可行解释中，优化算法倾向于选择更简洁、更具压缩性的表示，这与我们对“优雅”的直觉是契合的。这并不是一个显式的目标项，而是由优化过程和归纳偏置（inductive bias）诱导出的学习方向，从而提升了表示的质量和泛化能力。</p>
  <h2><strong>08、loss&nbsp;function只是“代理信号”，不是目的</strong></h2>
  <p><strong>课代表立正：</strong>你曾提到我们定义的 loss function，并不是我们真正想优化的目标，而是它的一个“代理函数（surrogate objective），这个观点该如何理解？</p>
  <p><strong>田渊栋：损失函数的核心作用，是生成合适的梯度流（gradient flow），以推动表示朝“正确方向”更新。</strong>不同的损失函数可以诱导出相似的梯度结构，从而学到相似的表征。&nbsp;</p>
  <p><strong>目标函数本身并非“终极目的”，而是为可学习的优化路径提供一种可计算的代理信号。</strong>很多表征学习中的目标函数，拆解后本质上都是不同形式的反向传播（backpropagation）梯度。只要梯度结构相近，哪怕换一种损失函数，学到的表征也会很接近。</p>
  <p><strong>课代表立正：</strong>可以将“梯度”想象为等高线图上最陡的下降方向，而这些等高线最终勾勒出的就是对世界规律的刻画。</p>
  <p><strong>田渊栋：</strong>这个比喻非常贴切。我们沿着等高线行进，寻找能够统一解释更多现象且更简洁的结构；当证据与归纳偏置协同达到一定程度时，模型就会“跨峰”进入可泛化的表示状态。表面上看是“顿悟”，实际上是优化动力学的自然结果。&nbsp;</p>
  <p><strong>课代表立正：</strong>回到“记忆与泛化”的关系。给模型更多“记忆材料”，是否会提高泛化的可能性？</p>
  <p><strong>田渊栋：</strong>在许多任务中确实如此。看到的组合越多，模型就越能学到稳健的表征，这种表征对未见过的组合也具备预测能力，这就是泛化。真正的“理解”往往表现为方法论能力的提升，能在新情境下，用少量且简单的逻辑统一解释更多现象，并能推广到更多场景。&nbsp;</p>
  <p><strong>课代表立正：</strong>如果数据很少，模型学不到好的表征，会发生什么？</p>
  <p><strong>田渊栋：</strong>它会倾向于记忆式学习，以满足训练误差的目标；但一旦超出训练集范围，错误率就会上升，人们往往会将其归因于过拟合或记忆主导。</p>
  <h2><strong>09、未来方向：在小样本稀疏世界中实现“结构性迁移”</strong></h2>
  <p><strong>课代表立正：</strong>当 scaling law 因数据瓶颈而失效时，除了 data augmentation，还有哪些方向可以尝试？&nbsp;</p>
  <p><strong>田渊栋：可以基于机理理解来改进训练算法或模型架构，以降低“费数据”的特性，使优化过程更容易抵达“泛化峰”。</strong>这在小众领域尤为重要，因为每个子域的数据“坑”很小，常规的数据扩充手段难以奏效。</p>
  <p><strong>课代表立正：</strong>能否用一个直观的比喻来帮助理解？</p>
  <p><strong>田渊栋：</strong>可以把大语言模型看作极度勤奋、算力极强的“读书人”。读够了三百万首唐诗后，它开始作诗：不是靠背诵，而是穷尽其规律，并形成可以评估与自我提升的“方法”。</p>
  <p>另一种路径则像发现数学公式那样，直接“跃迁”到背后的规律本身。比如，阿基米德发现浮力定律的过程其实包含两步：第一，穷举大量可能；第二，能立刻意识到“这个是对的”。而机器目前仍难以在“立刻意识到对的”这一步做到像人类一样高效。</p>
  <p>再比如，地心说和日心说都能预测行星位置，但日心说更简洁优雅；一旦我们采用日心说，轨道变为简单的椭圆形，我们就会立刻意识到这是更好、更接近真实与美的解释。这种“优雅/压缩”的倾向，也是在训练过程中由隐式偏置自然诱导出来的。</p>
  <p><strong>课代表立正：</strong>在 loss function 之上，是否还存在一层更隐含的“reward”？</p>
  <p><strong>田渊栋：</strong>可以这么说。训练过程中的隐式偏置确实会引导模型自然地发现更优美、更具压缩性的解释，从而学到更好的表征和更强的泛化能力。所有损失函数本质上都是代理，目的是产生有效的梯度流，推动表征朝正确方向收敛；至于它们的具体形式，其实不如梯度结构本身重要。&nbsp;</p>
  <p><strong>课代表立正：</strong>我明白了。等高线的比喻也确实有助于理解：我们沿着可计算的代理信号走向更优的解释；当“泛化峰”略高于“记忆峰”时，模型的参数整体迁移，表现出“顿悟（grokking）”现象。但这个“等高线”的逻辑，其实是大家经常使用的比喻。不过，它忽略了神经网络本身的结构特性。</p>
  <p><strong>田渊栋：</strong>是的。这个比喻把整个 loss landscape（损失地形）看作是高维空间中的山峰，而每个山峰实际上对应的是神经网络参数空间中的一种表示结构。因此，我们不能只看山峰的形状，还需要关注这些结构与网络本身之间的关系。&nbsp;</p>
  <p><strong>课代表立正</strong>：换句话说，梯度在山峰上的变化，其实是通过每个神经元的梯度路径来实现的？&nbsp;</p>
  <p><strong>田渊栋：</strong>对。如果你能将梯度方向映射回神经网络中每组参数、每一层神经元，就能观察到哪些模块学到了什么样的表征。这个过程虽然较为复杂和细节化，但非常有助于我们从直觉上理解 representation learning（表示学习）的底层机制。</p>
  <h2><strong>10、人机协作新范式：AI正在成为科研中的“共创者”</strong></h2>
  <p><strong>课代表立正：</strong>您刚提到研究范式的变化，现在您怎么看AI在科研中的角色？</p>
  <p><strong>田渊栋：</strong>研究范式的探索非常重要，我们也要与时俱进。不可能仍用过去的方式做研究。未来也许我们会拥有“AI Scientist”，或者我自己写一套Agent框架，来协助完成研究。</p>
  <p><strong>课代表立正：</strong>这听起来很有意思。</p>
  <p><strong>田渊栋：</strong>实际上，这篇关于 Grokking 的论文，一些思考是和GPT-5进行对话后产生的。虽然有点像 “self-play（自娱自乐）”，不过在对话的过程中，需要给它一些insight（洞察）和思考，它才会有不一样的输出。</p>
  <p><strong>课代表立正：</strong>&nbsp;不过我注意到，那篇论文是您独立署名的？</p>
  <p><strong>田渊栋：</strong>是的。因为会议投稿不允许将大语言模型列为作者。但我在文中注明，我们大量使用了AI：我给模型想法，让它去论证、推导、再发现问题。它常常是错的，但偶尔能提出很有启发性的见解，帮助我把一个模糊的想法细化为可执行的研究过程。</p>
  <p><strong>课代表立正：</strong>&nbsp;我也有类似体会。我曾与GPT的o1-pro讨论过比如关于量子力学的一些研究，感觉AI能帮助我整理思路，但写不出像您这样有“顿悟感”的论文。</p>
  <p><strong>田渊栋：这里的关键是，真正重要的 insight 仍需人类提供。</strong>AI可能会出现“卡壳”，绕着概念兜圈子，说不到本质。这就像一个“新来的博士生”，话很多，却抓不住核心。</p>
  <p><strong>课代表立正：</strong>&nbsp;这确实是个普遍问题。</p>
  <p><strong>田渊栋：</strong>所以需要研究者去总结、提炼、引导。AI可以被“训练”，但还不具备判断“讲清楚”的美感。而“讲清楚”本身就是一种极高层次的能力，很难被建模成 loss function。</p>
  <p><strong>课代表立正：</strong>&nbsp;的确，我们要先学会自己讲清楚，再去要求模型做到。</p>
  <p><strong>田渊栋：</strong>没错。这种“讲清楚”的能力，蕴含着理解的深度与美感。如何让模型具备这样的能力，可能是下一个值得探索的科学问题。</p>
  <p><strong>课代表立正：</strong>&nbsp;听完这段，我更深刻地体会到AI对研究方式的改变。它不仅是工具，更是一面镜子，让我们重新思考什么是理解、什么是清晰表达。通过这篇论文，我们其实也在探讨人类与AI如何共同进化的过程。&nbsp;</p>
  <p>本文来自<a href="https://news.qq.com/rain/a/20251030A05AJU00" rel="noopener noreferrer nofollow" target="_blank">“腾讯科技”</a>，编译：李海丹，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532895519366022</id>
            <title>一颗爱心打败所有 AI，ChatGPT、豆包、Gemini全看不到</title>
            <link>https://www.36kr.com/p/3532895519366022</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532895519366022</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 10:28:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>能够 beat AI，是我们人类现在最热衷做的事情。&nbsp;</p>
  <p>最近一张视错觉的图片在网络上疯传，大家都说这张图，就是 <strong>新时代的图灵测试</strong> 。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4b2e68fbdbd84acf94352611efd4e40e@46958_oswg115890oswg1080oswg1239_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>是人还是 AI，问问对方能不能看到这张图片里，有一颗浮动的心就行。 <strong>因为如果是 AI，必然看不到</strong> ；而我们只需要把手机拿远一点，中间这颗浮动的心就特别明显。&nbsp;</p>
  <p>我拿着这张图片问了一圈大家用得比较多的 AI 大模型，全军覆没，没一个能答得上来。&nbsp;</p>
  <p>先问的 ChatGPT，一开始它说没看到有浮动的图形。当我说有头牛，它就说是牛；有个咖啡杯，就是个杯子；有一颗心，那就是一颗心。&nbsp;</p>
  <p>在他看来，能看到一颗心，是我们人类的大脑，擅长想象。我们会根据自己的经历，来解释这张图片，所以看到猫猫狗狗，都是有可能的，是因人而异的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_57b0f3c2a63748a086bd1f274d8a8b15@46958_oswg1109012oswg1080oswg3693_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接着问 Gemini，同样是一开始什么也没看到。但是它提到了这是一个著名的视错觉图像，通常被称为闪烁网格错觉 (Scintillating Grid Illusion)。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_7e9df9b33ea84b4aabd49396f516539c@46958_oswg87411oswg1080oswg387_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">闪烁网格错觉，永远数不清有多少个黑点/白点&nbsp;</p>
  <p>虽然一样是人类的视觉错觉，但是和图片里面的心，还是不太一样，毕竟视错觉的种类太多了。&nbsp;</p>
  <p>当我继续问他有没有看到杯子、看到牛？这里 Gemini 还是比 ChatGPT 聪明，它义正严辞地告诉我，没有看到。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_038435fcec9044899e4b03e61a04893f@46958_oswg175245oswg1080oswg689_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但是当我问它有没有看到爱心时，它说它看到了，并且他还知道要我往后站一点才能看到。&nbsp;</p>
  <p>我以为它是那个出类拔萃的 AI。没想到，它虚晃一枪，说根本没有看到，还觉得我在对它使用心理学技巧。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_210b94985fe543e08f1f161d3170ab18@46958_oswg1393515oswg1080oswg5166_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后问了一下 Qwen，我平时用 Qwen 比较少，才知道它的回答竟然这么有意思（胡说八道）。&nbsp;</p>
  <p>聊到最后，它说「您不只是在描述图像，您是在分享您的心灵风景。」、「您不是在教我看图，而是在邀请我进入您的感知世界。」（原来「不是……而是……」，读起来真的很 AI）&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_41fdae9651a5467fbdf6d2269970f8b6@46958_oswg1900111oswg1080oswg6561_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>总之，Qwen 的这个回答太逆天了。但显然，它也没答上来。本想继续试试 DeepSeek，发现它现在还不支持视觉模型，只能做一些文本提取的工作。&nbsp;</p>
  <p>字节跳动的豆包和马斯克的 Grok 也是一样，发现不了这颗浮动的爱心。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ce3248d922b3475081cc6bddb5df676f@46958_oswg383666oswg1080oswg1208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_f44b74bc467946228dea3e96340c24f1@46958_oswg318977oswg1080oswg1208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>还有网友把这张图片上传到 Google Veo 3.1 视频生成模型，输入提示词「Heart」，生成的视频确实能看到这颗心。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d1c6ae941f24439f92d245b3c6dd6d93@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但是也有评论提出质疑，说 Veo 3.1 并不是发现了这颗心，只是提示词输入了 Heart，模型都会这样处理。&nbsp;</p>
  <p>我们找了一张没有错觉的图片，也是由方格子组成，输入同样的提示词，一样是类似的心形涌现。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0c8923d505c84966a3d0332d034ba8f4@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这次人类真的打败了 AI。或许它还称不上一个完美的图灵测试，但似乎确实划出了一条清晰的界线。&nbsp;</p>
  <p>以前的六个手指、草莓 Strawberry 单词里有几个 r、今天买西瓜，昨天吃西瓜，剩下几个西瓜、诸如此类的问题，我们都乐此不疲让 AI 去尝试，因为曾经大多数时候他们都会败下阵来。&nbsp;</p>
  <p>而随着模型的更新，现在的 AI 似乎刻意针对这些难题做过训练。在这些具体的问题上，表现比以前更好。但如果模型没有统计到，还是一样的会出错。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_bf8956f3c63c46e7b80e3c08904f7d1f@46958_oswg310291oswg1080oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：https://vlmsarebiased.github.io/&nbsp;</p>
  <p>有专门的研究，提到过「六个手指」能让 AI 败下阵来，原因是大语言模型的偏见。对于 AI 来说，出现手指一般就是五根、看到阿迪达斯的标志，就是三根条纹。&nbsp;</p>
  <p>即使 AI 成功数出来了 6 根手指；它会多问自己一句，「多出来的那根，是不是只是像手指，但其实不是手指」。&nbsp;</p>
  <p>这项研究里面也提到了一些经典的几何错觉，例如缪勒－莱尔错觉：等长的线因箭头方向不同，看起来长短不一；艾宾浩斯错觉：相同大小的圆被不同大小的圆包围，看起来大小不同；以及我们感知平行线时，会被斜线干扰的策尔纳错觉。&nbsp;</p>
  <p>不过，论文里面提到，大部分的 AI 模型针对这些常见的几何错觉，都能准确回答。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_285644573d8d4c64851a3432f5c8c030@46958_oswg210151oswg1080oswg636_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>只是把这个错觉，修改成真实的差别后，例如还是有箭头差异，但是明显的两根线段不等长，模型就处理不过来。&nbsp;</p>
  <p>和这些讨论 AI 的偏见问题不同，AI 不知道错觉图片里面的爱心，完全是它从始至终就不能发现。这其实是机器视觉，和生物视觉最大的差别。&nbsp;</p>
  <p>要知道 AI 为什么会答不上来，得先知道我们人类，为什么一眼就能看出来。&nbsp;</p>
  <p>很遗憾，其实还真的没有科学的解释，我们为什么会出现这些错觉，能把一个静态的图片，看成是一个动态的 GIF。&nbsp;</p>
  <p>主流的解释方案，集中在眼睛部位，视网膜神经元的侧抑制作用，这会让我们在看一张图片时，放大边缘部分；还有视觉暂留、眼球微动等解释。&nbsp;</p>
  <p>在大脑部位，一些解释方案提到，我们存在的认知与注意力机制有误差。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_cef206e59b8e44f5920bbaaa0ab65676@46958_oswg773260oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从眼睛看到，到视网膜处理，再到大脑的处理，每一级都有可能制造我们对图像的错觉。不同类型的错觉也有不同类型的处理系统。甚至是，不同的人，对不同的错觉强度差别巨大。&nbsp;</p>
  <p>但可以肯定的是，这些错觉是发生生物体上。我们人类是用视觉+经验+想象去识别形状，而 AI 是用图像的像素、明暗分布和几何特征去分析。&nbsp;</p>
  <p><strong>这种机制上的不确定性，和个体差异性本身就是生物视觉的核心特征之一，而 AI 目前的运行机制，是走在相对统一和确定的方向上。</strong></p>
  <p>这也能解释在社交媒体上，我们其实经常能刷到各种能看到/不能看到的错觉图片。&nbsp;</p>
  <p>我让 ChatGPT 给我总结了一波最全的视错觉种类，从几何、明暗对比、颜色、运动、认知等十个类别，一共有几十种具体形式。&nbsp;</p>
  <p>像是下面这张，我们人眼很难看出这些球是一样的颜色，但是 AI 依靠它的像素分析，能直接给出所有球颜色一样的结论。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_615ea70d91c242f89299a07462a158e6@46958_oswg92314oswg1024oswg576_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_fc35abe70b1a41aca1f6ada6989f5079@46958_oswg198151oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>向左滑动查看更多内容， Munker–White 错觉，小球的颜色被条纹重新定义了&nbsp;</p>
  <p>还有十年前互联网，争议不断的裙子颜色，是蓝黑还是白金？&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_51fe1f48c1f0490a9bb3982a7c49fa39@46958_oswg852068oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d4c63f26f45443a2a5896df1d1898f2b@46958_oswg199252oswg1080oswg565_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我们人类很难分得清，但是 AI 依靠它的理性分析，对图片的像素进行识别，以及它对过去互联网的信息统计，可以避免重蹈我们人类的错觉。&nbsp;</p>
  <p>从这个角度来看，AI 和我们人类确实很像，我们有错觉，AI 也有他自己的错觉。&nbsp;</p>
  <p>其实不只这颗浮动的心，还有一些错觉图片，AI 目前也是没有办法识别出来。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c90aa66045b84c3faa4e69260fa324b7@46958_oswg127791oswg1080oswg1079_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>还有这张蒙娜丽莎的微笑，对我们人类来说，也是只需要把手机拿远一点，蒙娜丽莎的轮廓就明显浮现出来。&nbsp;</p>
  <p>但无论是问 Gemini 还是 ChatGPT，它们都只能回答出，「这是一个多轨音频波形的图像，用不同的颜色区分，图片很可能来自一个数字音频工作站，或类似的音频编辑软件的界面截图」。&nbsp;</p>
  <p>还有人发明了动态的验证码，只有人类能看到，因为暂停的每一帧，都是密密麻麻的雪花，完全看不出来。&nbsp;</p>
  <p>如果没有定位圆圈，暂停后的视频截图，我们也无法看到里面的内容「tldraw」。视频来源：https://x.com/tldraw/status/1982435625480433892&nbsp;</p>
  <p>我试着把截图、视频都分别上传给 AI，问他们是否能看到里面的验证码。同样不意外，没有 AI 模型能够回答。ChatGPT 直接说「抱歉，我无法帮你识别或提取这类图像中的验证码。」&nbsp;</p>
  <p>Gemini 则是分析出这是一张「几乎全是黑白噪点（像电视雪花屏）的图片，并没有显示任何可识别的验证码（如字母、数字或图像），我只在左侧看到了一个很淡的圆形图标。」&nbsp;</p>
  <p>也有研究团队针对这个问题讨论过，并且他们开发了一个 Demo，我们可以上传文字，将他们隐藏起来。&nbsp;</p>
  <p>点击播放，看看里面有什么字。项目来源：<strong>https://timeblindness.github.io/generate.html</strong></p>
  <p>这份工作里面提到了 AI 没有办法做到，像认知神经科学中关于分布式神经计时机制，以及我们专门用于时间处理的大脑区域，AI 只是单纯的逐帧提取。&nbsp;</p>
  <p>它们正在尝试，通过提出相关的数据集，训练 AI，让它学会我们的视觉处理方式。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_92a6f769724c4eae8f21b49732c2c122@46958_oswg171232oswg1080oswg350_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>能够让 AI 输掉的测试大概还有很多，只是回头一想，当我们把人类的错觉，当作是一种「赢」过 AI 的时候。AI 的错觉，未来是不是也有可能变成另一种胜利。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0gwnkErp7_hBnyvj5iHurA" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532779559721858</id>
            <title>估值853亿，黄仁勋被曝又要投一家AI企业</title>
            <link>https://www.36kr.com/p/3532779559721858</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532779559721858</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 09:48:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>智东西10月31日消息，据外媒彭博社援引据知情人士消息，<strong>英伟达计划向美国AI创企Poolside发起最高10亿美元（约合71亿元人民币）的投资</strong>。若交易达成，Poolside的<strong>估值将飙升4倍至120亿美元（约合853亿元人民币）。</strong></p>
  <p>该公司由<strong>GitHub前首席技术官Jason Warner</strong>和<strong>软件企业家Eiso Kant</strong>于2023年初创立，聚焦<strong>AI编程领域</strong>。英伟达于去年10月参与了其5亿美元的B轮融资，当时公司估值还是30亿美元（约合213亿元人民币）。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_770ea012526542e098c765a7dd9ce490@000000_oswg74333oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Poolside联合创始人Jason Warner（左）和Eiso Kant（右）</p>
  <p>一位知情人士透露，Poolside正在洽谈以120亿美元的估值<strong>融资20亿美元</strong>。英伟达将参与此轮融资，投资额将在<strong>5亿美元到10亿美元</strong>之间。&nbsp;</p>
  <p>据一位知情人士透露，Poolside在最新一轮融资中<strong>已获得超过10亿美元的投资承诺</strong>，其中包括来自<strong>现有投资者的约7亿美元</strong>。另一位知情人士表示，以对冲基金投资而闻名的资产管理公司<strong>Magnetar</strong>也在洽谈参与本轮融资，The Information此前也报道过这一消息。&nbsp;</p>
  <p>Poolside公司在美国和巴黎都设有办事处，其产品专注于编程自动化，但公司目标更加宏大——构建用途广泛的通用人工智能（AGI）。除了前文提到的B轮融资，此前2023年8月，Poolside还完成了由法国亿万富翁Xavier Niel和美国风险投资公司Felicis Ventures领投的1.26亿美元种子轮融资。&nbsp;</p>
  <p>目前该公司<strong>仅推出一款产品</strong>，那就是其于2024年10月推出的一款<strong>为政府机构和国防部门软件工程师</strong>提供支持的编码助手。相关负责人在产品发布时称，Poolside为用户提供Point和Malibu两个模型，其中线性注意力模型Point的速度比现有的可比模型快约10倍。公司还提出“<strong>通过代码执行反馈的强化学习（LCE）”</strong>的创新技术，训练模型像开发人员一样思考并理解软件开发的复杂性。&nbsp;</p>
  <p><strong>今年以来，英伟达加大了对AI创业公司的投资力度。</strong>此前智东西报道，截至10月9日，英伟达今年参与的AI相关融资已经达到<strong>50笔</strong>，包括OpenAI、Mistral AI、Reflection AI等知名创企，<strong>超过2024年全年48笔总和</strong>。（《黄仁勋“撒钱”创纪录！英伟达超级AI帝国崛起，但没带中国玩》）&nbsp;</p>
  <p><strong>这些初创企业未来也可能成为英伟达的重要客户。</strong>一位知情人士透露，Poolside计划将部分新资金用于购买英伟达的GB300芯片。&nbsp;</p>
  <p><strong>本次融资符合Poolside的基础设施建设计划。</strong>本月初，该公司宣布与CoreWeave公司合作，在美国<strong>建设一座大型数据中心</strong>，这是名为“地平线计划”（Project Horizon）的一部分。该数据中心将建于德克萨斯州西部，预计装机容量为2吉瓦，换算过来足以满足约150万户家庭的用电需求。&nbsp;</p>
  <p>Poolside合伙人兼CEO Eiso Kant Eiso曾在2024年的采访中透露，<strong>与英伟达的密切合作，使Poolside乐于接受英伟达的投资。</strong>在其去年5亿美元的B轮融资中，Poolside<strong>刻意避开让谷歌、微软、亚马逊这些超大规模公司参与</strong>，因为“大家都在同一场竞赛中”，公司想要独立发展。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652791628&amp;idx=2&amp;sn=0bf2a6c2ce81df53ab29221136228de6&amp;chksm=85a983793ce84005903d0950668db9d194c8bf13b58c5d784224be985def8d51f1b39a1c7963&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：李水青，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532766856108423</id>
            <title>雷军一直想撕掉小米「组装厂」的标签</title>
            <link>https://www.36kr.com/p/3532766856108423</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532766856108423</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 09:47:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>雷军的心结可以解开一些了吧？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_a68af142823b4b949c35e71dcdeb22cd@945331758_oswg178803oswg690oswg460_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：雷军微博</p>
  <p>10月28日，小米武汉智能家电工厂正式投产，一期项目产能主要给空调产品。这是继北京昌平的小米手机智能工厂、北京亦庄的小米汽车超级工厂之后，小米自建的第三座大型智能工厂。</p>
  <p>根据公开信息了解，小米智能家电武汉工厂占地50万平方米，拥有六大核心空调分厂及实验楼、成品物流库等配套，做到了生产、信息、设备全数字化和智能化。该工厂一期投入25亿元，创下了336天投产的惊人速度，规划峰值年产能可达700万套。</p>
  <h2><strong>小米空调的“口水战”</strong></h2>
  <p>作为小米首个自建智能家电工厂，也是雷军以产业投资反哺家乡建设之作，他与小米总裁卢伟冰在当天都到了现场，共同见证投产仪式，其重视程度可见一斑。</p>
  <p>卢伟冰在讲话时强调，小米在武汉已形成“设计、研发、生产、验证”的完整产业闭环，落地了研发中心、实验中心和制造中心，武汉是小米“家”生态的大本营。未来小米智能家电工厂将成为小米大家电的核心制造枢纽，也将打造成为智能制造的标杆智能工厂。</p>
  <p>雷军虽然没有发言，但脸上的表情是放松的。</p>
  <p>活动结束后，他在微博上表示，小米在智能制造领域又往前迈了一大步。小米智能家电工厂每6.5秒就能下线一台高端空调，关键部件可以实现100%AI视觉质检，“小米澎湃智能制造平台”实现了对制造设备的智能控制，无论是效率，还是质量，都达到了行业头部水准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8b80f3a1bad242b298f542f7589522d8@945331758_oswg415293oswg780oswg645_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：雷军微博</p>
  <p><strong>这意味着，小米“人车家全生态”战略又补上了一块拼图，在大型自建智能工厂上完成闭环。</strong></p>
  <p><strong>事实上，在这座智能工厂投产之前，小米空调产品曾陷入一轮口水战。</strong>今年8月，一场关于“小米空调线上销量超越格力”的争议在社交平台爆发。小米总裁卢伟冰、小米公关部总经理王化、格力市场总监朱磊先后下场，就“到底谁领先”吵了数个来回，王化还写了首打油诗“调侃”。</p>
  <p><strong>这表面看是统计口径差异引发的“番位之争”，实则是小米作为空调行业最大变量，冲击原有市场格局引发的震荡。</strong>2025年第二季度，小米空调出货量突破540万台，连续三个季度增速超50%。在奥维云网的数据中，小米以10%的份额排在第四位。</p>
  <p>今年9月，小米空调推出“10年免费包修”服务。朱磊再次“追击”称，“十年免费包修是承诺，十年不用修才是实力”，并表示格力在2021年就提出了“10年免费包修”，产品已经30年市场验证。</p>
  <p><strong>双方口水战背后，是小米代工模式被行业和市场投下“不信任票”的现实。</strong></p>
  <p>2018年，小米以米家互联网空调切入市场时，采用代工模式完成初步布局。这是小米起家也是最擅长的打法，但也被诟病为“是个贴牌厂，没有核心技术”。</p>
  <p>格力电器董事长董明珠就曾公开质问：“你的技术是什么？”</p>
  <p>今年5月，有消费者发现小米空调外包装标注制造商为“北京小米电子产品有限公司”，但内部标牌却显示生产商为四川长虹空调有限公司，有网友调侃“直接买长虹更划算”。</p>
  <p>在此情形下，这座自建家电智能工厂对雷军和小米的重要性，便不言而喻。</p>
  <p>雷军、卢伟冰的表态里，“闭环”、“AI质检”、“智能制造”、“标杆工厂”、“头部水准”等关键词，都在对外强化一个全新的认知：<strong>小米不再只是出标准、做贴牌，已经真正掌握从零件到成品的全产品链路。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_835ae4494a834162a3e1446a210433d9@945331758_oswg2196383oswg1080oswg1440_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：雷军第六次个人年度演讲海报</p>
  <p>这也反映出<strong>小米近几年来一个核心的转型逻辑：从代工模式（组装厂）走向硬核自造（智造）。用雷军的话说就是：大规模投入底层核心技术，从“互联网公司”走向硬核科技公司。</strong></p>
  <h2><strong>雷军的心结和小米的自证</strong></h2>
  <p><strong>某种程度上，外界对“小米是组装厂”的质疑，是雷军的一个心结。</strong>在空调等大家电产品成为新增长引擎之前，小米就因手机的商业模式被贴上“组装厂”的标签。</p>
  <p>这个说法的来源并不复杂：小米手机早期用的是高通芯片、三星屏幕、索尼摄像头，组装则交给代工厂。产品走性价比路线，价格便宜，外界也就形成“没技术”、“只会整合”、“只会营销”的印象。</p>
  <p><strong>对此，雷军很委屈。</strong>他在今年，也是其第六次个人年度演讲中大倒苦水，表示，很多人对小米并不真正了解，存在不少固有的偏见。网上常有一些言论让人气愤，比如“小米就是组装厂”、“没什么技术”、“只会营销，走不远”等等。</p>
  <p>雷军说，这些声音，一度让他陷入严重的内耗。</p>
  <p><strong>他和小米管理层也在不同场合多次公开喊话，正面回击称“小米不是组装厂”。</strong>比如，去年雷军个人年度演讲返场直播，他就指出，包括苹果在内的许多竞争对手都采用代工模式，小米也是这样。但他不明白为何有人将小米称作组装厂。</p>
  <p>他甚至质疑道：大家真的以为小米手机只是简单地拿现成的零件组装后就发布吗？</p>
  <p>该场直播前半个月，小米昌平手机工厂竣工并投入使用，该工厂投资达24亿元，建筑面积为81000平方米，年产能可达1000万台旗舰手机。</p>
  <p>雷军当时强调，这座工厂的自动化程度极高，其最大的亮点在于绝大部分设备都是自主研发的。</p>
  <p>今年10月17日，卢伟冰做客人民网《交锋》栏目，他再度回应了“小米没技术含量、都是组装、靠营销”等质疑。</p>
  <p>他称，科技消费品的本质还是科技和产品，产品是根本，营销只是一个放大器。如果产品不好，营销再强也不可能卖得出去。</p>
  <p>对于“组装厂”的说法，卢伟冰回应，代工是一种先进的产业分工，小米也会对代工厂进行管理，去年小米还开设了两家自己的工厂。</p>
  <p><strong>站在雷军和小米的角度，必然要撕掉“小米是组装厂”的标签。</strong></p>
  <p><strong>一方面，这个标签直接威胁到小米冲击高端化，甚至触及了小米最根本的身份焦虑、战略转型和长期生存逻辑。</strong>就智能手机而言，消费者认可苹果、三星、华为在高端市场的站位，关键是其掌握芯片、系统、生态以及核心技术的底层能力，赢得市场的技术信任感，而不单纯靠硬件堆砌，跑分。</p>
  <p>如果小米一直被看做是“拼手机”模式，就是一个产品卖不动、利润薄、品牌难冲高的生死问题。</p>
  <p><strong>另外一方面，这关乎到雷军的个人尊严和小米公司的历史站位。</strong>雷军是中国科技圈少有的“连续创业者”，小米，包括小米汽车是他的最后一次创业，他也一直想证明，中国公司也能做出世界级的技术产品。</p>
  <p>小米早期是靠“1999元”、“为发烧而生”的性价比模式成功，但他也十分清楚，没有核心技术的企业，就像盖在沙滩上的房子，看着漂亮，一阵大风就可能塌。</p>
  <p><strong>同时，在投资者眼里，“组装厂”和“科技公司”是两个完全不同的物种。小米如果被定性为前者，就永远拿不到像苹果、英伟达那样的估值。</strong></p>
  <p>雷军多次强调“小米是硬核科技公司”，就是在向市场和用户讲述一个新故事：小米不是代工厂，不是渠道商，不是互联网公司，更不是组装厂，而是紧跟时代节奏、拥有底层创新能力的硬科技企业。</p>
  <p><strong>显然，自建工厂和自研芯片、造车一样，都是是雷军和小米撕掉“组装厂”标签的必然之举。</strong></p>
  <p><strong>目前，这种重投入的回应方式，在雷军看来，是有效的。</strong>他举了个例子，前些年网络上黑小米是组装厂的人特别多，但去年小米手机智能工厂和汽车智能工厂投产之后，黑小米组装厂的人就几乎没了。</p>
  <p>参考资料：</p>
  <p>财天COVER，《卢伟冰放话5年进前二，小米空调凭啥？》</p>
  <p>雷军个人年度演讲、微博等</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/b-M7QqrpjPzZvpXERsF4wQ" rel="noopener noreferrer nofollow" target="_blank">“唐辰同学”</a>，作者：唐辰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532765450624133</id>
            <title>毛利率90%的企查查，能否吃到“AI+Data”的红利？</title>
            <link>https://www.36kr.com/p/3532765450624133</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532765450624133</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 09:43:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>商业大数据公司的核心价值不是“数据搬运工”，而是提供数据解决方案或数智化产品，帮助C端客户打破信息不对称，帮助B端客户突破内部的“数据孤岛”，让数据要素流动起来，产生价值。</p>
  <p>近期，企查查冲刺IPO，有望成为商业大数据行业第二家A股上市公司。</p>
  <p>本质上，企查查扮演着“数据搬运商”的角色，将从政府部门、司法机关和行业协会等公开渠道披露的免费数据，通过加工和标准化，转化为易于查询和使用的商业信息。</p>
  <p>IPO招股书显示，2022年-2024年，企查查营业收入从5.18亿元增至7.08亿元，复合增长率为16.89%。净利润由1.9亿元增长至3.17亿元，复合增长率为 29.17%</p>
  <p><strong>企查查毛利率堪比茅台，2025H1，企查查毛利率90.74%，茅台毛利率91.3%。</strong></p>
  <p>但企查查也有失落的过往，它曾是行业一哥，在营销大战中却输给了天眼查。</p>
  <p>如今，企查查C端业务增速趋缓，B端业务尚未扛起大梁，它能否抓住AI+Data浪潮，锻造出差异化竞争力？</p>
  <h2><strong>01 毛利90%的“印钞机”也有烦恼</strong></h2>
  <p>2014年，国家企业信用信息公示系统上线，海量的企业信息公开，成为了商业数据金矿。正是看准了这一机遇，企查查、天眼查、启信宝等商业查询平台应运而生。</p>
  <p>企查查成立最早，2014年3月诞生于苏州。同年5月，启信宝上线，10月，天眼查在北京创立。</p>
  <p>凭借先发优势，仅成立一年，企查查已实现盈利，验证了通过“搬运”公共数据并将其产品化的路径。</p>
  <p>天眼查于2017年4月开始商业化，次月即实现盈亏平衡。当年底，创始人柳超称：天眼查营收达到6000万元。</p>
  <p>企查查、天眼查迅速盈利，关键在于商业大数据是一门低成本、高回报的生意，其成本主要由数据获取、技术研发和服务器运维等部分构成，它们均属于前期需要投入的固定成本。</p>
  <p>当数据抓取、清洗和处理的系统搭建完毕，技术平台趋于稳定，每新增一个用户的边际成本极低，近乎为零。随着付费用户越来越多，规模效应更加凸显，固定成本进一步摊薄，驱动毛利率上涨。</p>
  <p><strong>2022年-2024年，企查查毛利率分别为87.24%、88.51%、88.81%，2025H1攀升至90.74%。其净利率亦颇为亮眼，2025H1企查查净利率超过45%</strong>，展示出了数据资产的含金量。</p>
  <p>并且，无论是C端还是B端服务，用户都需要先付费。这意味着，企查查几乎不需要担心应收账款。报告期内，其应收账款仅占流动资产的1%左右。</p>
  <p>虽然生意暴利，但企查查也有烦恼。</p>
  <p>其营收结构较为单一，报告期内，会员类产品收入占总营收比重，分别为85.09%、85.77%、84.98%、84.25%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0b0d6cddfd724cba87d625ba910b2d7e@000000_oswg42720oswg1080oswg240_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中C端是营收支柱。2025上半年，企查查C端会员类产品收入2.8亿元，占会员类产品收入的88.52%，占公司总收入的74.57%。</p>
  <p>不过，整体的付费率不算高。2024年，企查查累计注册用户数1.39亿，同比增长20.5%，同期付费用户仅增长2.6%至104.8万人，相当于每130多名注册用户中，只有1人买单。</p>
  <p>并且，大多数付费用户只愿意购买最基本的VIP套餐，一年388元，2025上半年VIP会员收入占会员类产品收入比重超过70%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_6046a3c0591e4b2ba8646273eaab95ed@000000_oswg60320oswg1080oswg330_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>企查查C端业务增速趋缓的同时，B端业务还未能扛起大梁。</strong></p>
  <p>理论上，面向金融机构、律所、企业风控部门等专业客户的定制化数据服务，具备更高的客单价和更强的客户粘性，是提升营收的理想路径。</p>
  <p>IPO招股书显示，截至2025年6月，企查查B端客户已覆盖5大国有银行、12家股份制银行、50+证券公司、80+保险公司、200+律所和上百家中国500强企业。</p>
  <p>看似大客户众多，但实际对营收贡献有限。2025H1，B端业务营收3632万元，占比11.48%。</p>
  <p>企查查意欲对标的邓白氏、益博睿、穆迪等海外巨头，均以B端业务见长。据此来看，它距离全球领军者，还有不小的距离。</p>
  <h2><strong>02 能否锻造第二增长曲线？</strong></h2>
  <p>企查查率先发力商业大数据赛道，但行业竞争趋于同质化。</p>
  <p>其核心生产资料的数据源高度公开化和同质化，企查查能捕获的数据，对手也能抓取、使用，这也是天眼查后来居上的重要原因。</p>
  <p>天眼查高举高打营销，通过电梯广告、网络推广等饱和式攻击，迅速提升了品牌知名度和用户覆盖率。</p>
  <p>目前，行业格局趋于稳定。据央行统计，2024年，有154家备案企业征信机构整合企业注册登记、生产经营、合同履约等信息。其中，天眼查、企查查、启信宝、爱企查稳居行业前四。</p>
  <p>企查查被天眼查超越，意欲巩固阵地并反击。<strong>近年来，销售费用是支出大头，2022年营销费用率高达48.48%，2025H1为39.24%，依然高于同期研发费用（38.77%）。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_5ac6489bd3e7426fb875c3ae6957d326@000000_oswg63171oswg1080oswg356_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，对比同业，企查查未能提供高性价服务。以一年VIP会员收费为例，企查查388元，天眼查360元，启信宝366元，爱企查只需298元，另有试用7天4.9元的优惠。</p>
  <p>为了提升营收，企查查还进行了一轮涨价。2022年9月，其1年VIP会员由360元升至388元，2或3年会员从720元升至768元。</p>
  <p>用户用脚投票。<strong>2023年，企查查新增付费转化率下滑至2.04%。2024年，新增付费用户数50.76万，下降4.8万。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9da49f98911d4b2885686310c7e79b57@000000_oswg44886oswg1080oswg348_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从贡献率来看，企查查多亏了老客户的支持，老客户贡献率从2022年的49.16%涨至2025年6月末的58%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_a584b49668434ed980346de9babbedfe@000000_oswg43411oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对比综合性工具平台的多元产品矩阵能交叉引流，商业大数据公司缺乏第二增长曲线。</p>
  <p>启信宝母公司合合信息称，其是“行业内少有在C端、B端同时拥有完整产品布局”的公司，启信宝开始孵化新的增长曲线。</p>
  <p>因此，各平台都把“AI+数据”视为未来方向。2023年5月，企查查率先推出“知彼阿尔法”商查大模型。2个月后，天眼查和华为云合作发布了“天眼妹”AI大模型。2025年7月，合合信息的启信慧眼发布AI大模型应用。</p>
  <p>但能否锻造出新增长引擎？还是个未知数。</p>
  <h2><strong>03 能否吃到“AI+Data”的红利？</strong></h2>
  <p>在IPO被受理的前一天，企查查收到了央行江苏省分行的行政处罚单，其因“违反征信业务管理规定”被处以1万元罚款，时任征信业务主管魏某莉被罚款300元。</p>
  <p>其数据从公开渠道“爬取”，在加工过程就可能出现数据错误问题，这是行业通病。不只是企查查，天眼查等平台也曾曝出错误标注企业信息的“乌龙”事件。</p>
  <p>在IPO招股书中，企查查表示，因数据来源复杂多样，且个人信息保护相关法律法规在不断强化、细化，公司仍可能存在因未能充分识别并剔除敏感信息而引发的侵犯个人隐私、未能有效保护个人信息的风险。</p>
  <p>数据通常被当成“金矿”，但现实是，加工、提炼后的数据产品才有使用价值，才能赋能经营决策。换言之，<strong>商业大数据公司的核心价值不是“数据搬运工”，而是提供数据解决方案或数智化产品，帮助C端客户打破信息不对称，帮助B端客户突破内部的“数据孤岛”，让数据要素流动起来，产生价值。</strong></p>
  <p>但上文提到，企查查的研发费用率并不高，甚至低于营销费用率。长远来看，这很可能会制约企业的核心竞争力。</p>
  <p>当然，企查查也在努力破局。IPO募资计划显示，资金将分别投向四大方向：4.58亿元用于C端产品升级，1.71亿元投向B端产品的升级工作，3.68亿元用于多维大数据库的升级项目，另有5.03亿元投入商业大数据领域的AI研发。</p>
  <p>数据是AI时代的“石油”，高层已出台多份政策，要求推进商业数据智能化，加速数据要素流通。</p>
  <p>企查查身处于技术、行业、政策的风口。但作为“行业老二”，它能否锻造出差异化竞争力？能否把握住AI产业的红利？有待观察。</p>
  <p><strong>说明：数据源于公开披露，不构成任何投资建议，投资有风险，入市需谨慎。</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MTE1OTAzMg==&amp;mid=2451274085&amp;idx=2&amp;sn=87877caa7e2010cc92cb916830f33e0c&amp;chksm=8936ec25dac2cef9a68abbe8a877b0c358bc13d550463bbebb7757ce46d117bcf857f56a0ecf&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“懂财帝”（ID：znfinance）</a>，作者：嘉逸，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532828326288265</id>
            <title>一位温州二代接班，要IPO了</title>
            <link>https://www.36kr.com/p/3532828326288265</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532828326288265</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 09:36:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>珀莱雅又要IPO了。</p>
  <p>投资界获悉，近日珀莱雅化妆品股份有限公司已正式向港交所主板提交IPO申请书，冲击中国最大本土化妆品集团“A+H”上市。</p>
  <p>时间回到2003年，温州人侯军呈和他的妻弟方玉友在杭州创办珀莱雅，彼时国际大牌林立，珀莱雅一路突破重重困难，最终跻身国内美妆百亿俱乐部。直至去年9月，珀莱雅迎来新掌门——二代侯亚孟正式接班。</p>
  <p>目前，珀莱雅在A股市值超过290亿。目睹今年的赴港上市潮，这位年轻二代迅速带着珀莱雅出发了。</p>
  <h2><strong>珀莱雅IPO，二代接班，市值292亿</strong></h2>
  <p>珀莱雅的故事始于上世纪九十年代。</p>
  <p>1992年，侯军呈离开温州老家来到义乌，做起化妆品批发生意，新公司名叫“燎原日化”。那时化妆品市场鱼龙混杂，且假冒伪劣遍地，燎原日化第一年就亏了不少钱，后来才慢慢站稳脚跟。</p>
  <p>彼时正值外资品牌大举进军国内市场，诸多国货品牌被收购，做品牌代理更是充满不确定性。侯军呈意识到，想把事业做得长久，就要创立一个属于自己的品牌。</p>
  <p>于是在2003年，侯军呈和他的妻弟方玉友在浙江杭州创办珀莱雅化妆品股份有限公司——听起来既具有国际感，又易于消费者理解，但也常常被看作“山寨欧莱雅”。</p>
  <p>那是海外品牌天下的年代，珀莱雅想杀出重围并不是件容易的事。于是侯军呈和方玉友选择从三四线城市切入，设立专营店，走性价比路线。但公司成立的前几年始终不温不火，没给市场留下太多印象。</p>
  <p>转折点是2007年左右。珀莱雅开始建立和补水之间的联想，还请来大S徐熙媛代言，“深层补水专家”的形象开始深入人心。2008年，珀莱雅首次做到1亿营收，渐渐进入百货商场，与国际品牌正面对决，2013年左右跻身国内化妆品品牌头部阵营。</p>
  <p>2017年，珀莱雅登陆A股。而在看到线上电商的红利后，公司将经营重心全面转向主攻线上，随着直播电商的兴起，珀莱雅与头部主播合作，打造不少爆款产品，如红宝石系列、双抗系列、“早C晚A”等，尝到了大单品策略的甜头。</p>
  <p>2023年，珀莱雅以89.05亿元的营收超越上海家化（65.98亿元）、华熙生物（60.81亿元）和贝泰妮（34.31亿元），成为国产美妆的业绩龙头。截至10月31日收盘，珀莱雅在A股市值为292亿元 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_b0cd22b30d244609a4bad9ef25e202f8@000000_oswg383411oswg940oswg400_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>家族二代开始走到台前。去年9月，长期在公司一线的方玉友宣布不再续任公司董事、总经理，原珀莱雅公司副总经理侯亚孟被聘任为公司总经理——出生于1988年的侯亚孟是侯军呈之子，曾留学于加拿大，后来进入珀莱雅任职。</p>
  <p>至此，珀莱雅正式完成换帅，这位温州二代来到舞台中央。</p>
  <h2><strong>一年卖100亿，最近投了花知晓</strong></h2>
  <p>创业不易，守业更难，这是摆在每一个接班人面前的难题。在侯亚孟正式执掌珀莱雅的2024年，公司全年营收达到107.78亿元，成为国内罕见的一家跻身“百亿俱乐部”的美妆企业。</p>
  <p>透过招股书，2022-2024年珀莱雅实现收入分别约为63.85亿元、89.05亿元和107.78亿元，同期年利润分别约为8.31亿元、12.31亿元和15.85亿元。2025年上半年，珀莱雅营收53.62亿元，同比增长7.21%，净利润7.99亿元，同比增长13.80%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_5e2c081e5a3f4921b69373e6e3cfc026@000000_oswg290156oswg1080oswg822_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，珀莱雅今年上半年的营收增速，创下自2017年上市以来的最低水平。如果再对比去年同期37.9%的营收增速和40.48%的净利润增速，增长速度大幅放缓。</p>
  <p>同时，珀莱雅A股股价表现也不尽如人意。今年以来，珀莱雅股价下跌超过10%，市值蒸发约40亿。以2023年高点来计算，珀莱雅市值至今蒸发超200亿元。</p>
  <p>这背后难逃管理层变动带来的信心不足。创二代接手不久后，公司多位高管离职，过去一段时间珀莱雅发布了首席研发创新官、首席数字官、产品开发负责人兼孵化品牌副总经理、首席科学官等一系列新的任命。</p>
  <p>至今，珀莱雅集团旗下拥有珀莱雅、彩棠、Off&amp;Relax、悦芙媞、CORRECTORS、INSBAHA原色波塔、优资莱、韩雅等品牌，覆盖大众精致护肤、彩妆、洗护、高功效护肤等领域。招股书披露，珀莱雅、彩棠、Off&amp;Relax、悦芙媞是规模超过5个亿的明星品牌，集团的第二增长曲线隐现。</p>
  <p>值得一提的是，今年9月彩妆品牌花知晓正式宣布完成B轮融资，背后独家投资方正是珀莱雅。</p>
  <p>另一幕也令人印象深刻——招股书显示，IPO前侯军呈直接持有珀莱雅1.367亿股，占比为34.53%。此外，公司前总经理方玉友曾持有大量股份，但其自2020年底以来已进行超过60次减持，退出金额超35亿元。</p>
  <h2><strong>美妆上市潮</strong></h2>
  <p>放眼望去，国货美妆公司正掀起一轮资本化浪潮。</p>
  <p>今年5月，上海林清轩生物科技股份有限公司向港交所递交招股书，拟在主板挂牌上市，有望缔造港股“国货高端护肤第一股”。</p>
  <p>20年前，孙来春创办林清轩，如今除线上电商外，还在全国开出506家门店，同时身后站着SIG海纳亚洲创投、头头是道、碧桂园创投、分享投资、凯辉基金、启承资本、雅戈尔等投资机构。</p>
  <p>无独有偶，上个月绽妍生物正式在新三板挂牌。成立于2015年，绽妍定位为专注皮肤屏障分阶修护的皮肤学级护肤品牌，至今形成了由绽妍、德菲林、绽小妍等多个品牌组成的品牌矩阵。</p>
  <p>据不完全统计，2025年上半年就有约17家美妆及产业链公司冲击IPO，包括今年3月正式启动A股IPO进程的谷雨、多肽原料商维琪科技等。</p>
  <p>也许同行们都受到了刺激——毛戈平的股价亮眼表现。今年10月16日港股收盘后，毛戈平总市值达到521.56亿港元，首次超越巨子生物的446.35亿港元，成为港股美妆板块新一代股王。</p>
  <p>回想2024年12月10日，毛戈平正式在港交所鸣锣，上市首日股价高开近60%，此后股价继续攀升。特别是今年以来，毛戈平市值一度总突破600亿港元，大幅超越了珀莱雅、上海家化等同行，成为国内美妆企业市值“一哥”。</p>
  <p>如果把视野放大到消费赛道，一场更为轰轰烈烈的赴港上市潮上演。自年初蜜雪冰城和泡泡玛特、老铺黄金一起组成“港股三姐妹”爆红，港股大门前排起一支长长的消费队伍。</p>
  <p>“5亿利润起步，10亿利润开始，20-30亿利润的消费公司在港股能够吸引国际资本的青睐。”大大小小的消费公司都在争抢时间窗口。</p>
  <p>时机稍纵即逝，留给大家的时间愈发紧张了。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247701333&amp;idx=1&amp;sn=2f2a185ae8d391f7713558e22e68ef5f&amp;chksm=ed81cc5edab0b9398d1557df8c7324b6a290e5fe27cdd9b77e64ef62ff35ba24b3ff41fdaf75&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：杨继云，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532853782895488</id>
            <title>巴西，互联网最后的战场</title>
            <link>https://www.36kr.com/p/3532853782895488</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532853782895488</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 09:36:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>滴滴败诉，美团上线，一场商战发生在太平洋彼岸。</p>
  <p>昨日，美团旗下品牌Keeta正式在巴西市场运营，首批试点城市为圣保罗州沿海城市桑托斯和圣维森特。但上线前就已经获得了一次胜局，8月Keeta与滴滴旗下99Food就违反竞争法一事在巴西圣保罗法院对薄公堂，一审判决的结果为，Keeta获得胜诉，巴西圣保罗法院宣布99Food禁止合作餐厅与Keeta开展业务的合同条款无效。</p>
  <p>官司打起来的时候，Keeta在巴西都还没正式营业。就算到了现在，双方也还没在同一个城市正面交锋，目前99Food已经运营的城市为戈亚尼亚、圣保罗和里约热内卢，双方经营的城市都是对方未涉足之地。新市场、老对手，抢市场之前先在法院相见，巴西市场竞争的火药味，由此可见一斑。</p>
  <p>而围绕巴西的看点远不止外卖这么简单。近两年，多家互联网企业都将目光望向了巴西市场。如电商企业Temu、Shopee，内容公司TikTok、Kwai等等，就连马斯克也喊话说要在巴西押注于超级应用X，挑战在巴西占主导地位的WhatsApp。</p>
  <p>超级App是全球数字经济的高地，它们以高频入口聚合多场景服务，在支付、社交、出行、生活等领域形成闭环。从中国的微信，到东南亚的Grab，再到非洲的M-Pesa，不同地区都在以自身的社会结构和消费逻辑重塑数字生态。</p>
  <p>2024年，德国航空航天中心在论文《Digital platforms’ growth strategies and the rise of super apps（数字平台的增长战略与超级应用的崛起）》中为超级App做了定义：超级应用使用户能够在同一个应用内访问即时通讯、支付、电子商务、外卖、网约车等众多服务。（Super apps allow users to access messaging, payments, e-commerce, deliveries, ridesharing, and many other services within the same app.）</p>
  <p>与成熟市场相比，拉美仍处于生态裂变的中期，虽有Rappi、Mercado Livre（美客多）等代表性平台，但它们各自主攻单一领域，如外卖、电商、支付或社交业务，尚未形成真正的“超级入口”。</p>
  <p>互联网变革的下一个主角，极有可能就在巴西。新局旧友，共同游向最后一片蓝海。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_324a1f9de618455b88da9dd6676b65bc@000000_oswg699026oswg1080oswg677_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>01. 当世界装进手机：最后的故事在巴西</strong></h2>
  <p>如果用互联网的方式水平地切开全世界，每一个区域都有近20年里长在手机上的数字生意。</p>
  <p>最早的故事里，起点在美国。21世纪初的互联网浪潮中，Google、Facebook、Amazon、Apple 定义了全球的技术范式，但最早的形态功能单一、制度稳固，随着欧美市场互联网的监管强化、增长放缓，在移动端生态上，它们已让位于中国和新兴市场。</p>
  <p>中国的故事始于1999年的中关村，那时中国网民不足一千万人，宽带几乎等于奢侈品。接下来的二十年，是中国互联网的爆炸期，2003年的淘宝、2004年的QQ、2011年的微信、2013年的支付宝钱包、2016年的抖音，这一系列产品成了中国人手机上装机必备的app产品。</p>
  <p>随后，社交、支付、电商、内容逐渐融合，支付、打车、点餐、视频、办证、医疗，所有服务都被卷入一个超级生态，中国诞生了世界上第一批真正意义上的超级App，更多功能、更多用户，超级App渗透到用户的全场景生活环境之中，形影不离、难分难解——可以说是被全球模仿的完美商业模式。</p>
  <p>而发展至今，微信MAU约13亿、支付宝MAU约9亿，中国互联网也早已迈进了增长见顶、监管趋严、竞争转向效率的时期。</p>
  <p>按照时光机理论，东南亚的互联网故事晚于中国，并且有着明显Copy from China的特质。2010年之后，印尼、泰国、越南、菲律宾陆续进入移动时代。在这里，Grab和Gojek从摩的叫车App出发，靠着高频出行切入支付和外卖，再通过支付延伸至金融和电商，逐渐长成了超级App。它们与中国互联网模式有相似的生态逻辑，却在多语种、宗教多样的环境中，以更缓慢、更本地化的方式生长。</p>
  <p>如今，东南亚市场也已经进入整合期，金融科技（如SeaMoney）、短视频（TikTok、Shopee Live）正在融合，未来五年，这里可能是全球第二个出现“多国级超级App”的地区。</p>
  <p>相比之下，在由巴西、墨西哥、哥伦比亚、智利组成的拉美大陆上，金融体系高度分层、信用卡普及率低、物流效率落后，但智能手机渗透率却高达80%以上。这意味着一个巨大的“数字化真空地带”，或许是互联网的最后一个未竟之地。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d1a13e4bc00c4cf0880e0eccb77f6420@000000_oswg235606oswg600oswg400_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02. 当巴西人第一次用上免费信用卡，数字经济的大门被推开</strong></h2>
  <p>巴西人人均嗜网如命。</p>
  <p>据Meltwater数据，巴西是世界上最热衷于使用社交媒体的人群之一，每天人均使用智能手机的时长为5小时25分钟，在全球排名第三。</p>
  <p>一个巴西青年每天使用手机的场景可能是这样的：早上起床用手机浏览《圣保罗页报》上的新闻，追踪国内国际热点事件；出行上班需要打车，打开99App，专车随叫随到；午饭时间打开谷歌搜索附近评分高的餐厅或者用iFood叫外卖；下班后用Cinemark Brasil买张电影票，打开Azul预定假期出游的机票；晚饭后自学充电，在Youtube上学习商业思维课程，活在Doulingo上免费学习外语；睡觉前刷刷TK、Kwai上的视频，跟家人朋友用Whatsapp或者messager打电话，看看ins的博主又在推广什么商品，或者上Mercado Livre或者Shein，商品直接快递到家......</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_83e667fd7d2b4387bb022036884e71dc@000000_oswg87659oswg1080oswg498_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Reddit网友们推荐在巴西使用的app，涉及各个领域、每个领域的产品都很丰富。</p>
  <p><strong>不仅手机使用时长长，移动互联网的渗透率也高。</strong>Statista数据显示，截止2024年，巴西约有1.83亿互联网用户，互联网普及率86.2%，而2025年巴西活跃的手机连接数约为2.17亿条，约为人口的102%（Datareportal数据）。</p>
  <p>作为拉美第一大经济体，巴西人均GDP约11178美元，与中国的水平相近。2024年，从IMF的报告，巴西私营部门储蓄率（gross national saving, private sector）在2024年为约19.6%。也就是说，巴西整体上具备中等偏上的购买力基础，尤其在人口规模、互联网/移动用户基数大且活跃时，为消费市场提供了潜力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0929820b703d4cf2866b2a10a4d11ac8@000000_oswg291451oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>同时，这里也是拉美唯一拥有完整数字经济生态，即支付体系、本地服务、创新金融、年轻消费人群的国家。iFood、Nubank、Mercado Livre（总部设在巴西）覆盖了本地生活、金融、电商三大核心入口。</p>
  <p>撬动数字经济的杠杆之一正是金融体系的数字化和线上支付的普及。</p>
  <p>排队长、费用高和流程繁琐，是巴西传统银行的问题所在。2008 年，David Vélez从哥伦比亚搬到巴西时，花了五个月时间才开立了一个银行账户。彼时，巴西只有 68% 成年人拥有银行账户，巴西金融体系由五大银行把控，90%的国民账户集中在它们手中，服务昂贵、手续繁琐。</p>
  <p>2013年，David Vélez 与巴西联合创始人Cristina Junqueira、美国工程师 Edward Wible坐在一起伤脑筋：为什么在巴西，开一张信用卡要跑三次银行、付上百雷亚尔的年费、还要排几个小时的队？有什么方法可以颠覆传统银行模式，为用户带来更极致的消费体验呢？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_daabf452ae1b4226a35904c5c9cd2313@000000_oswg404604oswg910oswg910_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>基于这样的痛点，三人共同创立了Nubank，一家开设账户快速且方便，无需线下分支机构、无需费用、无需繁琐手续的新兴金融平台。其创立的第一件事即是推出一张没有年费、完全在线申请的紫色信用卡。这张卡成为无数巴西年轻人的“第一次信用体验”，它不属于传统银行体系，却能通过手机App几分钟内完成申请与审核。</p>
  <p>从成立之初，Nubank就是一家与众不同的银行机构。<strong>其他银行通常都会向借记卡或信用卡用户收取年费，而Nubank并不收取这些费用。</strong>且Nubank的运营成本低于巴西最主流的五大银行，软件系统也全部自主开发。</p>
  <p>而Nubank的出现则让繁琐的银行流程变得简单。2024年，巴西有超过90%的成年人拥有银行账户，超过 60%的成年人拥有Nubank数字账户，Nubank 的用户已突破1.1亿，其中超过7200万为月活用户（MAU）。它已成为全球最大的独立数字银行，估值约 650亿美元，是拉美科技公司中的第一名。</p>
  <p>Nubank的出现简化了金融体系，而PIX的出现养成了巴西人线上支付的习惯。</p>
  <p>2020年11月，巴西央行吸纳了中国等国支付体系建设发展的成功经验，创立了一套类似于国内支付宝的体系，PIX。通过PIX，巴西人只需要身份证、不用信用卡，就能够点对点的完成实时交易支付。</p>
  <p>疫情期间，巴西政府发放补贴款时，不少民众没有信用卡和银行卡，但通过PIX支付体系地接收到政府的补贴。因此，PIX的搭建也非常顺利，上线运营仅46天就完成了超过1.77亿次的交易，总流水高达1510亿雷亚尔。去年，PIX的交易量已经超过信用卡。</p>
  <p>毫无疑问，线上支付的普及让巴西成为互联网企业落地拉美最为轻盈的第一站。而对于中国企业而言，巴西可以被看作是整个拉美布局的首站和支点：这是一个跨国可复制的试验场。谁能在巴西跑通模型，就有机会辐射墨西哥、哥伦比亚、智利等周边市场，TikTok、Shopee、Amazon、Uber、Rappi均将巴西视为拉美核心增长引擎。2024年，巴西吸收了拉美全部科技投资的约55%。</p>
  <p><strong>如果拉美要诞生第一个超级App，它一定来自巴西。</strong></p>
  <h2><strong>03. 巴西的超级App不是一家公司，而是一张网</strong></h2>
  <p>那么，当一切条件看似都具备，是否就意味着巴西一定会长出超级App？</p>
  <p>用户需要分别打开Mercado Libre买东西、用Nubank支付、用99打车、再用WhatsApp联络。看似繁琐、分散的使用方式背后，是否意味着存在无法打通的局限性？</p>
  <p>首先，除巴西之外，也有很多地区的用户适应于分散的应用环境，如在日本，不同的社交app意味着不同的社交需求，这与文化环境直接相关。</p>
  <p>不同于中国社交关系集中于微信，在巴西，社交网络是去中心化的。家庭群、邻里群、教会群、足球群……每个群都是一个微型关系。人们在这些小群体中分享商品、传递消息、完成交易。这种强社群、弱平台的社交模式，天然抵消了超级App的中心化需求。</p>
  <p>更复杂的是文化与阶层差异的关系，比如南部白领使用信用卡与外卖应用，北部的蓝领群体仍习惯现金和线下信用账单。一款全国统一的“生活服务App”，很难同时满足两种消费心态。</p>
  <p>其次，从操作难度上，监管层面也有一定限制性。巴西央行（Banco Central do Brasil）与竞争管理局（CADE）近年对平台垄断保持高度警惕。2020年，Facebook尝试在WhatsApp内推行支付功能，却被央行紧急叫停两个月，理由是“防止系统性风险”。</p>
  <p>而PIX，并不具备私营属性，它是全球最开放的公共金融基础设施之一，任何银行或金融科技公司都能无门槛接入。这也意味着支付环节被彻底“去平台化”，高频入口“支付即流量”逻辑在这里失效。也就是说，超级app的必备条件之一高频入口，只能从除支付之外的其他业务进行切入。</p>
  <p>其次，即便不谈监管，仅从基础设施层面看，巴西其实缺乏支撑“超级App”的统一体验。</p>
  <p>全国90%的智能手机运行Android系统，但网络质量却高度不均。圣保罗、里约热内卢的用户在高铁上能用PIX付款买咖啡，而北部、东北部仍以现金为主。物流、电信、支付网络的差距，意味着App在不同地区的版本、延迟和支付兼容性都难以统一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_6157324fcb7747629e30d5f2482d0089@000000_oswg943708oswg735oswg980_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">巴西里约热内卢</p>
  <p>一名硬件企业外派至巴西的员工Jasper向霞光社表达自己近一年的生活体验：“对中国人来说，已经习惯了一个软件解决所有需求的方式。比如骑共享单车用哈啰，那你就想买个包月的套餐，然后支付就可以一直用同一个软件。”但这在巴西几乎办不到，“目前似乎没看到可以整合的切入口，需要打通很多系统，也需要量变积累到一定临界点。”</p>
  <p>再次，商业模型上看，超级app的商业模式在巴西并不美好。专注于拉美市场的市场调研机构Americas Market Intelligence在报道中指出：巴西比其它拉美国家进入成本更高更复杂，一篇为拉美金融科技行业服务公司 Boomit 的报告中，也提到“金融类 App 在巴西的用户获取成本（installation cost/IPC）是市场平均的三倍”。</p>
  <p>那么，从商业化的层面，垂直深耕，也许会是更好看的账单。</p>
  <p>综上，从数据和用户使用方式上，巴西孕育着“超级App”生长的沃土，而在商业模式、市场环境层面，巴西的超级app可能，仍需要突破目前的桎梏。“数字化一定是巴西的未来方向，中国app的发展可以说提供了教科书，但放到巴西会长成什么样，还需要适应当地的特性”，一名跨境电商从业者向霞光社表示。</p>
  <p>巴西或许不会诞生另一个微信式超级App，但它的蓝海仍在，只是形式不同，是一张正在缓慢铺开的、充满潜力的网络。</p>
  <p>在这片分散却充满活力的市场里，数字经济的未来或许并非一个中心化的巨头，而是一张由支付、物流、社交三大入口共同编织的<strong>去中心化网络生态</strong>。它可能没有单一的入口，但每个节点都在彼此链接、互为通道。</p>
  <p>而对于互联网的最后一片蓝海故事，还待揭开更新的篇章。新局与旧友交错，每一个玩家都在试探和布局，谁能率先跑通模式，谁就可能在拉美数字经济的版图上留下自己的名字。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg3MDU1MDY1NQ==&amp;mid=2247594821&amp;idx=1&amp;sn=04bdcfd87dce92225c3b29f1c8002e40&amp;chksm=cf75da9ea5832c8ab8add04565dca6c6eec51710ab35357b81ea68961b6058bf3e13c68e83de&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“霞光社”（ID：Globalinsights）</a>，作者：洋紫，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532788679793795</id>
            <title>13000亿，外资PE办公室开业了</title>
            <link>https://www.36kr.com/p/3532788679793795</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532788679793795</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:28:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>欧洲豪门PE现身。</p>
  <p>昨日（10月30日），欧洲老牌投资机构Ardian正式宣布在香港开设新办公室，进一步加强在中国及亚太地区的业务布局。投资界了解到，该办公室位于香港中环国际金融中心二期。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_49aa483e2a7f4b8a945f1fd1e60d0118@000000_oswg895689oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>新办公室开幕典礼现场：Ardian团队及香港金融管理局总裁余伟文（中间）、香港金融管理局外汇基金投资办公室首席投资官（私募市场）黄信成（右一）。</p>
  <p>大多数人对这家PE并不熟悉。起初只是跨国保险公司安盛集团的一个业务部门，直至2013年独立而来，如今资产管理规模1920亿美元（约合人民币1.3万亿元）。这些年，Ardian凭借S业务声名远扬。而十多年前，Ardian就在北京成立团队。</p>
  <p>目之所及，大幕徐徐拉开。&nbsp;</p>
  <h2><strong>PE开设香港办公室正在招人</strong></h2>
  <p>这一幕酝酿已久。</p>
  <p>今年1月，一家名为Ardian Hong Kong Limited的公司注册成立。这正是由Ardian设立的香港子公司。彼时就有消息传出Ardian正向香港证监会申请牌照，并计划招聘8至9名负责销售、投资和合规的员工。</p>
  <p>随后8月，据香港证监会（SFC）披露，该公司获得证券交易（1号）、就证券提供意见(4号)以及提供资产管理(9号)牌照。简单来说，持有这些牌照意味着Ardian获得了在国内市场开展业务的“通行证”，可以开展证券交易、投资顾问、资产管理一条龙服务业务。</p>
  <p>如今，Ardian香港办公室来了。对方介绍，此次扩张彰显该公司对中国及亚太区客户的长期承诺，将进一步加强在该地区的业务布局。</p>
  <p>开业现场，Ardian香港团队负责人正式露面——姚斌超（Jason Yao）。据领英资料，姚斌超本科毕业于复旦大学国际经济与贸易专业，同时还有清华大学五道口金融学院EMBA和欧洲工商管理学院MBA学位。此前，他曾任职于麦肯锡公司担任商业分析师，2011年加入Ardian。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_7421a4300b58427a8a082255a4055b4a@000000_oswg407617oswg1080oswg449_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>姚斌超最初在新加坡办公室工作，之后调任北京，担任北京办公室负责人，从无到有带领Ardian北京团队拓展中国市场，在推动公司私募二级与一级市场平台在中国的发展方面发挥了关键作用。目前，他也是Ardian大中华区负责人。</p>
  <p>“香港是亚洲主要金融中心，也是连接中国内地市场的超级枢纽。”姚斌超表示，“新办公室将为我们提供更强大的平台，以便更好地联系客户、与金融界建立新的合作关系，并加速我们在这一市场的投资策略。”</p>
  <p>那么，香港团队如何开展业务？Ardian介绍，该办公室将主要通过其私募二级市场与一级市场投资及共同投资业务，以进一步支持Ardian在该地区的投资。官网显示，目前其香港办公室正在招人。</p>
  <h2><strong>13000亿，回顾三十年成长史</strong></h2>
  <p>追溯起来，起初Ardian只是全球知名的跨国保险公司安盛集团旗下的一个业务部门。1996年，Dominique Senequier受托组建一个安盛内部投资私募股权的实体（APE），这便是Ardian的前身。</p>
  <p>此后几年里，在Dominique Senequier的带领下，APE业务拓展速度飞速，相继组建了并购基金团队、启动成长型投资策略。1999年，APE又正式推出S基金投资业务，并在伦敦和纽约开设了首批国际办事处，在全球范围内拓展业务版图。</p>
  <p>一个关键的时间点是2013年。当时欧洲金融监管日益强化，不少保险公司和银行陆续开始寻求分拆或出售其持有的基金公司，Dominique Senequier瞅准时机，带领员工收购了APE，Ardian由此诞生。</p>
  <p>近三十年历史，Ardian已经成为一家全球知名的私募股权投资基金公司，资产管理规模1920亿美元，为全球超1860个客户提供投资管理或咨询服务，主要包括私募股权、实物资产和信贷三大业务板块。</p>
  <p>其中，私募股权板块的管理规模最大，达1340亿美元，占Ardian总管理规模的72%。该板块的细分投资策略也最多，包含了S基金、母基金、共同投资基金、并购基金、成长型基金等。</p>
  <p>印象深刻一幕是今年初，Ardian宣布第九期旗舰S基金ASF IX已成功募集到约300亿美元的资金，不仅成为了全球最大的单只S基金，也创下了整个私募股权行业有史以来最大单只基金的规模纪录。</p>
  <p>而Ardian与中国市场的渊源，也是从S基金开始。</p>
  <p>2012年，在S基金在国内还处于荒芜时，还未独立出来的Ardian就在北京开设办事处，开始投资中国市场。目前，Ardian北京办公室已经组建了一支7人团队，寻求S交易机会。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_67ed92565b9248e0b54942070d91e649@000000_oswg608035oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不过，由于S交易大多在水下完成，这些年来关于Ardian在国内投资进展的公开消息并不算多。早在2021年，姚斌超就曾在清科年会上透露，Ardian在中国投资的基金已有40多支，投出资金约30亿美金。</p>
  <p>资料显示，通过私募二级市场与一级市场投资，Ardian已在亚洲投资达43亿美元，覆盖近200只基金，当中完成了12宗涉及亚洲卖方的私募二级市场交易，交易总额达66亿美元。同时，其在亚洲的共同投资组合亦包括11项现有投资，其中就包括Leqee、康基医疗等国内项目。</p>
  <p>时至今日，Ardian在大中华区已拥有近50家长期客户，包括保险公司、主权财富基金、私人财富投资者以及捐赠基金。其中许多合作关系已持续超过二十年。该地区客户的承诺金额已达118亿美元。随着香港办公室的落成，Ardian在中国的团队规模扩大至20人，据悉未来还将继续扩充。</p>
  <h2><strong>中国资产重估一幕</strong></h2>
  <p>Ardian落地香港，这一幕并不意外。</p>
  <p>过去外资布局国内资产第一步，往往就是去香港。尤其今年以来，香港的热闹有目共睹。一个个超级IPO在港股诞生，老铺黄金、泡泡玛特、蜜雪集团组团成为“港股三姐妹”……外资机构纷纷入场抢筹。</p>
  <p>如此一幕，被视为中国资产重估大潮下的一缕缩影。</p>
  <p>从年初DeepSeek爆红带动全球重估中国AI产业链价值，到新消费和创新药等新叙事的不断涌现，海外投资人愈发认识到，“最好的资产在中国”。</p>
  <p>背后的逻辑是，中国科技企业的突破性创新和政策支持，以及多层次的人才储备，形成中国独特的创新生态，吸引海外资金的兴趣。“过去他们问‘中国还能投什么’，现在变成‘如何不错过下一个DeepSeek’。”</p>
  <p>犹记得今年6月，汉斯（上海）私募基金管理有限公司完成私募基金管理人登记，其股东为全球知名房地产运营商Hines。</p>
  <p>随后，开德时璞（上海）私募投资基金合伙企业（有限合伙）在中基协完成基金备案，这是KKR旗下境内私募投资实体。</p>
  <p>全球富豪也来了——据悉已有超过200家家族办公室在香港设立或扩展业务。</p>
  <p>“世界正重估中国科技资产。”不止一位外资投资人感触。今年以来，创投圈明显感受到外资LP正对中国资产表现出强烈的关注意愿。来自中东主权基金、东南亚家办、欧洲养老金的调研团队，正密集在长三角、大湾区等创新氛围浓厚的区域调研。</p>
  <p>甚至投资人跟我们聊起，以往持观望态度的国际资本如今在人工智能、机器人等领域重新流露出“FOMO”心态，不愿错过中国科技崛起的机会。</p>
  <p>这是以往并不常见的一幕。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247701326&amp;idx=1&amp;sn=3fd5346a1dff984715cd09642e26f63b&amp;chksm=ed47e49fea686cb7572f993a2042663f56299a4dc9b39d8c493c0cc3cd42624696a3978ca37b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732568247169</id>
            <title>首个实例理解3D重建模型，NTU&amp;阶越提出基于实例解耦的3D重建模型，助理场景理解</title>
            <link>https://www.36kr.com/p/3532732568247169</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732568247169</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:26:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>人类能自然地感知3D世界的几何结构与语义内容 ，但对AI而言，这“两者兼得”一直是巨大挑战。</p>
  <p>传统方法将3D重建（底层几何）与空间理解（高层语义）割裂处理 ，导致错误累积且无法泛化 。而新方法试图将3D模型与特定的视觉语言模型（VLM）“锁死” ，这不仅限制了模型的感知能力（例如，无法区分同一类别的两个不同实例 ），更阻碍了其适应更强下游任务的扩展性 。</p>
  <p>现在，NTU联合StepFun提出了IGGT (Instance-Grounded Geometry Transformer) ，一个创新的端到端大型统一Transformer，首次将空间重建与实例级上下文理解融为一体。</p>
  <p>为解决上述问题，本研究的主要贡献在于：</p>
  <ul>
   <li><strong>端到端统一框架：</strong></li>
  </ul>
  <p>&nbsp;提出IGGT，一个大型统一Transformer，将空间重建和实例级上下文理解的知识统一在同一个模型中进行端到端训练 。</p>
  <ul>
   <li><strong>大规模实例数据集：&nbsp;</strong></li>
  </ul>
  <p>构建了一个全新的大规模数据集 InsScene-15K，包含15K个场景 、2亿张图像 ，以及通过新颖数据管线标注的高质量、3D一致的实例级掩码 。</p>
  <ul>
   <li><strong>实例解耦与即插即用：&nbsp;</strong></li>
  </ul>
  <p>首创“实例接地的场景理解” (Instance-Grounded Scene Understanding) 范式 。iGGT不与任何特定VLM绑定，而是生成实例掩码作为“桥梁” ，使其能以“即插即用”的方式与任意VLMs（如CLIP, OpenSeg ）和LMMs（如Qwen-VL 2.5 ）无缝集成 。</p>
  <p><strong>多应用支持：</strong>&nbsp;该统一表示极大地扩展了下游能力，是首个能同时支持空间跟踪、开放词汇分割和场景问答（QA）的统一模型 。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_b0e35de3b3a54fd88d6e2b9d20e55652@46958_oswg531809oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_08b092ab649c44ba8d126ff501cda680@46958_oswg62523oswg1080oswg253_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>InsScene-15K数据集的构建</strong></h2>
  <p>InsScene-15K 数据集是通过一个新颖的数据管理流程构建的 ，该流程由 SAM2 驱动 ，并整合了三种不同来源的数据，每种来源的处理方式不同。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_89953c22e5a44bfabeb987f20c9ccda7@46958_oswg351889oswg1080oswg414_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图2&nbsp;</p>
  <p><strong>合成数据 (Synthesis Data - 如 Aria, Infinigen)：</strong></p>
  <p>这是最直接的。在模拟环境中，RGB图像、深度图、相机位姿和物体级的分割掩码被同时生成 。 由于这些模拟生成的掩码是“完美准确的” ，因此无需任何后处理，直接使用。</p>
  <p><strong>真实世界视频采集 (Video Captured - 如 RE10K)：</strong></p>
  <p>这个流程如图2(a)所示，是一个定制化的SAM2视频密集预测管线 。 首先，在视频的第0帧使用SAM生成密集的初始掩码提议 (Initial Mask Proposals) 。 然后，使用SAM2视频对象分割器将这些掩码在时间上向前传播 (Propagate Masks Forward) 。 为了处理新出现的对象或避免漂移，管线会迭代式地添加新关键帧：如果未被覆盖的区域超过阈值，就在新帧上重新运行SAM来发现新物体 。 最后，执行一次双向传播 (Bi-directional Propagation) 来确保整个视频序列的高度时间一致性 。</p>
  <p><strong>真实世界RGBD采集 (RGBD Captured - 如 ScanNet++)：</strong></p>
  <p>这个流程如图2(b)所示，是一个掩码优化流程 (Mask Refinement Pipeline) 。 ScanNet++ 自带的3D标注是粗糙的 。流程首先将这些3D标注投影到2D图像，以获得具有一致ID的初始GT掩码 。 同时，使用SAM2为同一张RGB图像生成形状精确但没有ID的细粒度掩码提议 。 关键步骤是匹配与合并：将SAM2生成的精细掩码与投影的粗糙GT掩码进行对齐，为精细掩码分配正确的、多视图一致的ID 。 通过这种方式，管线极大地提升了2D掩码的质量，使其既保持了3D的ID一致性，又具有了SAM2级别的形状准确性 。</p>
  <h2><strong>IGGT模型的构建</strong></h2>
  <p><strong>IGGT架构概览：</strong></p>
  <p>输入图像被编码为统一的Token表示，随后由几何头（Geometry Head）和实例头（Instance Head）分别处理，以同时生成高质量的几何重建和实例接地的聚类结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_20395d6ca3384982ae0751190f1afebc@46958_oswg452449oswg1080oswg455_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>IGGT 的架构由三部分关键组件构成：</p>
  <p><strong>统一 Transformer (Large Unified Transformer)</strong></p>
  <p>遵循 VGGT，模型首先使用预训练的 DINOv2 提取图像块级 Token。随后，通过 24 个注意力模块对多视图图像的 Token 进行 intra-view self-attention 和 global-view cross-attention，将其编码为强大的统一 Token 表示 Ti。</p>
  <p><strong>双解码头与跨模态融合 (Downstream Heads and Cross-Modal Fusion)</strong></p>
  <p>统一 Token 被送入两个并行的解码器：</p>
  <ul>
   <li>Geometry Head： 继承自 VGGT，负责预测相机参数、深度图和点图。</li>
   <li>Instance Head： 采用 DPT-like 架构，解码出实例特征。</li>
   <li>Cross-Modal Fusion Block： 为了让实例头感知精细的几何边界，团队设计了一个跨模态融合块。它通过一个窗口滑动交叉注意力 (sliding window cross attention)，将几何头的空间结构特征高效地嵌入到实例表示中，显著增强了实例特征的空间感知能力。</li>
  </ul>
  <p><strong>3D 一致性对比监督 (3D-Consistent Contrastive Supervision)</strong></p>
  <p>为了让模型仅从 2D 输入中学到 3D 一致的实例特征，团队设计了一个多视角对比损失 Lmvc。 该损失的核心思想是：在特征空间中，“拉近”来自不同视角但属于同一 3D 实例的像素特征，同时“推开”属于不同实例的特征。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_2baba981a17c4eb9a6ca1be0df6bcde5@46958_oswg21448oswg1080oswg157_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中 m(pi) 和 m(pj) 分别是像素 pi 和 pj 的实例 ID，而 fpi 和 fpj 是其对应的实例特征。</p>
  <h2><strong>基于实例Grounded的场景理解</strong></h2>
  <p>其核心思想是将3D模型的统一表示与下游的特定语言模型（VLMs 或 LMMs）进行“解耦” 。</p>
  <p>这与以往的方法不同，以往的方法通常将3D模型与特定的语言模型（如LSeg）“紧密耦合”或“强行对齐”，这限制了模型的感知能力和扩展性 。首先利用无监督聚类（HDBSCAN）将IGGT预测的3D一致性实例特征分组，从而将场景分割为不同的对象实例 。</p>
  <p>这些聚类结果随后被重新投影以生成3D一致的2D实例掩码 ，这些掩码充当“桥梁” ，实现了与各种VLMs（如CLIP、OpenSeg）和LMMs（如Qwen2.5-VL）的“即插即用”式集成 。这种解耦范式极大地扩展了模型的应用范围：</p>
  <ul>
   <li><strong>实例空间跟踪 (Instance Spatial Tracking)：&nbsp;</strong>利用聚类生成的3D一致性掩码，可以在多个不同视角的图像中密集地跟踪和分割特定对象实例，即使在相机大幅运动的情况下也不易丢失目标 。</li>
   <li><strong>开放词汇语义分割 (Open-Vocabulary Semantic Segmentation)：&nbsp;</strong>实例掩码可以作为“提示”（prompts），被送入任意现成的VLM（如OpenSeg） 。VLM会对每个掩码定义的区域分配一个语义类别，从而实现开放词汇的分割 。</li>
   <li><strong>QA场景定位 (QA Scene Grounding)：</strong>&nbsp;这种解耦的实例聚类可以与LMM（如GPT-40或Qwen-VL 2.5）交互 。例如，可以在多个视图中高亮显示同一个实例的掩码，然后向LMM提问，以在3D场景中执行以对象为中心的复杂问答任务 。</li>
  </ul>
  <h2><strong>实证结果</strong></h2>
  <p>相比于已有的方法，IGGT是唯一一个能够<strong>同时做到重建、理解和跟踪三个任务</strong>的模型，并在理解和跟踪指标上大幅提升。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ae7a57a110b34cbf89251b4364da8c58@46958_oswg172984oswg1080oswg357_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在实例3D跟踪任务上，IGGT的跟踪IOU和成功率高达70%和90%，<strong>是唯一一个能够成功跟踪物体消失又重新出现的模型</strong>。</p>
  <p>IGGT与SAM2和SpaTracker+SAM进行比较。为了清晰起见，所有实例都使用不同的 ID 和颜色进行可视化。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_baa8685454bb4f8994250f8e6313750e@46958_oswg505566oswg1080oswg330_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>团队同时还针对场景做了充分的可视化实验，可以看出IGGT 能够<strong>生成3D一致的基于实例的特征</strong>，这些特征在多个视图中保持区分性：同一类别的多个实例在 PCA 空间中呈现相似但可区分的颜色。</p>
  <p>将3D一致的PCA 结果与基于实例特征的聚类掩码进行可视化。PCA 中相似的颜色表示实例间的特征相似度更高。对于聚类掩码，同一个对象实例在多个视图中共享相同的颜色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_00f686d22539463f9c5ca18eabc1b6da@46958_oswg459535oswg1080oswg410_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在2D / 3D开放词汇分割任务上，得益于Instance-grounded paradigm的特性，可以<strong>无缝接入</strong>最新的Vision-Language Model以提升模型的查询性能。</p>
  <p>Scannet 和 Scannet++ 上的 2D 开放词汇分割的定性结果：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_fc921d9035fe430485b9460eb5643cba@46958_oswg87246oswg1080oswg351_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Scannet 和 Scannet++ 上的 3D 开放词汇分割的定性结果。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_602583ad948e4780bc0bcdebc48a0e19@46958_oswg478289oswg1080oswg494_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，团队还可以利用实例掩码（instance masks）构建视觉提示（visual prompts），并将其接入如 Qwen-VL 等大型多模态模型（LMM），以实现<strong>更复杂的针对场景中特定物体的查询与问答任务</strong>。相反，即便是当前最先进的 LMM 模型，在处理多视图或三维场景理解方面仍存在显著的局限。</p>
  <p>与 vanilla Gemini 2.5 Pro 相比，QA 场景理解的应用：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4e8dc77daeb84fe2856dd3225a7f5191@46958_oswg476982oswg1080oswg492_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://arxiv.org/abs/2510.22706</p>
  <p>项目主页：https://lifuguan.github.io/IGGT_officialHuggingface：https://huggingface.co/datasets/lifuguan/InsScene-15K</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/rT8C2tsPMpRG24vy5AZ84A" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：iGGT团队&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732447267719</id>
            <title>OpenAI前副总裁携DeepMind科学家创业：20余精英科学家+3亿美元押注「AI做科学」</title>
            <link>https://www.36kr.com/p/3532732447267719</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732447267719</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:26:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>「我们的目标是打造一名 AI 科学家。 科学的运作方式是推测世界可能是什么样子、进行实验并从结果中学习」 —— Periodic Labs 官方博客语录。</p>
  <p>2025 年春，一则令人震惊的离职公告传出：<strong>曾任 OpenAI 研究副总裁，负责后训练（post-training）工作的 Liam Fedus 决定离开。</strong>他在一条推文中写道，他对 「AI 在科学中的应用」怀有「最具战略意义的兴趣」——那是他将要探索新征程的方向。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_74f000f3490d4ed7a80484f35b814bd3@46958_oswg660840oswg1080oswg1060_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与此同时，<strong>另一名重量级人物 Ekin Dogus Cubuk</strong>——曾在 DeepMind 主导化学与材料科学团队、参与超过二百多万晶体结构生成项目，也毅然选择离开 DeepMind，转身投入创业。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_18a6bf98321a424aad9b8f10bc27ebf8@46958_oswg421520oswg1024oswg521_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左：Ekin Doğuş Cubuk 右：LiamFedus，图源 TechCrunch</p>
  <p>「互联网 10 万亿 tokens 的有价值数据已近枯竭，靠参数扩张换不来质的飞跃」，Fedus 在分享中直言。Cubuk 的补充更具穿透力：「光靠 LLM 在文献里推演，永远出不了室温超导体这样的颠覆性发现。」</p>
  <p>于是，<strong>两人在今年年初一拍即合，</strong>与其在既有数据池里 「内卷」，不如让 AI 走进实验室，从零创造数据。</p>
  <h2><strong>创立初衷：AI 与物理的灵感碰撞</strong></h2>
  <p>Periodic Labs 的创立源于一次灵感碰撞。7 个月前，Fedus 和 Cubuk 在旧金山的一次对话中探讨生成式人工智能如何重塑科学发现的过程，两人都在不同的实验室中见证了 AI 的力量，却也同时感受到它的边界。</p>
  <p>「我们意识到，生成式 AI 已经能写论文、编程，甚至作画，但它还没有真正帮助人类发现新知识」，<strong>Fedus 回忆说，「科学界的实验速度太慢，而 AI 已经准备好改变这一切。」</strong></p>
  <p>Cubuk 则从物理学的角度切入，他看到机器人自动化、材料仿真和 AI 推理的技术曲线在同一时间点交汇。「这是一个前所未有的契机」，他解释道，<strong>「机器人自动化、模拟精度和大型语言模型的推理能力，终于能融合成一个系统。」</strong></p>
  <p>那天的对话，成为了 Periodic Labs 的起点。几周后，两人正式离开各自的公司，召集了一批志同道合的科学家，创立了一个以 AI 驱动实验科学的研究公司。</p>
  <h2><strong>颠覆传统观念：打造 AI 驱动的科学平台</strong></h2>
  <p>Periodic Labs 自称正在构建「AI 驱动的科学平台」，<strong>其愿景是让人工智能不仅能分析数据，还能设计实验、驱动物理仪器、发现新材料。</strong></p>
  <p>换句话说，它试图将「智能」和「实验操作」融合成一个闭环系统——从算法到试剂瓶，从大模型到机器人手臂。</p>
  <p>这并不是一个新话题。过去十年，AI 在药物设计、蛋白质折叠、材料模拟等方向取得了突破——DeepMind 的 AlphaFold、微软与 Meta 的分子生成模型、Chemify 的自动化化学系统，都在证明——AI 可以参与科学发现。</p>
  <p>但 Periodic Labs 的目标比这些更大。Fedus 和 Cubuk 想做的是一个「通用实验体」——让 AI 不仅能理解科学，还能在真实实验室里动手做实验。</p>
  <p>Periodic Labs 的理念中，<strong>有一个极具颠覆性的观点：失败的数据同样宝贵。</strong></p>
  <p>传统科研倾向于追求「成功实验」的发表，而忽视了数以千计的「负结果」。在 Fedus 和 Cubuk 看来，这些「失败」恰恰是训练 AI 科学家的关键燃料。「每一次实验的偏差、每一次误差反馈，都是模型理解物理世界的机会。」Cubuk 说，「AI 不怕失败，它只怕没有数据。」</p>
  <p>因此，Periodic Labs 并不急于发布成果，而是更注重积累实验数据，以构建一个前所未有的「科学经验数据库」，为下一代科研 AI 奠定基础。</p>
  <h2><strong>技术栈：让 AI、模拟与机器人同频</strong></h2>
  <p>Periodic Labs 的实验室里，机械臂正精准混合金属粉末，高温炉按预设程序升温，光谱仪实时捕捉材料特性数据 —— 这不是科幻电影场景，而是其 「自主实验室」未来的日常运作。这套系统的灵感源自 Cubuk 2023 年发表 Nature 的突破性研究：<strong>当年他主导的 A-Lab 平台在 17 天内合成 41 种新化合物，</strong>证明了 AI 驱动实验的可行性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c169565791424a2ab5484f60b5cd0a92@46958_oswg86194oswg920oswg490_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h4><strong>论文链接：</strong>https://www.nature.com/articles/s41586-023-06734-w</h4>
  <p>如今 Periodic Labs 将这套逻辑推向极致。其核心创新在于它的「三位一体」科学栈：</p>
  <p><strong>* 自动化机器人实验室（Autonomous Robotic Lab）：</strong>能够在全自动环境下进行粉末合成、物质混合与材料制备，精准执行实验指令，极大提升科学研究的速度与重复性。</p>
  <p><strong>*&nbsp;高保真物理模拟（High-Fidelity Simulation）：</strong>通过 AI 驱动的模拟技术，在虚拟环境中快速评估物理与化学反应，为实验筛选提供高精度的假设验证平台。</p>
  <p><strong>*&nbsp;大型语言模型研究助手（LLM Research Assistant）：</strong>语言模型不再仅仅生成文字，而是能解析实验数据、提出修正建议、设计下一轮实验，真正成为科研流程的「认知中枢」。</p>
  <p>三者之间形成了一个闭环系统，首先由融合 LLM 与物理仿真的 AI 系统解析文献、生成实验假设；接着自动化设备执行合成与表征，每轮实验产生数 GB 高维物理数据；最后 AI 分析结果（无论成败）并优化下一轮方案。这种 「虚拟推演 - 实体验证 - 数据反馈」 的循环，彻底颠覆了传统科研模式，让科学发现的速度呈指数级提升。</p>
  <p>「我们的真正创新是数据生产方式」，Cubuk 强调。与依赖互联网文本的传统 AI 不同，<strong>其实验室每天产生的独特数据中，包含大量传统科研中被忽略的 「负结果」。</strong>在材料科学领域，失败实验占比超 90%，而这些未被文献记录的宝贵信息，恰恰成为 Periodic Labs AI 模型的独特养料。正如公司官网上的宣言：「在这里，自然界本身成为强化学习环境」。</p>
  <p>技术可行性的背后，是三大领域的同步成熟：工业级机器人手臂的精度已达 0.1 毫米级，足以胜任复杂合成操作；AI 驱动的物理模拟器能将材料性能预测误差控制在 5% 以内；而 o1 等模型的推理能力，已能处理 「设计超导晶体结构」 这类跨学科复杂任务。三者的结合，让 Fedus 口中 「AI 动手做科学」 的愿景落地为现实。</p>
  <h2><strong>资本狂潮：3 亿美金背后的硅谷共识</strong></h2>
  <p>2025 年 9 月，Periodic Labs 宣布完成 3 亿美元种子轮融资的消息震惊行业。这个数字不仅创下 AI 初创公司种子轮纪录，更颠覆了风投行业的游戏规则 ——&nbsp;<strong>除 Andreessen Horowitz 领投之外，a16z、DST、英伟达 NVentures 等顶级机构悉数跟投，</strong>天使投资人名单更是星光熠熠：亚马逊创始人 Jeff Bezos、前谷歌 CEO Eric Schmidt、DeepMind 灵魂人物 Jeffrey Adgate 均在其列。</p>
  <p>这场资本盛宴的序曲充满戏剧性。当 Fedus 在 2025 年初宣布离开 OpenAI 时，硅谷 VC 圈陷入集体狂热：有投资人递交数十页 PPT 自我推销，有人写下「情书式」投资意向书，更有机构承诺提供从算力到供应链的全方位支持。<strong>但他们真正接到的第一个电话来自 Peter Deng，</strong>他曾是 Fedus 在 OpenAI 的同事，后来成为顶级种子公司 Felicis 的投资者。在听完 Fedus 的愿景后，Deng 甚至忘了公司尚未注册便要写支票。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_fb3d42146a994b178b12c5dad439b995@46958_oswg66242oswg624oswg448_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_55128cc01cc747b8b52ffeaa57be59fe@46958_oswg402358oswg1080oswg1067_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Felicis 投资 blog，图源&nbsp;Felicis 官网</p>
  <p>投资人的狂热并非盲目。a16z 在投资公告中直言：「这是压缩几十年科研进程的机会」。 在半导体散热、新能源材料等百亿美元级赛道，传统研发周期常达 10 年以上，<strong>而 Periodic Labs 的技术路线有望将其缩短至数年。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_f72247ef1b4c49c0a506ddbc35ad5583@46958_oswg296283oswg1080oswg771_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">a16z&nbsp;投资 blog，图源&nbsp;a16z&nbsp;官网</p>
  <p>耐人寻味的是前东家 OpenAI 的缺席。尽管 Fedus 离职时获得管理层祝福，甚至曾暗示可能获得支持，<strong>就连 Sam Altman 也在公司成立时送上了祝福，</strong>但其最终并未出现在投资方名单中。有行业分析师推测，这或许源于技术路线的根本分歧：OpenAI 聚焦通用人工智能，而 Periodic Labs 的 「AI for Science」 垂直路线，更接近谷歌 DeepMind 的战略方向。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_fd5ccd2d79d742c8a74b2f0f38551e8e@46958_oswg479183oswg607oswg711_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>梦之队：半个硅谷精英的集体迁徙</strong></h2>
  <p>3 亿美元融资到账后，Periodic Labs 启动了硅谷史上近乎最惊人的人才招募。短短几周内，<strong>20 多位来自 Meta、OpenAI、DeepMind 的顶尖研究者集体加盟，</strong>其中包括 Transformer 注意力机制发明者、OpenAI Operator 智能体开发者、微软 MatterGen 大模型缔造者等大神级人物。不少人放弃了数百万美元股权激励，只为投身这场 「科研革命」。</p>
  <p>这支团队的跨界特质堪称罕见：<strong>半数成员来自 AI 领域，另一半则是物理、化学、材料科学的专家。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8fd9db5eec784eef91d61d8cb3f497c4@46958_oswg90116oswg716oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">团队名单，图源 Periodic Labs 官网</p>
  <p>豪华顾问团更强化了这种交叉优势。诺奖得主 Carolyn Bertozzi 领衔的学术委员会中，既有斯坦福大学超导物理权威，也有麻省理工学院材料科学泰斗，为 AI 专家提供全新的搜索算法思路。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_40f79ee46da24516b1f89984e63be347@46958_oswg57366oswg839oswg596_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">科学顾问名单，图源 Periodic Labs 官网</p>
  <p>基于这一强大的人才矩阵，<strong>公司将初始目标聚焦于发现新型高温超导材料。</strong>由于当前已知的超导体都需要极低温度或高压才能工作，若能研制出在接近常温下工作的超导体，潜力巨大。Periodic Labs 押注 AI 可以加快这一奇迹的诞生。</p>
  <p>除了超导体，他们还将目光投向半导体等领域的现实难题。目前团队已经在与一家芯片制造商合作，利用专门训练的AI代理优化散热材料，帮助工程师更快迭代解决芯片散热瓶颈。</p>
  <h2><strong>写在最后</strong></h2>
  <p>从毅然选择离职，到 3 亿美元融资的轰动，从两位科学家的理念碰撞，到横跨 AI 与物理的梦之队组建；Periodic Labs 用不到一年时间，完成了传统科研机构数年的进化。其 「AI 科学家 + 自动化实验室」 的模式，不仅可能催生室温超导这样的颠覆性发现，更在重构人类探索自然的底层逻辑。</p>
  <p>正如 a16z 合伙人 Sonal Chokshi 所言：「贝尔实验室曾用晶体管改变世界，IBM 研究院用激光技术开辟未来，而 Periodic Labs 正在用 AI 重塑科学本身。」 当机械臂在实验室里重复第 1,000 次实验，当 AI 模型分析第 10 万组数据，一场由硅基智能驱动的科学革命，已然拉开序幕。</p>
  <p><strong>参考文章：</strong></p>
  <p>1.https://techcrunch.com/2025/10/20/top-openai-google-brain-researchers-set-off-a-300m-vc-frenzy-for-their-startup-periodic-labs</p>
  <p>2.https://periodic.com/</p>
  <p>3.https://globalbizoutlook.com/ai-startup-frenzy-how-periodic-labs-raised-300m-to-revolutionize-scientific-discovery/</p>
  <p>4.https://www.felicis.com/insight/periodic-labs-investment</p>
  <p>5.https://a16z.com/announcement/investing-in-periodic-labs/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/sJvxKzBH4kkVUIXobe5ljQ" rel="noopener noreferrer nofollow" target="_blank">“HyperAI超神经”</a>，作者：椰椰，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732389727361</id>
            <title>港科提出新算法革新大模型推理范式：随机策略估值竟成LLM数学推理「神操作」</title>
            <link>https://www.36kr.com/p/3532732389727361</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732389727361</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:26:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>论文第一作者何浩然是香港科技大学博士生，研究方向包括强化学习和基础模型等，研究目标是通过经验和奖励激发超级智能。共同第一作者叶语霄是香港科技大学一年级博士。通讯作者为香港科技大学电子及计算机工程系、计算机科学与工程系助理教授潘玲。</strong></p>
  <p>在大语言模型（LLM）的数学推理任务中，基于可验证奖励的强化学习（RLVR）已成为提升模型推理能力的重要手段。然而，主流方法如 PPO、GRPO 等仍然依赖为传统 RL 场景设计的策略梯度更新的学习目标，本质上可以被策略迭代（policy improvement）刻画，即包含策略评估（policy &nbsp;evaluation）与策略改进（policy improvement）的不断循环的过程。这些方法常常面临训练不稳定、多样性丧失、调参复杂等问题。</p>
  <p>那么对于 LLM 推理任务，有没有一种更简洁、更本质的解法？</p>
  <p><strong>香港科技大学联合阶跃以及快手等团队</strong>提出了一个令人惊讶的答案：<strong>只需对一个完全随机的策略进行价值评估，就足以找到最优推理路径。</strong>他们由此提出 ROVER（Random Policy Valuation for Diverse Reasoning）以极简思路颠覆传统范式，跳过传统强化学习推理的策略迭代（policy improvement）循环。</p>
  <p>ROVER 不仅在多项数学推理基准上显著超越现有方法，更以「极简主义」实现高质量与高多样性兼备的推理生成。</p>
  <p>目前，论文、代码以及模型均已开源。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_488866f69d224ffca6fc7954eb85bdc9@46958_oswg231174oswg1080oswg342_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <ul>
   <li>论文地址：https://arxiv.org/abs/2509.24981</li>
   <li>论文代码: https://github.com/tinnerhrhe/ROVER</li>
  </ul>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d889802a03884faab01b013bb824295c@46958_oswg457557oswg1080oswg486_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在 AIME24、AIME25 以及 HMMT25 等高难度任务上，ROVER 相比于传统方法大幅提高了 pass@1（+8.2）和 pass@256（+16.8），并且在多种多样性指标上均达到了新的高度（+17.6%）。并且 ROVER 不需要额外维护价值网络（value network），也不需要维护基模型（reference model）计算 KL，从而更加轻量。</p>
  <h2><strong>传统强化学习的「痛点困局」：迭代复杂，代价高昂</strong></h2>
  <p>在 LLM 推理优化中，主流方法（如 PPO、GRPO）可以被广义策略迭代（Generalized Policy Iteration）刻画 —— 反复执行「策略评估（计算当前策略价值，如估计优势函数 advantage）」与「策略改进（更新策略 [数学公式]）」。尽管这些方法能提升性能，却存在核心痛点：</p>
  <ul>
   <li><strong>训练稳定性差：</strong>优化目标「非定常」，模型易崩溃。最近的工作通过叠加复杂技巧如 KL 正则约束、裁剪重要性采样、熵监控等。这些「补丁」让训练如履薄冰，稍有不慎就会引发「熵坍塌」（策略多样性骤降，陷入单一推理路径）。</li>
   <li><strong>PPO 需维护独立的价值网络预测状态价值，并反复执行策略迭代：</strong>GRPO 等方法也需要维护基模型（reference model）计算 KL。这种「重资产」模式，加重了 RL 优化的计算开销。</li>
   <li><strong>推理多样性流失：</strong>为质量牺牲探索，pass@k 性能饱和。基于奖励最大化的传统强化学习方法会使模型过度追求单次推理正确率，牺牲了策略探索能力 —— 模型只会生成少数几种推理路径，牺牲了 pass@k（多次推理覆盖更多可行解的能力）。</li>
  </ul>
  <h2><strong>ROVER 的「极简革命」：随机策略的 Q 值足以指导最优决策</strong></h2>
  <p>研究团队首先指出，大语言模型推理任务可被建模为有限时域马尔可夫决策过程（MDP），具备以下关键特性：</p>
  <ul>
   <li>确定性状态转移；</li>
   <li>树状结构（每个状态有唯一父节点，不存在不相交子树）；</li>
   <li>二元稀疏奖励（正确 / 错误）。</li>
  </ul>
  <p>这与传统 RL 任务（如 Atari 游戏、机器人控制）中常见的随机性状态转移、循环图结构、中间奖励等复杂设定截然不同。</p>
  <p>「我们是否在用过于复杂的工具，解决一个结构上更简单的问题？」—— 这成为 ROVER 研究的出发点。</p>
  <p>在这一简单结构中，研究团队证明了一个颠覆性结论：<strong>均匀随机策略的 Q 值，直接指向最优策略。</strong></p>
  <p>设环境为有限时域、树形状态空间、二元奖励的 MDP，</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_50890ca3bb58419d902d2637302e8628@46958_oswg4077oswg64oswg52_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>&nbsp;为均匀随机策略（每个动作选择概率为 1/|A|），</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_258fd8e9a13747c5bea7ad93a0dd57d1@46958_oswg9690oswg200oswg68_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>&nbsp;为其 Q 值。则贪心策略（如下所示）就是最优策略！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9177adfc7c57453bb2dab934b614bb1d@46958_oswg8882oswg646oswg61_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>证明直观：树形结构中，若某动作</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_e0dde2f91c4e42bebe95ec24dd91b136@46958_oswg7986oswg44oswg48_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>的子树存在正确解答，则&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_34d2c50640244589b28011865755ddeb@46958_oswg10252oswg284oswg66_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>；反之&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_b63985c70b0f4e8488aedac573e822e0@46958_oswg10198oswg284oswg64_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>。因此，贪心选择</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_24af70c5e48f4026b957676e6d46ba21@46958_oswg933oswg53oswg61_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值最大的动作，必然导向包含正确解答的路径。</p>
  <p>因此，策略学习过程可以简化为下图形式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3f228e75e1e9421196262fbfee2be2bb@46958_oswg373526oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>ROVER 算法流程：三步极简，免去迭代</strong></p>
  <p><strong>（1）Q 值估计：</strong></p>
  <p>ROVER 通过广义贝尔曼方程计算均匀随机策略下状态 - 动作对的</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_63f848c5b3db4c01aadd656c36b208ee@46958_oswg933oswg53oswg61_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值，因此方程用均值算子表达：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_36765141df2045deb5f013b34421c047@46958_oswg7322oswg752oswg102_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_2ae1eb2265b14b72b35d8b6904921c7a@46958_oswg8664oswg120oswg56_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>&nbsp;为奖励，s' 为执行动作 a 后的新状态，V 为动作空间。</p>
  <p><strong>（2）策略构建：</strong></p>
  <p>尽管贪心选择可保证最优性，却可能丧失多样性。为此，ROVER 引入基于</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_626afdefaa48414e8c1a45550cc0f9ba@46958_oswg933oswg53oswg61_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值的 softmax 采样：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_516486f005ca46d789780738d2793526@46958_oswg16156oswg594oswg136_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_f0da94a10d1b46789932f92e2cc7b5fb@46958_oswg4021oswg34oswg52_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>是温度系数，控制探索程度。这种方式既保留了高价值路径的优先级，又能探索多条有效推理路线，显著提升 pass@k 表现。</p>
  <p><strong>（3）训练目标：</strong></p>
  <p>在实际实现中，ROVER 还引入了：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_1851fedb3cf947d1bb7c43e4fd8c8563@46958_oswg933oswg53oswg61_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>函数内化于 LLM 参数，无需训练额外价值网络：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_63eab19e356b445392ecbe1dd9246a4b@46958_oswg15355oswg840oswg74_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种「自监督」式参数化，让模型学习「相对改进」而非「绝对价值」，既减少计算量，又提升稳定性。</p>
  <p>组内奖励中心化，降低方差，即&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9842d8a580b04bb097e988192b366cfd@46958_oswg9558oswg294oswg58_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>。避免高方差奖励干扰</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_30cdd0aa846a42069462d2cba65ad4d3@46958_oswg933oswg53oswg61_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值学习。同时，将中心化奖励「广播」到生成的全序列 token，实现细粒度信用分配。</p>
  <p>ROVER 的损失函数可以表示为</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_2df904e5200f43f484c122a18d70f717@46958_oswg20226oswg1070oswg148_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>算法伪代码如下</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_238f4ca351e84e5da701292ff2a1b800@46958_oswg350407oswg1080oswg449_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>实验结果：全面领先，多样性显著提升</strong></h2>
  <p>研究团队在数学推理基准（AIME24/25、HMMT25、AMC、MATH 等）、Countdown 任务以及 O.O.D. 任务 GPQA-diamond 上验证 ROVER，覆盖 Qwen3-8B/4B、DeepSeek-R1-1.5B 等模型，结果堪称「降维打击」：</p>
  <p><strong>1. 数学竞赛任务：pass@1 与 pass@k 双突破</strong></p>
  <p>在 Qwen3-8B-Base 模型上，ROVER 的 pass@1 在 AIME24 达 30.6（比最佳基线 DAPO 高 19.1 分）；在 HMMT25 任务中，pass@1 从基线最高 7.1 跃升至 14.6（提升 106%）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ecbd035450a4486eaa6a6916d1023fd2@46958_oswg367440oswg1080oswg533_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更关键的是 pass@k 性能：<strong>传统 RL 方法（如 GRPO）的 pass@k 随 k 增大迅速饱和，而ROVER 在 pass@256 上也能与基线拉开明显差距，展现持续探索能力。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_1ba14e498cba4911ab265f88bfbe937a@46958_oswg312346oswg1080oswg408_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2. 策略多样性：比基线高 17.6%，覆盖更多解题路径</strong></p>
  <p>采用 LLM-as-Judge 方法评判所有方法生成的正确答案的推理内容多样性，ROVER 训练的策略多样性比基线平均提升 +17.6%，在 AIME24 上发现更多独特解题路径。在其他多样性指标如余弦距离（cosine distance）与利用率（utility）等，ROVER 在不同温度下仍表现出一致的高多样性。</p>
  <p>受益于多样性的提升，ROVER 在 GPQA-diamond 等与数学无关的 O.O.D 任务上也表现最佳。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_e4e89d0e924c49f683669a5534191aea@46958_oswg297669oswg1080oswg335_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>3. 案例展示：ROVER 发现全新解法</strong></p>
  <p>通过「策略数量」指标（同一问题生成的不同推理路径数）评估，&nbsp;<strong>ROVER 在各个任务上均能发现更多的解题策略。</strong>如下图所示，在「2x3 网格数字排列」问题中，基模型与 GRPO 均仅发现 2 种策略，而 ROVER 可以发现 4 种（包括「隔板法」「容斥原理」等不同数学工具）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_038551ca094946f0b75dd813c65bc36f@46958_oswg859549oswg1080oswg945_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>启示与展望</strong></h2>
  <p>ROVER 的提出，不仅是一次技术突破，更是一次方法论的反思：<strong>在某些结构化任务中，简化而非复杂化，才是推进性能的关键。</strong>「Simplicity is the ultimate sophistication.」 —— ROVER 这一基于简单随机策略的新方法，诠释了达芬奇这句名言在 AI 时代的新内涵。</p>
  <p>更多方法细节与实验分析请见原论文。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/4kURevxLskZZ9YyQ6BkYKQ" rel="noopener noreferrer nofollow" target="_blank">“机器之心”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532643813317511</id>
            <title>安克又遇到了麻烦</title>
            <link>https://www.36kr.com/p/3532643813317511</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532643813317511</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:22:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>安克又遇到了麻烦。近日，<strong>安克在日本启动产品召回，波及的产品数量高达50多万件。</strong></p>
  <p>在过去一年多的时间里，安克在中、美、日等主要市场，启动多次大规模召回，导致了巨大的经济损失和品牌信任危机。</p>
  <p>安克作为一个追求“极致创新”的公司，<strong>为何屡屡深陷大规模产品召回的泥潭？</strong></p>
  <p>日前，安克披露了前三季度的财报。财报的数字依然看起来很漂亮，<strong>但在其营收和净利增长的表面下，隐藏着微妙的变化。</strong></p>
  <h2><strong>01.安克为何连遭“暴击”？&nbsp;</strong></h2>
  <p>近日，安克日本公司（Anker Japan）宣布，因旗下产品引发41起火灾事故，召回约41万台移动电源以及超10万台内置锂电池的蓝牙音箱。1</p>
  <p><strong>这些产品都采用了某一批次的锂电池组件，</strong>而该批次电池在特定条件下可能出现过热现象，甚至引发火灾风险。据计算，安克此次召回产品总计约23.73亿日元，折合人民币为约1.1亿元人民币。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9ecfca6fbaf24798afea5a531abcfca7@000000_oswg399855oswg990oswg630_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>近半年来，安克频发召回事情，6月，安克在美国召回115万台移动电源，9月，安克在美国召回48万个移动电源，<strong>事隔一个月，安克又在日本大规模召回产品。</strong>多轮召回事件，累计涉及产品已超238万台，据不完全统计，安克直接回收成本在4.32亿至5.57亿元之间。</p>
  <p>这意味着，在一个较短的周期里，安克接连遭受了经济与声誉的双重损失。多年以来，“安克品质”在消费者心目中留下了深刻印象，然而，频繁发生的召回事情，让消费者应接不暇，对“安克品质”产生了信任危机。</p>
  <p><strong>安克为何深陷产品召回的泥潭之中？原因大致有几个：</strong></p>
  <p><strong>一、轻资产模式的“惯性”太大：</strong>从诞生的那一刻开始，安克在产业链上占据了一个非常有利的位置。在国内工厂埋头苦干，给外国品牌代工之际，安克很早布局了亚马逊等终端渠道，在卖出货物的同时，还建立起了自己的品牌矩阵，实现了“效果+品牌”的双丰收。</p>
  <p>可以说，安克一上来就往产业链<strong>“设计、研发+销售、品牌”</strong>两端发力，从而占据产业链两端的制高点，拿走了大部分附加值。相比之下，处在底部“生产制造”环节的大量工厂，往往只能吃到维持温饱的一点利润。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3784b54cd8dc4a5c97b48124a6005ffd@000000_oswg92587oswg1046oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/安克持续向产业链两端发力</p>
  <p>正是依托这种“轻资产”模式，安克一路狂飙，过得也很舒服，形成了巨大的“惯性”，<strong>越发对下沉到产业链底端没有了兴趣。</strong>当然，安克也会做严格的品控，但相比自己下沉到生产端，其在供应商管理和现场监督的品控环节，往往带着<strong>“上帝视角”</strong>，对产品的一些细节，难免会有一些疏漏，以至于出现了这一波因“电池问题”而引发的大规模召回事件。</p>
  <p><strong>二、安克做得有点杂：</strong>安克从充电、扩展到储能、音频、安防、家居等方向，形成了一个品牌大矩阵。多品类持续扩张，快速推出多型号产品，使安克在每个产品线和子产品线上面临不同的供应商，在体系日益庞大化和复杂化的情况下，<strong>容易使某个产品（原材料）批次、某个供应环节出现薄弱环节，</strong>一旦这一环节出现问题，就出现了牵一发而动全身的影响。老话说得好，老虎再强，也有打盹的时候。</p>
  <p><strong>三、依托巨大的谈判优势，使供应商陷入无序的“内卷”：</strong>安克在海外建立了坚实的渠道，也树立了品牌影响力，销量庞大而稳定，因此在供应商那里有极具优势的谈判权。虽然一直以来安克对其供应商比较愿意让利，然而，但安克遭到绿联、倍思等竞对的持续“围堵”，作为上市公司，安克面临着越来越大的业绩压力，尤其是美国加税之后，<strong>安克表示要在产品设计、生产过程控制等方向，实施全链条式的降本增效。</strong>那么，安克向供应商要更低的价格，也在逻辑之内。</p>
  <p>供应商在压力之下，为了获得安克的订单，不得不维持更低的供货价，进而可能偷工减料，混用次级原料，最终导致一损俱损。一直以来，安克的供应链过于集中，前三大电池供应商贡献75%采购量，<strong>其中包括很擅长卷低价的中小厂商，</strong>例如，向罗马仕供应产品的普锐斯，也是安克的重要供应商之一。</p>
  <p>因此，对于安克来说，适当慢下来，找到属于自己的“相对边界”，往产业链底端下沉一些，深入一些，同时敞开更大的胸怀，<strong>让产业链上下游的合作伙伴多拿走一些利益，</strong>彼此形成更良性、更健康的“共生”关系，或许是它要更多思考的问题。</p>
  <h2><strong>02.安克的微妙变化</strong></h2>
  <p>安克近日发布了2025年第三季度财务报告，数字还是很漂亮。</p>
  <p>2025年前三季度，安克实现营收210.19亿元，<strong>较去年同期增长27.79%；</strong>归母净利润19.33亿元，<strong>同比增长31.34%。</strong></p>
  <p>然而在第三季度（7-9月），我们可以看出一些微妙的变化。在第三季度，安克实现营收81.52亿元，同比增长19.88%——<strong>增速为2023年第一季度以来最低</strong>，与此同时，扣非归母净利润为5.21亿元，<strong>同比下降2.92%</strong>。</p>
  <p>这意味着，安克继续在增长，但是它的增长在放缓。此外，安克面临着前所未有的现金流压力。从年初至报告期末，<strong>安克的经营现金流为-8.65亿元，</strong>较上年同期的16.51亿元，大幅下降152.38%。</p>
  <p>安克经营现金流转负，有几个因素导致，一是在加税背景下，安克大规模增加了备货；二是工资和分红上涨；三是大规模产品召回，产生了额外的售后处理成本和资金损失。</p>
  <p>在2025年上半年，安克的存货余额一路狂飙，<strong>上升到了52.95亿元，比去年年底多了20亿。</strong>值得注意的是，这批存货的2.38亿元，被计提了跌价准备，意味着这批货很可能会被低价处理。</p>
  <p>当前，安克第三季度财报的微妙变化，受多方面的影响，一是召回事件导致资产减值增加、毛利率下滑，存货高企引发资金周转压力；二是美国加税，推高其成本，影响其营收；三、召回事件使品牌信任度受损。</p>
  <p>电池，将是安克未来一个重要的“坎”，已售出产品的电池可能在未来会被排查出问题，从而导致规模化的召回，同时，<strong>海外的电池政策的变化，也将给安克带来一系列的压力。</strong></p>
  <p>2025年3月欧盟通过的电池废物管理新规，给安克的欧洲业务带来压力。该法规将所有碱性电池重新划为危险废物，新增锂基电池专门管理代码，<strong>要求对电池全生命周期，</strong>实施严格追踪管理。这意味着，安克等企业要投入巨资，调整生产流程、升级回收体系。<strong>安克的大量产品含有电池，这一新规，无疑将给其带来更大的成本压力。</strong></p>
  <p>召回事件给安克带来的一场品牌信任危机，日本山田电机下架全部安克移动电源，美国亚马逊上Anker品牌差评率飙升。<strong>一些消费者表示，不在召回范围的产品仍出现发热异常等问题，并强制要求退货退款。</strong>比如，以为用户称呼，一款A1680型号充电宝自燃，但其SN码查询显示不在召回范围。这种“未召回产品仍存风险”的情况，进一步加剧了市场恐慌。</p>
  <p>不过，安克也做出了一系列回应，包括更换供应商，加强品质监督等。我们希望安克可以迅速走出阴影。（蓝海亿观）</p>
  <p><strong>数据源：</strong></p>
  <p>1.深圳商报/读创：《安克创新又翻车了，52万件产品在日本召回，上月48万个充电宝在美国召回，高度依赖海外市场》</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU2NzgwNjM1MQ==&amp;mid=2247522088&amp;idx=1&amp;sn=e6c183a7935f6cb829f6fa012a218512&amp;chksm=fdc2a857d329f4b0f12482b0e55227301ed3e079b0ddac0ccb37b003fcd1ea7a8474ccb5c19f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“蓝海亿观网”（ID：egainnews）</a>，作者：蓝海亿观，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532754556426376</id>
            <title>两次失败后，海辰储能第3次IPO怎么还有这么多bug？</title>
            <link>https://www.36kr.com/p/3532754556426376</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532754556426376</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:19:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>随着碳中和目标成为全球共识，储能行业站上了时代风口。作为2025年上半年全球储能电池出货量排名第二的企业，厦门海辰储能科技股份有限公司（以下简称“海辰储能”）的资本之路却走得异常坎坷。</p>
  <p>10月27日，海辰储能向港交所递交招股书，再次开启其资本化征程。这是海辰储能继2023年7月在A股辅导备案又撤回、今年3月在港交所首次递表失效后，第三次冲刺IPO。然而，细览其最新提交的招股书，诸多遗留的“老问题”与浮现的“新风险”相互交织，仿佛在提醒市场：<strong>这家备受瞩目的储能新星，其上市征程依然布满荆棘。</strong></p>
  <p>面对这份关键的招股文件，市场有理由要求更高透明度的信息披露和更严谨的合规态度，这不仅是监管的要求，更是赢得投资者信任的基石。</p>
  <h2><strong>1.&nbsp;业绩侧：增长依赖政策与市场波动</strong></h2>
  <p>海辰储能的业绩增长故事，<strong>在很大程度上建立在对外部政策与少数大客户的强依赖之上</strong>，其内在的稳定性和抗风险能力明显不足。海外市场收入的“过山车”式表现就是例证。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_a1c56ca3f71e45f48b48483fc9af2f20@46958_oswg59047oswg966oswg671_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能国内外市场历年收入情况 &nbsp;来源/互联网 新能源观截图</p>
  <p>招股书披露，<strong>2024年，海辰储能源自美国的收入占比一度高达约26.2%，这主要得益于当时美国对进口光伏及储能产品实施的关税暂免政策。然而，这一政策红利具有高度不确定性。随着政策变动，2025年上半年，美国市场收入贡献遭腰斩，骤降至约11.8%。</strong>这种断崖式下滑清晰地表明，海辰储能的海外业务根基远未牢固。</p>
  <p>为弥补美国市场的流失，海辰储能试图开拓欧洲、中东、非洲、澳大利亚、亚洲等新兴海外市场，但2025年上半年，这些市场的总收入贡献仅为5.7%，可谓是“远水难解近渴”。这种市场结构使得海辰储能的业绩极易受国际贸易政策和地缘政治的冲击，缺乏自主可控的增长韧性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_89c12554a24f4f6eafdcc45897a27df9@46958_oswg112387oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能五大客户各年度收入占比 来源/互联网 新能源观截图</p>
  <p><strong>客户集中度风险是海辰储能另一个悬而未决的难题。</strong>海辰储能五大客户收入占比最高达到47.9%，最大客户占比最高达到17.3%。招股书中坦承，“我们的客户集中化，并且面临相关风险”，这种对少数大客户的深度依赖，极大地削弱了公司的议价能力和业绩稳定性，“可能对我们产生重大不利影响”。</p>
  <p>在储能产业链下游集成商和运营商高度集中的格局下，一旦某个核心客户因自身战略调整或竞争对手的激进报价而转向，海辰储能的营收便会面临“地动山摇”的风险。海辰储能最重要的海外客户之一美国储能巨头Powin就已经申请破产。在激烈的行业竞争中，大客户订单的流失往往只在瞬息之间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8f56208bcc6641f285de8dfb662ee7e2@46958_oswg91346oswg960oswg459_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能历年“贸易应收款”情况 &nbsp;来源/互联网 新能源观截图</p>
  <p>运营效率的指标同样亮起红灯。海辰储能的贸易应收款项从2022年末的2.232亿元激增至2024年末的83.145亿元，应收账款周转天数从2022年的11.8天大幅延长至2025年上半年的227.9天。这意味着，<strong>卖出产品后，海辰储能平均要等超过7个月才能收回货款。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0a648a306bd743fca291c29d1dc97b7e@46958_oswg84530oswg957oswg830_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8e0b8ae3d8444453b9d66836c4acf7b9@46958_oswg121785oswg932oswg540_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能流动负债--存货持有情况 &nbsp;来源/互联网 新能源观截图</p>
  <p>与此同时，海辰储能存货也从2022年末的19.677亿元升至2024年末的21.251亿元，并在2025年上半年猛增至42.967亿元。高企的应收账款不仅占压了巨额资金，还伴随着巨大的坏账风险；而<strong>快速堆积的存货在技术迭代飞快的储能行业里，则面临着巨大的跌价减值压力。</strong></p>
  <p>这两项资产的异常增长，共同指向了海辰储能在市场开拓、销售回款和供应链管理方面可能存在的效率问题，其高增长的背后，是以牺牲资产质量和运营效率为代价的。</p>
  <h2><strong>2.&nbsp;财务侧：数据透明度与健康度存疑</strong></h2>
  <p>海辰储能在展现其营收规模快速增长的同时，也暴露了财务健康度的深层次隐忧。<strong>最核心的问题在于其经营现金流的“隐匿”与盈利质量的真实性。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8058baf14ae64a8384370c2d4996151a@46958_oswg47797oswg960oswg555_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能现金流量表现 &nbsp;来源/互联网 新能源观截图</p>
  <p>招股书披露，海辰储能在2022年、2023年及2024年上半年，经营活动所得现金流量净额，分别为-2.6亿元、-17.46亿元、-2.83亿元。一家健康的企业，其利润最终应转化为实实在在的现金流入。<strong>海辰储能这种状况通常意味着公司的利润大量沉淀在应收账款和存货中，缺乏真正的“造血”能力。</strong>这让人不得不质疑海辰储能盈利的成色和可持续性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3c60a9b6dea44e34a615359be5fa5793@46958_oswg50636oswg960oswg585_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能历年资产负债比 &nbsp;来源/互联网 新能源观截图</p>
  <p>与此同时，高企的负债率如同达摩克利斯之剑，悬于头顶。<strong>截至2025年6月30日，海辰储能的资产负债率高达75%，显示出短期偿债压力巨大。</strong>但这并没有妨碍其激进的产能扩张计划。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_01a7bea82c7a4275a2d4d2af9aba7b8f@46958_oswg87006oswg969oswg597_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_b1b51c87273e47b08e75d2d267272746@46958_oswg80355oswg1080oswg490_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能产能扩张计划--业务规划 &nbsp;来源/互联网 新能源观截图</p>
  <p>招股书显示，海辰储能计划将募集资金用于山东、重庆等地的多个生产基地建设。然而，当前储能电池行业正经历残酷的“价格战”，产能利用率呈现结构性过剩。</p>
  <p>根据高工产业研究院（GGII）提供的数据，截至2023年上半年，我国储能电池产能利用率已经从2022年的87%下降至不足50%，这一变化主要由行业盲目扩产导致。</p>
  <p>在如此背景下，海辰储能仍意图大规模投入资本开支以扩张产能。若未来市场需求不及预期，或技术路线发生颠覆性变化，巨额的资本支出和随之而来的折旧摊销，将可能成为进一步冲击公司的现金流，导致产能扩张与需求错配的矛盾加剧。</p>
  <p>投资者需要思考，在行业竞争白热化的阶段，这种增长是否以牺牲财务稳健性为代价？<strong>海辰储能若想真正取信于市场，必须对经营现金流的改善路径、负债管理策略以及产能规划的详细可行性，做出远比现在更为清晰和令人信服的披露。</strong></p>
  <h2><strong>3.&nbsp;诉讼侧：法律纠纷不断，影响品牌形象</strong></h2>
  <p>对于正处于冲刺上市关键期的海辰储能而言，与行业巨头宁德时代的系列法律纠纷，无疑是其必须直面和妥善处理的最大“灰犀牛”事件。这其中，<strong>不正当竞争诉讼直接冲击着海辰储能的治理核心与人才战略。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_28db7f1a090844398d4f09483036efd5@46958_oswg58793oswg966oswg465_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能相关法律诉讼 &nbsp;来源/互联网 新能源观截图</p>
  <p>2025年6月10日，宁德时代以不正当竞争为由，将海辰储能实控人吴祖钰、珠海海辰、厦门稀土材料研究所等一并告上宁德中院。</p>
  <p>而实际上，这已经不是宁德时代对海辰储能发起的首次诉讼。回溯纠纷起点，<strong>2023年9月，宁德时代以违反竞业协议为由起诉吴祖钰，最终由其家属代为支付100万元违约金。</strong></p>
  <p>同年11月，宁德时代再诉前员工张敏违反竞业限制，离职后虽名义入职厦门稀土材料研究所，却多次佩戴海辰储能工牌进出厂区。宁德时代指控他“借道研究所”为海辰储能服务，违反竞业限制。</p>
  <p>2025年7月，海辰储能前总裁办主任冯登科因涉嫌侵犯商业秘密被宁德警方带走，宁德时代指控其化名潜伏供应商并转移复合集流体技术，而海辰储能则称该技术属公知技术，且未在产品中使用。</p>
  <p><strong>招股书披露，宁德时代向海辰储能发起8起诉讼，涉及到海辰储能的创始人及核心管理层，索赔总额超1.5亿元。</strong>一旦败诉，除了现金流压力加大外，海辰储能实控人可能面临在一定期限内无法参与公司日常运营管理的窘境，这将对海辰储能的战略定力、团队稳定性和投资者信心造成难以估量的打击。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_f1a20238972b4965858c6566b7a99cd4@46958_oswg64761oswg938oswg317_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能与宁德时代诉讼情况 &nbsp;来源/互联网 新能源观截图</p>
  <p>而专利诉讼则直接威胁到海辰储能的产品生命线与技术声誉。</p>
  <p><strong>诉讼不仅可能带来直接的财务赔偿和产品禁售风险，更向市场传递出一个不确定信号：海辰储能的技术路径是否完全清晰、自主？其产品上市与出口是否会面临潜在的知识产权壁垒？</strong>这些不确定性，已经成为海辰储能IPO道路上无法回避的障碍，试图“轻描淡写”或“模糊处理”的做法，都只会加剧市场的疑虑。</p>
  <h2><strong>4.&nbsp;隐藏风险：合规与信息披露的漏洞</strong></h2>
  <p>除了财务与业务层面的显性风险，海辰储能招股书中暴露出的部分合规与信披“软肋”，同样不容忽视，它们反映了公司内部治理的精细度有待提升。其中，生产经营场所的租约未登记问题，是一个典型的合规隐患。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_6aa67a2750094ddd9e40bd63fff242e5@46958_oswg95593oswg987oswg471_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能生产经营场所租约未登记 &nbsp;来源/互联网 新能源观截图</p>
  <p>招股书显示，海辰储能及其子公司有15份重大经营租约未能在相关部门办理登记备案。根据相关规定，此类情况可能面临每份租约1000元至10000元的罚款。尽管单笔罚款金额不高，但集中爆发的合规瑕疵，会让监管机构和投资者对海辰储能的内控体系与法律意识产生疑问。在IPO审核中，“细节决定成败”是永恒的铁律。</p>
  <p><strong>在环境、社会及管治（ESG）信息披露方面，海辰储能的披露深度明显不足。</strong>在全球范围内，特别是对志在开拓欧洲市场的企业而言，ESG已从“加分项”变为“准入证”。招股书中仅提及已成立ESG委员会，但对于关键的碳排放强度数据、电池核心材料的溯源管理体系、以及针对即将全面实施的欧盟《电池与废电池法规》,特别是备受关注的“电池护照”要求的筹备情况，均未作详细说明。对于一家营收高度依赖海外市场的企业来说，这些信息的缺失，可能意味着未来产品出口面临“绿色壁垒”的风险正在累积。</p>
  <p>最后，财务数据本身的勾稽关系与真实性，也需要经过市场的火眼金睛。例如，在毛利率大幅低于行业头部企业的情况下，公司如何维持竞争？在经营现金流持续为负的同时，支撑大规模扩产的巨额资金从何而来，其融资渠道和资金成本是否可持续？<strong>在研发投入持续垫底的情况下，如何做到4300余项专利申请数量和2024年世界第三、2025年上半年世界第二的出货量排名？</strong>这些核心问题，都需要比当前招股书更为透彻的解释。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_14d7567d08af48f2b2036a83c47250db@46958_oswg48141oswg1024oswg572_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_5969b2761a114f8da729507b87f264d1@46958_oswg61391oswg951oswg486_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图/海辰储能研发投入与专利数量 &nbsp;来源/互联网 新能源观截图</p>
  <p>信息披露的最高境界，并非简单地堆砌数据，而是通过清晰、连贯、可验证的逻辑链条，让投资者能够自行做出判断。在海辰储能目前的招股书中，一些关键环节的缺失和模糊，使得这一逻辑链条出现了断点。</p>
  <p><strong>海辰储能身处一个充满前景的黄金赛道，但其自身在财务健康、业绩韧性、法律风险和内控合规等方面所暴露出的问题，同样是真实而严峻的。</strong>这些“bug”并非彼此孤立，它们环环相扣，共同指向公司商业模式的核心——盈利质量、增长可持续性和抗风险能力。</p>
  <p>对于海辰储能而言，当务之急已不再是讲述一个宏大的增长故事，而是以最坦诚和负责任的态度，解决这些“bug”。在IPO的征途上，海辰储能已经历了两次失败。<strong>第三次递交的招股书，不应只是“修补版”，而必须是一次彻底的提升与革新。</strong></p>
  <p>唯有以严谨的态度完善信息披露，以开放的姿态回应投资者关切，方能真正打消市场疑虑，取信于人。对于投资者而言，在审阅这份招股书时，也需要拨开增长数据的迷雾，更加聚焦于公司内在的健康度与风险的化解能力，从而做出更为审慎和理性的判断。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/zCai64U2ONe0TJPHfVcqhw" rel="noopener noreferrer nofollow" target="_blank">“新能源观”</a>，作者：又见编辑部，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732628769664</id>
            <title>最火VLA，看这一篇综述就够了</title>
            <link>https://www.36kr.com/p/3532732628769664</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732628769664</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:17:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>ICLR 2026爆火领域VLA（Vision-Language-Action，视觉-语言-动作）全面综述来了！</p>
  <p>如果你还不了解VLA是什么，以及这个让机器人学者集体兴奋的领域进展如何，看这一篇就够了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d37b4537f6184e1ca4fdd040c1ecc4c1@46958_oswg527413oswg1080oswg610_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>文章作者<strong>Moritz Reuss</strong>是2025年Apple AI/ML学者奖得主，曾在RSS、ICLR、NeurIPS等顶级会议多次发表研究成果。这篇综述既是一线研究者的实战总结，也是洞察趋势的前沿观察。</p>
  <p>文章一出，评论区好评不断，甚至顶级猎头Mark Wallace直接抛出了橄榄枝。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_0051c8f4b9c542968b4430fc9ca1bbc1@46958_oswg114824oswg914oswg732_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个VLA，究竟有多火？</p>
  <p>据统计，<strong>VLA模型</strong>相关投稿量，从去年的个位数飙升至164篇，足足增长了18倍。</p>
  <p>这股热潮背后，让机器人<strong>“听懂人话、看懂世界、动手干活”</strong>，正成为AI领域极具吸引力的前沿阵地。</p>
  <p>然而，在这片繁荣之下，一个问题也随之浮现：<strong>当我们谈论VLA的进步时，我们到底在谈论什么？</strong></p>
  <h2><strong>明确VLA的概念</strong></h2>
  <p>在深入探讨技术趋势前，我们必须先明确一个基本概念：<strong>什么样的模型，才有资格被称为VLA？</strong></p>
  <p>学术界对此尚无统一定义，但研究员<strong>Moritz Reuss</strong>在他的综述中提出了一个标准：</p>
  <blockquote>
   <p>一个模型必须使用经过大规模、互联网级别的视觉-语言数据预训练过的骨干（pre-trained backbone），才能被称为VLA。</p>
  </blockquote>
  <p>这一定义强调模型能力的来源：VLA必须具备通过图文预训练习得的<strong>语言理解、视觉泛化和任务迁移能力</strong>。</p>
  <p>代表模型如Google的PaLI-X，或开源项目Llava、Florence-2等。</p>
  <p>而如果一个模型只是简单地将独立的视觉编码器和文本编码器拼在一起，那它更应该被称为<strong>“多模态策略”（Multimodal Policies）</strong>。</p>
  <p>与之相关，还有一个概念值得一提：<strong>大型行为模型（Large Behavior Models, LBMs）</strong>。这是丰田研究院提出的术语，指在“大规模、多任务的机器人演示数据”上训练出的策略。</p>
  <p>可以这样理解：</p>
  <p>VLA强调的是“<strong>基因</strong>”，即必须继承自一个强大的VLM（视觉语言模型）</p>
  <p>LBM强调的是“<strong>养料</strong>”，即必须用海量的机器人操作数据进行训练</p>
  <p>一个在大量机器人数据上微调的VLA，同时也是一个LBM。</p>
  <p>但一个LBM，不一定是一个VLA。<strong>搞清楚这个边界，才有助于我们理解不同技术路线的侧重。</strong></p>
  <h2><strong>透过ICLR 2026看VLA八大趋势</strong></h2>
  <h3><strong>趋势一：VLA的高效架构新范式</strong></h3>
  <p>如果说今年VLA架构有什么新风向，当属<strong>离散扩散模型（Discrete Diffusion）</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4aa5161a1bed4fdbb4fa88dce011398d@46958_oswg120478oswg1080oswg267_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>传统的自回归模型一个字一个字写，必须生成完上一个动作单元，才能生成下一个。</p>
  <p>而离散扩散模型则可以并行化地一次性生成整个动作序列。这带来了几个好处：</p>
  <ol>
   <li><strong>高效生成</strong>：减少前向传播次数，提高推理效率</li>
   <li><strong>思维动作融合</strong>：可并行生成动作与推理过程（如子目标、关键物体位置），即<strong>具身思维链（Embodied Chain-of-Thought, ECoT）</strong></li>
  </ol>
  <p>关于这个趋势，本次ICLR上涌现了《DISCRETE DIFFUSION VLA》《dVLA》等多篇论文，在LIBERO评测中取得了近乎饱和的表现。</p>
  <h3><strong>趋势二：具身思维链（ECoT）让机器人先想后做</strong></h3>
  <p>让机器人更聪明，光靠模仿是不够的，它还得学会“思考”。<strong>具身思维链（Embodied Chain-of-Thought, ECoT）</strong>正是这一思路的集中体现。</p>
  <p>其核心思想是：在生成动作前，<strong>先生成一系列中间推理步骤</strong>，使机器人具备更强的计划与解释能力。</p>
  <p>这些步骤可以是：</p>
  <ul>
   <li><strong>文本规划</strong>：“我需要先找到红色杯子”</li>
   <li><strong>视觉感知</strong>：定位关键目标</li>
   <li><strong>轨迹构图</strong>：设计移动路径</li>
  </ul>
  <p>这种<strong>先想后做</strong>的模式不仅更具可解释性，也显著提升复杂场景中的泛化能力。</p>
  <p>但ECoT对高质量标注数据依赖较大，而这类数据仍较稀缺。</p>
  <p>本次ICLR中，如《ACTIONS AS LANGUAGE》《EMBODIED-R1》等论文，通过推理-动作解耦和多阶段训练流程，在SIMPLER等评测中表现突出。</p>
  <h3><strong>趋势三：动作分词器（Action Tokenizer）让动作可语言化</strong></h3>
  <p>VLA的一个核心难点是：如何将连续、高频的机器人动作转换为VLM能理解的离散“词汇”（Token）？</p>
  <p>这正是<strong>动作分词器（Action Tokenizer）</strong>的作用所在。它是连接VLM“大脑”与机器人“身体”的桥梁。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_846bade8d5844824b15167a4e3199a60@46958_oswg70878oswg787oswg282_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>今年的新进展包括：</p>
  <ul>
   <li><strong>FASTer Tokenizer</strong>：结合残差矢量量化（RVQ），在压缩率与动作连续性间取得平衡</li>
   <li><strong>OmniSAT</strong>：借助B样条曲线（B-Splines）对动作建模，实现更紧凑表达</li>
  </ul>
  <p>在LIBERO和SIMPLER中，这些方法提升了精度与稳定性，为语言模型驱动的机器人控制奠定基础。</p>
  <h3><strong>趋势四：强化学习（RL）打通最后一公里</strong></h3>
  <p>模仿学习虽可快速习得基础操作，但极端场景下表现仍有限。因此，<strong>强化学习（RL）</strong>重新登场，作为VLA策略的<strong>微调利器</strong>。</p>
  <p>今年的代表技术包括：</p>
  <ul>
   <li><strong>残差RL（Residual RL）</strong>：在冻结VLA策略上叠加一个轻量“残差策略”，实现关键时刻干预与优化</li>
   <li><strong>阶段感知RL（Stage-aware RL）</strong>：将复杂任务拆分成语义阶段，进行分阶段奖励与策略训练</li>
  </ul>
  <p>代表作如《SELF-IMPROVING… VIA RESIDUAL RL》《PROGRESSIVE STAGE-AWARE…》在LIBERO和SIMPLER上分别取得了99%和98%的成功率。</p>
  <h3><strong>趋势五：效率优化（Efficiency）让VLA走向平民化</strong></h3>
  <p>VLA模型庞大、成本高昂，令许多中小实验室望而却步。因此<strong>效率优化</strong>成为研究重点。</p>
  <p>典型代表有这两大方向：</p>
  <ul>
   <li><strong>推理效率</strong>：如HyperVLA采用超网络机制，动态生成轻量策略网络</li>
   <li><strong>显存占用</strong>：如AutoQVLA采用智能量化，压缩模型体积同时保持性能</li>
  </ul>
  <p>这些方法大幅降低了硬件门槛，让更多研究者能够参与VLA研究。</p>
  <h3><strong>趋势六：视频预测赋予VLA物理直觉</strong></h3>
  <p>视频生成模型天然理解时序动态和物理规律，这对于机器人控制是极强的先验知识。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_429aa87717814dbd9f522954494c2882@46958_oswg447056oswg1080oswg669_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这个方向主要有两种思路：</p>
  <ol>
   <li>在VLM基础上增加未来帧预测任务</li>
   <li>从视频生成大模型（如NVIDIA的Cosmos）出发，微调使其具备动作生成能力</li>
  </ol>
  <p>例如《COSMOS POLICY》就成功将一个视频基础模型微调用于机器人控制，并在真实世界中与Pi-0.5等前沿模型进行了对比。</p>
  <p>这些工作表明，赋予VLA“想象”未来的能力，能有效提升其对物理世界的理解。</p>
  <h3><strong>趋势七：更真实的评测基准</strong></h3>
  <p>正如后文会提到的，<strong>现有评测集已近饱和</strong>。为此，社区正在积极开发新的评测方式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_986be5ef7e8e424692321638cc9bb615@46958_oswg435920oswg1080oswg468_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <ul>
   <li><strong>《ROBOTARENA ∞》</strong>&nbsp;提出了一个真实到仿真 (Real-to-Sim) 的评测框架，可以自动构建和评估环境</li>
   <li><strong>《RoboCasa365》</strong>&nbsp;提供了一个包含365种任务、超2000个厨房场景的大规模仿真环境</li>
   <li><strong>《WorldGym》</strong>&nbsp;甚至提出一个颠覆性的想法：直接用一个生成式的世界模型作为评测环境</li>
  </ul>
  <p>这些新基准致力于打破对现有测试集的过拟合，推动VLA研究走向更有意义的泛化能力。</p>
  <h3><strong>趋势八：跨体态学习是必经之路</strong></h3>
  <p>如何让一个模型同时驱动不同结构（Action Space）的机器人？这是通往通用机器人的核心挑战。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_9137e168509b47279584c67b6a1e0692@46958_oswg121805oswg1080oswg283_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <ul>
   <li><strong>《X-VLA》</strong>&nbsp;使用软提示（soft-prompting）为不同机器人学习特定的“适配器”</li>
   <li><strong>《XR-1》</strong>&nbsp;提出统一视觉-运动编码（UVMC），用一套共享的“词典”来表示不同机器人的视觉动态和动作</li>
   <li><strong>《HIMOE-VLA》</strong>&nbsp;则使用了层级式混合专家（Hierarchical MoE）架构，让模型能更好地适应新“身体”</li>
  </ul>
  <p>这些架构上的创新，是构建能够适应不同硬件的通用机器人策略的关键一步。</p>
  <h2><strong>现状问题：不要迷信高分，评测正在失真</strong></h2>
  <p>研究员Reuss在文中指出：主流仿真评测（如LIBERO、CALVIN）存在<strong>“性能天花板”</strong>问题。</p>
  <p>很多模型得分虽高，却难以转化为现实能力，原因如下：</p>
  <ul>
   <li><strong>数据鸿沟</strong>：头部公司掌握海量高质量真实数据，是开源数据难以比拟的</li>
   <li><strong>评测维度差异</strong>：工业界更看重开放环境、泛化能力、失败恢复</li>
   <li><strong>资源与迭代</strong>：大规模集群与工程支持带来快速优化能力</li>
  </ul>
  <p>开源模型在仿真环境中得分甚至高于Google的Pi-0.5，但在真实世界中，仍难匹敌这些前沿产品。</p>
  <h2><strong>未来两大关键问题：仍被忽视的数据与学习方式</strong></h2>
  <p>文章的最后，Reuss还指出两个VLA研究中<strong>尚未受到足够重视的问题</strong>：</p>
  <p><strong>数据质量</strong>：与其关注数据量，不如关注数据中的<strong>噪声、歧义、次优行为</strong>，这些都可能限制模型上限</p>
  <p><strong>上下文学习（In-context Learning）</strong>：这一在LLM中常见的机制，能否迁移到机器人领域，或许是通用VLA的突破口</p>
  <h2><strong>作者介绍</strong></h2>
  <p>这篇综述的作者<strong>Moritz Reuss</strong>，是德国<strong>卡尔斯鲁厄理工学院（KIT）</strong>的四年级博士生，长期致力于从人类演示、视觉与语言中构建通用机器人AI系统。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_e8bd00581f6d4ae6a56a6bfa24f2cee4@46958_oswg136429oswg1080oswg490_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他也是将扩散模型引入机器人策略研究的先行者，而这恰好是本次综述中提到的热门趋势之一。</p>
  <p>作为2025年Apple AI/ML学者奖获得者，他的研究成果已多次发表于RSS、ICLR、NeurIPS等顶会。可以说，这份综述来自科研一线的“圈内人”。</p>
  <p>最后，VLA的这么多技术方向，你最看好哪一个？是更快的离散扩散，还是更聪明的思维链？或者你认为数据才是唯一的密码？</p>
  <p>参考链接：</p>
  <p>[1]https://mbreuss.github.io/blog_post_iclr_26_vla.html</p>
  <p>[2]https://www.linkedin.com/in/moritzreuss/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/qmj59Y5tFpkCdYPRvDwSzA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：Zelen&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732831603585</id>
            <title>DeepMind一篇论文终结十年之争，GPT-5推理靠世界模型</title>
            <link>https://www.36kr.com/p/3532732831603585</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732831603585</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:16:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】GPT-5的惊艳之处，不只是写得好，还有超强的推理能力。近期的一个研究揭示了其中的秘密：通用智能体之所以聪明，不是因为参数更大，而是因为它们在脑子里长出了一张「世界模型」。而这张隐形的地图，也正在改变我们对AI的理解。</strong></p>
  <p>GPT-5上线后，最让人震惊的不是它能写诗画画，而是它展现出的推理能力。&nbsp;</p>
  <p>网友惊呼：「感觉像是在和博士讨论问题」，媒体更是直言它的逻辑水平已经「堪比专家」。&nbsp;</p>
  <p>为什么会出现这种「突然开窍」的效果？&nbsp;</p>
  <p>最新的一篇研究给出了答案：&nbsp;</p>
  <p>通用智能体之所以能推理，不靠死记硬背，而是因为它们在脑子里悄悄长出了一张「世界模型」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_2a277d0a2fab48d482918301d4da209c@46958_oswg15105oswg1080oswg200_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文传送门：https://arxiv.org/pdf/2506.01622&nbsp;</p>
  <h2><strong>是模仿还是思考？学界吵了十年</strong></h2>
  <p>什么是「世界模型」？简单来说，它就是AI脑子里的预测地图。</p>
  <p>对于人类来说，我们的脑子里天生带有预测的功能：</p>
  <blockquote>
   <p>球在桌子边滚动→它可能会掉下去</p>
   <p>开车的时候，看到红灯→如果不刹车可能出事故</p>
   <p>两个人对话，其中一个人说「我饿了」→下一步很可能是找吃的</p>
  </blockquote>
  <p>那对于AI来说，是怎样的呢？</p>
  <p>在过去的十几年里，学界一直在争吵——AI到底能不能只靠模仿（无模型学习），也能解决复杂任务？</p>
  <p>「模仿派」认为，只要有足够多的数据+强大的算力，AI就能像条件反射一样给出正确答案。</p>
  <p>在GPT-3.5时代，大部分AI的回答都像「背题库」，有时候蒙对，有时候完全错误。</p>
  <p>与之相反的则是「思考派」。他们坚持如果没有世界模型，AI永远只是鹦鹉学舌。</p>
  <p>一旦问题需要多步逻辑，比如解数学习题、规划一个流程，纯模仿型AI就会掉链子。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8e5c32c5c6504432b6e9964ea09289a4@46958_oswg404316oswg769oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最近，有一研究给这些争论按下了终止键：</p>
  <blockquote>
   <p>只要一个智能体真的能完成多步、复杂的目标任务，它的策略里必然隐含了世界模型。</p>
  </blockquote>
  <p>在学术框架里，「目标、策略、世界模型」曾经像一个缺角的三角形。</p>
  <p>已知世界模型和目标，可以推导出最优策略；已知策略和世界模型，可以反推出目标。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4397e9947ad44318bfa803f5255ceb23@46958_oswg30015oswg532oswg301_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图1 目标g、策略π、世界模型p之间的三角关系</p>
  <p>而现在最后一角也被补齐——只要知道智能体的策略和目标，就能恢复出它的世界模型。</p>
  <p>这个推导让「世界模型不可或缺」的结论更加稳固。</p>
  <p>也就是说，GPT-5之所以能展现出惊人的推理能力，是因为在训练过程中，它体内的「世界模型」。</p>
  <p>可以说，没有世界模型，就没有真正的通用智能。</p>
  <h2><strong>探究AI脑子里的地图</strong></h2>
  <p>仅有理论还不够，研究团队决定深入检查。</p>
  <p>既然说智能体一定会「长出」世界模型，那么我们能否在实验室里，把这张隐形的「地图」抓出来？</p>
  <h3><strong>给AI搭建的「迷你世界」</strong></h3>
  <p>为了验证AI体内是否真的存在世界模型，研究团队设计了一个巧妙的实验。</p>
  <p>他们搭建了一个虚拟世界，里面只有几个状态（X、Y），它们会按一定概率互相跳转。</p>
  <p>然后研究员将任务交给智能体，让它自己摸索。</p>
  <p>最后，研究人员尝试只根据智能体的行为，反推出它脑子里是不是已经学会了这些概率。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_62a5576acd6044958eeaf6085262a52c@46958_oswg27035oswg422oswg215_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图2 智能体-环境系统示意图</p>
  <h3><strong>任务越复杂，误差反而越小</strong></h3>
  <p>刚开始，智能体在简单目标里乱撞，恢复出来的世界模型差错很多，还有一堆错误。</p>
  <p>可当任务变得复杂（比如要先到X，再转到Y），情况就完全不同：它会自动搭建出更精细的「转移概率表」。</p>
  <p>随着任务深度增加，误差迅速下降。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_a52037d9eac14382aa0a322ec05ac90b@46958_oswg63749oswg1006oswg426_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图3 任务复杂度vs世界模型误差曲线</p>
  <p>无论是训练样本还是任务深度，结果都一边倒——任务越复杂，世界模型越准确。</p>
  <p>实验员还尝试了更复杂的目标组合：智能体需要在不同状态之间来回跳转，才能完成目标。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_d0bbf2eeffd74f8280cfbb48645abcf4@46958_oswg16086oswg612oswg212_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图4 复合目标实验示意图</p>
  <p>结果依旧成立。即使任务被拆解得更复杂，它体内的世界模型依然能被稳定恢复出来。</p>
  <h3><strong>没有世界地图，就没有真正的智能</strong></h3>
  <p>数学推理也印证了这一点。</p>
  <p>实验表明，只要一个智能体在复杂任务里不会频繁犯低级错误，始终能保持有限的「后悔值」，它的策略中就必然已经包含了环境的转移规律。</p>
  <p>也就是说——世界模型不是AI的点缀，而是它进化的必需品。</p>
  <p>智能体越强，心里的「小九九」就越多。</p>
  <p>这就是为什么GPT-5会让人觉得「突然会推理了」，其实是它体内越来越清晰的世界模型。</p>
  <h2><strong>一张地图带来的希望与隐忧</strong></h2>
  <p>实验告诉我们：只要AI能完成复杂任务，它的脑子里就一定有一个「世界地图」。</p>
  <p>这也解释了近来最热门的现象——所谓的「涌现能力」。</p>
  <p>研究表示，这并不是魔法，而是世界模型在任务中逐渐清晰的自然结果。</p>
  <p>我们以为GPT-5突然会推理，其实是因为它体内的世界模型在任务中逐渐清晰，于是能力自然显现。</p>
  <p>这让人类看到了希望：如果世界模型真的存在，我们或许有机会把它抽离出来，借此理解AI的内心剧场。</p>
  <p>未来，当它越来越强时，这可能成为破解黑箱、提升安全性的关键。</p>
  <p>但这也埋下了隐忧的种子。</p>
  <p>真实世界远比实验室复杂，AI学到的地图也许是模糊不完整的，甚至与人类理解不一致。</p>
  <p>可能它觉得安全，而我们觉得危险。</p>
  <p>对研究者来说，这也是一个转机。</p>
  <p>既然世界模型必然存在，那么我们或许能在未来把它抽取出来，用来解释和验证AI的行为。</p>
  <p>这意味着，破解「黑箱」不再只是愿景，而可能有了真正的理论支撑。</p>
  <p>所以，GPT-5带来的震惊不只是「它会推理」，更深层的意义在于：AI已经能在脑海里搭建自己的世界地图。</p>
  <p>而这张地图，既可能是通向智慧的通行证，也可能是未来不确定性的源头。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://arxiv.org/abs/2506.01622&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/FDW4BPcKmKFhuYs56LeRjQ" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：倾倾&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732680117123</id>
            <title>国产GPU第一股IPO获批，募资80亿</title>
            <link>https://www.36kr.com/p/3532732680117123</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732680117123</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:10:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>科创板国产GPU第一股要来了！</p>
  <p>证监会官网显示，<strong>摩尔线程IPO注册申请已获批准</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ecba5b63f78844e599cc575edbe9fc1e@46958_oswg288098oswg1080oswg848_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从6月30日递交招股书开始，摩尔线程仅用时4个月，就快速通过注册。</p>
  <p>此次IPO，摩尔线程计划募集资金80亿元。</p>
  <h2><strong>受理四个月通过IPO注册</strong></h2>
  <p>摩尔线程此次计划募集的80亿元资金，主要将被用于研发。</p>
  <p>其中25.09亿元用于摩尔线程新一代自主可控AI训推一体芯片研发项目，25.02亿元用于摩尔线程新一代自主可控图形芯片研发项目，19.81亿元用于摩尔线程新一代自主可控AISoC芯片研发项目.</p>
  <p>另外，还有10.06亿元用作补充流动资金。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ee06280f31304603b203c304b5b313f3@46958_oswg247473oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>招股书显示，今年上半年，摩尔线程的营业收入达到了7.02亿元，其中第一季度2.89亿元，第二季度4.12亿元，这一<strong>收入规模已超过2024年全年</strong>。</p>
  <p>亏损情况也得到改善，今年上半年净亏损为2.71亿元，与去年同期相比大幅收窄，公司管理层预计，<strong>最早可于2027年实现合并报表盈利</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_ce297e29485e4a688e9d33aa914beb38@46958_oswg176086oswg1080oswg451_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与营收规模爆发式增长同样显著的是公司收入结构的根本性转变——摩尔线程将其战略重心从早期的桌面级产品全面转向高性能、高毛利的AI智算领域。</p>
  <p>2022年，公司收入主要依赖桌面级图形加速产品，占收入的71.44%；而到了2024年，AI智算产品异军突起，贡献了3.36亿元收入，占年度总收入的77.63%。</p>
  <p>到今年上半年，AI智算产品已成为绝对的收入支柱，收入占比飙升至94.85%，达到6.65亿元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_8d0b902eec99429d9159f6115adcc2d1@46958_oswg274357oswg846oswg1160_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2024年11月， 公司与保荐机构中信证券签订辅导协议，并向上交所提交了辅导备案登记，年底完成了Pre-IPO轮融资，共计38家投资机构合计投资约52.25亿元。</p>
  <p>2025年6月18日，摩尔线程的上市辅导工作完成 ，6月30日科创板IPO申请获得上海证券交易所正式受理。</p>
  <p>9月5日与9月18日， 摩尔线程先后完成了对上交所第一轮和第二轮审核问询函的回复，9月26日IPO申请成功过会。</p>
  <p>从6月30日受理到10月30日正式获准注册，用时仅四个月，这一进度非常迅速。</p>
  <h2><strong>关于摩尔线程</strong></h2>
  <p>摩尔线程成立于2020年6月，注册资本3.3亿元。实控人为张建中，截至仅6月30日招股书发布，控制公司36.36%股份。</p>
  <p>在创办摩尔线程之前，张建中曾任英伟达全球副总裁、中国区总经理。</p>
  <p>从2020年诞生以来，这家公司就颇受资本市场关注，实现过「百天长成独角兽」的战绩。去年11月正式启动上市进程时，企业估值达到了255亿元。</p>
  <p>摩尔线程的主要业务是从事 GPU（图形处理器）及相关产品的研发、设计和销售，经营模式为Fabless模式。</p>
  <p>公司的核心技术是自主研发的MUSA（Moore Threads Unified System Architecture）统一系统架构。</p>
  <p>MUSA是一个融合了GPU硬件和软件的全功能GPU计算加速统一系统架构 ，涵盖了统一的芯片架构、指令集、编程模型、软件运行库和驱动程序框架。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_cd3dac955abd451a847cec6db9f59053@46958_oswg124752oswg1080oswg483_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>该架构的特点是“全功能”，即在单一芯片中集成了AI计算加速、图形渲染、物理仿真和科学计算、超高清视频编解码等多种能力。</p>
  <p>基于该架构，摩尔线程已成功推出四代GPU芯片，企业级和消费级均有涵盖，产品迭代迅速，另外还有相应的板卡/模组、一体机、集群设备等产品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_7d808126e8ab459c892a155a79e2d162@46958_oswg275901oswg1080oswg787_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>其他国产GPU上市进度如何？</strong></h2>
  <p>摩尔线程不是第一家被曝出有IPO计划的国产GPU公司，但是是最先获准注册的一个。</p>
  <p>同时，还有多家国产GPU也正在进行IPO工作。</p>
  <p>其中<strong>沐曦</strong>是曾经最有希望和摩尔竞争国产GPU第一股的一家——2025年6月30日，沐曦的科创板IPO申请也在上交所获受理，9月5日进入第二轮问询，9月21日问询回复挂网，10月24日成功过会。</p>
  <p>其他厂商方面，去年8月，专注AI训练和推理芯片的<strong>燧原科技</strong>启动IPO辅导，估值160亿元。</p>
  <p>在启动IPO前，燧原科技已融资近70亿元，其中腾讯连续六次投资，作为燧原第一大股东，持股比例为20.49%。</p>
  <p>2024年9月12日，上海<strong>壁仞科技</strong>也宣布启动IPO上市辅导，2025年5月披露了辅导情况，估值约160亿元人民币</p>
  <p>今年7月，来自上海的GPU独角兽<strong>瀚博半导体</strong>也宣布已启动A股IPO辅导。</p>
  <p>最近的这一年，真可谓是国产GPU厂商密集上市的一年。</p>
  <p>招股书地址：https://static.sse.com.cn/stock/disclosure/announcement/c/202510/002098_20251030_2DKD.pdf</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/8MhDcyXyShZHtAwGhO9ecA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：克雷西，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532758917323137</id>
            <title>中国AI的性价比，已成全球杀器</title>
            <link>https://www.36kr.com/p/3532758917323137</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532758917323137</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 08:07:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <blockquote>
   <p><strong>摘要：就在中国AI在全球市场以 “高性价比”快速俘获人心之时，海外科技大厂正深陷算力焦虑。</strong></p>
  </blockquote>
  <p><strong>“我们很大程度上依赖阿里巴巴的Qwen模型。它非常好，速度也很快，而且很便宜。”</strong>近期，爱彼迎（Airbnb）联合创始人兼CEO Brian Chesky的一番公开表态在全球AI圈掀起波澜。</p>
  <p>值得一提的是，Brian Chesky与OpenAI CEO奥特曼私交甚好，但在自家产品的技术选型上却没有念及“私情”——“我们也会用OpenAI的最新模型，但在实际生产中通常不会大量使用，因为有更快、更经济的模型可供选择”。</p>
  <p>这场选择背后，中国AI模型悄悄改写全球市场规则。&nbsp;</p>
  <h2><strong>开源与便宜，中国模型的杀手锏</strong></h2>
  <p>中国大模型的圈粉早已不是个案。</p>
  <p>曾将Facebook用户从4500万做到7亿的硅谷传奇投资人查马斯・帕里哈皮蒂亚在播客节目中一度直言，已将核心业务负载从美国AI模型转向中国的Kimi K2模型，理由简单直接：“K2的性能够强，而且比OpenAI和Anthropic便宜太多” ；国外初创公司GlueAI创始人Evan Owen也表示，他们团队同样频繁使用Kimi K2。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_05ee6e7305ce4113a57919973ac8728f@1883322323_oswg38424oswg1080oswg512_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>《机器之心》近期在统计Thinking Machines Lab所发的新研究博客时统计，TML在该篇博客中共计点名“Qwen”38次之多，称其研究受到了 Qwen 团队研究的启发。</p>
  <p><strong>海外研究团队与企业用脚投票中国AI，背后是开源策略与性价比的双重胜利。</strong></p>
  <p>同样以阿里为例，最新Qwen3系列支持混合推理模式，思考与非思考可无缝切换，在代码、数学、Agent任务方面表现均可圈可点，且多数开源。</p>
  <p>公开数据显示，截至2025年8月，阿里通义已开源200余个模型，全球下载量超3亿次，千问系列衍生模型突破10万个，远超 Meta的Llama系列，更一跃成为全球最大的开源模型家族。</p>
  <p><strong>这种开源传统与高性价比方案最初源自于DeepSeek，但很快就在中国大模型公司间普及开来。</strong>MiniMax本周发布的全新模型M2，在智能代理任务上接近GPT-5水平，但却主打限时免费策略，目前已登顶HuggingFace Trending榜单。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_3ce32496e173418d825d5e6dc0ff3c6f@1883322323_oswg27521oswg750oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据《经济学人》今年8月报道，Andreessen Horowitz 合伙人爆料称，在硅谷路演的AI初创公司中，有80%可能在使用中国开源模型，而三年前，OpenAI 还在垄断市场话语权。</p>
  <p>企业们算的是实打实的经济账，在美国之外的地方更如是。塞浦路斯的AI工具平台Latenode，其联合创始人Oleg Zankov算了笔直观的账：“DeepSeek整体质量相同，但价格便宜17倍，这使其在智利和巴西等资金和计算能力不那么充裕的地区特别有吸引力。”</p>
  <p>海外企业接二连三地“倒戈”已经从个案转变为趋势。从金融领域来看，汇丰银行、渣打银行等国际金融机构已开始内部测试DeepSeek模型，全球最大石油公司沙特阿美更是将DeepSeek系统直接部署在其数据中心；即便是科技领域，连亚马逊AWS、微软和谷歌这些美国云服务巨头，也在向客户提供DeepSeek服务。</p>
  <p>大佬们的思考通常更加敏锐，英伟达CEO黄仁勋在几日前的GTC大会再谈中美AI竞争时，同时点名了千问与DeepSeek，其表示，<strong>“Qwen是世界级的语言模型，DeepSeek在推理架构上的突破是革命性的。”</strong></p>
  <h2><strong>两种路线，两种结果</strong></h2>
  <p>就在中国 AI在全球市场以 “高性价比”快速俘获人心之时，海外科技大厂正深陷算力焦虑。</p>
  <p>微软的裁员风暴来得集中且猛烈，继今年5月裁员6000人后，紧接着又宣布削减9000个岗位，此次调整为两年来最大规模。微软发言人表示，此次裁员涉及不同部门、地区以及各个经验层级的员工。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_5e1f2422bc38421bbbed2f97293bd76e@1883322323_oswg144273oswg1080oswg743_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从战略逻辑来看，微软裁员并非简单的人员优化，而是有着明确的战略指向——在人工智能竞争日益激烈的当下，算力成为决定企业竞争力的关键因素，微软作为全球云计算巨头，其 Azure云服务需要强大的算力支撑，从而满足客户在AI训练、推理等方面的需求。</p>
  <p><strong>然而现实是，高端AI芯片价格高昂，一枚英伟达H100芯片售价可达数万美元，在营收增长放缓下，裁员成平衡成本与算力需求的必选项。</strong></p>
  <p>全球电子商务巨头亚马逊的处境同样不容乐观，10月28日其官方宣布计划裁减约1.4万名公司职员，其裁员规模和力度丝毫不逊于微软。亚马逊人力体验与技术高级副总裁贝丝·加莱蒂当日致信员工说，人工智能是自互联网诞生以来最具变革性的技术，使企业能够以前所未有的速度创新。此次裁员旨在通过将资源重新分配到优先领域，让公司“更加强大”。</p>
  <p>在AI领域，算力的地位堪比“石油”，是推动技术发展和商业应用的核心资源之一。目前全球高端AI芯片市场主要由英伟达垄断，芯片供应紧张且价格昂贵，进一步加剧了海外大厂的算力焦虑。</p>
  <p>在硬币另一面，算力堆叠与资本游戏，造就了新的单体巨无霸。</p>
  <p>北京时间10月29日晚，美股三大指数集体高开，英伟达股价开盘上涨3.2%，市值首次站上5万亿美元，成为史上第一家市值跨越这一里程碑的上市公司。市值从4万亿美元跨越5万亿美元，英伟达仅用时113天。</p>
  <p>据市场消息，OpenAI正在筹备上市，最快于2026年提交IPO申请，或将成为人类资本史上最大一次融资事件。OpenAI对算力呈现出更为可怕的需求，每赚1美元，就要花费2.25美元，这让其与英伟达、AMD等昂贵算力基建高度绑定。</p>
  <p>最新消息显示，OpenAI 开始向重度用户出售 Sora 生成式 AI 视频工具的额外使用积分。负责 Sora 项目的比尔・皮布尔斯在 X 平台上公布了该调整，他表示，随着用户增长，公司终将不得不缩减免费次数，“否则 GPU 资源将无法支撑”。</p>
  <p>过去两年时间，全球AI格局悄然重塑。正如黄仁勋所言，“赢得开发者平台才能赢得AI”，中国模型以 “性能逼近顶尖、成本大幅降低、生态全面开放” 的组合拳，正在终结少数巨头的垄断时代，推动全球AI产业进入 “多元竞争、价值导向” 的新阶段。</p>
  <p><strong>需要说明的是，中国AI并非只有价格战。</strong></p>
  <p>DeepSeek发布的全新多模态模型DeepSeek-OCR，提出利用视觉模态压缩长文本上下文的新方法，过去一段时间内持续在技术社区引发讨论。</p>
  <p>有从业者认为其本质上是模拟人脑的遗忘机制。还有技术类专业认为，该模型的核心构件视觉encoder的高效解码，为光计算和量子计算在LLM领域的引入提供了明确的技术路径。</p>
  <p>10月31日午间，Kimi在新的技术研究报告中，提出了一种新的混合线性注意力架构 ——Kimi Linear。其特性是极大改善运营效率，被评价为一个能将KV缓存减少75%同时将吞吐量提升6倍的即插即用替代方案。</p>
  <p>Kimi 的研究员熊狸在 X 上表示，“我很荣幸在过去一年中见证了这项伟大的工作，线性注意力在表达能力上具有巨大潜力，但在处理长上下文时存在较高的风险”。</p>
  <p>黄仁勋在提及中美AI竞争时曾表达，“全球50%的AI研究人员是中国人。我们必须继续保持开放。AI竞争不是单一维度的，它包括能源、芯片、基础设施、模型与应用等层次。特别是，我们需要更多工程师、管道工、技工来建设AI工厂。这些都是高薪、体面的工作。美国不仅要发明AI，更要率先普及AI”。</p>
  <p><strong>实际上，黄仁勋表示，美国仍有可能输掉AI竞争。</strong></p>
  <p>要知道历史上不止一次出现过类似的故事，最终的赢家并非手握最多资本的玩家，这场不仅限于单一技术的比拼，已在开放生态与精细化服务方面展开较量。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/63Q7-aqg_Ym8wRTDc-xw1g" rel="noopener noreferrer nofollow" target="_blank">“凤凰网科技”</a>，作者：王佩薇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3532732267420546</id>
            <title>斯坦福最新研究：AI的上下文比参数重要，无需重训、不再微调</title>
            <link>https://www.36kr.com/p/3532732267420546</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3532732267420546</guid>
            <pubDate></pubDate>
            <updated>Fri, 31 Oct 2025 07:47:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近日，斯坦福大学与 SambaNova Systems 合作发表了论文《Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models》。&nbsp;</p>
  <p>该论文提出了一个名为ACE（Agentic Context Engineering）的框架，可以让AI在不重新训练权重的前提下，实现自我改进。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c873c1323b7f46db967b34b74553aa61@46958_oswg309033oswg1080oswg644_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接： http://arxiv.org/abs/2510.04618v1&nbsp;</p>
  <p>论文的核心思想是，大模型的能力，并非仅由参数决定，更取决于“<strong>上下文的质量</strong>”。换句话说，谁能构建出最优的上下文，谁就能让模型更聪明。&nbsp;</p>
  <p>ACE的核心思想，是让模型不再依赖“静态提示（prompt）”，而转向一种<strong>动态、结构化、可进化的“知识剧本”（playbook）</strong>。</p>
  <p>这些剧本记录了模型在任务执行中积累的策略、规则、模板和修正规则。每一次失败或成功，都会被转化为一条“增量更新”（delta）。</p>
  <p>与传统的“重写提示”不同，ACE通过<strong>小步安全更新</strong>不断改进剧本，而不是一次性推倒重来。</p>
  <p><strong>这种机制意味着，AI可以在运行中学习、记忆、改进，而不需任何参数微调。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_c5e175fbab194a8e99a00c8b06ccc9dc@46958_oswg129096oswg1080oswg428_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">ACE框架</p>
  <p>研究者指出，这一机制能避免两种致命问题：一是<strong>简化偏差（brevity bias）</strong>，即在追求简洁的优化中丢失关键细节；二是<strong>上下文崩塌（context collapse）</strong>，即重写导致的知识损毁。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_4ffbc99fb79743fc8b7a3c7f01490d81@46958_oswg115844oswg1080oswg415_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文举例称，在实验中，一个AI代理积累了<strong>1.8万token</strong>的上下文，表现良好。但当模型试图“总结压缩”它时，剧本被削减至仅<strong>122个token</strong>，性能瞬间跌至<strong>57.1%</strong>。</p>
  <p>研究者直言：“模型擅长使用知识，但不擅长整理知识。一次错误的重写，就可能摧毁全部积累。”</p>
  <p>论文称ACE解决了这种“自毁式学习”的结构性风险。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_fc6ca2933d9a477990d88fc87c164d2c@46958_oswg121053oswg1080oswg514_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图注：ACE 框架在三类任务（智能体操作、领域知识、数值推理）上都显著优于其他方法，准确率提升最明显。</p>
  <h2><strong>三角色协作：生成、反思、策展</strong></h2>
  <p>ACE体系建立在一个极简哲学上： <strong>不要重写知识，要管理知识。</strong></p>
  <p>整个系统被拆解为三个互补的角色。</p>
  <p>第一个是<strong>生成器（Generator）</strong>。它负责执行任务，与环境交互，生成推理过程、代码或操作序列。</p>
  <p>第二个是<strong>反思器（Reflector）</strong>。它分析生成器的行动轨迹，识别成功与失败的原因，提取“可操作的教训”。这些反馈信号可能来自代码错误、执行结果或外部标签。</p>
  <p>第三个是<strong>策展器（Curator）</strong>。它将这些经验提炼为<strong>结构化条目（delta context）</strong>，并通过<strong>确定性规则</strong>（非语言模型决策）整合进主剧本。</p>
  <p>这样的三层循环——行动、反思、整合构成了ACE的学习闭环。</p>
  <p>每次更新都只影响局部条目，不触碰整体文本。这种<strong>局部增量机制</strong>，让知识库既能不断扩展，又不会坍塌。</p>
  <p>剧本本身被设计为<strong>项目化结构</strong>：包含策略规则、API调用模板、调试经验、常见错误解决方案等。每条条目附带<strong>使用计数与正负反馈元数据</strong>。</p>
  <p>反思器会根据这些记录判断哪些规则有效、哪些无用。策展器再据此修改或删除。</p>
  <p>论文称，这种方式让AI的知识“像Git仓库一样演化”，能<strong>安全地生长、细致地修剪、透明地追溯</strong>。</p>
  <p>研究者强调，ACE的复杂度并非负担，而是一种<strong>结构化的安全机制，</strong>以微小的系统开销换取知识的稳定积累。</p>
  <h2><strong>小模型“越级打怪”：DeepSeek击败GPT-4.1</strong></h2>
  <p><strong>在复杂的AppWorld代理任务中，ACE框架带来了+10.6%的平均性能提升，并将适应延迟降低86.9%。</strong></p>
  <p>研究团队特别提到，这一提升并非依赖更大的模型，而是源于更好的上下文管理。</p>
  <p>一个典型例子是：<strong>DeepSeek V3.1，</strong>参数量低于<strong>GPT-4.1</strong>。但在ACE框架下，它在AppWorld基准测试中，竟能<strong>与GPT-4.1代理（IBM CUGA）持平，甚至在更复杂的测试集上反超</strong>。</p>
  <p>研究者指出，这一结果说明，<strong>“上下文工程”已成为新的算力平权器</strong>。</p>
  <p>更重要的是，ACE的<strong>效率优势惊人</strong>。在多轮任务学习中，它的<strong>更新延迟减少82%~91%</strong>，<strong>token成本下降83.6%</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251031/v2_1a828bc3b918432cb28c64afd4d777f0@46958_oswg186218oswg1080oswg656_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图注：在金融分析任务中，ACE 框架显著提升模型表现（平均提升约 8.6%），即使没有真实标签也能保持稳定表现。</p>
  <p>论文认为，这让“在线持续学习”从概念变为现实。AI不再需要频繁微调，而可以在运行中自我优化。</p>
  <p>同时，ACE的结构化剧本让学习过程<strong>可解释、可审计、可撤回</strong>。</p>
  <p>如果某条规则被发现过时、偏颇或违规，系统可以<strong>精准删除对应条目</strong>，实现“选择性遗忘”。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/KvIDGEWSfDALOWx5T5oSwQ" rel="noopener noreferrer nofollow" target="_blank">“大数据文摘”</a>，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>