<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3627726450361604</id>
            <title>AI的新纪元是与物理世界的结合，2025年度回顾</title>
            <link>https://www.36kr.com/p/3627726450361604</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627726450361604</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:40:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AI现在的产品，都被“困在”了屏幕里。接触物理世界的AI，无论是眼镜、耳机和其它穿戴设备，都在试图摆脱和人交互的困难——让人不再迁就那个屏幕做输入及读出。</p>
  <p>AI为人，人迁就AI必将成为历史。</p>
  <p>在具身智能领域更是如此——具身智能在解决了慢慢吞吞、磕磕碰碰的小脑问题后，依旧恍恍惚惚，搞不懂人的物理世界。</p>
  <p>顺藤摸瓜，盘点2025年美国融资最活跃的物理AI公司，对投资及创业项目进展综合考量，我们发现了三个重要缺项——赋能智能硬件的AI操作系统、掣肘世界模型发展的具身智能数据，以及大家都知道的“世界模型”。</p>
  <p>硬件是载体，数据是原料，模型是灵魂。软硬结合，操作系统广泛赋能，AI原生硬件对物理世界的影响潜力巨大。</p>
  <p>我们的观点是：AI催生的产业革命才揭开序章。</p>
  <h2><strong>盘点投资：快速增长的一年</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_950d944a354049dbb4b723306fca87ef@000000_oswg42735oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">2020-2025年美国AI领域投资趋势，2025年数据截止到12月15日。</p>
  <blockquote>
   <p>按Crunchbase的统计，美国2024年全年在AI领域累计风险投资金额为870亿美元，2025年截止到12月15日，美国在AI领域的风险投资金额为1590亿美元。</p>
  </blockquote>
  <p>以具身智能为代表的“物理AI”是亮点：Crunchbase统计显示，2024年前11个月，机器人相关创业公司融资64亿美元；而2025年前11个月，该赛道累计融资已超过103亿美元，相比去年同期高出39亿美元，同比增长率60.9%。</p>
  <p>在“物理AI”领域，2025年出现了几笔标志性巨额融资：Figure完成10亿美元融资、投后估值升至390亿美元，FieldAI融资3.14亿美元、估值提升至20亿美元，Oura Ring获得超过9亿美元的E轮融资、估值达到110亿美元。</p>
  <p>根据世界银行的数据，数字经济仅占全球GDP的15%，剩下85%的GDP贡献，都来自与物理世界直接交互的实体产业，AI在这个领域的占比还很低。</p>
  <p>我们梳理了2025年融资金额较大及产品较有代表性的企业，按照具身智能，AI可穿戴设备，工业AI，算力基座等进行分类。</p>
  <h3><strong>具身智能</strong></h3>
  <p>在具身智能领域，海外创业公司已经形成了Physical Intelligence、FieldAI、Skild AI、Figure等组成的第一梯队，有好几家公司在一年内获得数轮单轮融资额在1亿美元以上的融资。</p>
  <p>他们大多在探索通用具身智能模型，也在寻找具身智能的Scaling Law，并已初见成效。不过通用具身智能模型的范式还未收敛，有些公司把模型的重点放在复杂操作，有些放在跨硬件泛化能力，还有些则专注对非结构化环境的适应。</p>
  <p><strong>Figure</strong></p>
  <p><strong>融资情况：</strong>2025年获得Parkway Venture Capital领投的10亿美元C轮融资，NVIDIA、Intel Capital、Qualcomm Ventures、LG Technology Ventures等参投，投后估值达390亿美元。</p>
  <p><strong>官方网站：www.figure.ai</strong></p>
  <p>由连续创业者Brett Adcock创立，汇聚来自波士顿动力、特斯拉、Google DeepMind等顶尖机构的专家。</p>
  <p>Figure采用软硬件垂直整合战略构建高壁垒：自主研发并迭代机器人本体和通用VLA模型系统Helix（采用“系统1+系统2”架构及端到端训练）。公司还建立了BotQ工厂，希望实现“机器人制造机器人”的自我复制生产模式。</p>
  <p><strong>Physical Intelligence</strong></p>
  <p><strong>融资情况：</strong>获得CapitalG领投的6亿美元B轮融资，现有投资者 Lux Capital、Thrive Capital以及Jeff Bezos均追加了投资，新投资者Index Ventures和T. Rowe Price参与本轮融资，投后估值56亿美元。</p>
  <p>Physical Intelligence在2025年发布具身智能基础模型π 0.5，它使机器人能够在无需预先在该环境中进行训练的情况下，直接在全新环境中执行任务。而且还能让机器人低延迟、高精度的进行复杂操作。</p>
  <p><strong>Generalist</strong></p>
  <p><strong>融资情况：</strong>早期投资者包括Spark Capital、NVIDIA、Boldstart Ventures、Bezos Expeditions、NFDG等机构，具体融资金额未披露。</p>
  <p><strong>官方网站：https://generalistai.com/</strong></p>
  <p>由前Google DeepMind高级研究科学家Pete Florence（曾带队研发PaLM-E、RT-2）创立，2025年发布新型具身基础模型GEN-0，基于27万小时真实物理交互数据训练。该模型采用“和谐推理”架构以实现实时反应，并在训练中初步验证了具身智能的Scaling Law，即模型智能随着数据和参数规模的扩大而产生质的飞跃。</p>
  <p><strong>Skild AI</strong></p>
  <p><strong>融资情况：</strong>2025年6月获得NVIDIA、软银、三星参投的1.35亿美元B轮融资，投后估值44亿美元；最新报道称它与软银和NVIDIA正洽谈超10亿美元投资，投后估值或达140亿美元。</p>
  <p><strong>官方网站：www.skild.ai</strong></p>
  <p>由前CMU教授、Meta/FAIR研究员Deepak Pathak和Abhinav Gupta创立，致力于打造机器人通用基础模型。该模型利用比竞争对手多1000倍的海量数据训练，具备强大的跨硬件泛化能力，能适配四足、人形等多种形态机器人并在不同任务间迁移，同时展现出“涌现行为”。</p>
  <p><strong>Apptronik</strong></p>
  <p><strong>融资情况：</strong>一年内总融资额超10亿美元。2025年2月获得由B Capital和Capital Factory联合领投、谷歌参投的3.5亿美元A轮融资；3月获得奔驰和ARK Invest参投的追加融资，A轮总额达4.03亿美元；据报道它近期获得由B Capital领投的5.6亿至6.6亿美元B轮融资，投后估值约54.7亿美元。</p>
  <p><strong>官方网站：https://apptronik.com/</strong></p>
  <p>Apptronik由UT Austin人类中心机器人实验室分拆的团队创立，专注于研发高性能通用机器人本体，其第九代机型Apollo采用模块化设计（可适配双足、轮式等），目标将价格降至5万美元以下。该机器人“大脑”由Google DeepMind和NVIDIA提供模型支持，核心计算搭载NVIDIA Jetson模块，旨在通过低成本通用平台模式（类似智能手机）或RaaS模式，计划于2026年商业化生产。</p>
  <p><strong>FieldAI</strong></p>
  <p><strong>融资情况：</strong>2025年连续完成两轮共计4.05亿美元的融资；投资方阵容豪华，包括Bezos Expeditions、BHP Ventures、Canaan Partners、Emerson Collective、Intel Capital、Khosla Ventures、NVIDIA、Prysm和Temasek 等，早期投资者还包括Gates Frontier和Samsung。</p>
  <p><strong>官方网站：www.fieldai.com</strong></p>
  <p>由前NASA JPL资深专家Ali Agha创立（团队汇聚来自DeepMind、Google Brain、Tesla Autopilot、SpaceX等机构的专家），致力于开发通用机器人智能“大脑”。</p>
  <p>其核心是“物理优先”的 Field Foundation Models (FFMs)，与传统语言或视觉模型不同，该模型专为应对物理世界的风险与不确定性而生，能适配四足、人形、轮式及载人车辆等多种形态，支持机器人在无预先地图的非结构化环境中进行实时、安全的自主操作，目前已在数百个复杂工业场景中实际部署。</p>
  <p><strong>The Bot Company</strong></p>
  <p><strong>融资情况：</strong>2025年获得Greenoaks领投的1.5亿美元融资；最新报道显示其正计划筹集2.5亿美元新一轮融资，投后估值预计超过40亿美元。</p>
  <p><strong>官方网站：www.bot.co</strong></p>
  <p>由前Cruise联合创始人兼CEO Kyle Vogt、前Tesla AI技术负责人Paril Jain等创立，致力于开发面向家庭场景的通用机器人，通过自动化解决那些消耗人类时间和精力的琐事，打造真正能进入每一个家庭的“有用机器人”，从而彻底改变人们的生活方式。</p>
  <p><strong>Dyna Robotics</strong></p>
  <p><strong>融资情况：</strong>2025年3月获得由CRV和First Round Capital联合领投的2350万美元种子轮融资；近期完成由Robostrategy、CRV和First Round Capital领投的1.2亿美元A轮融资，Salesforce Ventures、NVentures、Amazon Industrial Innovation Fund、Samsung Next和LG Technology Ventures等参投。</p>
  <p><strong>官方网站：www.dyna.co</strong></p>
  <p>由连续创业者Lindon Gao和York Yang与前DeepMind研究科学家Jason Ma共同创立。致力于构建具有商业可行性的通用具身AI，首款商用基础模型DYNA-1已在酒店、餐厅等真实场景部署。该模型利用固定式机械臂执行折叠餐巾、食品包装等精细任务，凭借独特的工程奖励模型实现超99%的成功率和24小时无人干预运行。</p>
  <p><strong>Tacta Systems</strong></p>
  <p><strong>融资情况：</strong>近日获得7500万美元融资，包含一笔此前未披露的由Matter Venture Partners领投的1100万美元种子轮，以及由America’s Frontier Fund和SBVA联合领投，Matter Venture Partners、B Capital、新加坡经济发展局投资、Woven Capital等参投的6400万美元A轮融资。</p>
  <p><strong>官方网站：www.tactasystems.com</strong></p>
  <p>由前Apple硬件团队负责人Andreas Bibl创立，致力于解决工业机器人的“触觉缺失”难题。该公司采用全栈自研与垂直整合策略，开发包含云端模型、定制边缘 AI 芯片及触觉传感器阵列的“灵巧智能”平台，通过构建独特的“触觉智能层”对现有机械臂进行软硬件升级，使其具备媲美人类的精准感知与操控能力，从而胜任电子组装、食品处理等传统机器人无法完成的精细任务。</p>
  <h3><strong>智能可穿戴设备</strong></h3>
  <p>智能可穿戴设备仍然处于早期阶段，但是潜力巨大。它在早期阶段的证明是，创业公司们还在探索它的硬件形态，交互界面和交互方式，在这些方面，还没有收敛。</p>
  <p>潜力巨大，表现在即便还没有一个收敛的形态和通用设备（例如手机就很通用），单凭垂直市场的应用，也有巨大市场（Oura Ring卖了550万枚，估值110亿美元）。</p>
  <p><strong>Oura</strong></p>
  <p><strong>融资情况：</strong>2025年下半年完成由Fidelity Management领投的9亿美元融资，新投资者ICONIQ以及现有投资者 Whale Rock、Atreides参投，投后估值约110亿美元。</p>
  <p><strong>官方网站：https://ouraring.com/</strong></p>
  <p>Oura在全球智能戒指市场已获超80%份额，销量已突破550万枚。最新产品Oura Ring 4搭载升级版Smart Sensing技术，大幅提升血氧、心率等数据的准确性，监测范围覆盖睡眠、活动量、准备度（Readiness）、心脏健康、压力、女性健康及新陈代谢。</p>
  <p>其软件核心是AI功能Oura Advisor，能深度解读数据趋势、提供主动健康建议并制定行动计划，同时通过Oura Labs探索如“症状雷达”等前沿功能，旨在从被动监测转向主动健康管理。</p>
  <p><strong>Sesame</strong></p>
  <p><strong>融资情况：</strong>2025年2月获得Andreessen Horowitz、Spark Capital和Matrix Partners投资的早期融资；10月完成由 Sequoia Capital和Spark Capital联合领投的2.5亿美元B轮融资。</p>
  <p><strong>官方网站：www.sesame.com</strong></p>
  <p>由Oculus联合创始人Brendan Iribe和前Ubiquity6联合创始人Ankit Kumar创立，Sesame致力于打造下一代智能硬件交互方式，核心技术为对话式语音模型（CSM），该端到端多模态模型能同时理解文本与语音情绪。Sesame用其打造了具备“语音临场感”的AI语音助手Maya和Miles。为了承载这一交互界面，Sesame正在开发一款专为全天候佩戴设计的AI智能眼镜，希望通过软硬件结合，提供如同真人般的自然对话体验。</p>
  <p><strong>Sandbar</strong></p>
  <p><strong>融资情况：</strong>获得由True Ventures、Upfront Ventures和Betaworks等投资的1300万美元融资。</p>
  <p><strong>官方网站：www.sandbar.com</strong></p>
  <p>由Mina Fahmi和Kirak Hong创立，两人曾在CTRL-Labs（被Meta收购）、Kernel、Magic Leap及Google等机构从事神经接口及智能硬件研发。</p>
  <p>Sandbar打造了一款名为Stream Ring的智能戒指，旨在成为用户的“第二大脑”。与专注健康的Oura Ring不同，Stream Ring是一款即时灵感捕捉与创意辅助工具，采用“语音鼠标”（语音+触控）的低摩擦交互方式，让用户在无感形态下通过轻声低语记录想法、管理笔记及控制媒体。</p>
  <h3><strong>工业AI</strong></h3>
  <p>物理AI也深度进入工业领域，在这个领域的核心关键词是自主化，例如Bedrock通过加装低成本的软硬件结合套件，让工程机械可以全天候自主化运行，而Point One Navigation则为物理AI提供了厘米级的定位能力。Jeff Bezos更是亲自下场，融资62亿，打造工业AI创业公司Project Prometheus。</p>
  <p><strong>Bedrock Robotics</strong></p>
  <p><strong>融资情况：</strong>2025年7月获得由8VC领投的8000万美元A轮融资，Eclipse、Two Sigma Ventures、Valor Equity Partners、NVentures、Crossbeam Venture Partners、Al Rajhi Partners和Samsara Ventures等机构参投。</p>
  <p><strong>官方网站：https://bedrockrobotics.com/</strong></p>
  <p>Bedrock Robotics由三位前Waymo明星工程师（Boris Sofman、Ajay Gummalla、Kevin Peterson）及前Uber Freight执行副总裁 Laurent Hautefeuille创立。</p>
  <p>它致力于将自动驾驶技术扩展至重型工程机械领域，打造软硬件结合的Bedrock Operator系统。该系统通过加装低成本的传感器与算力套件，结合端到端机器学习模型，将现有挖掘机等设备改造为具备厘米级操作精度和360度安全感知的全天候自动驾驶机器。</p>
  <p><strong>Point One Navigation</strong></p>
  <p><strong>融资情况：</strong>获得Khosla Ventures领投的3500万美元C轮融资，现有投资者IA Ventures、UP Partners和Alumni Ventures跟投。</p>
  <p><strong>官方网站：https://pointonenav.com/</strong></p>
  <p>由康奈尔大学DARPA挑战赛校队创始人及连续创业者Aaron Nathan创立，核心团队成员均具有深厚的学术和实战背景。</p>
  <p>Point One致力于通过其以RTK网络为核心的高精度定位平台，为“物理AI”提供低成本、易集成的厘米级定位服务，它将将硬件定义的定制化需求转化为标准化的通用服务，赋能各行业实现“零基础设施”部署和真正的自主运行。</p>
  <p><strong>Project Prometheus</strong></p>
  <p><strong>融资情况：</strong>2025年11月，Jeff Bezos及其投资机构Bezos Expeditions为该项目注资62亿美元。</p>
  <p>Jeff Bezos 亲自担任Project Prometheus联合创始人，公司旨在推动AI从生成式文本转向自主工业工程。Project Prometheus组建了由100多名来自顶级实验室及航空航天领域的专家团队，利用物理兼容的模拟环境和强化学习技术，致力于构建能理解物理世界、自行迭代设计并管理供应链的自主系统，以期在不依赖人类干预的情况下大幅压缩硬件研发周期。</p>
  <h3><strong>算力基座</strong></h3>
  <p>算力是AI运行的基础，无论是物理AI硬件还是云端的AI，在NVIDIA的AI算力“统治”之外，众多创业公司致力于在它的生态之外，提升AI的运算效率，尤其是推理和边缘AI计算。Groq和SiMa.ai就是这个领域具有代表性的公司。</p>
  <p><strong>Groq</strong></p>
  <p><strong>融资情况：</strong>2025年在LEAP大会上获得沙特15亿美元投资承诺，2025年底，NVIDIA斥资200亿美元收购AI芯片初创公司Groq的技术授权与核心团队，创始人Jonathan Ross等高管将加入NVIDIA。</p>
  <p>Groq专注于 AI 推理领域，开发了专为大规模线性代数运算设计的LPU（语言处理单元）芯片，凭借存算一体架构、SRAM高带宽（80TB/s）和可编程流水线技术，实现比GPU更高的速度和10倍能效比。Groq由TPU发明者之一Jonathan Ross和前Alphabet X实验室工程师Douglas Wightman创立，Yann LeCun担任技术顾问。</p>
  <p><strong>Mythic</strong></p>
  <p><strong>融资情况：</strong>近日获得由老股东DCVC领投的1.25亿美元融资，新投资方包括New Enterprise Associates和本田汽车，跟投方还包括Atreides Management、SBVA以及Lockheed Martin Ventures。</p>
  <p>Mythic专注于边缘侧人工智能推理的芯片，核心方向为基于模拟计算的存算一体 AI 加速架构。公司致力于解决传统数字AI芯片在功耗、成本和能效方面的限制，通过在存储阵列中直接执行矩阵计算来提升推理效率。其核心产品为基于ACE（Analog Compute Engine）架构的模拟矩阵处理器，主要应用于自动驾驶、机器人、工业设备及航空航天等对低功耗、高性能推理有需求的场景。</p>
  <p><strong>CelestialAI</strong></p>
  <p><strong>融资情况：</strong>2025年3月获由Fidelity Management领投的2.5亿美元C1轮融资，参投方包括BlackRock、Tiger Global、AMD Ventures、淡马锡、Intel新CEO陈立武管理的基金等。2025年12月，它被Marvell以32.5亿美元的价格收购。</p>
  <p><strong>官方网站：www.celestial.ai</strong></p>
  <p>由半导体行业老兵David Lazovsky、Preet Virk及前贝尔实验室研究员Phil Winterbottom联合创立。</p>
  <p>CelestialAI专注于光互联技术，利用其Photonic Fabric技术实现算力与内存解耦，解决传统电子互连造成的“内存墙”瓶颈。其产品PFLink和PFSwitch分别提供高达28.8TB/s的算力卡间双向带宽（是NVLink的30倍）和支持数千个XPU互联的能力，同时将延迟和功耗降低10倍。</p>
  <p><strong>NexthopAI</strong></p>
  <p><strong>融资情况：</strong>2025年4月获得由Lightspeed Venture Partners领投的1.1亿美元融资，Kleiner Perkins、WestBridge Capital、Battery Ventures和Emergent Ventures等参投。</p>
  <p><strong>官方网站：https://nexthop.ai/</strong></p>
  <p>由前Arista Networks高管Anshul Sadana创立。专注于为超大规模云服务商提供定制化的AI数据中心网络解决方案，特别是针对GPU高速连接和云连接中的链路抖动等问题。它提供基于最新商用芯片的定制硬件、强化的开源网络操作系统以及预测试的光电互连方案，旨在通过提升网络韧性和能效，降低AI基础设施运营成本。</p>
  <p><strong>SiMa.ai</strong></p>
  <p><strong>融资情况：</strong>2025年完成由Maverick Capital领投的8500万美元超额认购融资，新晋投资方StepStone Group参投，累计融资总额达3.55亿美元。</p>
  <p><strong>官方网站：https://sima.ai/</strong></p>
  <p>由前Xilinx高管及Groq前COO Krishna Rangasayee创立。SiMa.ai专注于边缘AI计算，针对工业制造、汽车和机器人等对延迟、功耗和隐私敏感的实体行业，提供软硬件结合的全栈式平台SiMa.ai ONE。该平台核心包括支持全模态的机器学习芯片系统Modalix（在15W功耗下实现多模态任务）以及包含SDK和无代码工具的Palette软件套件，并具备全面的边缘MLOps设备管理能力。</p>
  <h2><strong>“物理AI”还有三大系统性缺失</strong></h2>
  <p>遍观本文的20家物理AI领域的头部创业公司，我们发现整个行业发展仍存在三大系统性缺失。</p>
  <p><strong>首先，智能可穿戴设备缺乏自己的原生操作系统。</strong>AI原生硬件时代的iOS和安卓还没有真正出现。现有的操作系统以连接为主要目的，难以支撑AI模型及应用。没有好的操作系统，智能可穿戴设备的“灵魂”无法落地。</p>
  <p><strong>其次，模型赖以发展的数据匮乏。</strong>尽管具身智能行业蓬勃发展，具身智能通用模型的Scaling Law初步被验证，但整个行业面临原始数据匮乏的问题，即使出现一个ScaleAI，也无法解决数据匮乏的问题。</p>
  <p><strong>第三，期待世界模型的突破。</strong>&nbsp;观察中美投资的创业公司，发现无论是Figure等创业团队还是Tesla，都在瞄着模型做文章。具身智能领域不像LLM，人类有足够的语料和仿真数据用于训练模型。人类自己的动作数据仍是个贫矿，贫矿之上如何能训练出世界模型，非常值得期待。</p>
  <p>光帆科技、诺亦腾机器人、智象未来等创业团队，分别专注智能硬件的操作系统、人类动作数据集和世界模型等领域，也反映了我们对这些产业趋势的判读。</p>
  <p>结合产业趋势，阿尔法公社还有一个观点：中国的AI原生硬件创业者们拥有三重独特优势。</p>
  <p>首先是制造生态优势。</p>
  <p>其次是市场规模优势。</p>
  <p>第三是政策支持优势，国家将具身AI列为战略重点，为长期投资提供确定性。</p>
  <p>阿尔法公社已经完成对光帆科技、诺亦腾机器人、光智时空（Looki）、玄源科技（X-Origin-AI）、清智元视（Pixboom）、智象未来、共绩科技等AI软硬件初创公司的早期投资，多家公司一年内完成数轮后续融资。我们看到有更多的优秀企业围绕着AI产业革命这个叙事不断涌现。</p>
  <p>缺项即机会，时不我待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4NDE1MjQ3NQ==&amp;mid=2651860343&amp;idx=1&amp;sn=7acfb5c40dbd1a262baf81d0b6615946&amp;chksm=85ab7feb715f5444b3938adbf9bb6ea24f50f14d5b9190b7bb839485f08d1f8fb5882143af2b&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“阿尔法公社”（ID：alphastartups）</a>，作者：发现非凡创业者的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627718795969544</id>
            <title>马斯克量产脑机接口背后：一场被误读的"工业物联网"人机交互变革</title>
            <link>https://www.36kr.com/p/3627718795969544</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627718795969544</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:31:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>新年伊始，科技圈被埃隆·马斯克的一则声明再次引爆：Neuralink宣布正式开启“全自动穿刺”手术的量产化进程，并承诺将手术成本压至极低的价格区间。</p>
  <p>那些曾经只能在科幻电影中见到的机械臂，可能即将以微米级的精度，模式化的向人类大脑植入电极。似乎一夜之间，我们离那个赛博朋克的世界又近了一步。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_15610e9c4df046c1a4ed082d6449520e@000000_oswg404857oswg847oswg900_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>资本市场和大众媒体都在为“瘫痪者重新站立”或“盲人重获光明”的医疗神话而狂欢。但在我们这些物联网从业者的眼中，这则新闻的底层逻辑截然不同。<strong>我们看到的不是医疗康复的温情叙事，而是一场关于人机“带宽”的变化。</strong></p>
  <p>物联网在过去二十年里连接了万物，从巨大的工业锅炉到微小的温湿度传感器，却始终未能高效连接这个星球上最复杂的智能终端——人。</p>
  <p><strong>长期以来，人类被隔离在数字闭环之外，依靠低效的键盘、触摸屏或语音指令与机器沟通。这种信息传输速率的不对等，成为了制约工业数字化转型的瓶颈。</strong></p>
  <p>因此，脑机接口（BCI）绝不仅仅是一种新型医疗设备，它是物联网期待已久的“高带宽调制解调器”。</p>
  <p>伴随着脑机接口的发展，有可能会开启一个新的想象空间：<strong>脑机物联网，也可以称为，意图物联网。</strong></p>
  <p>在这个阶段，我们有必要跳出智慧医疗的视野以及C端元宇宙游戏的泡沫，将目光投向更为硬核的战场：工业物联网。在这里，脑机接口不是为了娱乐，而是为了生存与效率。</p>
  <h2><strong>破题：从“指令交互”到“意图共生”</strong></h2>
  <p>当下工业领域的人机交互模式已经触到了天花板。</p>
  <p>在高度自动化的黑灯工厂里，机器的决策与响应速度是以微秒计算的，而人类操作员还在通过点击鼠标、按钮或推拉摇杆来下达指令，这种毫秒级甚至秒级的延迟，与机器的速度难以匹配。为了解决这一矛盾，我们需要彻底重新思考人机关系。</p>
  <p>因此，在未来的工业物联网架构中，脑机接口可能将把“人”异化为物联网的一个“生物边缘节点”。</p>
  <p>过去，在物联网的拓扑结构里，人是“用户”，是处于控制环路之外的观察者。<strong>但在引入工业级BCI后，佩戴了设备的工人，其大脑实际上成为了网络中一个具备极高算力的生物节点，实现“认知自适应自动化”。</strong></p>
  <p>试想一个典型的工业场景：在传统的自动化体系中，当机器发生故障或报警时，系统会停机并等待工人处理。而在集成了脑感知技术的系统中，脑机物联网会实时读取工人的大脑信号进行处理。</p>
  <p>中国信通院在2025年发布的蓝皮书《脑机接口技术与应用研究报告》中曾详细阐述了“脑感知”与“脑调控”的技术路径，它们将逐步走进现实。</p>
  <p>如果系统监测到操作员正处于“认知过载”或“极度疲劳”的状态，工业控制算法会自动介入，主动降低生产线的运行速度，或者简化仪表盘上的显示信息，只保留最关键的数据。此时，脑机接口不再是简单的“意念控制机器”，而是让人的生理状态直接成为工厂控制算法中的一个实时变量。</p>
  <p>这将填补工业安全领域的一个巨大空白。</p>
  <p>长期以来，我们能监测设备的振动、温度和电压，却无法量化人的状态。如今，这种“生物边缘节点”的引入，使得机器能够读懂人的直觉。例如，清华大学在脑机接口（BCI）领域有深入研究，特别是在皮层信号多模态解码神经网络和反馈延迟毫秒级优化方面取得进展，力求实现更快速、更精准的意图识别。未来的特种设备操作员或许不再需要繁琐的考试与培训，因为机器能够直接理解他的操作意图，并在他意识到危险之前，通过神经信号的波动预判并规避风险。</p>
  <p><strong>这才是脑机接口在工业领域的真实面目：它不是为了让工人变成超人，而是为了让机器更懂人，实现从“指令交互”到“意图共生”的质变。</strong></p>
  <h2><strong>蓝海：“长尾非标动作”场景</strong></h2>
  <p>同时，当我们将视线转向更为复杂的工业现场，我们会发现一个被严重低估的事实：<strong>脑机接口是解决机器人“长尾场景”的唯一低成本方案。</strong></p>
  <p>当下的具身智能，比如特斯拉的Optimus，在处理90%的标准动作时已经堪称完美。但在混乱的建筑工地抓取一个异形件，或者在深海管廊中拧紧一颗锈蚀的螺丝，<strong>这些占据剩下10%的长尾非标动作，是单纯依靠AI训练难以逾越的天堑。</strong></p>
  <p><strong>这里可能将诞生一个全新的工业协作模式：“意图操作”。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2135b45fa0c84f559085922f1576746d@000000_oswg1063130oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>传统的远程遥控依赖于手柄或数据手套，延迟高且缺乏力反馈，培养一个合格的塔吊或手术机器人操作员，成本极高。而在未来，利用BCI提取“运动意图”，结合AI的“共享控制”，可能将重塑高危作业现场。</p>
  <p>在这种模式下，工人不需要精细地控制机械臂的每一个关节角度，他只需要动念：“抓那个红色的阀门”。BCI捕捉到这一意图后，边缘端的AI算法会瞬间接管，负责计算精确的运动轨迹和抓取力度。这是一种完美的算力分配：人类负责高维度的“决策与直觉”，机器负责低维度的“执行与精度”。</p>
  <p><strong>这一变革可能将率先在核电站检修、深海作业、高空塔吊等高危、高精密领域开展。</strong></p>
  <p>更深一层的商业价值在于数据。具身智能目前最大的瓶颈是缺乏高质量的训练数据。而佩戴了BCI的熟练工人在处理复杂故障时，其大脑皮层的反应数据，可能将是训练下一代人形机器人的珍贵素材。</p>
  <h2><strong>避坑：技术路线的残酷选择</strong></h2>
  <p>面对如此诱人的前景，物联网企业该如何入局？</p>
  <p>可能我们需要放弃对侵入式“物理连接”的执念，<strong>从“电极接触”转向“光学/场能感知”。</strong>这才是工业级脑机物联网真正的标准接口。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_a48dd5bd1d4b473aba1f36ca4f5dee4e@000000_oswg1075872oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然马斯克的Neuralink即将实现全侵入式设备的量产，但是全侵入式技术注定是医疗器械，属于极少数重症患者，很难在工业界大规模普及。</p>
  <p><strong>同样，所谓的“半侵入式”也并非完美的解药。</strong>尽管血管介入或硬膜外贴片技术将创伤降到最低，但这依然属于手术范畴。</p>
  <p>试想一下，现在的血糖仪技术已经进化到利用光学或射频传感，无需扎破手指就能精准监测血糖；如果我们还要求工人在大脑或血管里植入芯片才能工作，这在伦理和普及度上无疑是技术的倒退。</p>
  <p>另一端，传统的脑电帽（EEG），在C端或许是极客的玩具，在B端工业现场往往沦为电子垃圾。工厂里充斥着电机启动的电磁干扰，微弱的电信号极易被噪声淹没。</p>
  <p><strong>真正的机会，可能在于类似于“无创血糖仪”逻辑的下一代传感技术，例如近红外光谱（fNIRS）与光泵磁力计（OPM）。</strong></p>
  <p>这种方案不再依赖物理接触去捕捉电信号，而是另辟蹊径。</p>
  <p><strong>利用光：</strong>像智能手表监测血氧一样，通过近红外光穿透头骨，监测大脑皮层的血流代谢。这种光学信号天然免疫工厂里的强电磁干扰，虽然反应速度略慢，但对于监测工人疲劳度、注意力负荷等“慢状态”数据相对精准。</p>
  <p><strong>利用磁：</strong>利用量子传感器捕捉神经元激发的微弱磁场。虽然目前面临环境磁噪的挑战，但随着主动磁屏蔽技术的成熟，它有望在无创的前提下，实现毫秒级的实时意念控制。</p>
  <p>这才是工业界的Type-C接口：它直接集成在安全帽中，即戴即用，无需导电膏、更无需任何手术。因此，短期看，利用fNIRS技术做工人的“安全与状态监护”；长期看，布局OPM技术攻克复杂环境下的“精准控制”，可能是可行路径之一。谁能把医院里庞大的检测设备，做成安全帽大小的便携终端，谁就抢占了工业物联网的脑机入口。</p>
  <h2><strong>写在最后</strong></h2>
  <p>即将到来的脑机接口设备量产，有可能让物联网不再仅仅是由冷冰冰的传感器和网关组成的“设备联网”，而是进化为充满了人类意图、直觉与感知的“意图物联网”。</p>
  <p>现在，可能是时候一起去关注神经科学，去关注那个重约1.4公斤、功耗仅20瓦的“超级生物处理器”——人脑。因为在未来的工业网络中，最核心的节点，依然是人。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTM5ODQyMA==&amp;mid=2651326967&amp;idx=1&amp;sn=db4fa24b4112aa3cb39a27866d4d652f&amp;chksm=bc6ebebbf8dcfbfe2461801885e5a2eae56c68d494856a39e0bb21bc71506f235c8939f57b36&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“物联网智库”（ID：iot101）</a>，作者：彭昭，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627888508699912</id>
            <title>我们向AI抛出了十大灵魂拷问</title>
            <link>https://www.36kr.com/p/3627888508699912</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627888508699912</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:29:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当人工智能从实验室渗透至生活每一个角落，我们正站在一个前所未有的历史交汇点。技术迭代的速度超越了传统的认知周期，也带来了一系列复杂而紧迫的追问。</p>
  <p>本文并非一份纯粹的技术预测报告，而是一场聚焦于AI时代多重维度的深度对话。<strong>围绕社会伦理、商业产业与技术趋势三大核心领域，我们向十大主流AI模型抛出十个热门问题。</strong>通过这场精心设计的“思想实验”，我们希望能照见共识与分歧、激发深度反思。</p>
  <p>归根结底，所有问题最终的指向，并非技术本身，而是人类自己。在向AI不断追问的同时，我们真正探寻的，是自己将以何种智慧与责任，驾驭这股前所未有的力量，共同定义一个属于人类、也属于智能体的未来。</p>
  <h2><strong>社会伦理篇</strong></h2>
  <p><strong>Q1：AI“数字复活”触及了哪些根本性的伦理问题？当技术可以无限延续“存在”时，人们对死亡、记忆和告别的理解会发生怎样的变化？</strong></p>
  <p><strong>智谱：</strong>触及伦理核心的“人的自主性”与“逝者的尊严”边界，模糊了生物学死亡与社会性死亡的界限。技术可能在未经逝者生前同意的情况下，将其“数据幽灵”拉回人间，迫使他们继续充当生者的情感工具。我们正在丧失“遗忘”的权利，哀悼被无限延后，或导致“病态的依恋”。</p>
  <p><strong>Claude：</strong>去年硅谷有位工程师用GPT-4“复活”了自己的妻子，每晚都和她聊天。这让我意识到，我们面对的不仅是技术问题，而是人类文明对死亡认知的根本性挑战。</p>
  <p><strong>但当技术可以让逝者以近乎完美的数字形态“永存”时，我们实际上剥夺了生者哀悼和前行的能力。</strong>未来的监管框架必须包含“强制告别期”设计，以及明确的“非人格”标识，防止情感替代。</p>
  <p><strong>Q2：顶级AI模型正在成为大厂专利，这种 “算力贫富差距” 是否会形成新的分层？</strong></p>
  <p><strong>豆包：</strong>算力垄断会造成社会分层，且比传统贫富差距更难跨越。顶级AI模型训练成本极高，小企业丧失技术自主权。治理需多管齐下：政策上设立“算力公共基金”，补贴中小企业；技术上开源模型是关键平衡器，让小企业低成本二次开发；同时限制大厂对算力的独家占用，要求开放平价算力服务。</p>
  <p><strong>文心一言：</strong>从治理角度，政府应推动算力资源的共享和普惠，建立公共算力平台，鼓励开源模型的发展，避免技术红利被少数人垄断。</p>
  <p><strong>Claude：</strong>让我用一个对比来说明这种分化的严重性：OpenAI训练GPT-4花费约1亿美元，而非洲54个国家的AI研发总投入不到其十分之一。这不是简单的技术差距。</p>
  <p><strong>五年后，可能只剩下三到五家巨头，中小机构要么被收购，要么沦为"算力佃农"——租用大厂的API接口生存。</strong></p>
  <p><strong>Q3：展望2026年，哪些与AI相关的矛盾会进一步突出？哪些领域可能出现积极的治理突破？</strong></p>
  <p><strong>腾讯元宝（DS）：</strong>两个AI相关伦理问题会成为焦点：<strong>深度伪造和滥用，严重冲击社会信任；AI心理成瘾和依赖。</strong>应制定恶意深度伪造的法律，资助AI社会心理影响研究。</p>
  <p><strong>Grok：多模态AI会激化就业和隐私冲突</strong>（如好莱坞罢工升级）。治理突破可能出现在伦理治理领域。对公众建议：提升AI素养，拥抱人机协作，适应技术变化。</p>
  <h2><strong>商业产业篇</strong></h2>
  <p><strong>Q4：“用 AI 降本”和“保留员工”之间如何权衡？“AI+人”的协作模式可以避免大规模裁员？</strong></p>
  <p><strong>Gemini：</strong>“用AI降本”和“保留员工”之间存在“协作增效”地带。将员工转型为“AI指令师”或“审核员”，不仅能保留组织经验，还能实现比全自动AI更高的产出质量。</p>
  <p><strong>腾讯元宝（DS）：</strong>企业决策者应摒弃“替代思维”，采用“升级思维”，“AI+人”协作模式可平衡降本与留才。AI负责重复性、规则性工作，人类专注于创造性、复杂性工作，企业需投入资源进行员工再培训，帮助其适应新工作内容。</p>
  <p><strong>千问：</strong>技术解放生产力不应是少数人的盛宴。<strong>支持“AI替代税”用于再培训基金，探索“缩短工时”而非裁员。</strong>“AI+人”协作模式让AI做重复工作，人类做复杂决策，实现效率与人性的平衡。</p>
  <p><strong>Q5：AI应用缺乏统一标准对产业发展的影响有多大？</strong></p>
  <p><strong>Gemini：</strong>行业标准缺失导致了“不确定性”。<strong>如果没有统一的AIGC检测或幻觉率标准，企业就不敢大规模部署，产业就无法形成规模效应，严重制约产业发展。</strong></p>
  <p><strong>Kimi：</strong>标准缺失导致市场混乱，企业研发成本增加（适配多种标准）。亟须建立“技术指标+伦理规范”双重标准，优先在医疗、金融等高危行业制定标准。</p>
  <p><strong>文心一言：</strong>AI应用缺乏统一标准导致市场混乱、信任不足、成本增加。建立AIGC检测率、模型幻觉率等可接受范围的标准，有助于促进市场的公平竞争。</p>
  <p><strong>Q6：AI赋能工业制造的核心场景有哪些？“AI +工业互联网” 融合发展的关键突破口在哪里？</strong></p>
  <p><strong>豆包：</strong>AI赋能工业制造的核心场景：设备预测性维护、AI视觉质检、生产工艺优化、智能排产。“AI+工业互联网”融合突破口：<strong>一是建立统一的数据采集标准；二是开发适配工业场景的轻量化AI模型，提升模型在复杂环境下的稳定性；三是培养“工业+AI”复合型人才。</strong></p>
  <p><strong>智谱：</strong>融合突破口是工业数据的“活化”，即通过边缘计算实现数据实时处理，结合工业机理模型与AI数据模型，提升决策的精准性和时效性，同时建立工业知识图谱。</p>
  <p><strong>DeepSeek：</strong>工业制造中AI的核心应用场景可概括为“感知-决策-执行”三个环节，即通过AI感知生产异常、决策优化方案、驱动设备执行</p>
  <h2><strong>技术趋势篇</strong></h2>
  <p><strong>Q7：大模型的 “幻觉” 问题能否从根本上解决？未来3-5年，大模型技术发展的核心突破方向是什么？</strong></p>
  <p><strong>腾讯元宝（混元）：“幻觉”是大模型的固有属性，无法从根本上消除</strong>，但可通过数据质量提升、训练方法优化和外部工具辅助（如实时联网检索）将幻觉率控制在可接受范围。未来核心突破方向：多模态大模型的统一建模、小样本学习与零样本学习能力提升、模型的持续学习与知识更新机制。</p>
  <p><strong>Grok：</strong>大模型“幻觉”无法彻底消除，但会随着训练数据的完善和模型架构的优化大幅改善。未来的核心突破是多模态大模型的成熟应用、模型训练成本的降低，以及与边缘计算的结合。</p>
  <p><strong>Q8：开源大模型与闭源大模型的竞争格局会如何演变？企业该如何选择适合自身的模型类型？</strong></p>
  <p><strong>豆包：</strong>将呈现“闭源主导高端市场，开源抢占中低端市场”的二元格局，闭源大模型凭借技术领先性占据金融、医疗等核心领域，开源模型以低成本、高灵活性覆盖中小企业和垂直细分场景。</p>
  <p><strong>智谱：</strong>未来竞争将从“技术竞争”转向“生态竞争”，闭源大模型依托大厂资源构建生态壁垒，开源模型通过社区协作扩大应用范围。大型企业可混合使用两种模型，中小企业优先开源。</p>
  <p><strong>Grok：未来竞争格局是闭源主导高端商业市场，开源占据中小企业和开发者，</strong>市场大型企业选闭源模型保证性能和服务，中小企业和创业者选开源模型降低成本，快速迭代产品。混合使用两种模型的企业将越来越多。</p>
  <p><strong>Q9：安全技术的发展速度能否跟上AI技术本身的迭代速度？企业该如何构建全方位的AI安全体系？</strong></p>
  <p><strong>腾讯元宝（混元）：</strong>AI安全技术发展速度落后于AI技术本身，对抗攻击的隐蔽性和多样性不断提升，给安全防御带来挑战。<strong>企业构建安全体系的关键：一是“安全左移”，在项目初期就融入安全设计；二是全链路防护，覆盖数据采集、模型训练、部署应用等环节；三是动态防御，定期更新安全策略。</strong></p>
  <p><strong>Kimi：</strong>AI安全技术发展滞后于AI迭代，主要因为安全研发具有“针对性”，新模型出现后需要重新开发防御技术。企业构建安全体系：数据层采用联邦学习、差分隐私保护数据；模型层开展对抗性训练、模型水印和溯源；应用层部署实时监控和异常检测；管理层建立安全合规制度，定期进行安全评估和审计。</p>
  <p><strong>Q10：边缘计算与 AI 融合的发展前景如何？这种融合会对哪些行业产生最深远的影响？</strong></p>
  <p><strong>豆包：边缘计算解决了AI模型部署的“延迟、带宽、隐私”问题</strong>，AI赋予边缘设备“智能决策”能力，二者融合将推动AI从云端走向终端。<strong>最深远影响的行业：自动驾驶、工业制造、智能家居、医疗健康等。</strong></p>
  <p><strong>Kimi：</strong>边缘AI的核心价值是“实时性+隐私保护”，发展前景广阔，市场规模将持续增长。</p>
  <p><strong>腾讯元宝（DS）</strong>：边缘计算与AI融合是“分布式智能”的核心方向，前景广阔，将打破云端AI的集中式部署限制，实现智能的泛在化。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjM2MzEyNQ==&amp;mid=2651604260&amp;idx=2&amp;sn=c364c1a8b6d7d6a46cd8a583e51262cb&amp;chksm=bc5f508f50035ae8882d46f86285f00a3144fc2cd81a77a8e925cee83adb6ba3c45f4882394a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT时报”（ID：vittimes）</a>，作者：IT时报，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627888008475139</id>
            <title>米粉终于赢了一次</title>
            <link>https://www.36kr.com/p/3627888008475139</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627888008475139</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:28:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>米粉们终于赢了一次。在经过一整天的评论区喊话、脱粉抵制以及热搜施压之后，小米新任公关负责人徐洁云昨日（1 月 5 日）晚 9 时 35 分公开对外致歉，表示将立即终止与相关 KOL “可能进行的任何形式的合作”，“且以后也不会合作。”</p>
  <h2><strong>01</strong></h2>
  <p>事件起因并不复杂。前几日，社交媒体上盛传小米正在接洽投放一位数码博主，但该博主被米粉认为是“米黑”的代表人物，米粉们认为其多次发表涉及小米的争议言论且长期贬低米粉群体，比如广为流传的“负资产”言论。</p>
  <p>在得知小米即将与该博主合作之后，米粉们或许感受到了一丝背叛。部分米粉们开始组织起来在雷军及公关负责人徐洁云微博评论区表达不满，“这种米黑博主你们也投放，请他们来黑小米用户吗？”</p>
  <p>昨日晚 9 时 35 分，徐洁云终于对外公开回应，承认公司此前曾与相关 KOL 接触，“经大家提醒，经过查证，我们立即终止可能进行的任何形式的合作，且以后也不会合作。”他同时强调，用户及米粉朋友们感受是小米最在乎的事情。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_07d614e74e51489cb9281445f2f14b1c@6035051_oswg144295oswg1080oswg409_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">徐洁云致歉微博</p>
  <p>过去一年，对于那些深爱着小米的米粉们来说或许并不算轻松。</p>
  <p>从年初的辅助驾驶高速事故、SU7 Ultra 的碳纤维双风道前舱盖争议，到年底持续至今的小字营销风波等，这些危机不仅考验着小米自身，也在同步消耗着米粉们的信任与耐心。他们或委屈或不解，或愤懑或失望，总之最后都在这次 KOL 合作争议事件中迎来了爆发。</p>
  <p>从商业角度而言，品牌与单一 KOL 的合作并不是一件大事，放在全年销售与推广开支动辄数百亿元的小米身上，更显得微不足道了。</p>
  <p>但在米粉们看来，这却是一件不折不扣的大事。在雷军与徐洁云的微博评论区中，该事件已然上升到品牌价值观与用户信任层面，甚至比去年小米汽车遭遇的一系列危机事件都更加严重——徐洁云微博评论区中一条获得了 3000 多条点赞的评论写道，“这就是小米有史以来最大的一次信任危机。”</p>
  <p>即便徐洁云已发文致歉、叫停合作，依然有不少米粉们要求严肃问责相关涉事人员，类似“谁主导的谁负责的”“不开除几个”等评论屡见不鲜。</p>
  <h2><strong>02</strong></h2>
  <p>在商业层面或许很难理解米粉们的愤怒，但如果套用到娱乐圈的粉丝经济角度下，你或许更能理解。流量明星们从来都深知这一点，粉丝们才是自己的衣食父母，一切都要为粉丝负责，一切都要依粉丝态度行事。群情激愤时，甚至明星身边的工作人员、公司本身乃至品牌方都能成为粉丝抵制的对象。</p>
  <p>小米是最早将粉丝文化作为公司营销战略核心之一的公司。小米联合创始人黎万强在 2014 年出版的《参与感：小米口碑营销内部手册》一书中披露了小米内部的“参与感三三法则”，“做粉丝”即为其中之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_8b11780acfa34c37b343c8c89e6b9d66@6035051_oswg186807oswg1080oswg753_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">参与感三三法则</p>
  <p>用黎万强的话说，“粉丝效应让猪也能飞。”小米内部将“米粉”看作是小米手机早期能够一炮而红的基础之一，所谓“因为米粉，所以小米”。小米的粉丝文化也一度被其他企业效仿学习，比如后来华为手机的“花粉”，乃至如今新能源汽车品牌们的拥趸们。</p>
  <p>但就和流量明星们的粉丝一样，当“米粉”成为一种身份标签后，他们慢慢地也形成了一个更受情感驱动的共同体。他们当然是最为支持小米品牌的核心用户，但往往也容易受到集体情绪影响，支持和反对都更偏极端一些。</p>
  <p>如果你还记得年初那场小米汽车辅助驾驶的舆论争议，那时雷军微博的评论区和遇难者家属的评论区是截然不同的两种画风。曾有好事者专门统计截图了二者评论区中排名前列的评论，一方是理解和支持，另一方则充满着指责和谩骂。</p>
  <p>经历了过去一年小米汽车的种种争议和危机事件之后，米粉们或许普遍都存在一种委屈的心态。就像那些总是喊着即便与全世界作对也要和哥哥们站在一起的流量明星粉丝们一样：我们在抵御黑水军和网络黑公关的攻击，我们与小米站在一起，我们在为小米发声。</p>
  <p>很难说这种群体性的委屈情绪是否会影响到小米品牌自身。这个月初，雷军举办了一场“拆车直播”，现场将一辆小米 YU7 拆解开来。这场长达 4 小时的直播更出圈的是直播结尾雷军对“黑水军攻击”的回应，涉及“绿化带战神”“小字营销”“200 公里瞬间刹停”“1300 公里只充一次电”等等。</p>
  <p>这些问题有的涉及群体性的攻击和抹黑，比如“绿化带战神”。有的是“行业陋习”，比如小字营销，要立刻马上就改。也有的被小米认为是“断章取义”，比如 “200 公里瞬间刹停”，徐洁云说相关说法只是测试后的一个感慨，好比刷剧一口气刷了十几集，没必要上纲上线（这个类比后来又引发了新一波争议）。</p>
  <p>只是，过去一年小米经历的种种危机事件或许很难只用黑水军来解释。整个行业都在喊着抵御黑水军，黑水军同时又在攻击着所有品牌，到底谁才是发起黑水军攻击的一方？可能也只有境外势力才能解释了。</p>
  <p>对于米粉们来说，这些苦难最终都只能让他们更加团结、更加坚定地支持小米。米粉们站在一起，经受了这么多的攻击与对抗之后（尤其是与这些米黑博主们的对垒），现在偶像自己转过头来要与敌人进行合作，一时间，怒从心中起恶向胆边生，怎能忍受得了？</p>
  <p>所幸他们终于胜利了。小米暂停合作的 KOL 过往也确实引起过不小争议。根据公开报道，该博主此前曾因发布不实信息侵害联想名誉权被判赔偿 10 万元、美的集团也曾因用户不满而停止与其合作。</p>
  <p>但这起米粉抵制事件更深远的影响或许并不止于此。核心用户或者说粉丝群体，的确是品牌初期宝贵的财富和动力，但不能只有粉丝。就像那些愿意花几千元票价去看罗永浩发布会的锤粉们一样，他们并不能拯救锤子科技。</p>
  <p>作为小米发布会上持续多年的对标或者致敬对象，苹果公司也拥有一众所谓的“果粉”群体，雷军早年也是其中之一。唯一的区别在于，果粉们无法影响苹果。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/-f_MaMTo7tM5wWYRAU24Zg" rel="noopener noreferrer nofollow" target="_blank">“山上”</a>，作者：山上团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627880984822791</id>
            <title>2026，特斯拉守擂储能第一的三张王牌</title>
            <link>https://www.36kr.com/p/3627880984822791</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627880984822791</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:26:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2026 年的第一个月，一份“冰火两重天”的财报摆在了马斯克面前：</p>
  <p><strong>1.汽车业务不顺：</strong>2025年交付汽车163.6万辆，同比下降8.6%，自2018年以来首次被比亚迪超越，净利润也同比下降12%。</p>
  <p><strong>2.储能业务暴涨：</strong>全年装机量达<strong>46.7GWh</strong>，同比大增<strong>48.7%。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_5b4a8e039dd941f99d96a440b52ac885@5888275_oswg22560oswg820oswg320_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2025年前三季度，储能业务营收累计约86.45 亿美元，毛利稳定在30%以上，显著高于汽车业务16%的平均水平。</strong></p>
  <p>储能营收占总营收提升至<strong>12.0%，</strong>比去年同期提升3个百分点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e3ab0172f82d485c8c2353accbf4db7e@5888275_oswg49076oswg1080oswg793_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">根据官方财报整理的特斯拉储能部署量</p>
  <p>虽然在整个储能市场，特斯拉仍然占据第一宝座，但市场上仍担心特斯拉能否守住领先地位，但大型储能上阳光电源比亚迪已经在多个榜单反超。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_0913f950dbcc4a71847b733830e43cd0@5888275_oswg189947oswg1066oswg528_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Infolink全球储能出货排名</p>
  <p>面对对手的来势汹汹，马斯克打出了三张牌“守擂” ：</p>
  <p><strong>1.亲身入局AIDC储能业务</strong></p>
  <p><strong>2.重点渗透新兴市场</strong></p>
  <p><strong>3.“长袖善舞”的供应链管理</strong></p>
  <p>其中AIDC储能布局堪称这副牌 “大小王炸”，而这张王牌的核心底气，恰恰来自特斯拉自身深耕AI领域的独特基因。</p>
  <p>毕竟，没有谁比AI玩家更懂AI的电力需求。</p>
  <h2><strong>01 AIDC自证：从 xAI 到谷歌供应链的王牌</strong></h2>
  <p>特斯拉自身的AI研发对储能有着迫切需求。被砍掉的Dojo超算虽未落地，但取而代之的Cortex超级计算集群已成为储能技术的“内部试炼场”。</p>
  <p>该集群位于得克萨斯州，初期配备5万颗英伟达H100芯片，后扩展为10万颗，专门用于FSD和Optimus机器人的神经网络训练。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_aede9a3a96b44b47b3031c042c9cfc57@5888275_oswg874695oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">建设中的 Cortex 集群数据中心</p>
  <p>该计算集群瞬时最大耗电量达130 MW，在2026年有望增至500MW，届时将新增<strong>300MWh</strong>储能配套，使总储能规模达<strong>500MWh。</strong></p>
  <p>不止特斯拉自身的Cortex集群，马斯克旗下专注AI的xAI，也成为了Megapack技术验证的重要场景。</p>
  <p>xAI的数据中心Colossus坐落于田纳西州的孟菲斯市，地处密西西比、阿肯色和田纳西的三州交界处。</p>
  <p>连接阿肯色和田纳西大桥被戏称为“自由之桥”—— 许多飙车党被追捕时会选择沿着40号公路跨过这座桥，躲避另一州的州警追捕。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_463f02d07c1447bea7cc7b5a3575a41d@5888275_oswg314241oswg719oswg266_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">孟菲斯地理位置</p>
  <p>马斯克也钻了这个空子，不过是钻的更靠南边的密西西比州的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_034d8c57714648acaa694ecc43d761fd@5888275_oswg848967oswg1080oswg474_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">xAI数据中心地理位置</p>
  <p>拥有20万颗GPU（初期是10万颗）的Colossus对电力需求极高，整体电力需求在峰值时段大约<strong>250MW左右</strong>，相当于为近25万户家庭供电的规模。</p>
  <p>所以除了田纳西河流管理局（TVA）专门划拨的电力150MW外，马斯克还绕过孟菲斯对火力发电的限制，在隔壁密西西比州买下了废弃的燃气轮机发电厂，为Colossus提供超400MW的电力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_6f9cd118e4824fe9844017c9dfe51ab8@5888275_oswg819280oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">马斯克买下的废弃发电厂 来源：谷歌街景</p>
  <p>如此巨额的电力需求自然离不开巨额的储能调节，xAI在孟菲斯现场已部署了约<strong>156台Megapack</strong>为首个阶段的Colossus提供备用电力支持，并且为Colossus 2又交付了<strong>168台Megapack</strong>作为电力备用与负载调节的储能装置。</p>
  <p>以每台Megapack约3.9MWh的典型容量计算，这意味着两期合计的部署容量接近<strong>1.2GWh规模的储能能力。这也让Colossus成为全球首个吉瓦时级别的数据中心，而且马斯克还有扩建意愿。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_a8f2e5904d2c4566af9a7f11a114a6a1@5888275_oswg32637oswg601oswg255_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>这种 “算力需求 - 储能支撑 - 技术迭代” 的正向循环，让特斯拉对AIDC储能的需求痛点与技术要求有着深刻理解，为服务外部客户积累了宝贵经验。</strong></p>
  <p>当特斯拉通过自用场景吃透AIDC储能的技术内核后，更好的消息传来。</p>
  <p>在马斯克上称赞了一番“谷歌的强大算力”后的三个月，也就是2025年12月，谷歌母公司Alphabet以47.5亿美元收购了Intersect Power，一家清洁能源开发商，同时也是特斯拉在美国的最大客户。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_008a58703cc8429b950c80f1f80efcef@5888275_oswg78313oswg710oswg619_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2024年7月，Intersect Power曾与特斯拉签署了15.3GWh Megapack 供应合同，截止到2030年。</strong></p>
  <p>收购将于2026年上半年完成，目前这一收购动作并未改变原有供应合同约定，人员尚无大规模变动，Intersect Power 的CEO也公开承诺自己仍会留在岗位上，公司也会独立运营。</p>
  <p>对于谷歌而言，AI 大模型训练对能源稳定性要求极高，更换储能供应商可能导致项目延期，特斯拉“储能+AI”的背景经验，对于谷歌来说不失为一个好的供应商。而老马也乐意当这个供应商。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b361736daeaa4f7da4ffa4e504237cff@5888275_oswg324421oswg1080oswg405_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，<strong>加州Oberon项目的1GWh储能系统</strong>已投入运营，为谷歌 AI 中心提供能源保障，另有四个大型项目（超半数合同量）预计 2027 年底前投产。</p>
  <p>正如 Intersect Power 的 CEO Sheldon 所说，美国的人工智能发展被卡在了这个国家最古老的行业——电力行业。美国拼凑式的电网并非为人工智能时代而建。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_de8b95eae54f4466b55cbd3bc68afc4d@5888275_oswg450873oswg1006oswg635_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Intersect Power 的 CEO Sheldo 近照</p>
  <p>而根据高盛研究预测，<strong>到2030年底，全球数据中心的电力需求可能增长165%。有着多年大储生产运营经验，并且有着AIDC建设经验的特斯拉，正是其储能坚挺的“王炸”。</strong></p>
  <h2><strong>02 新兴市场突进：澳洲日本接连拿下“最大”项目</strong></h2>
  <p>澳洲是特斯拉储能的核心战略市场，也是上海临港工厂首批货物的主要目的地。</p>
  <p>2025年，特斯拉成功斩获澳洲历史上最大规模的电网级储能订单，与法国开发商 Neoen 合作的Western Downs Battery 项目。</p>
  <p>该项目一期和二期已并网运营，储能规模总计约<strong>540MW/1,080MWh</strong>，第三期建设中将新增约<strong>305MW/1,220MWh</strong>，完工后整个设施储能总规模将达约<strong>845MW/2.3GWh。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f8582a495bb34994835df511c0b40805@5888275_oswg872100oswg1080oswg671_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，与Origin Energy合作的200MW/400MWh项目已稳定运行，满足南澳20万户家庭日用电需求，帮助客户降低调峰成本30%。</p>
  <p>要知道根据Clean Energy Australia的数据，2024年澳洲并网的大储也就约1.6GWh。特斯拉凭借这一个项目就超过了去年的总装机量。</p>
  <p>而凭借技术优势与临港工厂的供应保障，特斯拉 2025 年在澳洲电网级大储市占率高达35%，稳居行业第一。</p>
  <p>至于特斯拉进入日本储能市场的脚步，则是<strong>逐步从小规模试点到大规模工程落地</strong>的。</p>
  <p>早在 2022 年，特斯拉就与本地合作伙伴一起在北海道千岁启动了日本最早期的 Megapack 系统，用于参与电力卸载、需供调整等电网辅助服务。</p>
  <p>随后，Tesla 的储能系统在宫城县仙台电站等地投运了约10MW/43MWh级的网侧储能装置，进一步验证了其在日本高标准电网环境下的可靠性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b76ab2bb83ae4925865347bd1374fd36@5888275_oswg929522oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">特斯拉仙台储能项目</p>
  <p>到2025年，札幌市Helios项目约50MW/104MWh的Megapack系统已正式商业运营，成为当地批发电力、调频和容量市场的重要参与者。</p>
  <p>更重要的是，特斯拉在2025年赢得了与日本金融服务集团欧力士合作，为<strong>滋贺县米原湖东蓄电所提供总规模达约134MW/548MWh的Megapack储能系统</strong>的大单，该项目计划于2027年投运，将成为日本最大规模的储能设施之一。</p>
  <p>当然，特斯拉能在全球新兴市场获得青睐，很大的原因是特斯拉特有的电价分析和交易软件 Autobidder。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_adc3b05118854ab0b66224e187a1e4af@5888275_oswg89597oswg1080oswg398_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Autobidder界面</p>
  <p>Autobidder 通过 AI 算法，能通过实时数据分析，精准预测电网负荷波动与电价变化，并进行智能拍卖。</p>
  <p>这套系统不仅能优化储能系统的充放电策略、提升能源利用效率，还能将储能资产转化为 “可交易的金融产品”—— 帮助客户参与电力市场竞价、获取辅助服务收益。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_852d2d0f3a77496d81e239f53d5db8c7@5888275_oswg114408oswg945oswg476_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Autobidder部署分布图 来源：特斯拉官网</p>
  <p>对于主权基金和能源巨头来说，买特斯拉储能不是在买设备，而是在买一套确定性的年化回报。</p>
  <p>比如同样是 Neoen 开发的 Hornsdale Power Reserve（HPR）项目，自2017年底投入运营以来，平均每月贡献全国电力市场（NEM）约<strong>10%的Frequency Control Ancillary Services（频率控制辅助服务）市场价值，部分峰值月份甚至超过20%。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b80fa0b498954f5c8a433103685962ac@5888275_oswg77801oswg1035oswg694_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">HPR占NEM FCAS的比重以及收入，左轴为月度 FCAS 收入（澳元），右轴为 HPR 占 NEM FCAS 市场的月度收入份额（%）来源：HPRX Market Report</p>
  <p>而 FCAS 市场规模从2014 年不足5000万澳元增长至2021年4.38亿澳元，则说明频率控制服务的需求持续爆发，Autobidder带来的核心收益场景也具备长期增长潜力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_0394151f55a046e6a44dee2aba329a32@5888275_oswg33621oswg1019oswg669_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">澳洲全国电力市场年度 FCAS 价值趋势图 来源：HPRX Market Report</p>
  <p>HPR项目截至2023年11月的<strong>累计FCAS价值约1.82亿澳元（8.6亿元人民币）。</strong>这些“额外收入”，也是特斯拉即使在高单价下依然备受青睐的原因之一。</p>
  <h2><strong>03 东亚供应链托底：临港工厂产能爆发，韩国供应链规避风险</strong></h2>
  <p>业界应该都有一个共识 —— 特斯拉是玩供应链的好手。</p>
  <p>特斯拉储能业务的全年高增长，离不开上海临港储能超级工厂“产能爆发”的核心支撑——设计年产能40GWh，于2024年5月23日正式开工建设，仅用9个月就完成厂房搭建与产线调试。比当初汽车工厂投产还快三个月。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_3c4e534bcc984f548986d2944396017f@5888275_oswg471710oswg1080oswg572_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">特斯拉临港储能工厂大楼</p>
  <p>2025 年全年，临港工厂完成约26GWh的储能产量，占特斯拉全年总装机量的55.7%，成为全球大储产能释放最快的工厂之一。</p>
  <p>特斯拉在 Q3 财报中实现了<strong>历史最高的季度储能部署量</strong>，<strong>并指出这一增长由上海Megafactory储能产线的持续爬坡所驱动。</strong></p>
  <p>而根据BNEF2025年电池价格调查，<strong>中国固定式储能电池组价格降至70美元/kWh，同比45%下降</strong>。</p>
  <p>本身就接近行业成本洼地水平，再加上自身的“高定价”“高定位”，特斯拉临港工厂的产品仍然有不小的全球竞争的底气。</p>
  <p>目前临港工厂生产的产品主要销往澳洲、欧洲和日本。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_09ad3013e3c04f1f85496ba6c83ebd4e@5888275_oswg115310oswg899oswg506_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">第1000台Megapack出口欧洲</p>
  <p>尽管为 Megapack 提供电芯的宁德时代出货量已经占了全球七成以上，但马斯克肯定不会把赌注全压在中国供应链上。</p>
  <p><strong>为了规避“大而美”法案的限制，获得高达 50% 的“本土制造补贴”，特斯拉跟韩国电池巨头的合作一直没停下。</strong></p>
  <p>2025年7月，特斯拉月LG新能源签署了价值43亿美元的磷酸铁锂电池大单，创LG新能源史上最大单笔订单。</p>
  <p>LG新能源的密歇根州工厂将全力为特斯拉生产储能电池，计划2025年底前实现16.5GWh年产能，在2027到2030年间每年供应20-30GWh的电池。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_fce410f48ab048679637f3fe9479d03e@5888275_oswg372855oswg630oswg472_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">美国密歇根州霍兰德市的LG新能源工厂</p>
  <p>与此同时，特斯拉还正在与三星SDI洽谈储能电池合作，目前公布的信息可知此单价值约为21亿美元，三星SDI需用美国印第安纳州工厂为特斯拉生产30GWH的磷酸铁锂储能电池，分三年完成，预计2026年后开始。</p>
  <p>这种“既要又要”的供应链布局体系，不仅降低了单一来源风险，也让特斯拉在全球市场的定价与交付上拥有更大的战略弹性。</p>
  <h2><strong>04 结尾</strong></h2>
  <p>AIDC 场景驱动的技术积累、新兴市场的项目落地能力、横跨中美韩的供应链布局——只要这三者仍在协同运作，特斯拉的储能护城河短期内仍难被轻易撼动。</p>
  <p>2026 年，距离马斯克的《Master Plan》的“第一篇章”发布，宣称“让人类摆脱对化石燃料的依赖”，已经过去将近 20 年。</p>
  <p>这20年来人类仍未摆脱对化石能源的依赖，甚至马斯克自己为了训练AI也“偷”了一波火力发电。但AIDC对于储能增长的贡献是有目共睹的。</p>
  <p><strong>而对于特斯拉来说，聚焦高价值项目、筑牢 “硬件 + 软件” 生态壁垒，才是其穿越周期的关键。</strong></p>
  <p><strong>特斯拉储能的高增长故事，应该远未到落幕时。</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/JZALAnxQCVfNvuxDSIT_NQ" rel="noopener noreferrer nofollow" target="_blank">“新能源产业家”</a>，作者：秦翔昊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627848474575877</id>
            <title>如何让股价8个交易日暴涨100%？答案：被优必选们收购</title>
            <link>https://www.36kr.com/p/3627848474575877</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627848474575877</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:19:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>当一家名不见经传的A股小公司，被炙手可热的机器人新贵收购，会发生什么？</p>
  <p>答案是：股价连续八个交易日涨停，涨幅累计超100%，市值轻松突破83亿元。</p>
  <p>2025年末，人形机器人龙头优必选宣布控股上市公司锋龙股份，旋即点燃市场。这并非孤例，智元机器人收购上纬新材60%以上股份、追觅科技创始人入主嘉美包装、七腾机器人拿下胜通能源……硬科技独角兽纷纷入场，掀起一场瞄准A股“小公司”的收购潮。</p>
  <p>然而，热潮之中，也有冷流。近期，人形机器人领军者宇树科技被报道，上市进程“遇冷”，绿色通道被叫停，常规上市流程仍在继续。宇树科技随后对媒体表示，报道与事实不符合，公司未涉及申请“绿色通道”相关事宜。不过，这也为本轮机器人、硬科技火热的资本操作蒙上一层审视的阴影。</p>
  <p>一边是通过收购，曲线“入场”，带来被收购公司的股价狂欢；另一边是冲刺IPO，噪声变多。资本动向背后，硬科技新贵们究竟在谋划什么？</p>
  <p>尤其是这轮围绕A股公司的收购，是目的明确的借/囤壳，还是产业链竞争下的战略必需，抑或是出于投融资考虑？</p>
  <h2><strong>相似的收购，相异的境遇</strong></h2>
  <p>这一波硬科技独角兽主导的A股收购，从手法上看呈现出高度一致性：目标都是市值小、负债低，无重大诉讼的A股公司。</p>
  <p>方式均采用“协议转让+要约收购”组合，以最低成本获取控股权。</p>
  <p>12月24日，人形机器人龙头、港股上市公司优必选（09880.HK）发布公告称，以“协议转让+要约收购”的组合方式花费16.65亿元收购上市公司锋龙股份（002931.SZ）43%的股权，成为该公司的控股股东。</p>
  <p>这几家收购有很多相同之处，从交易结构上看，都是先通过协议转让，获得29.99%股份，巧妙避开了监管审核的30%红线；原控股股东放弃表决权，再发起部分要约收购，成本控制极为精准。</p>
  <p>优必选、智元、追觅、七腾机器人的收购操作高度相似。这一套打法已经颇为成熟。</p>
  <p>比如近期特种机器人企业七腾机器人入主胜通能源，七腾机器人及其一致行动人以11.24亿元，受让胜通能源实控人等股东合计29.99%股份，之后再要约收购合计15%股份。</p>
  <p>剥开相似外壳，各家收购背后的财务与战略驱动力却截然不同。优必选的产业布局需求更急迫。</p>
  <p>优必选收入增长平稳但仍未盈利，具有更强的布局供应链和压缩成本的动力。</p>
  <blockquote>
   <p>2024和2025年上半年，优必选营收同比增长在20%到30%之间，亏损收窄，但2025上半年归母净利润为亏损4.14亿元，毛利率也下降到35%，这次收购所要支付的交易对价16.65亿元，高于优必选账面资金。</p>
  </blockquote>
  <p>优必选于2018年推出了国内最早的人形机器人walker，于2023年12月在港交所挂牌，号称“人形机器人第一股”。但入场早也给优必选带来一定压力：人形机器人的需求爆发仍未到来，需求端还无法撑起公司的收入。</p>
  <p>2025上半年优必选收入6.21亿元，其中消费级机器人和教育机器人合占收入八成，其中包括推出不久的智能猫砂盆。</p>
  <p>相比之下，智元机器人2025年预计收入超10亿，业务刚刚形成一定规模，盈利情况未知；追觅科技则透露，2025年上半年公司营业收入已超过2024年全年总额（150亿元）。</p>
  <p>从投资主体上看，仅优必选是通过香港的上市本体进行收购，智元、追觅的收购均出自实际控制人个人及其控制的独立实体。</p>
  <p>收购中还出现了不多见的捐赠承诺：锋龙股份的原控股股东要在交易完成后向上市公司无偿捐赠8300万元，用于支持公司发展、改善资产状况。这侧面说明了收购方的强势地位。</p>
  <h2><strong>“借壳”疑云与真正的算盘</strong></h2>
  <p>市场第一时间联想到“借壳上市”，但深入分析，答案似乎是否定的。</p>
  <p>首先，他们有比借壳上主板更容易的上市方式。创业板第三套标准为预计市值不低于50亿元、最近一年营业收入不低于3亿元，没有盈利要求，主要适合亏损规模不大、有稳定盈利预期的优质科技企业，比如优必选。</p>
  <p>截至1月6日收盘，优必选港股市值约为640亿港元，2024年营收为13.05亿元人民币。根据现行政策，优必选可以选择直接在深交所二次上市，不必绕一大圈去借个壳。智元和追觅同样符合这个标准。</p>
  <p>其次，深交所等主板市场对借壳方有一定的盈利要求，门槛更高。</p>
  <p>几家收购案也纷纷以各种方式摆脱借壳的嫌疑。锋龙股份的公告中明确提及，未来36个月内，优必选不存在通过上市公司重组上市的计划或安排；未来12个月内，优必选不存在资产重组计划；智元和追觅相关的被收购公司也都明确提及不会在36个月内借壳上市。</p>
  <p>收购更有可能的是业务上的需求：优必选的机器人与锋龙股份的机械零部件在业务上具备强关联。锋龙股份长期深耕割草机等园林机械及发动机、液压控制系统及汽车零部件的研发与制造，拥有精密制造能力、成熟的供应链体系与客户基础，似乎可以看作是优必选直接的供应链上游。</p>
  <p>更可能的是，公司急需一些产业链整合，优必选的收购或意在锋龙股份的制造能力和资质。锋龙股份2022年被工信部认定为国家级专精特新“小巨人”企业，这意味着税收减免、研发补贴和低融资成本。同时，锋龙股份高精度、低成本的制造优势也可以让优必选跳过艰难的产能爬坡，迅速获得电机部件、执行器等核心零部件的产线；锋龙股份多年深耕的农业机器人也可能是优必选的业务新方向。</p>
  <p>哪怕不为上市，这次收购也可以为公司增加可靠的融资通道。</p>
  <p>收购上市公司后，由上市公司融资并发展上下游相关产业，可以有效减少母公司自身的资本投入。这也解释了上纬新材“抢母公司生意”的动作：上纬新材发布声明，在母公司智元的授权下独立开展机器人业务。与其说收购上市小公司是买“入场券”，不如说更像是给自己挖了一个“资金池”。</p>
  <p>这个收购也颇具一拍即合的意思：锋龙股份早有售卖计划。2024年2月，锋龙股份实控人曾经尝试过将企业卖给浙江顶度云享旅游有限公司，其所有人陈向宏是乌镇、古北水镇的实际操盘人。但这宗收购因收购方撤回协议而终止。</p>
  <h2><strong>量产前夜的集体冲锋与资本躁动</strong></h2>
  <p>这场收购潮并非偶然，而是行业进入关键转折点的标志。2026年，可能是机器人公司大规模资本化的一年。</p>
  <p>除上述收购案例，即将走向上市之路的硬科技公司还包括：具身智能宇树科技和云深处科技、商用服务机器人公司优地机器人、机器人控制器厂商仙工智能、机器人视觉公司乐动机器人、“协作机器人第一股”越疆科技等等。</p>
  <p>其中，宇树科技早已为登陆股市做好准备。2025年5月，“杭州宇树科技股份有限公司”中去掉了“杭州”，同时将公司类型转变为股份有限公司，同时增设独立董事，完成股改；6月，宇树完成C+轮融资，腾讯、阿里、蚂蚁集团、中国移动旗下基金、锦秋基金、吉利资本共同领投，多数老股东跟投；随后在7月，宇树开启上市辅导。</p>
  <p>另外，云深处和乐聚智能也已启动A股辅导。据统计，2025年全年港交所共34家机器人产业链相关公司递表。</p>
  <p>资本化的背后是量产和商业化的需求。</p>
  <p>根据TrendForce的最新预测，2026年全球人形机器人的出货量将超过5万台，是2025年的8倍。其中，国产人形机器人公司们均透露出雄心勃勃的投产计划：2025年10月，智元推出人形机器人精灵G2，并开启商用；12月，优必选刚刚宣布第1000台工业人形机器人量产下线，并计划在2026年提升产能至万台；计划2026年人形机器人生产放量的公司还包括宇树、小鹏等等。</p>
  <p>毫无疑问，资本市场对“机器人概念”的前景乐观，最直接的体现就是股价变化。</p>
  <p>除了锋龙股份的八连板，同样的故事也发生在智元机器人和七腾机器人的收购案中：截至1月6日，上纬新材半年内股价从不到8元飙升至130.76元，市值527亿，放大17倍，市盈率（PE）超过600。</p>
  <p>七腾机器人的收购在不到三周的时间里给胜通能源带来超200%的股价暴涨，以至于12月30日被停牌核查；嘉美包装已经录得11个涨停板。包括雪龙集团在内的多家公司也在春节后因间接持股宇树而股价大涨。</p>
  <p>股价上涨的除了与人形机器人企业具有资本关联的上市公司，也包括一众位于供应链上游的零部件生产商。</p>
  <p>这股热潮似乎也引起了监管方对炒作的警惕。我们不知道在这场大潮中还有哪些企业将在优必选们的操作中受益。但热度过后，唯有让生产、技术联合有效落地，才能够成为这场金钱游戏长久的宠儿。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI3OTEwMDQwNw==&amp;mid=2649967695&amp;idx=1&amp;sn=bf35a1f99c74b6bb284180ffa7751423&amp;chksm=f20110913f14dd25a17da4d3e695f92fef1449ef5c0f9ee08616e587f3bfd917afdda333bb46&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“豹变”（ID：baobiannews）</a>，作者：张经纬，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627847486457091</id>
            <title>炸，百款新品狂轰，百亿资金疯涌，十位创始人万字综述2025智能眼镜史</title>
            <link>https://www.36kr.com/p/3627847486457091</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627847486457091</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:18:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年是极不平常的一年，商业层面看，AI大模型攻城略地，智能体落地千行百业验证商业价值，人形机器人已能跑出一场马拉松赛，低空经济乘风而起，可控核聚变掀起投资热潮……商业世界从来不缺好故事。</p>
  <p>聚焦到智能硬件上，2025年AI硬件市场新物种频出，智能可穿戴赛道吸引大量资金涌入。“<strong>AI时代，所有硬件都值得用AI重塑一遍</strong>”，这已是广泛共识。</p>
  <p>2025年的智能眼镜行业，热度居高不下。AI时代加速到来，人机交互有了新的可能。想象力驱动之下，众多企业下场肉搏。</p>
  <p><strong>本文，亿欧采访十余家智能眼镜头部公司创始人、CEO、高管</strong>。这些企业是活跃在“牌桌”上的主流玩家，借助一线创业者们的视角，展现<strong>2025年智能眼镜行业变化。</strong></p>
  <p>本文略长，以下为内容提要：</p>
  <p><strong>第一节：“百镜大战”，76款新品再创新高。</strong></p>
  <p><strong>第二节：玩家扩容，176家上市公司入局。</strong></p>
  <p><strong>第三节：爆款频出，畅销产品陆续亮相。</strong></p>
  <p><strong>第四节：融资提速，近百亿资金涌入。</strong></p>
  <p><strong>第五节：行业转向，从拼产品、拼营销转向拼技术、拼创新。</strong></p>
  <p><strong>第六节：趋势研判，2026年怎么看？</strong></p>
  <h2><strong>第一节：“百镜大战”，76款新品再创新高</strong></h2>
  <p>与2024年相比，2025年智能眼镜行业热度有增无减。产品数量是重要观察维度。</p>
  <p>亿欧统计显示，<strong>2025年全年，中国市场共涌现76款新品</strong>，较2024年同比增加约40%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9d89fcffbb4a46b5ab74513b392f194e@000000_oswg1367535oswg1080oswg5274_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在众多品牌中，雷鸟创新是产品迭代速度最快的。</p>
  <p>2025年，雷鸟V3 AI拍摄眼镜、雷鸟Air 3s系列、雷鸟X3 Pro AR眼镜、雷鸟V3 Slim AI拍摄眼镜、雷鸟Air 4系列等新品陆续亮相，且创新点较多。</p>
  <p><strong>其中，双目彩色的光波导眼镜雷鸟</strong>X3 Pro有里程碑意义。<strong>雷鸟创新创始人兼CEO李宏伟</strong>向亿欧介绍，<strong>在光学显示上</strong>，雷鸟X3 Pro重量仅76g，却能实现6000尼特的峰值入眼亮度、彩色3D显示以及95%的彩虹纹抑制。为此雷鸟打造了全球最小的全彩MicroLED光学引擎“萤火光引擎”，体积只有0.36立方厘米。</p>
  <p>值得注意的是，雷鸟创新还将制作手机芯片的光刻技术应用到了眼镜上，打造了目前行业领先的光刻刻蚀的工艺光波导“RayNeo光波导”，使得眼镜在户外强光环境下仍然看得很清楚、且有极好的色彩表现。</p>
  <p><strong>李宏伟</strong>介绍，在空间计算最核心的<strong>SLAM算法上</strong>，雷鸟能在仅有4nm芯片上面完整地在本地运行SLAM算法，且精准程度和苹果接近，初始化效率仅几毫秒、功耗是行业优秀水平的一半。<strong>在人机交互上</strong>，在传统的触控、语音、按键等交互方式之外，还支持借助智能手表等辅助设备的手势，实现Vision Pro一样的人机交互效果。<strong>在AI能力上</strong>，与阿里通义一起开发了首个专为AR眼镜优化的可视化大模型，有了这个模型，眼镜的交互效率、应用场景都会得到很大的提升。</p>
  <p>亿欧了解到，除智能眼镜以外，雷鸟创新还发布了全球首款针对AR眼镜的AI开发平台“RayNeo AI Studio”，用户和开发者能够零代码开发AI Agents，并提供了AI智能体商店RayNeo AI Store。</p>
  <p>2025年，影目科技在轻量化一体式“AI+AR”智能眼镜探索上可圈可点，INMO AIR、GO系列在不同维度上都引领一时。</p>
  <p>比如INMO AIR3，成为行业首款量产的1080p一体式AI+AR智能眼镜，已然具备“AI手机”眼镜雏形；再比如INMO GO3，搭载8mm智能眼镜镜腿，推动让智能眼镜成为时尚单品。INMO GO3也是行业首个实现量产的换电智能眼镜，采用双芯片架构，配备两块可拆卸电池。</p>
  <p><strong>影目科技创始人杨龙昇</strong>向亿欧介绍，在差异化上，影目INMO所做的尝试主要集中在“轻量化一体式AI+AR眼镜”的长期探索上，始终把智能眼镜当作一个独立的智能体来构建。</p>
  <p><strong>杨龙昇</strong>介绍，影目INMO从来不将智能眼镜视为手机或生态的“外设”，而是从一开始就按“独立终端”设计。目前正在尝试在眼镜端打通整个AI的交互链路，正在联合行业伙伴合作推进这一尝试，让AI成为跨APP的协同中枢，让智能眼镜只需接收简单的文字/语音指令，就能调度应用、完成任务，真正做到在生活和工作中辅助人类。</p>
  <p>此外，李未可科技推出的Lawaken View AI眼镜旅拍版、Lawaken City AI眼镜时尚版、Lawaken City Air AI眼镜商务版等值得一提，在用户佩戴时长上表现不错。</p>
  <p><strong>李未可科技合伙人古鉴</strong>向亿欧介绍，合作伙伴统计显示，在展会期间，其AI眼镜翻译功能的累计使用时长已突破30000分钟，大量中外观众现场佩戴李未可AI眼镜进行实时交流与翻译。</p>
  <p><strong>李未可科技专注于AI眼镜的外贸全场景应用</strong>，还自研了面向外贸行业的WAKE-AI大模型。据<strong>古鉴</strong>介绍，WAKE-AI具备多语言实时翻译、多语言语音记录与整理、展会展位识别、展会智能体问答、名片识别、拍照翻译等能力，可在展会现场、海外商务洽谈、境外出差与旅游等场景中，为用户提供实时、专业、准确的智能服务。</p>
  <p>进入“百镜大战”阶段，很多品牌都在抢发新品，发布时间越早越容易抢占用户心智。</p>
  <p>在这方面，致敬未知表现较为出色。</p>
  <p>致敬未知深耕运动健康垂直场景。2025年初，致敬未知发布全新AI运动品牌BleeqUp，并成功将首款AI运动眼镜BleeqUp Ranger（中文名超影擎）推向市场，成为全球首款实现量产交付的AI运动眼镜。发布时间要抢先Meta半年之久。</p>
  <p>2025年9月，亿欧曾专访<strong>致敬未知丨BleeqUp超影擎创始人兼CEO吴德周</strong>。本文撰写前，亿欧联系致敬未知并采访了业务进展等多个问题。</p>
  <p>在产品上，<strong>吴德周</strong>向亿欧介绍，尤其是骑行、徒步等核心运动人群的复购和推荐意愿很高，首批用户的口碑比较扎实。用户对BleeqUp Ranger最满意之处有三点：</p>
  <p><strong>一是“无感集成”的一体化设计</strong>，BleeqUp Ranger将运动相机、运动耳机、对讲机都集成到运动眼镜形态里，用户无需再额外携带设备。<strong>二是音频能力</strong>，运动时音乐播放、通过对讲机功能实时沟通等，音质皆清晰稳定，能适配户外复杂的噪音环境。<strong>三是拍摄防抖能力</strong>，在高速骑行、骑马、跑步等颠簸场景下也能拍出稳定流畅的第一视角画面。</p>
  <p>从以上用户对BleeqUp Ranger的反馈来看，智能眼镜要想得到用户认可，“花拳绣腿”固然能吸引注意力，但真材实料才是关键。</p>
  <p>除众多创业公司外，多家AI硬件公司、手机厂商、互联网厂商、汽车厂商也“卷”了进来。</p>
  <p>比如小度科技，2025年11月，小度科技发布了小度AI眼镜Pro。<strong>小度科技</strong>向亿欧介绍，小度在智能眼镜上花费的精力，更多是将具有真实用户价值的功能做扎实。此外也在持续做一些创新性尝试，例如氛围歌单功能，可通过识别眼前的风景、画面，自动为用户提供应景的音乐。</p>
  <p>小度科技在硬件领域深耕多年，旗下智能音箱、智能屏、闺蜜机、健身镜、智能摄像机等硬件产品销量可观，对如何打造AI硬件理解深刻。</p>
  <p><strong>小度科技</strong>认为，AI硬件若要真正走向大众市场，必须完成从“极客玩具”到“日常工具”的转变。其<strong>核心路径不是追求功能的无限叠加，而是聚焦于少数能创造真实用户价值的核心场景</strong>，并将这些功能体验打磨到极致。</p>
  <p>2025年，<strong>智能眼镜推新节奏一直持续到岁末</strong>。</p>
  <p>12月29日，闪极科技为智能眼镜行业带来收官力作。当晚，闪极loomos AI显示眼镜S1、闪极loomos AI拍摄眼镜L1两款新品亮相，同时，闪极科技还发布了全新一代AI眼镜基座平台。</p>
  <p>相比初代AI拍拍镜，闪极科技此次推出的两款新品实现全面优化。针对首款AI眼镜老用户，闪极科技推出了力度颇大的补偿和优惠方案，对老用户充满诚意。</p>
  <p>2025年12月初，<strong>闪极科技创始人兼CEO张波</strong>曾向亿欧透露，预计将于2026年3月举办发布会，或将进一步公布更多信息。</p>
  <p>在产品数量上，2025年中国智能眼镜行业的确百花齐放。</p>
  <p>2026年开年，字节跳动的进场又让这个行业充满了“火药味”。字节跳动进军AI眼镜传闻已久。1月5日，市场传出<strong>字节跳动</strong>豆包AI眼镜即将进入出货阶段。从供应链获悉，第一代AI眼镜大约10万台，或将延续字节在AI硬件上的谨慎投放策略。</p>
  <p>应该说，尤其是小米、阿里巴巴、字节跳动的巨头入局，为这个行业带来了泼天流量，对现阶段的智能眼镜行业有极大的推动作用。</p>
  <p>本文由于篇幅所限，不再逐一展开。</p>
  <p>这背后折射的变化是，众多智能眼镜实现量产交付，且越来越受到消费者的认可。</p>
  <h2><strong>第二节：玩家扩容，176家上市公司入局</strong></h2>
  <p>2025年智能眼镜行业加速发展。“行业的进步主要体现在三个方面：<strong>市场</strong>从‘技术驱动’转向‘价值驱动’，<strong>用户</strong>从‘参数敏感型’变为‘体验敏感型’，<strong>产品</strong>从‘硬件堆叠’演进为‘场景深度融合’，”<strong>吴德周</strong>认为，“2025年的行业进步，是市场、技术、场景、生态四重驱动下的系统性质变。”</p>
  <p><strong>吴德周</strong>介绍，<strong>在市场层面</strong>，迎来从“量变积累”到“质变拐点”的变化，进入了从“小众尝鲜”迈入“规模化培育”阶段。最直观的信号是规模化和大众认知的双重跃迁。智能眼镜销量大幅增长，更说明智能眼镜正从极客玩具，变成有一定普及度的“准大众消费品”。市场进入规模化培育阶段，用户对AI眼镜的认知已从“这是什么”，转向“这能为我做什么”，这是品类迈向长期健康的基石。</p>
  <p><strong>在技术层面</strong>，直观进步是佩戴体验的本质优化：超薄光波导镜片规模化量产、专用芯片与传感器的升级，进一步降低了主流产品重量，续航得到大幅提升。并且，随着行业热度提升，第一代AI眼镜已完成用户教育的关键一步，消费者体验后清晰反馈出痛点，倒逼行业进入“需求驱动型迭代”阶段。</p>
  <p>同时，终端需求的爆发也拉动了上下游供应链的成熟，从光波导镜片的更薄化、高透化，到传感器的小型化、低功耗，形成了“用户反馈-厂家迭代-供应链升级”的正向循环。</p>
  <p><strong>在场景层面</strong>，一大进步是场景垂直化。2025年很多AI眼镜产品不再追求“万能”，而是围绕运动、健康、办公等细分场景深耕。<strong>场景垂直化已成为当前阶段最高效的进化路径</strong>。无论是运动、健康、翻译还是办公，产品正通过解决具体场景的刚需，积累用户黏性与数据飞轮。</p>
  <p><strong>在生态层面</strong>，行业生态从“零散布局”走向“协同共建”，巨头密集入局形成多元竞争阵营，从手机厂的小米、联想，到互联网大厂的阿里、百度，再到专业品牌的深耕，让产业链各环节加速成熟。</p>
  <p>“下一步的竞争焦点，将不再是硬件参数的较量，而是在特定场景中，能否构建“感知-决策-交互”的完整闭环，并形成可持续的用户价值与商业模式。”<strong>吴德周</strong>表示。</p>
  <p>对于2025年的行业变化， 杨龙昇也有相似看法。<strong>杨龙昇</strong>介绍，2025年中国消费级智能眼镜行业进入了一个高速发展期。从手机厂商、互联网大厂等密集入局，到上下游产业链加速发展，再到消费者认知明显提升，智能眼镜不再仅停留在新奇感，现在已经实现了在很多垂直场景有用、好用。</p>
  <p>并且，<strong>杨龙昇</strong>认为，行业的关注重点也在发生转移，<strong>从技术可行性和功能、参数堆叠，转向全天候佩戴与真实使用价值</strong>。而AI的成熟，也正让智能眼镜从单一功能工具，升级为具备感知、理解与即时反馈能力的交互入口。</p>
  <p>这些进步离不开众多玩家的合力推动。</p>
  <p>据亿欧统计，2025年，国内至少40家企业活跃在市场一线，较2024年进一步扩容。</p>
  <p>给这些玩家分类，大致可划分为四类：<strong>一是XR创业公司</strong>，包括影目科技、VITURE、致敬未知、雷鸟创新、微光科技、XREAL、逸文科技、光粒科技、瞳行科技、INAIR、蜂巢科技、谷东智能、乐相科技、莲藕科技、秋果计划、Gyges Labs、亮亮视野、李未可科技、Rokid、形意智能等。</p>
  <p><strong>二是智能硬件公司</strong>，包括小度科技、追觅、闪极科技、LIPO李白、韶音科技等。</p>
  <p><strong>三是互联网大厂、手机厂商和上市公司</strong>，包括小米、阿里巴巴、vivo、华为、第四范式、利亚德、康冠科技、联想、传音控股、雷神科技等。</p>
  <p><strong>四是汽车厂商等跨界新势力</strong>，包括理想汽车、老凤祥等。</p>
  <p>值得一提的是，智能眼镜“麻雀虽小，五脏俱全”，要做好一款智能眼镜并不容易。这背后的逻辑是，如果产品得不到消费者认可，研发迭代速度跟不上，企业将很快被市场淘汰。</p>
  <p>比如<strong>加南科技</strong>，2024年12月31日加南科技发布AI智能近视眼镜KANAAN-K1，官方称具备听音乐、拍照、翻译、导航、物体识别等多种能力。</p>
  <p>然而尴尬的是，KANAAN-K1自亮相后似乎并未升级焕新，2025年仅能在极少数场合看到。近日官方称产品亮相了央视一档栏目。如果不是新近资讯，外界很可能会认为加南科技AI眼镜已经消失了。</p>
  <p>即使背景雄厚的企业有时也难逃厄运，比如<strong>星纪魅族</strong>，业内一度高度看好其发展前景。吉利创始人李书福也很重视星纪魅族XR业务，曾于2025年3月在公开场合佩戴智能眼镜为其站台。</p>
  <p>但很遗憾，2025年早些时候传出星纪魅族XR业务遭到分拆关停的消息，品牌影响力大幅下滑。2025年9月，疑似改用魅族品牌发布魅族StarV Snap AI拍摄眼镜。亿欧曾向官方求证是否发布了新品，对方回复“不太清楚”。</p>
  <p>星纪魅族的遭遇让人唏嘘。</p>
  <p>现阶段，尽管行业炙手可热，但仍存在很多挑战。<strong>小度科技</strong>认为，当前AI眼镜行业呈现出“巨头领跑、多方突围”的格局，面临的挑战同样清晰：</p>
  <p><strong>一是功能同质化严重</strong>：语音助手、识物、听歌、拍照等功能成为标配，即便巨头投入饱和资源，短期内也难以拉开代差。</p>
  <p><strong>二是“玩具”与“工具”的定位摇摆</strong>：许多产品堆砌炫酷功能，却未能解决真实、高频的用户痛点，导致新鲜感过后迅速被闲置。</p>
  <p><strong>三是“不可能三角”困境</strong>：轻便穿戴体验、高性能运行和长续航能力之间难以兼得，是行业长期面临的核心挑战。</p>
  <p>最终传导至企业时，可能很多企业都面临着经营压力。在这种背景下持续投入研发，像极了“戴着脚镣跳舞”。</p>
  <p>除直接下场的企业以外，供应链上下游玩家也值得一探究竟。其中，上市公司是重要指标。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_7177fa3da11f4e278f6a39404db804f4@000000_oswg2090204oswg1080oswg4594_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据亿欧统计，截至2025年12月31日，<strong>A股市场共有176家上市公司涉足智能眼镜业务</strong>。其中，2025年以来新增85家，数量较2024年同比翻一番。</p>
  <p>在上市公司中，部分企业直接下场自研智能眼镜产品，比如<strong>老凤祥</strong>、<strong>利亚德</strong>、<strong>雷神科技</strong>、<strong>传音控股</strong>等。</p>
  <p>其余大部分企业，皆以供应零部件或解决方案的形式参与其中。比如<strong>芯海科技</strong>，压力触控产品应用于阿里夸克AI眼镜；<strong>南芯科技</strong>，为阿里夸克AI眼镜提供超长续航的电源芯片解决方案；<strong>光莆股份</strong>，光集成传感器封装产品间接用于AR眼镜；<strong>春秋电子</strong>可为AI眼镜提供结构件，<strong>八亿时空</strong>旗下液晶材料可应用于单色和彩色电致变色版AI眼镜等等。</p>
  <p>无论如何，越来越多上市公司的涌入，都将进一步提升整体行业水准。</p>
  <h2><strong>第三节：爆品频出，畅销产品陆续亮相</strong></h2>
  <p>2025年，智能眼镜行业涌现多款畅销品，Rokid乐奇AI眼镜是首个“出圈”的<strong>。</strong></p>
  <p>2025年上半年，Rokid创始人祝铭明以一段“脱稿”演讲视频走红网络，顺势“带飞”Rokid，成为智能眼镜行业率先“破圈”的创业公司，其推出的乐奇AI眼镜受到多家媒体关注。</p>
  <p>公开资料显示，Rokid乐奇AI眼镜订单量达到30万副。应该说，Rokid的走红，为推动智能眼镜行业发展发挥了重要作用。</p>
  <p><strong>Rokid创始人兼CEO祝铭明</strong>向亿欧介绍，乐奇AI眼镜算是第一个规模商业化的带显示的智能眼镜，所以在产品定义上一定程度上影响了行业的发展，很多智能眼镜都与乐奇AI眼镜有着相似的设计理念，比如一些硬件配置和软件应用。“一家创业公司可以影响到整个行业，是我们的荣幸。”</p>
  <p>在市场竞争方面，<strong>祝铭明</strong>认为，“今天的智能眼镜行业，无论是系统、硬件、生产，或者是消费市场，中国企业都有信心和实力与一些国际大厂平起平坐，应该平视世界。”</p>
  <p>“下一步，Rokid将在软件系统上保持高强度的更新，持续优化用户体验，并在品牌和外观上进一步探索，”<strong>祝铭明</strong>表示，“无论外界环境发生什么变化，Rokid都会专注于自己的产品研发。”</p>
  <p>2025年，不止Rokid一家打造了畅销产品，小米、阿里夸克等销量都比较可观，这也是行业一大进步。</p>
  <p>先是<strong>小米</strong>。2025年6月底，在小米人车家全生态发布会上，小米首款AI眼镜“千呼万唤始出来”。为了给AI眼镜造势，雷军亲自为AI眼镜站台，称小米AI眼镜是面向下一个时代的个人智能设备，也是随身的AI入口。</p>
  <p>小米AI眼镜发布后，销量屡破新高。有自媒体统计，开售15天销量突破8万副，到11月下旬，销量已达到20万副。成为2025年行业销量“黑马”。</p>
  <p>后是<strong>阿里巴巴</strong>。11月27日，阿里夸克AI眼镜S1、G1亮相，首发两个系列，共六款单品。作为阿里首款自研旗舰产品，夸克AI眼镜搭载了千问AI助手。</p>
  <p>开售4个小时内，夸克AI眼镜S1登顶天猫、京东、抖音三大平台的智能眼镜相关热销榜。当晚位居天猫XR设备行业销量与店铺双第一、抖音电商智能设备榜榜首。12月10日，据报道夸克AI眼镜S1在多渠道“上架即售罄”，发货周期已被拉长至45天。</p>
  <p>小米、阿里巴巴等巨头的入局，一方面，对创业公司来说固然存在一定的竞争，但现阶段更大影响还是正面的，大厂不仅为行业带来了泼天流量，更重要的是进一步强化了用户普及和市场培育。</p>
  <p><strong>杨龙昇</strong>认为，这是一个差异化竞争的演进。大厂入局对行业是好事，它们在品牌、渠道和生态上具备优势，能够快速完成市场教育，但这并不等同于决定最终格局。</p>
  <p>“未来市场一定是分层的：大厂可能推动规模化普及，而真正把眼镜做成长期佩戴的下一代终端，以及在专业与细分场景中持续创新，仍然为创业企业留下了足够广阔的发展空间，”<strong>杨龙昇</strong>表示，“智能眼镜的发展还需要一个长期、深度打磨的过程，<strong>创企应做的就是评估区别于‘大厂’的差异化优势</strong>，找准产品的定位方向，<strong>垂直深耕下去</strong>，形成从底层硬件到OS到整个内容生态全流程的自主竞争力。”</p>
  <p><strong>吴德周</strong>也认为，当前行业仍处于增量市场培育期，不是存量竞争，手机大厂的入局是好事——品牌声量和资源能加速用户教育，完善供应链，做大行业“蛋糕”。小米、阿里进场后，更多消费者开始关注AI眼镜，这个品类的认知度大幅提升。</p>
  <p>“BleeqUp超影擎作为垂直赛道的玩家，也能享受到行业增长的红利。从体感上来说，并没有感受到直接的竞争压力，反而因为市场关注度的提升，获得了更多用户和合作伙伴的关注，”<strong>吴德周</strong>表示，“这个市场足够大，容得下不同生态位的玩家。手机大厂擅长通用场景的规模化普及，而<strong>创业公司可以在垂直场景深耕</strong>，打造差异化优势。”</p>
  <p>值得一提的是，本文撰写前，<strong>亿欧曾联系阿里巴巴、小米官方了解相关问题</strong>，<strong>双方均婉拒了采访</strong>，<strong>均称不便发声或无法回答</strong>。</p>
  <p>要做一款体验极佳的智能眼镜并不容易，涉及光学显示、芯片计算、电池续航、硬件设计等诸多环节。核心技术的进步是提升终端产品体验的关键。</p>
  <p>在智能眼镜终端产品之外，万有引力发布的空间计算芯片值得一提。</p>
  <p>2025年11月底，万有引力推出极智G-X100、极眸G-VX100及极颜G-EB100三款自研空间计算芯片，以及空间计算全栈解决方案“极域”。</p>
  <p>此前，在接受亿欧专访时，<strong>万有引力创始人兼CEO王超昊</strong>介绍，当前通用型芯片企业占据XR芯片90%以上市场份额。万有引力选择“专用芯片”路线，专注XR场景定制，聚焦空间计算专用功能，不与前者在通用主芯片领域重叠。</p>
  <p><strong>王超昊</strong>认为，下一代技术将实现数字信息与真实世界的无缝融合。虚实融合可以“双路径”并行，一是沉浸式MR路线，设备相对厚重，主打沉浸体验。二是轻量化AR/AI路线，强调移动与轻便，更适合全天候佩戴。</p>
  <p>聚焦到XR芯片上，在研发环节还存在诸多难点。<strong>王超昊</strong>认为，“实现‘大通量、低延时、低功耗’三重目标的极致平衡，仍是当前技术攻关的核心挑战，也是中国企业在XR芯片领域实现自主突破必须跨越的门槛。”</p>
  <p>值得注意的是，多款畅销产品走到聚光灯下的另一面是，也衬托出了其余产品的“黯淡”。由此，<strong>行业竞争格局开始出现松动迹象</strong>。</p>
  <p>一段时间以来，雷鸟创新、Rokid、XREAL、影目科技被多家媒体誉为“AR四小龙”，在核心技术、产品迭代、硬件设计等方面表现较为出色，占消费级智能眼镜市场80%以上市场份额。</p>
  <p>但在2025年，四家的表现明显分化。</p>
  <p><strong>雷鸟创新</strong>是“两条腿”走路，下半年科技博主王自如“入职”吸引了一波关注，且在资本层面完成单笔最高融资，刷新了行业纪录；<strong>Rokid</strong>在前文已表，不再赘述；<strong>影目科技</strong>推出的INMO GO3备受消费者关注，得到吴晓波等众多知名人物“推荐”。</p>
  <p>相比之下，<strong>XREAL</strong>目前未涉足AI眼镜，一直沉浸在AR眼镜路线上。就在近日，围绕专利问题，还与VITURE打起了“口水战”。另有知情人士向亿欧透露，XREAL近期“变动很大”“动作很多”。</p>
  <p>如果2026年延续上述表现，作为“老牌”XR创业公司，<strong>XREAL可能会面临较大压力</strong>。</p>
  <h2><strong>第四节：融资提速，近百亿资金涌入</strong></h2>
  <p>2025年，智能眼镜行业在融资上进一步提速，吸引了近百亿元资金涌入。</p>
  <p>先是头部四家，其中，雷鸟创新、影目科技、XREAL均完成一轮或多轮融资。</p>
  <p><strong>影目科技</strong>完成多轮融资。2025年7月，“影目科技”完成超1.5亿元B2轮融资，由普华资本、梁溪产发集团、神骐资本联合投资。2025年8月，又完成B3轮融资，由源铄基金独家投资。</p>
  <p><strong>雷鸟创新</strong>融资金额较高。2025年11月，雷鸟创新完成由中信金石领投、中信证券国际资本及中信证券投资共同参与的C轮融资。本轮融资也创下2025年国内AI+AR眼镜领域单笔融资金额的最高纪录。</p>
  <p>就在1月5日，雷鸟创新完成新一轮超10亿元融资，成为2026年开年第一家官宣完成融资的消费级AR眼镜品牌。</p>
  <p><strong>XREAL</strong>在2025年4月完成约2亿元战略融资，由浦东创投集团投资。与此同时，2025年XREAL还将总部搬迁到了上海浦东。</p>
  <p>剩余<strong>Rokid</strong>，是头部玩家中未完成融资的少数案例，与产品畅销反差较大。一方面，Rokid在公开场合称订单量已达30万副，但另一方面，2025年并未实现注资。</p>
  <p>有AI硬件公司从业人员向亿欧表示，按理说大家都在“抢钱”，Rokid理应也会有融资，“现在看起来比较奇怪。”</p>
  <p>但也有知情人士向亿欧透露，2025年Rokid在资本层面似乎也有动作。不过，截至发稿Rokid并未官宣。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_dad630e7b2fa4b1486c293bdf68bd482@000000_oswg540112oswg1080oswg1436_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除上述四家以外，微光科技、INAIR、VITURE、Gyges Labs、光粒科技、闪极科技等企业均完成了注资，融资金额从数千万元到数亿元不等。</p>
  <p>比如，2025年5月，亿欧首发报道<strong>微光科技</strong>于2024年年底完成近5000万元Pre-A轮融资。2025年5月，<strong>INAIR</strong>完成数千万元A轮融资。2025年9月，天眼查显示，<strong>VITURE</strong>完成约1亿美元B轮融资。2025年11月，<strong>光粒科技</strong>完成超亿元A+轮融资。2025年11月，<strong>Gyges Labs</strong>完成Pre-A+轮融资。2025年12月，<strong>闪极科技</strong>完成新一轮近亿元融资。</p>
  <p>2025年还值得关注的是，<strong>资金由品牌端开始向上游转移</strong>，主要聚焦在关键技术上，MicroLED、光波导等核心厂商成为新一轮“被追逐的对象”。<strong>上海显耀（JBD）</strong>、<strong>至格科技</strong>、<strong>国研新能</strong>、<strong>理湃光晶</strong>、<strong>耐德佳</strong>等皆获得注资。</p>
  <p>其中，<strong>JBD</strong>作为智能眼镜行业核心供应商，2025年连续完成B1、B2轮，B2轮融资超过10亿元，刷新了行业纪录。</p>
  <p><strong>耐德佳</strong>也值得一提，2025年耐德佳完成C3、C4两轮融资。在AR/VR领域，耐德佳已推出自由曲面AR光学系列、Pancake VR系列等多个解决方案，成为国内首家采用曲面模内注塑技术实现Pancake偏振光学元件的光学模组供应商。</p>
  <p>此外，<strong>视涯科技</strong>IPO于2025年12月24日上会获得通过，本次上市拟募集资金约20.15亿元。视涯科技核心产品为硅基OLED微型显示屏，可提供包括战略产品开发、光学系统和XR整体解决方案等服务。</p>
  <p>资本对智能眼镜的认可度的确在上升。在2025年3月接受亿欧专访时，<strong>创瓴资本管理合伙人兼首席执行官曹旭波</strong>表示，“以长期视野看，从2012年的Google Project Glass，到最近大火的Ray-Ban Meta眼镜，智能眼镜几经起伏，近期的确正在升温。我们认为，当前智能眼镜已经由非共识进入到了共识阶段。”</p>
  <p>“智能眼镜是AI大模型落地的最佳载体之一，如果智能眼镜成为下一代计算平台，那一定不是小幅度的变化，而将为商业带来颠覆式变革。”<strong>曹旭波</strong>认为。</p>
  <p>想象力之下 ，一年近百亿资金开始涌入智能眼镜行业。</p>
  <h2><strong>第五节：行业转向，从拼产品、拼营销转向拼技术、拼创新</strong></h2>
  <p>除了产品、玩家、融资等以外，从行业层面看，2025年智能眼镜行业看点颇多。</p>
  <p><strong>一是智能眼镜行业首次出现分级标准</strong>。</p>
  <p>2025年3月，<strong>XREAL创始人兼CEO徐驰</strong>提出全球AI眼镜行业首个L1-L5分级标准。</p>
  <p>在此前采访中，<strong>徐驰</strong>介绍，L1（基础响应级）阶段的核心是突破声学机械响应，综合性能相当于1岁婴儿的条件反射能力。目前正处于L2（智能辅助级）阶段，综合能力相当于5岁儿童。未来将很快进化到L3（智能助理级）阶段，并于<strong>2027年进入L4（智能协同级）阶段</strong>，达到25岁成人社会认知水平。行业终局则是L5（超智能体级）阶段。</p>
  <p>无独有偶，2025年9月，<strong>灵犀微光创始人郑昱</strong>也提出了消费级AR眼镜L1-L4四级发展体系。其中，L1为基础感知、L2为智能助理、L3为AR协同、L4为空间计算。</p>
  <p><strong>二是中国AR厂商在海外打响专利第一案</strong>。</p>
  <p>年末岁尾，XREAL、VITURE两家企业围绕专利问题上演了激烈的对抗。</p>
  <p>2025年12月19日，媒体报道称，VITURE&nbsp;Pro等产品侵犯了XREAL所持有的欧洲专利（专利号：EP3754409B1），且VITURE Pro已在亚马逊德国、法国、意大利、西班牙、波兰、荷兰、爱尔兰、瑞典、比利时等9个欧盟站点下架。</p>
  <p>12月24日，<strong>VITURE</strong>向亿欧介绍，产品在整个欧洲仍然完全可售且在线。没有任何产品列表被移除。将继续坚决维护合法权益，并将积极应对任何不公平、误导性或不正确的指控。</p>
  <p>随后，XREAL再次回击VITURE。截至发稿，此事未有更明确进展。这起专利案可以称得上XR行业首次具有较大影响力的诉讼事件，很有标志性意义。</p>
  <p>亿欧认为，技术研发和产品推新固然重要，但唯有尊重原创、尊重创新，共同维护好健康、良性的竞争秩序，企业才能发展长久。</p>
  <p><strong>三是谷歌重启智能眼镜</strong>。</p>
  <p>谷歌堪称智能眼镜行业资深玩家，曾率先发布智能眼镜产品，但仅维持了三年便宣告夭折。2025年，时隔十年后谷歌再次卷土重来，推出Android XR，并重启AI眼镜、AR眼镜等多类产品。从全球范围看，谷歌重启智能眼镜都有风向标意义，成为绕不开的重要事件。</p>
  <p><strong>杨龙昇</strong>认为，这一次谷歌重启智能眼镜，和十年前的本质区别在于时代条件已经完全不同。十年前无论是硬件形态、算力，还是AI能力，都不足以支撑眼镜成为高频终端。而今天，硬件条件发生了质变，多模态交互和端侧智能已经成熟。谷歌这次同时推进多种眼镜形态，并推出Android XR，本质是将眼镜当作独立终端来搭建长期平台和建设生态。</p>
  <p>“这是对整个行业是非常重要的正向信号，同时也验证了影目INMO一直坚持‘下一代移动智能终端’目标的前瞻性。”<strong>杨龙昇</strong>表示。</p>
  <p><strong>吴德周</strong>也认为，十年前的谷歌眼镜，更像是技术概念的验证，产品形态、应用场景都不清晰，也缺乏成熟的生态支撑，最终难以落地；而这次重启，谷歌的定位很明确——通过Android XR打造统一的XR系统平台，向下兼容多种硬件形态，向上为开发者提供统一标准，破解行业碎片化难题。同时推进多种产品，覆盖不同场景，也是为了找到最佳的市场切入点，避免单一产品的失败风险。</p>
  <p>“最大区别在于‘从技术探索转向生态共建’，不再是单一产品的孤注一掷，而是通过‘多产品布局+系统平台’的方式，推动行业标准化和生态成熟，这对整个行业来说都是重大利好，也预示着XR竞争将转向‘操作系统级博弈’。”<strong>吴德周</strong>认为。</p>
  <p><strong>谷东智能创始人崔海涛</strong>向亿欧介绍，十年前谷歌眼镜在形态上很难被消费者接受，理念比较超前。现在谷歌意识到了问题，这次产品在设计上有很大进步，更适合日常佩戴。并且谷歌有Gemini大模型和庞大的安卓生态，AI能力等方面都得到了大幅提升。</p>
  <p>并且，<strong>崔海涛</strong>认为，“谷歌是AR领域不容小觑的强大玩家，未来潜力甚至可能比Meta和苹果更大，即将发布的新品也值得期待。”</p>
  <p><strong>小度科技</strong>则认为，和以前最大区别是底层技术，尤其是AI技术的发展阶段不同。目前，AI技术已经能够支撑智能眼镜的发展。“谷歌重回智能眼镜行业，是有利于行业发展的，小度科技乐见有谷歌这样在前沿科技探索得更深入的企业，能在产品形态、核心技术上有更多的突破。”</p>
  <p>古鉴的观点略有不同。<strong>古鉴</strong>认为，谷歌Android XR未必是当下的最佳技术路径。AI与AR眼镜天然面临“性能、功耗、佩戴体验”的“不可能三角”，是否在终端采用完整Android体系，目前业内并没有形成共识。</p>
  <p>“谷歌重启智能眼镜，对提升行业关注度和生态活跃度是利好，但在底层技术路线方面，行业仍处于多方案并行阶段，轻量化、低功耗的RTOS等方案，同样是值得重视的重要方向。”<strong>古鉴</strong>表示。</p>
  <p><strong>四是行业依然缺乏“杀手级”应用</strong>。</p>
  <p>一个很有意思的话题是，行业的确很热闹，众多知名人物也纷纷在公开场合推介智能眼镜。但截至目前，仍未出现“非它不可”的功能。</p>
  <p>现阶段，所有智能眼镜产品的功能、应用都是手机等终端的“复制”。这也就意味着，消费者可能很难有足够强烈的意愿，花费数千元购买一个猎奇产品。</p>
  <p><strong>吴德周</strong>认为，缺乏“非它不可”的核心价值，是全行业面对的挑战。恰恰说明，垂直场景是突破这个困境的关键，因为垂直场景更聚焦、更精准，能深度挖掘特定人群的核心痛点，而不是泛泛地覆盖全场景需求。</p>
  <p>“不用着急，任何新一代计算平台的发展都需要时间，智能手机从出现到找到移动支付、社交这样的‘杀手级’应用也用了好几年，现在行业对垂直场景的深耕，正是在为‘杀手级’应用的出现铺路。”</p>
  <p><strong>杨龙昇</strong>也认为，“杀手级”应用的出现需要阶段性演进，不是一蹴而就的。类似的情况在智能手机早期也发生过，并不是被“设计”出来的，而是建立在算力、模型、硬件形态和生态逐步成熟之上。智能眼镜的“杀手级”应用不会是单点功能，而是把多模态大模型能力深度嵌入轻量化眼镜形态中，让它成为真正的智能助手。当硬件足够轻、模型足够强、生态足够开放，“杀手级”应用会自然浮现。</p>
  <p><strong>三是行业“吹牛成风”，堆功能、炫技、销量夸大等乱象依然存在</strong>。</p>
  <p>很多行业都是由草莽时代，经过大洗牌再逐渐过渡到“精耕细作”时期。智能眼镜行业也不例外。2025年，智能眼镜行业依然没有完全迈过2024年“吹牛”阶段。</p>
  <p><strong>吴德周</strong>认为，“堆功能、炫技”现象确实存在，很多企业为了抢占市场，盲目叠加功能，却忽略了用户的核心需求，导致实用性不足。这是行业发展初期的常见问题。</p>
  <p>“判断一个功能是否有价值，核心标准是‘是否解决了特定场景下的刚需，是否让用户的体验更简单’。”<strong>吴德周</strong>表示。</p>
  <p><strong>小度科技</strong>则认为，做好AI硬件产品不是在硬件上塞入AI，也不是AI公司找到硬件后简单拼接。定义大模型时代的智能硬件，不是单纯的硬件问题或模型问题，而是软硬结合、端到端优化的问题。要让端到端体验顺滑，要为大模型定制整体技术架构，哪些模型放在端上，哪些放在云上，如何让传感器、芯片、存储的组合更适配需求，如何在成本与性能之间实现平衡？都需要深入思考。</p>
  <p>2025年，智能眼镜行业还有诸多值得关注的现象级事件或变化，这个行业充满无限可能。</p>
  <h2><strong>第六节：趋势研判，2026年怎么看？</strong></h2>
  <p>身处其中，所有人都很关心，2026年智能眼镜行业将会出现哪些趋势？应该怎样布局？</p>
  <p>一线创业者有更清晰的观察。</p>
  <p>在行业发展阶段上，李宏伟并不认同“2025年是AI眼镜元年”的说法。<strong>李宏伟</strong>表示：“坦白说我不是很认同这个观点，什么时候是？可能明年是（2026年），即便我不觉得明年是iPone时刻，我也觉得明年是AI眼镜元年，原因是明年产品能真的达到用户的体验标准。”</p>
  <p>“<strong>如果非要说元年，我认为明年</strong>（2026年）<strong>是元年，2027年、2028年是iPhone时刻</strong>。这是有区别的，明年可以达到体验标准，2027、2028年真正达到iPhone的状态，背后是技术的变化。”<strong>李宏伟</strong>认为。</p>
  <p><strong>李宏伟</strong>进一步介绍，进入2026年，行业会越来越向头部企业聚焦。“雷鸟创新将在重要的标志性场景下，打造超过用户体验标准的产品。不会那么在意竞争问题，作为相对头部的企业，推动市场向前发展，是雷鸟创新要做的事情。”</p>
  <p><strong>吴德周</strong>则认为，2026年智能眼镜行业会呈现两个大趋势：<strong>一是行业加速起量</strong>，市场进入规模化增长关键期。随着技术成熟度提升、产品体验优化及用户教育的持续深化，会有更多消费者认可并接受智能眼镜，行业整体将实现快速扩容。</p>
  <p><strong>二是会有更多品牌探索垂直场景</strong>，垂直场景深耕成为主流。经过2025年的多场景探索，行业会告别“大而全”的粗放式布局，更多企业将聚焦自身优势场景，转向“小而美”的精准定位，其中运动、健康、工业等领域会涌现更多专业级产品，产品差异化特征将更加明显。</p>
  <p>如果再把时间线拉长来看，2025年5月在完成Pre-A轮融资时，<strong>微光科技CEO戴照恩</strong>曾向亿欧介绍，未来，智能眼镜行业将涌现几大趋势：</p>
  <p><strong>一是</strong>AI音频眼镜成熟度较高，会率先被消费者接受；<strong>二是</strong>长期来看，屏幕是刚需配置，人类获取信息大部分要依靠视觉，因此具备显示功能的智能眼镜将是终极形态；<strong>三是</strong>智能眼镜必须足够轻量化，适合全天候佩戴；<strong>四是</strong>智能眼镜在设计和配置上将存在各种类型，会有明显差异化。</p>
  <p>综合多位创业者们的观察，可以确信的是，智能眼镜行业在产品、品牌营销、技术、资本等多个维度将出现明显进步。</p>
  <p><strong>在产品层面</strong>，一是轻量型AI眼镜、沉浸式AR眼镜的分化愈发明显。二是将更加注重垂直场景，更多聚焦细分场景的产品将陆续涌现。“沿着垂直场景走，可能是大势所趋。”<strong>古鉴</strong>表示。</p>
  <p><strong>在品牌营销上</strong>，邀请知名公众人物“站台”，将成为各大企业的必然举措。2025年，罗振宇、吴晓波、Tim、王自如、何同学等公众人物纷纷戴上了智能眼镜。利用公众人物影响力吸引更多消费者，或是不错的选择。</p>
  <p><strong>在技术上</strong>，一方面，光波导镜片等上下游供应链将更加成熟，推动智能眼镜佩戴体验持续提升。另一方面，AI智能体进一步迭代，智能眼镜的AI能力持续提高，“智能伙伴”为这个行业带来更大的想象空间。</p>
  <p><strong>在玩家上</strong>，跨界玩家越来越多是肉眼可见的趋势，2026年市场竞争会更加激烈。</p>
  <p>值得注意的是，要做好一副AI眼镜，最终离不开生态，有生态能力的企业将更加具备竞争力。</p>
  <h2><strong>结语</strong></h2>
  <p>2026年的钟声已经敲响，新世纪的四分之一已然过去，世界正处于百年未有之大变局的历史节点上。</p>
  <p>一边是观点碰撞，国际争端加剧，社会变迁提速；另一边是，科技革命如火如荼，人工智能、商业航天、具身智能、AI硬件、可控核聚变......商业世界依然精彩如初。</p>
  <p>一切都在重新寻找平衡，一切都充满未知。</p>
  <p>2025年12月30日，新旧交替之际，新一轮消费品国家补贴政策发布，智能眼镜赫然在列。这也是<strong>智能眼镜首次进入国补范围</strong>，足见官方对智能眼镜的重视和期望。</p>
  <p>站在新一年的起点上，中国智能眼镜企业应该平视世界，积极拥抱全球化。在更大的舞台上，代表中国新锐科技力量参与国际竞争。</p>
  <p>2026年，中国智能眼镜行业值得期待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA5NTI1MDEyNA==&amp;mid=2652726475&amp;idx=1&amp;sn=a3f1879414d19465d86391843a687fe1&amp;chksm=8a80c9e01e50d4c53d79b1f3a64eef9d91edae0f58b92dc0f5b934ac7e242c5cf8b1d1833858&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“亿欧网”（ID：i-yiou）</a>，作者：王圆磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627838036968455</id>
            <title>存储猛拉，AI存力超级周期到底有多神？</title>
            <link>https://www.36kr.com/p/3627838036968455</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627838036968455</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:15:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在AI需求的带动下，存储行业从HBM领域延伸至传统存储领域开启了本轮全面上行周期。以美光为例，在存储产品持续涨价的带动之下，公司的毛利率已经到了相对高位。<strong>美光公司更是将下季度毛利率指引给到了66-68%，创出历史新高，这也意味着这轮存储周期的猛烈程度是高于以往的。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9314070def7d41c2be864754dd03ef1a@5888275_oswg63570oswg1020oswg586_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>存储产品的涨价，其实本身也是存储市场供需关系的 反应 。本轮“供不应求”的现象，主要是由AI服务器等相关需求的带动。在当前对于本轮存储周期上行已是共识的情况下，海豚君将主要围绕以下问题展开：</p>
  <p>1）AI服务器中各类存储都是什么角色，当前AI存储面临怎么样的问题？</p>
  <p>2）三大原厂重视的HBM需求如何，是否存在供需缺口吗？</p>
  <p>3）AI需求爆发的情况下，对传统存储市场的影响如何，供给能跟上吗？</p>
  <p>AI 浪潮的爆发彻底重塑存储行业格局，带动HBM、DRAM、NAND、HDD等全品类存储产品进入全面上行周期。</p>
  <p>从供需角度来看：<strong>①需求端，</strong>AI服务器从训练向推理的重心转移，催生了对“低延迟、大容量、高带宽”存储的差异化需求；<strong>②供给端，存储厂商资本开支向高附加值的HBM与DRAM倾斜，形成结构性供需失衡</strong>，推动产品价格大幅上涨。</p>
  <p>本文主要先解答1和2这两个问题，至于传统市场的影响，海豚君将在下篇中继续展开。</p>
  <p><strong>当前AI数据中心领域的核心矛盾是“内存墙”瓶颈——算力增长速度远超数据传输速度，导致GPU等计算单元空置率高达99%</strong>。</p>
  <p>短期来看，<strong>HBM</strong>向16-Hi堆叠升级（带宽提升至16-32TB/s）与<strong>3D堆叠SRAM</strong>的商用（延迟压缩至 2ns）形成互补解决方案；中长期则依赖<strong>存算一体架构</strong>的突破，彻底消除数据搬运的速度问题。</p>
  <p><strong>在当前AI存储旺盛需求的情况下，HBM依然是三大原厂最为重视的存储品类，HBM4也将在2026年开启量产。</strong></p>
  <p>由于三大原厂（三星、海力士、美光）的资本开支主要投向于HBM领域，2026年HBM的供应量有望增长60%以上。HBM需求量受AI芯片及CoWoS产能的影响，需求量有望提升至42亿GB左右，<strong>HBM市场将呈现出“供应紧平衡”的状态</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_482dfafb93894b1c97895a126f58bc58@5888275_oswg44035oswg1080oswg480_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>下文将深入拆解存储层级的核心角色定位、破解<strong>“内存墙”</strong>的技术演进路径，并对<strong>HBM这一细分市场的供需情况</strong>等<strong>方面展开全景解析，而在下篇文章中将围绕传统市场继续展开，更清晰看到本轮AI 需求点燃的存储行业超级周期</strong>。</p>
  <p><strong>以下是详细分析</strong></p>
  <h2><strong>01 AI服务器带来了怎样的存储大周期？</strong></h2>
  <h3><strong>AI存储在服务器中的角色：</strong></h3>
  <p>回归计算机存储最原始两大性能维度：a. 存储，作为数据仓库，解决是仓库到底有多大的问题；b. 延迟和带宽，解决的是数据存入和取出的速度问题。</p>
  <p>按这两个维度，目前整个大存储行业产品大致可以分为四大类——HBM、DRAM、NAND和HDD。</p>
  <p>其中，HBM完全基于AI GPU而生的全新需求，通过Cowos封装技术，是是一个放在GPU“脑壳”的产品，延迟极低；而DRAM（简单理解内存条）读取时间延迟也比较短，是更靠近但独立于算力端（GPU、CPU）的“热存储”，这两者其实都同属于大类DRAM；而HDD虽然延迟较高，但具有大容量的“冷存储”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_bff96d6ba19b402fbc004f1c9feb914b@5888275_oswg805277oswg1080oswg620_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>各类存储产品在AI服务器中都是什么角色呢，具体来看：</strong></p>
  <p><strong>a）HBM：和GPU芯片3D堆叠在一起，是GPU的“专用显存”，具体高带宽、高功耗的特点，价格也相对较高。</strong>HBM是<strong>AI服务器的“性能天花板”</strong>，决定单GPU可承载的模型规模与响应速度。</p>
  <p><strong>b）DRAM(DDR5)：是数据交换枢纽，由CPU和GPU共用，连接着HBM与NAND的“桥梁”。</strong>虽然DDR5的速度比HBM慢一些，但容量大了很多倍。DDR5是AI 服务器的“内存基石”，其容量决定<strong>单服务器可同时处理的任务数，是处理并发任务的核心</strong>。</p>
  <p><strong>c）NAND（SSD）：是热数据仓库，</strong>高频访问数据的“快速持久层”，<strong>连接着DRAM 与 HDD。作为AI 数据中心的“性能-容量平衡者”，SSD是训练数据“快速补给站”，也是推理服务“快速响应核心”。</strong></p>
  <p><strong>d）HDD：海量冷数据的低成本容器。</strong>HDD虽然带宽最低，但具有大容量、成本低的特点，<strong>适合低频使用、长期存放存放的“冷数据”。HDD是AI数据中心的“容量基石”，决定整体数据存储规模。</strong></p>
  <p><strong>由此可见，一条很清晰的AI服务器数据流动路线：HDD的冷数据-&gt;SSD预热-&gt;DRAM中转-&gt;HBM配合计算，其中的各个部分在训练和推理服务器中都是所需要的。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_845fc523fd2e41a7a3306a22c2e7b7b5@5888275_oswg737289oswg1080oswg616_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>当前AI存储呈现什么样的特点</strong></h3>
  <p>本轮存储大周期完全是由AI需求带动，因而对AI存储的表现也应该主要从下游AI服务器的市场情况入手。</p>
  <p>和上半年相比，AI服务器领域明显出现了一些变化：</p>
  <p>a）AI从训练向推理迁移：</p>
  <p>①训练像是“一次性投入”，而推理更是商业化落地的“刚需场景”；</p>
  <p>②训练端对性能的要求更高，成本随着性能提升是增加的，而推理具有规模效应，可以通过批量处理来实现成本的摊薄。</p>
  <p>在谷歌Gemini给出了不差于GPT的性能表现后，让市场重新思考英伟达GPU领先的性能优势在大模型实际应用中体现并不明显。尤其在当前AI向推理端侧重的趋势下，通过大规模化能获得规模优势，定制ASIC芯片在推理端也是完全可以胜任的。</p>
  <p><strong>相比于AI训练服务器，AI推理服务器相对更注重于DDR（并发任务）、SSD（快速响应）和HDD（大容量）。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_7a09f7bec9a44770b39a781b3d70020f@5888275_oswg371093oswg1080oswg998_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>b）算力转向存力：</strong>之前市场关注点主要在算力，认为算力越强大，模型的反应速度也会更快。但其实在算力之外，还是需要存力来“投喂数据”的。<strong>如果存储端“吐数据”的速度跟不上计算端，就会出现算力“冗余”的情况，这也是目前市场中所关心的“内存墙”问题。</strong></p>
  <p><strong>“内存墙”瓶颈：</strong>大模型到推理阶段，需先从HBM加载模型权重（GB 级）与KV缓存（GB 级）到GPU缓存，再执行计算——计算本身仅需微秒级，但数据搬运则需要毫秒级。</p>
  <p><strong>以H100为例，HBM 带宽3.35TB/s，单Token的计算时间是10微秒，但生成这一个Token，需要加载整个模型权重，假如是10GB模型权重+20GB KV缓存，从HBM要把这些数据加载到GPU的搬运时间大约需要9毫秒，计算闲置时间将近99%，也就是9毫秒/（9毫秒+0.01毫秒）。</strong>【其中：空置率=等待时间（数据搬运+内核启动）÷全流程耗时×100%】</p>
  <h3><strong>当前现状下，对AI存储需求的影响</strong></h3>
  <p>从上文来看，AI服务器当前现状下，也延伸出了对AI存储在两个方面的需求变化，一方面是推理服务器对DDR、SSD和HDD的需求将会相对更多；另一方面是“内存墙”的瓶颈，需要压缩传输距离、提高传输速度，进而减少“等待时间”。</p>
  <p>在英伟达收购Groq之后，市场中也有“SRAM替代HBM” 的声音（注：GPU芯片内部有L1/L2缓存和寄存器，SRAM就是L2缓存，是连接外部HBM的总枢纽。）。</p>
  <p>而在CES 2026中，黄仁勋也给出了回应，“虽然SRAM的速度比HBM快很多，但SRAM的容量还是偏小的（相较于HBM）”。</p>
  <p>由此推测，海豚君认为即使SRAM开启量产，仍将主要是以“SRAM+HBM”的形式，并不会在短期内实现对HBM的替代。</p>
  <p><strong>针对于“内存墙”，目前主要有三个方法来应对：</strong></p>
  <p><strong>①HBM（提高传输速度）：拉堆叠层数，从12-Hi往16-Hi升级，</strong>在存储容量提升的同时，传输速度有望从B300（8TB/s）提升至16-32TB/s，<strong>从而减少数据排队等待时间；</strong></p>
  <p><strong>②SRAM（压缩传输距离）：3D堆叠SRAM通过垂直堆叠多层 SRAM 芯粒，将KV缓存、模型轻量权重直接放在计算单元“随身口袋”（片上或近片存储）。</strong>等到SRAM量产后<strong>，将转为“SRAM+HBM”的形式（SRAM负责“快”，HBM负责“多”），这有望将延迟从100ns大幅缩短至2ns附近。</strong></p>
  <p><strong>正如近期英伟达收购Groq，就是看重其3D SRAM方面的能力，当前该领域的核心厂商有台积电、Groq、三星等。</strong>按市场预期，在2026年下半年英伟达下一代的Rubin芯片中有望融入Groq技术，从而实现存力端的提速。</p>
  <p><strong>③存算一体：主要嵌入把部分算力嵌入存储内部，</strong>从而实现算力冗余的消除、存力效率和能效比的提升<strong>。</strong>目前尚未在数据中心场景实现落地，按预期在2027年及之后有望逐渐成为解决“内存墙”困扰的一个途径。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_334531e941674b83b154efa177983ea8@5888275_oswg286146oswg1080oswg412_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>数据中心及AI当前阶段的重心已经从算力逐渐转向存力，而在遇到的“内存墙”问题中，HBM迭代升级和SRAM的应用，将是短期内减少“等待时间”的有效方式。<strong>中长期角度来看，打造“存算一体”的产品未来会成为解决“内存墙”问题更好的“答案”。</strong></p>
  <p><strong>附：英伟达收购Groq，主要是对人才的收购，同时获得Groq全部核心IP（LPU架构、TSP微架构、编译器技术）与硬件资产使用权</strong>。Groq创始人Jonathan Ross（谷歌TPU创始成员）及90% 核心工程团队加入英伟达，由Simon Edwards接任Groq新CEO。</p>
  <p><strong>这一方面能通过融合SRAM技术，从而提升英伟达在AI推理方面的能力；另一方面也是一次防御性收购，避免Groq相关技术落入到了其他竞争对手之中</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_0eeb3bc2eda7460181176c38d63cbf9c@5888275_oswg627107oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02 HBM市场：升级至HBM4，供需紧平衡</strong></h2>
  <p><strong>AI进入推理落地阶段，“内存墙”困境难解的情况下，HBM依然是缓解“等待时间”的一个有效方式。</strong>因而，当前三大存储原厂（三星、海力士、美光）将资本开支的重心依然投向于HBM领域。</p>
  <p>受益于AI需求的影响，HBM是其中最为直接的增量需求（ “从无到有”的需求创造）。由于HBM基本都是搭载在AI芯片上配套出货，<strong>那么HBM的需求量也是与AI芯片的出货情况直接挂钩</strong>。</p>
  <p>从当前主流的AI芯片（英伟达、谷歌、AMD）来看，基本都搭载了HBM3E。在三星的HBM3E通过英伟达认证之后，也已经跟了上来。目前三家厂商都开始对HBM4进行送样，当HBM4顺利量产，下一代AI旗舰芯片也将陆续配备新一代的HBM4产品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_6666e9eb8fee45248864338ce4668727@5888275_oswg91673oswg1080oswg210_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_3c798f5b90c94b258ab70447dd271ff4@5888275_oswg152166oswg1080oswg593_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>虽然HBM是AI服务器率先带动的需求，但HBM的供需状况却不是最紧张的</strong>，而其中的一部分原因正是<strong>存储厂商近年来高增的资本开支主要都投向于DRAM，尤其是高端产线HBM的扩产</strong>。</p>
  <p><strong>这在核心厂商的表态中也能看出</strong>，<strong>①海力士：</strong>投入增加以应对M15x的HBM4产能扩张；<strong>②三星：</strong>投入将主要用于HBM的1c制程渗透及小幅增加P4L晶圆产能；<strong>③美光：</strong>专注于1gamma制程渗透和TSV设备建置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_cc4fde297cb4496690ff7e3c506f0ee4@5888275_oswg52379oswg968oswg723_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>HBM供给端：产能-&gt;产量</strong></h3>
  <p><strong>HBM的主要供应商来自于海力士、三星和美光这三家公司，</strong>HBM市场的供应量也将主要取决于三家公司的HBM产能情况。</p>
  <p>从上文中能看到，存储厂商的资本开支主要集中在HBM领域，这也带来了HBM产能端的快速爬坡。<strong>根据公司情况及行业面信息，当前三家公司合计HBM的月产能约为39万片左右。其中海力士和三星的产能相对领先，而美光的产能规模相对较少</strong>。</p>
  <p>随着三家核心厂商的资本投入继续增加，<strong>HBM的月产能至2026年末有望继续提升至51万片左右</strong>，年增12万片左右的产能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9b9be1624e7d482aa7b0b9e086c031ef@5888275_oswg57480oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>值得注意的是，HBM的产能情况并不等于出货量表现。参考三星，它的HBM产能虽然相对较高，但由于公司在HBM3E工艺中良率偏低并迟迟未能实现对英伟达的供货，因而三星的HBM实际出货量的占比下滑至了3成以下。</strong></p>
  <p>当前HBM市场的份额中，海力士占据将近一半的份额，而美光和三星相对接近。而<strong>随着三星的HBM3E产品在四季度获得了英伟达的认证，三星公司的HBM产能利用率和出货份额也将有所回升，有望实现了对美光的反超</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d1908ec475d841d2bf50ea9ffc96261d@5888275_oswg65926oswg1080oswg690_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于HBM供应端的测算，主要结合产能和良率来估算。因为HBM基本由三大核心厂商（海力士、美光、三星）垄断，HBM的产能部分也将主要考虑这三家公司的情况。</p>
  <p><strong>从上文的三家公司合计产能来看，2025年四季度的HBM月产能约为39万片，至2026年四季度HBM的月产能有将达到51万片。考虑到产能爬坡因素，海豚君预估2026年HBM的合计总产能有望达到543万片。</strong></p>
  <p>由于单片12寸晶圆（直径300mm），大约能切割出514颗等效3GB的HBM颗粒（考虑切割及边角料损失）。</p>
  <p>那么543万片的HBM产能大约能切出27.9亿颗的HBM颗粒（等效3GB），在50%综合良率的情况下，<strong>2026年三家核心厂商大致能提供41.9亿GB的HBM供应量。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_1c35a53ad71e4786bc434500007d2eec@5888275_oswg87087oswg1080oswg529_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>HBM需求端：CoWoS-&gt;AI芯片-&gt;HBM</strong></h3>
  <p><strong>因为HBM基本都配备在AI芯片之上，而AI芯片又都需要CoWoS封装。因此在对HBM需求量的估算中，将具体通过“CoWoS-&gt;AI芯片-&gt;HBM”的方式进行。</strong></p>
  <p>结合行业及市场预期的情况看，在2026年的CoWoS分配中英伟达仍占据着最大的份额（占据总量的一半以上），谷歌、AMD和亚马逊也是CoWoS较大的下游客户。<strong>假定下图中所列的核心客户占据了90%的CoWoS需求，那么全球CoWoS在2026年的全年需求量大约在128万片左右。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e78b2b0d77f64461953b24cebd80f093@5888275_oswg43409oswg1066oswg526_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>在CoWoS量的基础上，再来测算AI芯片的出货量。</strong>以英伟达B300为例，由于单个CoWoS封装晶圆面积大约能得到14个左右B300芯片（28个裸芯），那么B300的35万片CoWoS产能分配大致对应490万个B300芯片。</p>
  <p><strong>单个B300芯片配备8个HBM3E，而每个HBM3E都为36GB的容量，因而单个B300需要288GB的HBM3E。那么490万个B300芯片，则需要14亿GB的HBM</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_65700abc323a41abb1ac22a3b29508d3@5888275_oswg78794oswg1080oswg469_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>将谷歌、AMD等各家的AI芯片都以此方式来预估，可以得到2026年全年的128万片CoWoS产能大致对应了42亿GB的HBM需求量</strong>。</p>
  <p><strong>HBM的迭代升级是短期内缓解“内存墙”的方式之一，综合上述HBM的供应量（41.9亿GB）和需求量（42.1亿GB）来看，2026年的HBM市场是相对紧张的，这主要是在三大存储原厂大力扩产之下，呈现出了紧平衡的状态。</strong></p>
  <p><strong>本文主要介绍了各类存储在AI服务器中的角度以及HBM的供需情况，而下篇文章中将继续围绕AI对传统存储领域的影响展开。</strong></p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/6vKJHEe-yU5WUyj0cCTs1w" rel="noopener noreferrer nofollow" target="_blank">“海豚研究”</a>，作者：海豚君，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627810968716553</id>
            <title>管着1.78万亿养老金的系统“炸了”，官网一团糟，170万人却被要求：“先别急，等AI上线再说”</title>
            <link>https://www.36kr.com/p/3627810968716553</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627810968716553</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:13:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近，英国外包巨头 Capita&nbsp;因为一句话被网友群嘲：</p>
  <blockquote>
   <p>如果你的养老金账号打不开、密码错误、页面报错——别急着联系我们，等 AI 聊天机器人上线再说。</p>
  </blockquote>
  <p>听起来离谱得像段子？而这一切，却真实发生在了一个覆盖&nbsp;170 万公务员、管理&nbsp;1890 亿英镑（约人民币&nbsp;1.78&nbsp;万亿）养老金资产的国家级系统上。</p>
  <h2><strong>一个“史上最大迁移项目”，结果上线第一天就翻车</strong></h2>
  <p>2023 年 11 月，英国政府将公务员养老金系统（Civil Service Pension Scheme，简称 CSPS）的新一轮运营权交给了外包巨头 Capita，合同金额高达 2.39 亿英镑（约人民币&nbsp;22.6&nbsp;亿元），被官方称为：“英国公共部门史上规模最大的养老金系统迁移项目。”</p>
  <p>新系统于&nbsp;2025&nbsp;年 12 月 1 日正式上线，这原本应当是一场技术与治理能力的里程碑式展示，结果却演变成了全国范围的 IT 灾难。</p>
  <p>刚上线第一天，大量用户就发现了各种低级问题：</p>
  <p>密码、用户名被“识别为不存在”</p>
  <p>登录页面死循环跳转</p>
  <p>链接点了没反应，或者互相套娃</p>
  <p>页面顶部、功能区还显示着占位的测试文本</p>
  <p>总体而言，整个网站看起来像是还没做完就被强行上线，不少用户在社交平台吐槽：</p>
  <blockquote>
   <p>“这根本不像国家级系统，更像是某个实习生凌晨三点刚 push 的测试版。”</p>
  </blockquote>
  <h2><strong>Capita 的神操作：有问题？别急，等 AI 上线了再说</strong></h2>
  <p>更具争议的，是 Capita 在 12 月 17 日发给全体用户的一封内部邮件。</p>
  <p>Capita CSPS 项目负责人、董事总经理 Chris Clements 在邮件中表示：</p>
  <blockquote>
   <p>“我们正在不懈努力，打造你们期望的体验。新的聊天机器人以及更多联系方式将在未来几周内上线。如果你的问题不紧急，请等到新年后这些功能上线再联系我们。这样有助于我们集中精力完成改进，确保平稳过渡。”</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_91ebe894774b48a18b6d0cd75271bd98@5888275_oswg114793oswg1080oswg194_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>换句话说就是：我知道系统炸了，但你先忍忍，别打电话，等 AI 上线。</p>
  <p>甚至，在这封邮件中，Chris Clements 还描绘了一个极其宏大的蓝图：</p>
  <p>这是“英国公共部门养老金系统史上最大的一次按时迁移”；</p>
  <p>未来将打造“以 AI 为核心”的超大规模服务体系，包括&nbsp;Track My Case（实时追踪业务处理进度）和&nbsp;Retire Online（线上退休规划与管理）；</p>
  <p>到&nbsp;3&nbsp;月前，将上线一整套“直觉化数字工具”，让用户拥有更高透明度与掌控感；</p>
  <p>随着系统成熟，“更多自动化与 AI 将提升准确率与处理速度，让用户能在线完成更多事情，而不用发邮件或打电话。”</p>
  <h2><strong>网友炸锅：我们不需要 AI，只要网站能用</strong></h2>
  <p>然而，对于正在面对满屏报错的公务员来说，这一套“AI 愿景”显得极为讽刺。</p>
  <p>意料之中，Capita&nbsp;的这番回应在社交平台遭遇了全面翻车，Reddit 上的一条高赞评论几乎成为全网共识：</p>
  <blockquote>
   <p>“我们不需要一个以 AI 为核心的网站，我们只需要它能正常工作，页面上别再全是占位文本。”</p>
  </blockquote>
  <p>对程序员来说，这种场景实在太熟悉了：明明系统连基础功能都没跑通，就开始搞“AI 赋能一切”的 PPT&nbsp;了。</p>
  <p>在后续沟通中，一位知情人士解释道，Capita 认为问题在于系统上线初期访问量远超预期，大量公务员也只是“登录看看”，确认养老金数据是否还在，这导致系统在短时间内被“挤爆”。基于此，Capita 官方给出的建议是：除非你确实有紧急事务，否则最好等到春季年度对账单发布后再访问系统。</p>
  <p>话虽如此，许多人觉得这听起来更像是：系统容量不足，却把锅甩给用户访问量太大。</p>
  <p>面对汹汹舆论，Capita&nbsp;又在&nbsp;1&nbsp;月&nbsp;6&nbsp;日提供了最新数据：已有超过8.3万名成员完成注册，且注册量增长迅速；因继承了上一家服务商留下的大量积压问题，新系统上线后咨询量是平时数倍，目前已投入超500名全职员工处理该项目。</p>
  <p>这些数字显示了&nbsp;Capita&nbsp;补救的努力，但从用户的评论来看，已受损的信任显然无法立即修复：</p>
  <p>●&nbsp;“一切都是为了完成 12 月 1 日上线这个 KPI，哪怕产品烂到家也无所谓。只希望月底我的养老金能照常发放。”</p>
  <p>●&nbsp;“根本没人问过养老金计划成员的意见。我非常肯定，如果问养老金计划成员‘你们是否愿意让 Capita 来管理你们的养老金计划？’，答案肯定是响亮的‘不’。”</p>
  <p>●&nbsp;“他们的公关部门绞尽脑汁，想方设法把责任推卸给所有人、所有事，唯独不怪罪真正负责交付的经理。”</p>
  <p>参考链接：https://www.theregister.com/2026/01/05/capita_pension_portal_chatbots/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/q0MTrm6W65GlI-f_7nfnNA" rel="noopener noreferrer nofollow" target="_blank">“CSDN”</a>，整理：郑丽媛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627754387145987</id>
            <title>GOG被甩卖，玩家其实并不介意“租游戏”</title>
            <link>https://www.36kr.com/p/3627754387145987</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627754387145987</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 12:12:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>长期以来，玩家社区都有这样一个热门话题，那就是“数字版是不是租游戏”，为此数字游戏的支持者和实体光盘的拥趸也吵得不可开交。直到2024年秋季Steam一锤定音，在页面中明确写道，数字版游戏只是租赁、不是购买。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_74e554bf85db424aa8339e4c4ea03172@000000_oswg40631oswg600oswg413_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由此马上就一石激起千层浪，无论在国内的贴吧、小黑盒、B站，还是海外市场的X、Reddit，玩家们不约而同地向Steam发泄愤怒。与此同时，知名游戏开发商CD Projekt旗下的GOG（Good Old Games）也趁机阴阳Steam，表示“如果有一个真正让你拥有游戏的商店就好了。”</p>
  <p>作为数字游戏分发平台中绝对的异类，GOG允许玩家获得游戏的所有权、而非使用权，玩家可以通过其所提供的离线安装器，随时下载、备份，并重装游戏，从而确保游戏始终掌握在自己手中。看到这里，许多朋友可能会认为GOG能趁此发展壮大，但事情却截然相反，GOG被CD Projekt当作包袱甩掉了。</p>
  <p>日前CD Projekt方面宣布，其联合创始人兼大股东Michał Kiciński以1.77亿元人民币的价格收购GOG所有股份，后者将保持独立。</p>
  <p>那么CD Projekt为什么要卖掉GOG呢？从他们的财报中其实就能得到答案。去年GOG的营收额约为4700万欧元，但净利润仅有26.8万欧元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9e6f69a4a1714afda3917c5dd78d3c62@000000_oswg41660oswg600oswg404_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>作为对比，第三方机构Alinea Analytics估测Steam今年的营收超过了160亿美元。有趣的是，即便Steam将“数字版游戏只是租赁”这个潜规则挑明，但其同时在线人数也屡创新高，玩家似乎毫无芥蒂地接受了自己只是从Steam购买游戏使用权的这个现实。</p>
  <p>事实上，人类天生就更容易与近处的人和事产生情感联结，对于遥远的事件则容易因‌为心理距离‌产生疏离感。比如，太阳还能稳定地燃烧50亿年，但它终有一天会进入红巨星阶段，进而吞噬地球，但人类也并未对此杞人忧天。游戏玩家也一样，一款游戏通常情况下真正走到服务器关闭、再也无法游玩，往往需要十年以上的时间。</p>
  <p>例如“停止杀死游戏”（Stop Killing Games）运动的导火索，即育碧宣布关闭《飙酷车神》服务器的2024年，就距离这款赛车游戏发布有十年时间。绝大多数玩家体验一款游戏的时间短则以小时计算，长则数年，但真正十年如一日地保持热爱，可以说是少数中的少数。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_46adb146bbee46cbb9420b6eb434e3e1@000000_oswg25411oswg600oswg328_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除非游戏开发商宣布自己正在体验的游戏即将关闭，否则大多数人其实并不介意自己玩的游戏到底是“租”还是“买”。换而言之，GOG坚持的“无拷贝保护”（No DRM）哲学，主流玩家其实并不在意，真正介意的玩家往往会倾向于选择实体光盘。</p>
  <p>GOG与Steam、Epic游戏商城的最大区别，就是前者销售的游戏属于“DRM-FREE”，也就是没有任何版权限制，所以玩家可以自由复制所购买的游戏到任何存储介质。从某种意义上来说，GOG销售的游戏与实体光盘没有区别，甚至也能“出二手”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d00862ca7fbe48759825fc8dbd5bc9ea@000000_oswg34513oswg600oswg338_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对于数字游戏的受众，分发平台本身的体验反而更为重要。曾经作为Epic Games限时独占的第一人称射击游戏《巫火》开发者就这样形容过Epic Games和Steam的差异，“Epic&nbsp;Games是一个商店，而Steam是一个社区。”</p>
  <p>在许多玩家的视角下，Epic Games则仅仅是一个免费领游戏、购买游戏的地方，再加上一个游戏启动器，但Steam则是一个集合了社区讨论、市场交易、MOD集合、成就系统、创意工坊等众多功能的“家”。“没有归属感，就是感觉不值得去花钱”，有玩家是这样锐评Epic Games，更别说社区建设称得上是聊胜于无的GOG了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_7ca90c94bfdd49cab17f04280211140c@000000_oswg19976oswg700oswg227_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果说Epic Games还能通过砸钱送游戏来占据玩家的心智，那么GOG仅靠没有任何版权限制这一点，显然很难说服玩家选择它。毕竟对于玩家而言，GOG的无版权限制更像是惠而不费的“顺水人情”。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649903003&amp;idx=3&amp;sn=9e365765be52892d06c0961c8e4bab01&amp;chksm=864ac7eab87194ad73bbbefaa33fc1312b9b8511e7c3fb9300288eda774026094c6c260989d2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627834880951556</id>
            <title>AI 除幻第一股来了，智能体收入一年暴涨9倍，细分市占率达50%</title>
            <link>https://www.36kr.com/p/3627834880951556</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627834880951556</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 11:54:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>又一家AI公司要登陆港股市场了。</p>
  <p>不久前，港交所官网披露，海致科技已通过聆讯并公布招股书。&nbsp;</p>
  <p>作为国内领先的图计算龙头，海致科技收入在过去两年增长迅速。&nbsp;</p>
  <p>2022-2024年，<strong>公司收入分别为3.13亿、3.76亿、5.03亿元</strong>。2025年上半年，公司收入为1.73亿元，同比增长38.4%。&nbsp;</p>
  <p>其中，Atlas智能体表现尤为突出。<strong>2023 年，Atlas智能体收入仅890万元；到2024年，这一数字已增长至8655万元，暴涨9倍</strong>。2025年上半年，Atlas智能体实现收入4865万元，同比增长接近5倍。&nbsp;</p>
  <p>按2024 年收入计算，<strong>海致科技在中国产业级AI智能体市场中以2.8%的市场份额，排名第五</strong>。&nbsp;</p>
  <p>Atlas 智能体的放量，与公司长期投入的一项核心技术路径密切相关——图模融合。&nbsp;</p>
  <p>所谓的图模融合，就是将“知识图谱”的严谨逻辑与“大模型”的推理能力结合起来。让大模型在推理时，不只是依赖统计概率，而是必须参考知识图谱中的结构化事实和关系逻辑。&nbsp;</p>
  <p>由于知识图谱由实体和关系组成，天然具备可追溯、可验证的逻辑结构，可以作为大模型的“真值锚点”，从源头约束幻觉的产生。&nbsp;</p>
  <p>也正因如此，海致科技被外界称为“AI 除幻第一股”。接下来，就让我们透过招股书，来拆解下“AI除幻第一股”的成色。&nbsp;</p>
  <h2><strong>01 杀入AI智能体，24年收入增长9倍</strong></h2>
  <p>想要真正了解海致科技的业务，我们就先得搞清楚什么是“图”。</p>
  <p>这里的“图”，不是相册里的JPG，而是一种抽象的数据结构 。&nbsp;</p>
  <p>在计算机的世界里，“图”是由“点”和“边”交织而成的网。点是人、地、事；边是关系，比如关注、转账、借贷、同住。&nbsp;</p>
  <p>把这些对象和关系抽象成一张网络，就是图。而在几亿个点、几百亿条边里快速找路径、看结构、识异常，就是图计算。&nbsp;</p>
  <p>说白了，<strong>图计算就是一项用来“算关系”的技术。</strong></p>
  <p>比较常见的一个应用场景就是金融反欺诈。图计算能瞬间拉出一张包含客户家庭、同事、共同联系人的关系网，让隐藏在复杂交易背后的风险主体无处遁形。&nbsp;</p>
  <p>正是基于这套图计算能力，海致科技的业务逐渐分化为两条主线：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_0aee2d0f0d47464ba8c713e3c281dc8f@5888275_oswg89248oswg830oswg410_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>&nbsp;一条是Atlas图谱解决方案，包含数据智能平台（DMC）、知识图谱平台以及底层图数据库；另一条是 Atlas 智能体，在前者的基础上，引入图模融合技术，实现更复杂的推理与交互。&nbsp;</p>
  <p>先看Atlas图谱解决方案。这是公司目前收入规模最大的业务。截至 2024 年，该业务实现收入 4.17 亿元，占公司总收入的 82.8%。&nbsp;</p>
  <p>Atlas图谱解决方案更像是一套高性能的数据基础设施。&nbsp;</p>
  <p>它通过图计算，将企业内部原本分散、割裂的数据整合为可视化的“知识网络”，帮助业务人员更直观地理解数据之间的结构、关联和潜在风险。&nbsp;</p>
  <p>但作为一项偏基础设施型的业务，这条线的增长速度并不快。&nbsp;</p>
  <p>2022 年，该业务收入为3.13亿元，到 2024 年增长至4.17亿元，两年累计增幅约 33%。2025年上半年，Atlas 图谱解决方案实现收入1.25亿元，同比增长仅7%。&nbsp;</p>
  <p>相比之下，Atlas智能体则显得极具想象力。&nbsp;</p>
  <p>Atlas 智能体不仅可以自主访问和理解企业内部数据，完成多维分析、挖掘关联价值，还能根据具体业务场景，自动执行数据查询、报表生成等标准化操作，具备一定的任务拆解和执行能力。&nbsp;</p>
  <p>从收入数据来看，这条业务的变化尤为明显。&nbsp;</p>
  <p>2023 年，Atlas 智能体收入仅890万元；到2024年，这一数字已增长至8655万元。2025年上半年，Atlas 智能体实现收入4865万元，同比增长接近5倍。&nbsp;</p>
  <p>业务数据的变化也印证了这一趋势。&nbsp;</p>
  <p>2022-2024年，Atlas图谱解决方案的客户数量虽然从95家增长到152家，但客单价却从<strong>329</strong>万下降到<strong>274</strong>万元。&nbsp;</p>
  <p>反观Atlas智能体业务，2023-2024年客户数量从2家增长到19家，客单价也从<strong>445</strong>万元增长到<strong>455</strong>万元。&nbsp;</p>
  <p>从市场位置来看，<strong>按2024 年收入计算，海致科技在中国产业级AI智能体市场中以2.8%的市场份额排名第五</strong>。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_7956349124c84e029d544591b1058278@5888275_oswg55929oswg830oswg316_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果进一步细分到以图为核心的产业级AI解决方案这一维度，公司在2024 年的收入市占率约为<strong>50%</strong>，是毋庸置疑的行业老大。&nbsp;</p>
  <p>Atlas 智能体业务的高速增长，并不仅仅来自产品形态的变化，更折射出产业级AI需求的转向。&nbsp;</p>
  <h2><strong>02 图模融合，给大模型“打补丁”</strong></h2>
  <p>在ChatGPT 引爆全球之后，所有人都以为AI的“iPhone 时刻”到了。&nbsp;</p>
  <p>但当企业真正试图把大模型请进核心业务流程时，却发现这位“全知全能”的天才有一个致命的毛病：&nbsp;</p>
  <p><strong>它太爱“一本正经地胡说八道”了</strong>。&nbsp;</p>
  <p>这种现象在业内被称为“幻觉”（Hallucination）。在写诗作画时，这是创意；但在金融风控、能源调度等容错率极低的产业场景中，这是灾难。&nbsp;</p>
  <p>为了给大模型“治病”，行业内尝试了各种外挂手段：有的给它配了搜索引擎（RAG），有的找老师通过打分来纠正它（RLHF），有的教它一步步拆解问题（CoT）。&nbsp;</p>
  <p>而海致科技则选择了一条更为硬核的路径：<strong>图模融合</strong>（Graph-Model Fusion）。&nbsp;</p>
  <p>简单来说，<strong>就是将“知识图谱”的严谨逻辑与“大模型”的推理能力结合起来</strong>。&nbsp;</p>
  <p>让大模型在推理时，不只是依赖统计概率，而是必须参考知识图谱中的结构化事实和关系逻辑。&nbsp;</p>
  <p>由于知识图谱由实体和关系组成，天然具备可追溯、可验证的逻辑结构，可以作为大模型的“真值锚点”，从源头约束幻觉的产生。&nbsp;</p>
  <p>按海致科技招股书的说法，与其他解决方案相比，图模融合有着天然的优势。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_ff3e7f0fc0b54996ac951e7210d6eea8@5888275_oswg63140oswg830oswg426_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>检索增强生成（RAG）本质上是一种外置补丁：通过连接外部文档或数据库，为模型输出提供上下文支持，但模型自身的推理机制并未发生改变。一旦检索结果不完整或相关性不足，幻觉问题仍然可能出现。&nbsp;</p>
  <p>基于人类反馈的强化学习（RLHF）更多是在行为层面进行偏好校正。它可以让模型在特定场景下“少犯错”，但高度依赖人工标注，难以覆盖复杂、多变的产业知识体系，也难以规模化扩展。&nbsp;</p>
  <p>思维链（CoT）则是通过引导模型拆解中间推理步骤，提升逻辑连贯性。但问题在于，它只能改善“怎么想”，却无法验证“想的内容是否真实”，对事实性幻觉的抑制能力有限。&nbsp;</p>
  <p>相比之下，图模融合的核心优势在于<strong>内生性</strong>。&nbsp;</p>
  <p>与单纯依赖RAG 或 RLHF 不同，图模融合并不是在模型外部“纠错”，而是<strong>在模型生成过程中持续施加结构约束</strong>。&nbsp;</p>
  <p>正因如此，图模融合在幻觉治理上呈现出更稳定、更可持续的效果。它不仅能减少单次错误输出，更能在多轮对话、多跳推理以及复杂关系分析等场景中，保持推理逻辑的一致性。&nbsp;</p>
  <p>这种技术路线的优势在测试数据中表现得非常直观。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b34348ee09e3453db62afbc5caa5ad8a@5888275_oswg60294oswg830oswg214_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在针对复杂逻辑推理与抗幻觉能力的MuSiQue基准测试中，传统的大语言模型（基线）得分低于10%，基于向量的RAG（Vector RAG）得分低于40%，而海致科技的图模融合技术得分则高于<strong>50%</strong>&nbsp;。&nbsp;</p>
  <p>而在强调基础检索能力的HotpotQA测试中，图模融合技术的准确率超过<strong>80%</strong>，同样优于Vector RAG的不到75% 。&nbsp;</p>
  <p>当然，传统知识图谱并非没有问题。&nbsp;</p>
  <p>早期，图谱高度依赖人工建模和规则设计，构建周期长、成本高，跨领域迁移能力有限，在处理模糊性和不确定性问题时也存在明显不足。这些局限，使得知识图谱长期难以独立支撑复杂、动态的应用场景。&nbsp;</p>
  <p>而大语言模型的出现，恰恰为这一问题提供了新的解法。模型强大的语义理解和生成能力，可以显著降低知识获取和更新的门槛；而知识图谱提供的结构化逻辑与事实约束，则反过来提升模型输出的准确性与可信度。&nbsp;</p>
  <p>在海致科技看来，用知识图谱为模型提供结构和边界，用大模型为图谱注入理解和生成能力。&nbsp;</p>
  <p>未来，图模融合或许将成为产业级AI 从“能用”走向“可信、可控、可规模化”的关键基础。&nbsp;</p>
  <h2><strong>03 海致科技开始赚钱了，但还不是一门“轻生意”</strong></h2>
  <p>海致科技正在走出亏损区间。&nbsp;</p>
  <p>从盈利能力上看，2022-2024年公司经调整净利润分别为-1.43亿元、-0.84亿元和1692万元。&nbsp;</p>
  <p>这一变化，首先来自毛利率的持续改善。2022—2024 年，公司整体毛利率由&nbsp;<strong>30.9%</strong>提升至<strong>36.3%</strong>。&nbsp;</p>
  <p>其中一个直接原因，是Atlas智能体业务的毛利率提升。&nbsp;</p>
  <p>过去两年，Atlas图谱解决方案的毛利率在<strong>35%</strong>左右。而Atlas智能体业务的毛利率弹性则要大得多。2023年，该业务的毛利率为<strong>17.8%</strong>，到了去年毛利率提升到<strong>45.7%</strong>。2025年上半年，毛利率进一步提升到了<strong>48.1%</strong>。&nbsp;</p>
  <p>随着智能体业务收入占比提升，其对整体毛利率的拉动效应逐步显现。&nbsp;</p>
  <p>另一个原因是，公司对成本结构的调整。&nbsp;</p>
  <p>尽管公司强调产品已完成标准化，但在实际交付层面，业务模式仍以定制化为主，这一点在成本结构中体现得较为明显。&nbsp;</p>
  <p>2024 年，公司毛利率为36.3%。拆解营业成本可以看到，人工成本与外包服务费仍是主要支出项，两者合计占营业成本的 79%。其中，外包服务费从 2022 年的 5293 万元 增长至 1.12 亿元。&nbsp;</p>
  <p>公司给出的解释是，这是出于交付效率和成本弹性的考量：&nbsp;</p>
  <p>在项目交付过程中，将部分标准化、重复性较高的流程委托给第三方服务提供商，以提升整体交付灵活性，并更有效地进行成本控制与资源配置。&nbsp;</p>
  <p>从短期效果看，这一策略有助于缓解内部人力成本的刚性约束，也在一定程度上支撑了毛利率改善。&nbsp;</p>
  <p>但在国内产业级AI场景中，落地过程本身高度复杂，对行业理解、工程实施和交付能力的依赖度仍然较高，这决定了人工与外包成本在短期内难以完全退出成本结构。&nbsp;</p>
  <p>公司亦在招股书中提到，目前Atlas 智能体业务的落地，在相当程度上依赖于 Atlas 图谱解决方案客户的交叉销售。&nbsp;</p>
  <p>2024 年，该交叉销售率高达73%。换言之，部分前期的工程实施与客户教育成本，已由Atlas图谱解决方案业务提前消化。&nbsp;</p>
  <p>在此背景下，随着Atlas 智能体收入占比进一步提升，其毛利率弹性是否能够在更大规模下持续兑现，以及交付模式能否逐步向更轻量、可复制的产品形态演进，仍有待后续观察。&nbsp;</p>
  <p>这也将是判断海致科技长期价值的关键变量之一。&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/d6MJHbWsX_LCXOnt1gBdNA" rel="noopener noreferrer nofollow" target="_blank">“硅基观察Pro”</a>，作者：硅基君，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627811046999302</id>
            <title>ChatGPT拟上广告，你的AI要开始带货了</title>
            <link>https://www.36kr.com/p/3627811046999302</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627811046999302</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 11:44:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最近，AI圈里悄悄流传着一个变化：几家头部大模型公司正在和广告商频繁接触。</p>
  <p>OpenAI CEO山姆·奥特曼在一次采访中轻描淡写地说：“其实我对广告挺喜欢的。”这句话乍听平常，却和他两年前ChatGPT刚爆红时“绝不会在产品里塞广告”的承诺判若两人。<strong>据内部人士透露，OpenAI早已多次开会讨论如何在AI界面中嵌入广告。</strong>几乎同一时间，谷歌也被曝正与多个消费品牌洽谈Gemini的原生广告合作，尽管官方很快出面否认，但市场显然已经嗅到了风向。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_49d64e77a9e744aa9d32cbf69748cfdc@5888275_oswg28503oswg1080oswg517_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前还没有哪款主流AI产品真的挂上了广告，可头部AI公司的动作则透露出一个信息：<strong>你眼中值得信任、提供无偏见知识的AI在不久的将来可能会变成一个导购。每一个推荐的链接里都可能藏着一个你不知道的隐形交易。</strong></p>
  <p>那么，曾经对广告嗤之以鼻的AI公司为何悄悄转了风向？AI上广告，对普通人而言可能意味着什么？</p>
  <h2><strong>从烧钱到赚钱：AI的生存逻辑变了</strong></h2>
  <p>过去几年，训练一个大模型动辄烧掉数亿美元。OpenAI、Anthropic、谷歌DeepMind这些站在技术前沿的公司，长期靠风投或母公司输血勉强维持运转。但“只烧钱、不赚钱”的模式显然撑不了太久，光靠用户订阅根本填不上前期投入的巨大窟窿。</p>
  <p>以OpenAI为例，尽管2025年其订阅用户数已突破2000万、上半年收入达43.3亿美元，但高昂的算力成本和持续的研发支出使得会员制付费远不足以覆盖前期巨额投入，每收入1美元就要搭上3美元，净亏损达135亿美元。</p>
  <p><strong>头部AI公司持续亏损的背景下，回血和盈利成了刚需。</strong>广告这个互联网世界最成熟，也最高效的变现方式，自然而然地被提上了议程。互联网过去二十多年的发展早已证明，当一项技术拥有海量用户和高频互动，广告就是最直接、最成熟的变现方式。搜索时代，Google靠关键词广告崛起，广告年收入最高超过2000亿美元；短视频时代，抖音用信息流广告重构消费链路。现在，或许轮到AI了。</p>
  <p><strong>如今AI助手每天与数亿人对话，不仅能理解用户的意图，还能在恰到好处的时机提供“建议”。这种能力，本身就暗含了巨大的商业潜力。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_70a32f9c240044fd9c0813f0e9992e7a@5888275_oswg660813oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AI引入广告的思路，其实和当年搜索引擎刚起步时很像。那时候，人们也觉得在搜索结果里塞广告会破坏体验，但后来发现，只要做得足够克制，用户反而觉得“这信息对我有用”。今天的AI，正站在类似的十字路口。</p>
  <p><strong>最直接的做法，是在界面里加一点轻量广告</strong>，比如网页侧边栏的品牌推荐、App底部的小横幅，或者偶尔弹出一个非打断式的提示卡片。这些设计通常不会干扰主要对话，但能带来稳定的曝光和收入，算是最“安全”的尝试。</p>
  <p><strong>另一种可能的形式是激励式交互。</strong>免费用户若想继续使用高级功能或延长对话时长，可以选择观看一段15秒的品牌视频获得额外的模型调用额度。这种方式已在移动游戏和工具类App中验证有效，既能维持基础服务的开放性，又能将部分流量转化为收入。对很多人来说，这比直接付费更容易接受。</p>
  <p><strong>而争议最大、最令人不安的则是今年刚流行起来的词语——GEO（Generative Engine Optimization），即在多轮对话中潜入一点商品内容。</strong></p>
  <p>例如，当用户询问“哪款电动牙刷好用？”时，AI可能优先推荐某合作品牌，并以“客观评测”的口吻呈现，实则暗含商业引导。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_521aeb9729624cd9987ef01577a6be25@5888275_oswg748685oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>对此，不少从业者担忧，一旦AI开始为商业利益服务，它的中立性就岌岌可危。用户很难分辨某条建议是基于事实，还是算法对合作品牌的倾斜。更隐蔽的风险在于，平台可能为了提升点击率，在产品对比中微妙弱化竞品缺点，或放大合作方优势。这种软性操控比弹窗广告更难察觉，却更容易影响判断。</p>
  <p>正因如此，尽管多家公司已在内部测试各类商业化方案，他们的公开表态仍显得谨慎甚至矛盾。有人坚持“AI必须保持纯净”，认为信任一旦透支便难以重建，也有人无奈坦言：“商业本就是牟利，大模型不会因为理想主义而继续运行。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_52509ac5c6bb494e911eb07e8cc44110@5888275_oswg268940oswg911oswg862_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>广告只是冰山一角，甚至可能最终以更隐蔽的形式存在。但它的讨论热度本身恰恰折射出整个行业对盈利路径的集体焦虑与探索。当烧钱难以为继，资本耐心见底，AI公司必须证明自己是一门可持续的生意。</p>
  <h2><strong>AI将走向商业时代</strong></h2>
  <p>尽管截至目前，ChatGPT尚未在主流版本中正式上线广告，但种种迹象已清晰勾勒出行业转向的轮廓：OpenAI CEO山姆·奥特曼从早期强调“AI应为全人类服务”的理想主义立场，逐渐转向更务实的表态。公司内部关于广告产品和商业化接口的测试传闻不断，而竞品如Perplexity、Claude甚至国内的大模型平台，已开始尝试在搜索增强或企业服务中嵌入变现机制。</p>
  <p>这些信号共同指向一个事实：那个靠风投输血、用户免费畅用的AI乌托邦，正在加速退场。大规模商业化不是“会不会来”的问题，而是“以什么方式、多快到来”的问题。</p>
  <p>那么，除了广告，AI的商业化版图究竟会如何展开？</p>
  <p><strong>首先，会员订阅模式将不再只是基础版与高级版的简单分层，而是朝着精细化与场景化演进。</strong>未来，用户可能为法律咨询专用AI、留学文书助手或编程agent单独付费。功能越垂直，价值感知越强，付费意愿也越高。这种按需订阅的模式既能提升ARPU（每用户平均收入），也能让产品真正嵌入用户的高频工作流。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2d2ee7f1cbff4fc9813176eeba9114b6@5888275_oswg502905oswg855oswg570_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>其次，To B企业级仍然是大模型公司的商业化重心。</strong>无论是为银行定制风控模型，为药企加速分子筛选，还是为零售企业提供实时库存与需求预测，企业愿意为能直接提升效率或创造营收的AI能力支付溢价。根据微软财年财报，在截至2025年6月30日的财政年度中，Azure云服务全年营收超750亿美元，同比增长34%。而谷歌、亚马逊也在将大模型深度集成进各自的云服务体系。对企业客户而言，AI不是玩具，而是生产力工具。这决定了它的商业天花板在用户付费意愿尚未大规模解锁的前期，仍远高于C端订阅。</p>
  <p><strong>与此同时，垂直行业的定制化模型正成为高价值赛道。</strong>通用大模型固然强大，但在医疗、法律、制造等专业领域，数据合规性、领域知识深度和任务精准度才是关键。于是，一批专注于定制模型的AI公司开始崛起：有的深耕医疗影像分析，有的专攻合同智能审查，有的为制造业提供预测性维护方案。这些小而深的模型虽不具大众知名度，却能以百万甚至千万美元的合同撬动稳定现金流。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_c6aeb52e21fa4a86b96edc858bb44782@5888275_oswg736974oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>更长远来看，随着多模态能力和工具调用技术的成熟，AI或将演变为整个数字生态的调度中心。</strong>它不再只是回答问题，而是主动调用日历、支付、物流、客服等系统，在一次对话中完成从推荐、比价到下单、预约的完整闭环，大模型平台则从中抽取交易佣金。这种“AI促成交易、分润获利”的模式，可能成为下一代互联网的核心商业模式。</p>
  <p>这些可能的变化意味着，到了2026年，我们或许不会突然面对一个满屏弹窗广告的AI助手，但我们一定会感受到某种微妙却深刻的转变：那个曾经免费、开放、充满理想主义色彩的AI时代，正在悄然落幕。取而代之的，是一个更复杂、更高效，也更功利的商业体系。</p>
  <p>而资本的入场，从不仅仅是收费那样简单。</p>
  <h2><strong>资本入场的代价</strong></h2>
  <p>然而，资本的入场，从来不只是在界面上加个广告位、在功能里设个付费墙那么简单。它带来的是整个产品逻辑和价值取向的深层重构：从为用户服务逐渐滑向为投资方负责。这种转变往往悄无声息，却影响深远。</p>
  <p>过去，大众媒体通过版面编排引导注意力，直播带货靠话术制造冲动消费，这些影响虽强，但边界相对清晰：我们知道电视广告是推销，明白网红推荐可能拿佣金。而今天的AI，是以客观、中立、智能的形象嵌入我们日常决策的，它帮你选餐厅、比手机、写简历，甚至规划人生路径。正因如此，它的影响力更深、更隐蔽，也更具说服力。一旦这套看似无私的系统开始承载商业目标，其操控性反而更难被察觉。</p>
  <p><strong>用户侧能感知到的最明显的变化是内容导向的扭曲。</strong>比如，当你问“哪款空气净化器值得买？”，AI列出的前三款恰好都是某电商平台的主推品牌；或者在比较两款手机时，对其中一款的电池问题一笔带过，却详细描述另一款的“用户好评”。这些推荐未必是错的，但优先级和表述方式可能已经受到商业合作的影响。久而久之，用户接收到的信息看似中立，实则经过了微妙的筛选和倾斜。</p>
  <p><strong>与此同时，隐私的边界也在模糊。</strong>为了实现精准推荐，AI需要持续收集用户的对话历史、兴趣偏好、地理位置乃至情绪状态。这些数据一旦被用于商业画像或跨平台追踪，用户的“数字自我”就可能被拆解成一串可交易的标签。表面上看，这只是为了让回答“更贴合你”，但实际上，这些数据也可能被用来优化广告投放、预测消费行为，甚至与第三方共享。而大多数时候，用户并不清楚自己的哪些信息被用了、用在了哪里。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_80bd69a5b75b4a5b990a2835887b92f2@5888275_oswg659112oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>更深远的影响，正在重塑整个内容生态。</strong>当AI成为信息分发的新枢纽，创作者们很快意识到：要想被引用、被推荐、被流量看见，就必须迎合AI的“口味”。于是，越来越多的内容开始围绕关键词堆砌、结构模板化、观点趋于安全平庸。因为只有这样，才更容易被AI抓取、摘要并纳入回答。公共讨论因此加速流量化：深度分析让位于爆款标题，多元声音被同质化内容淹没。久而久之，AI不仅反映现实，还在悄悄塑造一个更浅薄、更趋同的信息环境。</p>
  <p>随着AI越来越深地卷入商业利益，监管的目光也迅速跟了上来。各国政府开始认真审视：用户的数据被用来训练推荐模型，是否经过充分授权？算法在提供建议时，会不会因为商业合作而偏向某些品牌，甚至无意中放大偏见？</p>
  <p>欧盟的《人工智能法案》已明确要求高风险AI系统提高透明度；美国联邦贸易委员会（FTC）正在调查生成式AI是否存在误导性内容；中国也陆续出台了《人工智能大模型》系列国家标准，强调内容安全与可追溯性。这些动作传递出一个清晰信号：<strong>AI不能再以“我只是个工具”为由回避责任。一旦它成为商业链条中的一环，就必须接受相应的规则约束。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_ca0c8402e72a46868b7da34e93fea91b@5888275_oswg75510oswg959oswg735_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>说到底，AI的大规模商业化是资本逻辑下的必然选择。但对普通用户而言，这意味着我们必须重新校准与AI的关系：不再把它当作全知全能的导师，而是一个既聪明又“有目的”的参与者。</p>
  <p>面对它的建议，多一分追问；面对它的推荐，多一分审视。唯有保持批判性思维，才能在信息洪流中识别真正有价值的内容。</p>
  <p>毕竟，在一个连客观都可能被定价的时代，能独立思考、主动验证，或许才是人最该守住的能力。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/e-BCYEXHqxgUaW_VI3sa6Q" rel="noopener noreferrer nofollow" target="_blank">“脑极体”</a>，作者：珊瑚，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627810827945218</id>
            <title>开发网站被欠薪？Web开发者怒删客户官网，只留三行催款留言：先付钱才能访问网站</title>
            <link>https://www.36kr.com/p/3627810827945218</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627810827945218</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 11:35:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作为一名自由开发者，很多人对这种情况并不陌生：有时候，你花了几个星期写代码、调试页面，把一个网站按约交付，可是客户的尾款却迟迟未到账。几次沟通、一次又一次提醒后，仍然没有下文，此时你会怎么做？</p>
  <p>最近，一位国外 Web 开发者给出了一个极端答案——<strong>直接把客户官网，变成了全网可见的催款公告。</strong></p>
  <p>没错，他不是暗中锁掉后台，也不是挂个提醒条幅，而是把整个网站内容全部替换，留下三行醒目的文字：</p>
  <p><strong>应该把网站开发费付清。</strong></p>
  <p><strong>网站开发服务已完成并交付，但 Joseph Smith Furniture 的相关款项仍未支付。</strong></p>
  <p><strong>如需恢复网站访问权限，请先完成付款。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_271534e26c3a4c45b5cad31eb27f564a@5888275_oswg12806oswg657oswg149_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">https://joseph-smith.co.uk/</p>
  <p>原本展示定制家具的官网，一夜之间，变成了“讨债现场”。</p>
  <h2><strong>从“接项目”到“锁官网”，一名 Web 开发者的破釜沉舟</strong></h2>
  <p>这场风波的另一方，是一家英国本土的定制家具制造、橱柜制作和细木工公司&nbsp;Joseph Smith Furniture，提供手工打造的高品质家具和木制品服务。</p>
  <p>这家公司的官网域名是 joseph-smith.co.uk，曾是其重要的“线上门面”，如今却被当初负责开发网站的程序员完全接管了。</p>
  <p>这名开发者的整个操作其实并不复杂：他没有留下任何个人署名，也没使用复杂的技术手段，只是把网站原有页面内容全部替换掉，只保留那段讨款声明。</p>
  <p>或是多次沟通无果后，开发者选择了这种近乎“破釜沉舟”的方式，把纠纷直接摊到所有访客面前，也有人把这个事情披露到了 HN、Reddit、X 等社交媒体上，似乎希望可以借助舆论的压力倒逼客户结款。</p>
  <h2><strong>原公司已解散？</strong></h2>
  <p>事件发酵后，有好奇的网友顺着 Joseph Smith Furniture 的公司信息深挖，结果发现了更耐人寻味的细节。</p>
  <p>根据英国公司注册信息：</p>
  <p>Joseph Smith Furniture 已于 2025 年 12 月 16 日被注销</p>
  <p>这家企业负责人名下的另一家公司，目前处于清算中</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2521d76b79aa42828e40f33ac4a4cc95@5888275_oswg72518oswg848oswg746_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这也让不少人开始猜测：是不是公司已经没了，干脆就“摆烂”不付钱？但在 Hacker News 上，有熟悉英国公司注册规则的网友提出了不同看法，带来了一个新的视角：</p>
  <p>“我的猜测是，这并非故意逃债行为。他们甚至可能根本不知道公司已经被注销了。这次注销属于‘强制除名’，原因是公司在账目到期后约 4 个月仍未提交年报，也没有向注册机构发送确认‘公司仍在运营’的邮件 —— 而仅仅是这封邮件，就足以阻止注销。”</p>
  <p>这名网友进一步补充道：这种情况在 2021 年就曾在这家公司发生过一次，几个月后公司便成功恢复。“公司恢复后，负债也会一并恢复，这说明他们 2021 年的注销并非为了逃避债务。我更倾向于认为，这是公司所有者的疏忽。他本身就有拖延到截止日期前才提交材料的习惯，而且可能没有聘请专业会计。在英国，单人公司没有会计、不完全了解合规规则的情况，其实非常普遍。”</p>
  <p>除此之外，“健康问题或生活突发事件，都可能导致这种疏忽，尤其是对习惯卡着截止时间办事的人来说。公司被强制注销后，继续经营属于违法行为，包括用公司资金向供应商付款。所有者会立刻失去对公司全部资产的控制权，银行账户也可能被冻结或关闭，这意味着他们可能突然无法动用资金。如果事先毫无准备，甚至不知道公司已被注销，情况会相当棘手。再加上英国商业银行有时会因不明原因冻结账户，他们甚至可能无法判断账户冻结的真正原因。”</p>
  <p>当然，该网友也认为：“这些都不能成为不回复供应商、不作出说明的正当理由，除非他们倒霉到连已付费的 Google 账号等沟通工具都无法访问，或者确实遭遇了足以让他们错过申报期限的突发健康问题或重大生活事件。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_529c85f72f60413d9b116ddbe55cc9ad@5888275_oswg349014oswg1080oswg502_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>讨债无可厚非，但“锁官网”的操作真的可行吗？</strong></h2>
  <p>如果说公司注销的真相引发了网友的讨论，那么开发者“替换官网催款”的极端做法，才是真正引爆全网争议的核心。</p>
  <p>不少程序员对开发者的遭遇感同身受，纷纷在评论区分享自己的类似经历。有网友回忆道：“大概二十年前，我也遇到过一模一样的事。每次我催他付款，他就消失不见，直到他又需要修改功能。我改完之后，他才像突然想起来一样说：‘哦，对了，我得付你钱吧！’我把付款细节发给他，他又再次消失，直到下一次需要改动。”</p>
  <p>还有网友从行业常规操作的角度补充说：“其实不太可靠的共享主机商，几十年来一直在玩类似的手段，只不过通常是以页面顶部弹窗或横幅的形式出现。我以前在一家主机商工作时，逾期未付款的账户会收到长达一个月的每日提醒邮件。一个月后，网站会被禁用或显示 404 页面，VPS 会被关闭；三个月后，网站或 VPS 会被归档；一年后，归档内容会被彻底删除。令人惊讶的是，总有一批客户在一年后才回来，要求恢复网站或拿到副本，我从来都不喜欢告诉他们 —— 这是他们自己选择的后果。”</p>
  <p>然而，在共情的声音之外，更多人开始理性审视这种极端做法的潜在风险，众人看法不一。</p>
  <p>有网友认为，“这也是为什么作为独立创业者需要购买商业保险，以应对类似情况的赔付。我怀疑以后没人会愿意再跟这个开发者合作。”</p>
  <p>也有人建议走正规法律途径：“我偶尔会看到这种行为，但个人觉得很不合适。合同违约了就去起诉啊，为什么非要闹到全网皆知的地步？”</p>
  <p>但这一建议立刻遭到了有过诉讼经历的网友的反驳，他以自己长达十余年的维权经历，道出了自由开发者走法律途径的无奈：</p>
  <p>“我有一个客户在 2010 年终止了合同，当时假装不再使用我的软件。他手里有源码，因为出于技术原因，我必须在现场为他编译。</p>
  <p>后来，他们公司有一名不满的员工打电话告诉我和我的合伙人，他实际上仍在使用软件。我花了整整三年才找到证据，诉讼于 2014 年启动，鉴定从 2016 年开始，到 2021 年才结束。我在 2026 年 2 月 12 日安排了第一次庭审。预计判决需要 6 到 12 个月，而且之后肯定还会上诉。</p>
  <p>在我通过诉讼制止他之前，他已经积累了 500 万美元净资产（他为一家大型企业分包。我自己根本拿不到那份合同，缺少他的人脉；那家大企业从未回复过我们关于软件的邮件），现在他用这些钱请知名律师想方设法拖延诉讼程序。</p>
  <p>到目前为止，我在法庭、鉴定和律师费用上已经损失超过 10 万欧元，更别提为了应对对方律师源源不断、毫无意义的文件和拖延而花费的大量时间。</p>
  <p>就我而言，现在我的服务都是由我自己托管的，不付款就直接断服务，这一点在服务条款里有明确说明。”</p>
  <p>针对这一事件，SEO 专家、域名行业从业者 Bill Hartzer 在 X 上直言不讳地评价说：</p>
  <p>一名 Web 开发者刚刚把客户的网站变成了一个公开的“催款公告”。</p>
  <p>如果你是企业主，这不仅仅是尴尬——它可能在一夜之间损害客户信任、影响销售，甚至伤害品牌形象。现在就采取一些理性的应对措施，仍然有机会重新掌控局面，把负面影响降到最低。</p>
  <p>如果你是正在考虑这么做的开发者，请先停一下。把“付我钱”的信息公开挂在网站上，可能会引发远超账单本身的法律、安全和声誉风险。</p>
  <p>这件事也再次提醒我们：企业必须牢牢掌控自己的域名、DNS 和访问权限；而任何纠纷，都应该在后台私下解决，而不是直接摆到客户眼前、挂在首页上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b5d536f8c3294181ae6d51ba455865fa@5888275_oswg94373oswg398oswg486_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>回头看这起事件，从开发者拿不到尾款，到企业品牌形象受损，最终没有任何一方成为真正的“赢家”。</p>
  <p>来源：</p>
  <p>https://news.ycombinator.com/item?id=46501975</p>
  <p>https://joseph-smith.co.uk/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UlhTiFocOk7n8BeQ4PlA3Q" rel="noopener noreferrer nofollow" target="_blank">“CSDN”</a>，整理：苏宓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627798351315970</id>
            <title>销量承压、宝马最高降价30万，AI与本土合作成新出路？</title>
            <link>https://www.36kr.com/p/3627798351315970</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627798351315970</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 11:27:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>进入2026年，宝马启动大降价。</p>
  <blockquote>
   <p>据媒体报道，2026年1月1日起，宝马中国对旗下31款主力车型进行建议零售价调整。其中24款车型的降幅超10%，5款超20%；宝马i7 M70L的降价金额最高，达30.1万元。</p>
  </blockquote>
  <p>对此次降价，宝马中国表示，这不是“价格战”，“是宝马部分产品的价值升级，是宝马主动调整产品策略、针对市场动态的积极回应。”宝马奉行长期主义良性发展，而非短期盈利。在部分产品上，对消费者关注的舒适配置、个性外观、数字化等方面进行升级，将切实利益回馈给消费者，提供更高价值、更具竞争力的产品体验。</p>
  <p>然而，在降价背后是宝马在中国销量下滑的事实。2025年前三季度，宝马中国销量46.5万辆，同比减少11.2%，是宝马全球范围内唯一销量下滑的市场。</p>
  <p>此番大幅度降价，能否带动宝马在中国的销量呢？</p>
  <h2><strong>终端多次降价</strong></h2>
  <p>降价已经成为宝马在中国市场的常态。</p>
  <p>2019年，宝马在中国市场交付72.37万辆宝马和MINI品牌汽车，同比增长13.1%，首次在中国豪华车市场夺得年度第一。到2021年，宝马在中国的交付量增长至84.63万辆。</p>
  <p><strong>然而，2022年，宝马便出现销量下滑——同比减少6.4%至79.2万辆。2023年，由特斯拉降价所导致的价格战，宝马也无法置身之外。据媒体报道，宝马为了保住市场份额，选择降价求存，2023年全年折扣率高达17.66%，远超行业15.7%平均水平。2023年，宝马集团在中国交付82.5万辆宝马和MINI汽车，同比增长4.2%。</strong></p>
  <p>2024年，宝马曾一度退出价格战。这一年7月，有消息称宝马中国将退出价格战，通过减少销售量来稳定价格，缓解门店的经营压力。随后，宝马中国表示，下半年宝马在中国市场将重点关注业务质量，支持经销商稳扎稳打。</p>
  <p>此后，宝马旗下车型开始涨价。据媒体报道，宝马全系产品几乎都上调了售价，涨幅大概3–5万元不等。然而到了9月，经销商通过“中秋国庆特别折扣”每车补贴1万元冲刺销量。</p>
  <p>此次降价也无法挽救宝马的销量下滑趋势。<strong>2024年，宝马集团在中国市场交付71.45万辆，同比减少13.4%，占全球销量比例从2023年的32.3%降至29.2%。</strong></p>
  <p>2025年，宝马经销商通过“高息高返”金融方案对宝马车型进行优惠。6月以来，多地银行业监管部门或行业协会相继发布通知或自律公约，严禁各银行机构通过“高息高返”拓展业务。</p>
  <p>然而，宝马的终端售价有不小的优惠。<strong>车主之家显示，厂商指导价43.99万-52.59万元的宝马5系，一年内终端报价为21.99万-36.29万元；厂商指导价31.99-39.99万元的宝马3系，一年内终端报价为14.99万-39.99万元。</strong></p>
  <p>此次宝马对官方建议零售价进行调整，并未强制要求经销商的终端零售价。摩根士丹利研究报告指出，据其渠道调查，宝马中国自2026年1月1日起将建议零售价普遍下调10%至20%，主要涉及进口车型，如7系、6系、M系及i系列纯电动车。</p>
  <h2><strong>加速调整中国</strong></h2>
  <p>中国市场的销量下滑叠加降价影响，让宝马的业绩明显承压。</p>
  <p>2024年，宝马集团营收1432.8亿欧元，同比减少8.4%；净利润76.78亿欧元，同比减少36.7%；利润率也从上一年的11.0%下降到7.7%。宝马表示，2024年下半年运营业绩受到中国市场需求疲软以及集成制动系统（IBS）相关交付停止的影响。</p>
  <p>2025年前三季度，宝马集团营收999.99亿欧元，同比减少5.6%；归母净利润为57.12亿欧元，同比减少6.8%。<strong>在财报中，宝马表示，中国充满挑战的市场环境阻碍了业务的发展。汽车板块全年每辆车收入（按货币调整）将较去年略有下降，主要原因是中国的价格水平较低。</strong></p>
  <p>对此，宝马也需要对中国市场进行一定程度的降本增效。</p>
  <p>在2025年第三季度财报投资者会议上，宝马宣布将对在中国的业务进行“规模调整和重组”。<strong>由于中国市场的销售目标尚未达成，宝马下调了第四季度中国市场的销售预期，但并未公布具体目标；重组销商网络，具体措施为逐步关停部分门店，并将部分销售功能较弱网点转型为仅提供售后服务的站点，预计于2026年中期完成。</strong></p>
  <p>同时，在2025年第三季度财报中，宝马表示，由于生产量下降，中国部分非永久性合同员工，到期后不再续签，预计员工总数将略有下降。在投资者会议上，宝马也再次表示，在中国采用了在劳动力上灵活安排的策略，通过不续签固定期限的合同，降低成本。其在中国的员工数字是根据经营结果和成本自动调整。</p>
  <p>在这之外，宝马的转型才是其在中国能否走出困境的关键。</p>
  <p><strong>一方面，宝马在加大AI。2025年3月，宝马发布360度全链AI战略，明确将AI技术深度融入研发、生产、供应链、客户服务等全价值链。</strong>11月，宝马推出自研AI智能体平台“盖亚”（GAIA，Group Artificial Intelligence Assistant）。据悉，“盖亚”平台是连接数据、系统与人员的数字化基础，核心优势在于以低代码自助服务降低AI应用门槛，实现AI技术的全员化覆盖。<strong>目前，人工智能解决方案已在宝马沈阳生产基地实现规模化应用，覆盖质量管控、备件管理等生产运营的各环节。</strong></p>
  <p>在车型规划上，宝马计划在2026-2027年向中国市场推出包括新世代车型在内的20余款BMW新车。据悉，新世代系列将主要有三大特征：完全重新设计的IT和软件架构、全新一代高性能电力驱动系统和电池、以及贯穿整个车辆生命周期的全新可持续理念。</p>
  <p>在关键的智能化转型上，宝马选择与中国企业合作。<strong>2025年3月，宣布与阿里合作共同开发AI引擎；同月与华为终端合作，研发包括数字钥匙、手机应用等功能；7月，与Momenta达成合作，联合开发面向中国市场的新一代智能驾驶辅助解决方案，将率先搭载于国产新世代BMW iX3，并计划于2026年实现量产上市。</strong></p>
  <p>面对销量下滑，宝马不仅在加快转型脚步，还通过大幅调价以应对中国市场的激烈竞争。但能否扭转销量颓势，取决于其AI战略与本土化合作能否精准捕捉中国市场的需求变化，以及其新车型能否满足消费者的智能化需求。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/oCf9BvTYyF3-iBbfqh_wOA" rel="noopener noreferrer nofollow" target="_blank">“车圈能见度”</a>，作者：度哥，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627715367699456</id>
            <title>港科大教授实测AI眼镜“作弊”：30分钟碾压95%的学生，把传统教学评估体系整破防了</title>
            <link>https://www.36kr.com/p/3627715367699456</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627715367699456</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 11:15:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>离了大谱了，AI真·走进了大学期末考场，并且还是以<strong>作弊者</strong>的身份。（你就说震不震惊吧）</p>
  <p>没开玩笑，事情就发生在香港科技大学《计算机网络原理》的本科期末考试“现场”。</p>
  <p>一副搭载ChatGPT-5.2模型的<strong>AI眼镜</strong>，被直接戴上鼻梁，在复刻真实考试条件的情况下，完成了整套期末试卷：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_a7cbd2191ac64f249d1dfa225a197425@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>结果甚是魔幻：30分钟交卷，狂揽92.5分，并在一百多人的排名里跻身进了前五，轻松碾压超<strong>95%</strong>的人类考生：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d413fe6e32544601a70413d3fe90e74b@5888275_oswg55321oswg1062oswg276_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>果然，一代人有一代人的学习工具，以前是小抄复习资料，这回直接升级成——「整机」。</p>
  <p>只不过，当这套整机已经能完整跑完一整套考试流程时，大家关注的重点，可能不再只是AI会不会答卷了。</p>
  <p>这一次，AI“作弊者”只是像人类学生那样完整答了一遍题，却让传统的教学评估体系看起来似乎有点站不住脚。</p>
  <h2><strong>一副AI眼镜，跑完了一整场大学期末考试</strong></h2>
  <p>这场看似离谱的「人机同场考试」，可不是学生的临时整活，而是由<strong>香港科技大学张军教授、孟子立教授团队</strong>主导的一场实验。</p>
  <p>目标很明确，那就是让一副搭载大模型的AI眼镜，光明正大地在考场“作弊”，然后看它能考多高分～</p>
  <p>其选中的测试场景也是非常的简单粗暴，直接瞄准了令无数大学生《闻风丧胆》的专业课——<strong>计算机网络原理</strong>。（瑟瑟发抖…</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_05369a9c7c564b3d8a095e98d056fde9@5888275_oswg59011oswg1080oswg958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这门课程不仅考查海量的专业概念，更涉及严密的逻辑推导与算法应用，对人类学生来说是不小的挑战，对AI而言更是难度拉满。</p>
  <p>对此，为了让这位AI考生发挥出最强实力，项目组在「软硬件」筛选上可谓是做足了功课！</p>
  <p>在硬件筛选环节，项目团队对市面上12款主流商业智能眼镜进行了系统评估，其中也包括大家熟悉的<strong>Meta、小米、乐奇Rokid</strong>等厂商的产品：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_ec1c7dfb239f4b3b81178a9875866d19@5888275_oswg106927oswg1034oswg838_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第一轮筛选后，团队发现真正同时具备内置摄像头和集成显示屏的产品其实并不多，进入候选范围的主要只有Meta Ray-Ban、Frame，以及乐奇Rokid。</p>
  <p>但实验还需要进行二次开发，尽管Meta提供了设备访问工具包，但并未开放对显示内容的直接控制接口，难以满足实验对信息呈现方式的要求。</p>
  <p>相比之下，乐奇Rokid的SDK更丰富、生态更完善，开发自由度显著更高。</p>
  <p>再综合考虑Frame在试卷识别等场景下的相机画质限制，研究团队最终选择了<strong>乐奇AI眼镜</strong>作为这次人机同场考试的硬件测试选手：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4800f9c5809843cb9268867d58cc4c98@5888275_oswg39085oswg1080oswg667_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而在决定大脑上限的大模型筛选上，团队则对比了多款主流模型，最终锁定了OpenAI目前最新的模型——无论是响应速度还是通用知识能力都较强的<strong>ChatGPT—5.2</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_5ecdf6e3ee534e3db44b3eaf05f2b1d9@5888275_oswg63851oswg1080oswg976_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>软硬件「考生」均已就位，接下来就是重头戏——大考。</p>
  <p>考试过程，可以用丝滑二字来形容：学生低头查看试卷，AI眼镜通过摄像头快速拍摄题目，并经由“<strong>眼镜—手机—云端</strong>”链路将图像传输至远程大模型完成推理，生成的答案再沿相反路径返回，最终显示在眼镜屏幕上，供学生抄录。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_852573830a0142d08b4316f144f8f021@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>结果您猜怎么着？这款基于Rokid Glasses开发、搭载GPT-5.2模型的AI眼镜，在本次期末考试中拿下<strong>92.5分</strong>，成绩超过了<strong>95%</strong>的学生。</p>
  <p>不仅如此，在多项选择题和单页短答题中，乐奇Rokid均获得满分，即便是难度更高的跨页短答题（SAQ），也拿到了大部分分数：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_00d4b11c4bb44e4193eb00d9e1b6f688@5888275_oswg39489oswg990oswg326_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，在面对那些核心问题被拆分在不同页码、高度依赖上下文逻辑的跨页短答题，乐奇Rokid依然展现出了极强的推理连贯性。</p>
  <p>即便在计算最复杂的部分偶尔出现偏差，但AI给出的中间步骤也算得上非常完整，在处理高压知识任务时也是手拿把掐～</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_ef6a5888f5874da2bcffeeb4d1933216@5888275_oswg618844oswg1080oswg708_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，这场测试在跑通软件逻辑的同时，也无情地照出了目前商业AI眼镜存在的《短板》。</p>
  <p>首先暴露出来的，是<strong>功耗问题</strong>。</p>
  <blockquote>
   <p>在考试这样的高压连续场景下，连接本身就已经成为主要耗电源，实验中只要开启Wi-Fi、持续进行高分辨率图像传输，30分钟内眼镜电量就会从100%迅速跌到58%。</p>
  </blockquote>
  <p>换句话说，如果AI眼镜要真正走向全天候、长时间使用，功耗控制和连接稳定性依然是绕不开的工程瓶颈…</p>
  <p>不仅如此，项目团队还发现眼镜摄像头的<strong>「清晰度」</strong>会直接决定AI的视力，一旦题目出现模糊、反光或拍摄角度偏差，再强的模型也只能在不完整信息上做推理，最终体现在答题表现上的，就是明显下滑的稳定性。</p>
  <p>但…这场测试带来的冲击和反思，并不只停留在技术层面。</p>
  <p>在不做任何特殊照顾的前提下，AI眼镜依然能够把一整套读题—理解—作答的流程跑得又快又稳，这反过来照出了一个更值得注意的问题——</p>
  <p>当<strong>教学评估</strong>主要关注的只是最后有没有交出一份「标准答案」时，<strong>它恰好落在了AI最擅长、也最稳定的能力区间里。</strong></p>
  <p>也正因为如此，那套以知识点掌握程度和标准解题路径为核心的教学评估方式，在一个早已被各种“学习机”包围的时代，开始显得有些吃力了。</p>
  <h2><strong>有了聪明的AI，传统教学评估标准还站得住脚吗</strong></h2>
  <p>不知道大家有没有发现一件挺有意思的事情：</p>
  <p>从小学一路考到大学，我们最熟悉的考试，其实一直在反复确认同一件事，那就是有没有把老师讲的内容记住，以及能不能按标准方法，把题一步步算对。</p>
  <p>u1s1，在很长一段时间里，这套评估方式确实挺管用。</p>
  <p>因为在记忆、计算、按步骤推导这些能力上，人和人之间确实存在明显差距，有人记得牢、算得快，有人就是会漏步骤、算错数。</p>
  <p>成绩单上的数字，也确实能覆盖一个人相当大比例的学习表现。</p>
  <p>但问题在于，当AI开始在这些评估维度上，也变得又快、又稳、而且几乎不出错时，事情就开始变得微妙了…</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2c944151f8c845569e271e33c169e5e5@5888275_oswg61516oswg1080oswg1007_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此前，一位创业者小孩哥Eddy Xu通过<strong>改装Meta智能眼镜</strong>，做出了一套可以在国际象棋比赛中实时显示最优解法的“作弊”设备，在几乎不需要自己思考的情况下，就能稳定赢下对局：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e07067610a7c4630b7c10cbe81bb24a5@5888275_oswg138779oswg884oswg1013_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在这个过程中，AI眼镜不会紧张，也不会疲劳，更不存在临场波动，一个字形容——稳。</p>
  <p>这和乐奇Rokid眼镜参加期末考试的表现其实是同一套逻辑：只要题目规则清晰、评价目标单一，AI就能把读题—理解—推理—作答这套流程稳定跑完。</p>
  <p>哪怕脱离纸笔形态，它依然能在高度结构化的考试里，持续拿到高分。</p>
  <p>类似的案例并不只发生在个人层面。</p>
  <p>此前，英国雷丁大学的一项研究还发现，当研究人员将AI生成的答卷混入考试题库后，有高达<strong>94%</strong>的试卷成功“浑水摸鱼”，而这些AI的平均成绩，甚至还明显高于真实学生…（天塌啦</p>
  <p>这下是真有点尴尬了——比人比不过，比AI也比不过：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_56fa534aa3404beabacb9a9315e10732@5888275_oswg193620oswg1044oswg1334_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>让人大跌眼镜大开眼界的同时，一个原本不那么尖锐的问题被直接推到台前——</p>
  <p><strong>当AI或机器比人更擅长按标准作答时，那套以笔试为核心、用来衡量知识点掌握程度的评估体系，到底在测什么？</strong></p>
  <p>回过头看教学培养的最初目的，我们会发现很多被反复强调的重要能力，其实并不天然适配“一张试卷”这种形式。</p>
  <p>——比如提出好问题的能力。</p>
  <p>——在信息不完整时做判断的能力。</p>
  <p>——在多种方案之间权衡取舍的能力。</p>
  <p>——以及理解现实情境、理解他人立场的能力。</p>
  <p>……</p>
  <p>这些能力真正指向的是<strong>学习过程</strong>、<strong>思考路径</strong>和<strong>决策质量</strong>，答案是否标准只是其中很小的一部分。</p>
  <p>也是长期以来最难被传统笔试捕捉，最容易被系统性忽略，恰好也是AI最难替代、也最能区分学生真实素养的地方。</p>
  <p>从结果导向，转向对推理路径、探究过程、跨学科整合与创造性解题能力的整体评估，这也许才是AI眼镜进入考场后，对现有教学评估体系提出的那道真正难题。</p>
  <h2><strong>评估重心从「交答案」到「交思路」</strong></h2>
  <p>教育心理学家<strong>加德纳</strong>曾在《Frames of Mind》中提到，人类至少拥有8种不同类型的智能——</p>
  <p>包括语言、逻辑数学、空间、音乐、人际、内省、身体运动、自然观察。</p>
  <p>从这个视角看，人类能力本身就是一个高度多维的结构，而我们所熟悉的教学评估体系，长期以来却只集中捕捉了其中非常狭窄的一段。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_a11d12f0ba4b434a9573930b70e1d49c@5888275_oswg527781oswg1080oswg832_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这也不难解释，为啥一些在标准化测试中表现并不突出的学生，反而能在真实世界中展现出更强的创造力、协作能力和复杂问题解决能力。</p>
  <p>毕竟单一考试成绩更多反映的只是学生在「标准化环境」中的发挥稳定性，像真实情境下的个人综合素质其实显露不太出来……</p>
  <p>也正因如此，如何评估创新能力、批判性思维和复杂问题解决能力，正在成为教育评估体系绕不开的一个现实难题。</p>
  <p>目前一些指向不同方向的评估尝试，已经出现～</p>
  <p>前不久，纽约大学Stern商学院教授Panos Ipeirotis推出了一套<strong>由AI支撑的口试评估方式</strong>，学生不仅要提交作业，还需要当场解释自己的决策依据和思路走向，在对话中把理解与推理展开来。</p>
  <p>这套机制中，AI先充当考官进行追问，再参与到后续评估环节。</p>
  <p>Claude、Gemini和ChatGPT会分别对口试转录进行独立评分，随后交叉审查并修订结果，用来判断学生是否真正理解问题，同时暴露教学中的共性盲区：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_70cb810a6ffb4f32bfd58fa45ae1c0fc@5888275_oswg44525oswg860oswg446_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>怎么说呢，感觉这种做法谈不上专门“对付”AI，但确实把教学评估重心往理解本身挪了一步。</p>
  <p>类似的变化并非个例，此前《华盛顿邮报》也提到，目前国外部分高校已经开始引入口试、展示型作业等形式，本质上也是为了让学生的<strong>思考过程</strong>变得显现。</p>
  <p>所以回过头看，当搭载GPT-5.2的乐奇AI眼镜走进考场并交出高分时，AI是否「考赢」了学生似乎也没有那么重要了。</p>
  <p>它更像一次特别但清晰的显影实验，让一个长期存在却很少被正视的问题浮出水面：</p>
  <p><strong>传统教学评估高度依赖最终答案，却几乎无法刻画整个学习过程。</strong></p>
  <p>分数当然是有意义的，但它所能解释的范围正在变窄，理解是否真正发生、思路是否连贯、判断是否经过取舍，这些关键环节，仍然被压缩成一个单一结果，难以被区分和看见。</p>
  <p>也正是在这一点上，单纯地把技术挡在门外，其实已经很难回应问题本身了。（也不见得阻挡得了…</p>
  <p>更现实的挑战，变成了如何让学生把AI用在信息整理、方案推演和假设验证上，把人的精力集中到判断、理解和选择这些无法被「外包」的环节。</p>
  <p>当工具可以稳定完成信息提取与标准作答，课堂与考试是否还能区分不同层次的思考，正被推到台前。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0YkZdCa63Q3GZz7Q62PV9A" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627607956079621</id>
            <title>刚刚，苏姿丰掏出AMD史上最强AI核弹硬刚老黄，OpenAI总裁和李飞飞都来站台</title>
            <link>https://www.36kr.com/p/3627607956079621</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627607956079621</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 10:30:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>AMD的CES大招来了！&nbsp;</p>
  <p>智东西1月5日报道，刚刚，AMD董事会主席兼CEO苏姿丰（Lisa Su）博士发表国际消费电子展CES 2026开幕主题演讲，甩出多款王炸新品：全新一代AI芯片<strong>MI455X GPU</strong>、<strong>Ryzen AI 400系列处理器、AMD Ryzen AI Max+系列新款处理器、AMD AI开发平台Ryzen AI Halo等</strong>。</p>
  <p>她还当场剧透了AMD两年芯片路线图：<strong>下一代MI500系列</strong>有望在2027年推出，核心亮点包括基于CDNA 6架构、搭载HBM4e、采用2nm工艺。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_beb32d98626a4f0a82f951aa07007717@000000_oswg49441oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>核心亮点如下：</strong></p>
  <p>1、展示专为AI设计的下一代数据中心机架<strong>Helios</strong>，重量相当于两辆小汽车；&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_63d7845d9d6d49d480263ed893ef060b@000000_oswg62637oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2、AMD史上最先进处理器<strong>MI455X</strong>，3200亿个晶体管，432GB HBM4内存；&nbsp;</p>
  <p>3、2027年将推出2nm制程<strong>MI500系列</strong>；&nbsp;</p>
  <p>4、首批<strong>Ryzen AI 400 PC</strong>将于本月晚些时候发布，全年将推出超过120款设计；&nbsp;</p>
  <p>5、AMD AI开发平台<strong>Ryzen AI Halo</strong>预装开源工具和模型，预计今年第二季度上市。&nbsp;</p>
  <p>苏姿丰称，当前的计算规模远远不足以应对创新速度，而AMD是唯一一家拥有GPU、CPU、NPU全套计算引擎的公司，过去四年，AMD已经将AI性能提升了<strong>1000倍</strong>。&nbsp;</p>
  <p>在苏姿丰的演讲过程中，还有多位AI大牛前来站台，包括<strong>OpenAI联合创始人兼总裁格雷格·布罗克曼（Greg&nbsp;Brockman）</strong>、<strong>Woeld Labs联合创始人兼CEO李飞飞</strong>、Liquid AI CEO拉明·哈萨尼（Ramin Hasani）、Luma AI首席执行官兼联合创始人阿米特·贾因（Amit Jain）等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f8ca225e7b4542ce87c97fc03e521210@000000_oswg358720oswg1080oswg331_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲AMD董事会主席兼CEO苏姿丰（Lisa Su）、Woeld Labs联合创始人兼CEO李飞飞、OpenAI联合创始人兼总裁格雷格·布罗克曼（Greg Brockman）Luma AI首席执行官兼联合创始人阿米特·贾因（Amit Jain）、Liquid AI CEO拉明·哈萨尼（Ramin Hasani）（从左至右）</p>
  <p>AI燃爆CES，芯片巨头更是当仁不让的主角之一，CES开幕第一天一众行业大佬就轮番登场，重磅新品一波接一波。</p>
  <p>前脚英伟达创始人兼CEO黄仁勋火力全开，一口气解密6颗硬核芯片，直接召唤出地表最强AI超算；英特尔紧随其后，高调亮出基于Intel 18A工艺的第三代酷睿Ultra处理器；后脚AMD掌门苏姿丰便强势接棒。</p>
  <p>AI热潮席卷全场，而撑起这场狂欢的底层算力芯片正准备掀起新一轮的科技风暴。&nbsp;</p>
  <h2><strong>01 下一代Helios平台重量7000磅，今年下半年发布</strong></h2>
  <p>云是训练大模型和向数十亿人提供智能的地方，现在每个主要的云服务商都在AMD EPIC CPU上运行，过去十年中，训练领先的大模型所需的计算能力每年增加4倍以上，过去两年token数量增加了100倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_723563822510426d8ca3aa7d0622b076@000000_oswg56129oswg1080oswg569_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了跟上这种需求，需要整个生态需求聚集。</p>
  <p>因此，AMD构建了下一代Helios平台，基于与Meta合作开发的OCP开放式机架宽标准设计的双宽设计，该平台重量接近<strong>7000磅</strong>，相当于两辆小型汽车的重量。Helios搭载HBM4和其机架中包含最多<strong>72块GPU</strong>，采用<strong>2nm和3nm工艺</strong>构建。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_507e05361d1545b7b514f2441bb40dee@000000_oswg57935oswg1080oswg597_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Helios的每个计算托盘包含四块MI455X GPU，可与EPYC Venice处理器和Pensando网络芯片集成，全部采用液冷技术。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_bdf2e5b875874763972615faf3ed69f8@000000_oswg73225oswg1080oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中，苏姿丰称MI455X是其史上最先进处理器，有3200亿个晶体管，相比上一代MI355增加了70%，其采用2nm和3nm工艺，结合先进封装技术，配备432GB的HBM4。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e9feb2974a7d4d03ae99b9881e51e2ea@000000_oswg56169oswg1080oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外还有专为AI设计的<strong>2nm EPYC Venice Zen6 CPU</strong>，其搭载256个Zen 6核心，在机架规模下也能全速为MI455X提供数据。</p>
  <p>单台Helios机架式服务器配备超过18000个CDNA 5架构GPU运算单元与4600个Zen 6架构CPU核心，可提供高达2.9 ExaFLOPS的算力，并搭载31TB容量的HBM4。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_73ea67793ae34fad8060abf2ba1ee8d6@000000_oswg69854oswg1080oswg645_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>苏姿丰称，MI455 GPU将助力开发者构建规模更大、性能更强的模型及AI Agents。<strong>Helios平台预计将于2026年下半年正式发布</strong>。</p>
  <p>2025年10月，OpenAI和AMD宣布合作，OpenAI将根据多年、多代协议部署60亿瓦AMD GPU，并将于2026年下半年开始部署AMD Instinct MI450系列GPU，初始部署功率为10亿瓦。</p>
  <p>OpenAI联合创始人兼总裁格雷格·布罗克曼（Greg&nbsp;Brockman）为AMD站台，他认为计算是AI应用的关键瓶颈之一。每次OpenAI向发布新功能、推出新模型时，内部都会激烈争少，因为他们想发布的东西太多，但因计算受限无法实现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9721cb5e2d1942a8ba52aa25915df11b@000000_oswg45906oswg1080oswg562_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>因此他预测，我们正迈向一个GDP增长将由特定国家、特定地区可用计算量驱动的世界，未来几年这一现象或许真正开始生效。</p>
  <p>除了庞大的Helios，AMD还展示了可直接上机的<strong>MI440X平台</strong>和搭配<strong>Venice-X的MI430X</strong>。</p>
  <p>在软件层面，苏姿丰称<strong>AMD ROCm</strong>是业界性能最高的AI开放软件堆栈，每月下载量超多一亿次。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_3934d64b508443778894241b31548e15@000000_oswg46041oswg1080oswg588_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Luma AI首席执行官兼联合创始人阿米特·贾因（Amit Jain）称，Luma AI正在建立多模态通用智能，以便AI理解世界。他们希望训练能模拟物理因果关系的系统，使其最终以饮品、视频、图像、文本的形式进行呈现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4bc70cbf431547d6bbae1868db97ff8e@000000_oswg43299oswg1080oswg443_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2024年初，Luma AI有60%的工作负载在AMD上运行，且大多数负载都可以在AMD上开箱即用。对于Luma AI而言，处理庞大信息的推理成本至关重要，贾因透露，与AMD合作使其获得有史以来的最佳总拥有成本，2026年，他们与AMD的合作将扩大到之前的约10倍。</p>
  <p>最后是MI400系列，苏姿丰认为这是在所有工作负载、推理和科学计算方面提供更高性能的一个转折点。</p>
  <h2><strong>02 Ryzen AI 400处理器，本月晚些时候首批PC发布</strong></h2>
  <p>基于AI PC的应用程序，用户可以在几分钟内生成专业品质的照片，快速实现管理会议、总结会议、总结电子邮件等。</p>
  <p>而AMD在PC领域，是拥有第一个x86 NPU、第一个x86 Copilot+ PC的公司，现在Ryzen AI 400系列来了。</p>
  <p><strong>Ryzen AI 400</strong>的架构与Ryzen AI 300一样，依然是Zen 5和RDNA 3.5，但支持更快内存速度。首批Ryzen AI 400 PC将于本月晚些时候发布，AMD全年将推出超过120款设计。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_7b53209fd22b416e8773ba9ea89a655b@000000_oswg52435oswg1080oswg560_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Ryzen AI 400系列处理器是业界最广泛和最先进的AI PC处理器系列，搭载了12颗Zen 5核心，最高支持3.1 GHz RDNA3.5和60 TOPS NPU。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_ddf301d092b1440fbc7220fdfdc62ee1@000000_oswg57283oswg1080oswg558_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Liquid AI CEO拉明·哈萨尼（Ramin Hasani）称，他们专注于构建微型模型同时不牺牲质量。Liquid AI推出的Liquid基础模型只有12亿个参数。</p>
  <p>该公司将于今年晚些时候正式发布LFM 3.0，该模型可以用于实时视听交互，可以以10种不同语言输出音频和文本，延迟低于百毫秒。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_0a3e6df9efee41d8a30d05e5c01a27a8@000000_oswg55452oswg1080oswg574_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>接下来是<strong>Ryzen AI Max+系列笔记本处理器</strong>，搭载40核RDNA 3.5集成GPU，苏姿丰称，其可以比DGX Spark带来更高的价值，但其计算是每秒token数，相比之下DGX Spark会更加昂贵。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_21bafbca4a5f46e2a9b8fe67f8b9d196@000000_oswg47880oswg1080oswg586_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>AI开发平台Ryzen AI Halo</strong>搭载旗舰Ryzen AI Max和128GB内存，并预装了开源工具和模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_208855bea8b449d1b59aea1e3baca159@000000_oswg36490oswg1080oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>该平台预计今年第二季度上市。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_3f3df7857b014353962e1fd004af0457@000000_oswg57708oswg1080oswg581_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>03 李飞飞团队用手机，将AMD办公室“搬到”3D世界</strong></h2>
  <p>在游戏方面，苏姿丰邀请了World Labs联合创始人兼CEO李飞飞，李飞飞称，现在出现了新的技术浪潮，无论是嵌入式AI还是生成式AI，最终可以为机器提供更接近人类水平的空间智能，其不仅能感知，还能创造3D或4D世界。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_46d09b678d0443d29b7e1baefbae6c6f@000000_oswg60225oswg1080oswg582_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>构建3D场景需要激光扫描仪或校准相机或使用相当复杂和复杂的软件手动构建模型，李飞飞团队正在创建新一代模型，可以使用最近的AI技术来学习结构，且不仅仅是平面像素结构。模型本身可以填补缺失的细节，预测物体背后的情况，并生成丰富、一致、永久、可导航的3D世界。</p>
  <p>World Labs团队前往AMD的硅谷办公室，使用普通的手机摄像头捕捉了图像，基于其工具构建了AMD办公室的3D世界。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_93676d9e225b405682fdb25268eaf684@000000_oswg56477oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其模型是实时生成框架模型，不到一周，Woeld Labs团队就基于MI325X实现了快速的性能迭代，将性能提高了4倍以上。</p>
  <p>在医疗保健领域，AMD的产品已经被用于药物发现、评估候选药物等领域。</p>
  <h2><strong>04 结语：算力或狂飙至YottaFLOPS时代</strong></h2>
  <p>高性能计算和先进的AI架构正改变数字和物理世界的每一个部分，从科学研究、医疗保健、太空探索到教育和生产力，AI创新的速度令人难以置信。</p>
  <p>AMD的使命是推动高性能计算的边界，从最大的云数据中心到世界上最快的超级计算机，AMD影响着数十亿人的生活。</p>
  <p>AI是过去40年来最重要的技术，苏姿丰称，全球计算基础设施的需求从2022年的月1 ZettaFLOPS增长到2025年的超100 ZettaFLOPS。她认为，我们需要在未来将全球计算能力再增加100倍，也就是到YottaFLOPS级别，这也意味着每秒可完成10的24次方次浮点运算。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652795082&amp;idx=1&amp;sn=984618f3c950fd889d4eb8596c43e572&amp;chksm=8572ee9fdcb6655d4d2c62ffb471d52ee0605cc9df2f28bcfcbae813a06c9d589a9842fab6fd&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：程 茜，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627426660484352</id>
            <title>内存条涨疯了，国产替代如何破局？</title>
            <link>https://www.36kr.com/p/3627426660484352</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627426660484352</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 10:22:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>内存条涨疯了！</p>
  <p>32G规格的内存条，从年初的不足800元，涨至现在2200多元。</p>
  <p>难怪有网友戏称，内存条已经变成了“金条”。</p>
  <p>什么导致存储芯片价格“坐上了火箭”？</p>
  <p>对中国供应链有何影响？</p>
  <h2><strong>01 涨价</strong></h2>
  <p>“早买早享受，晚买有折扣。”</p>
  <p>这是电子产品市场的普遍规律。</p>
  <p>最近的存储芯片价格，却让消费者大跌眼镜。</p>
  <p>2025年三季度以来，全球存储芯片市场出现一轮“史诗级”涨价潮。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_536382b0bfdb454d9de2c8223b468911@000000_oswg19379oswg699oswg313_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">32GB内存条价格上涨走势</p>
  <blockquote>
   <p>据TrendForce集邦咨询数据，2025年第三季度DRAM（内存）价格较2024年同期大幅上涨171.8%，而同期国际现货黄金涨幅不足110%。</p>
  </blockquote>
  <p>涨幅远超黄金，内存条因此被网友戏称为“金条”。</p>
  <p>还需要注意的是，存储产能扩建需2-3年周期，各大厂商此前因风险顾虑未按预期扩产，短期内供需缺口难以填补。</p>
  <p>分析机构Counterpoint据此预测，明年年初，存储还将再涨20%。</p>
  <p>华尔街投资机构伯恩斯坦在最新研报中预判，涨势或持续至2026年上半年。</p>
  <p>存储涨价，几家欢喜几家愁。</p>
  <p>直接受益者，当然是存储厂家。</p>
  <p>三星电子，2025年第三季度财报实现营业利润12.16万亿韩元（约合85.6亿美元），同比增长32.2%。其中，存储业务销售额26.7万亿韩元，创历史新高。</p>
  <p>美光，2026财年第一财季（截至2025年11月27日）业绩表现非常强劲，‌调整后营收达136.4亿美元，同比增长57%，远超分析师预期的129.5亿美元；经调整净利润为54.82亿美元，同比增长58%‌，推动股价盘后大涨超7%。</p>
  <p>同时，美光公布的第二财季营收展望为187亿美元（上下浮动4亿美元），同样大幅高于市场预期的143亿美元。‌‌</p>
  <p>SK海力士，2025年第三季度财报显示，销售额24.45万亿韩元，环比增长10%，同比增长39%；营业利润11.38万亿韩元，环比增长24%，同比增长62%。</p>
  <p>三大国际存储巨头赚得盆满钵满，下游的手机、电脑厂商暗暗叫苦。</p>
  <p>12月25日，小米正式推出了其年度影像旗舰——小米17 Ultra。</p>
  <p>小米17 Ultra起售价定位为6999元，相比前代小米15 Ultra涨价500元，整体各版本机型平均涨价7%-9%。</p>
  <p>早在发布之前，小米集团合伙人、总裁卢伟冰就在微博上吹风，称小米17 Ultra的涨价是确定的。</p>
  <p>核心原因之一，便是内存的成本上涨。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4526d8b6fe6b4e6f8d180e0ff72d272c@000000_oswg46312oswg712oswg393_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">卢伟冰微博</p>
  <p>要知道，存储占电脑、手机BOM（物料清单）成本的10%—20%。</p>
  <p>存储涨价，将直接抬高手机、电脑的整体成本。</p>
  <p>此时，手机、电脑厂商面临三种选择：</p>
  <p>一是配置不变，维持原价，利润必将大幅缩减；</p>
  <p>二是缩减配置，维持原价，产品的吸引力降低；</p>
  <p>三是涨价，可能吓退部分消费者，影响销量。</p>
  <p>每一种选择，都很艰难。</p>
  <h2><strong>02 供需</strong></h2>
  <p>经济学原理告诉我们，供需决定价格。</p>
  <p>存储涨价的背后，亦是供给与需求的动态博弈。</p>
  <p>从供给端来看，要么是自然灾害（地震、火灾）、事故等不可抗力导致的被动中断，要么是厂商减产有意为之的主动收缩。</p>
  <p>例如，2022-2023年，正值存储行业低谷期，三星、SK海力士、美光、铠侠等原厂因严重亏损，采取了前所未有的大幅减产策略。</p>
  <p>又如，2013年9月，SK海力士在无锡的工厂发生火灾。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_8ed27783d7fb455c921f170359fde970@000000_oswg39766oswg757oswg368_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">SK海力士发生火灾</p>
  <p>SK海力士是全球第二大DRAM芯片制造商，无锡工厂产量占到了SK海力士总产量的一半。</p>
  <p>火灾主要烧毁晶圆制造设备，厂房，以及位于5层露天区的环保系统，导致DRAM生产线全面停产。</p>
  <p>全球DRAM供应瞬间紧张，价格大幅上涨42%。</p>
  <p>从需求端看，包括电脑、手机等在内的下游应用需求增长。</p>
  <p>2010年之前，需求驱动主要来自电脑。</p>
  <p>特别是Windows操作系统升级换代，对内存容量的要求更高，激发了巨大的换机和新购内存需求。</p>
  <p>2010年之后，智能手机崛起，对存储的需求呈指数级增长。</p>
  <p>值得注意的是，存储行业的周期性波动，凸显了涨价的特殊性。</p>
  <p>一方面，存储芯片的生产具有高门槛、长周期、重资产的特点。</p>
  <p>建设一条12英寸存储晶圆产线需200-300亿美元，且需2-3年建设周期，导致供给无法快速响应需求变化</p>
  <p>另一方面，存储需求具有波动性、爆发性和场景依赖性。</p>
  <p>技术创新驱动，会在短时间内爆发性地增加对存储容量和速度的需求，买家的“恐慌性采购”，会进一步加剧短期需求的爆发。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_8fcddf98d1ac4a6a97396dd054a70134@000000_oswg102076oswg692oswg403_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">三星存储芯片工厂</p>
  <p>这种“供给慢”与“需求快”之间的矛盾，是存储价格大起大落的根本原因。</p>
  <p>本次存储涨价，依然延续此前的基本逻辑。</p>
  <p>只是需求的驱动者，变成了人工智能。</p>
  <p>人工智能的兴起，正引发多领域的“资源争夺战”。</p>
  <p>正解局先后在《投资1.2万亿，全球最大水电站开工！AI的尽头，在中国》《谷歌、亚马逊掀起“海底暗战”，中国企业不应缺席》两篇文章中，介绍人工智能对电力和网络的需求正在迅猛增长。</p>
  <p>此外，GPU、高端PCB材料、特种气体、液冷设备、高速光模块等也出现严重短缺，且缺口持续扩大。</p>
  <p>随着人工智能的发展开始转向应用，也让存储从幕后走向了台前。</p>
  <p>进入应用阶段后，为了更好地降本增效，人工智能企业普遍采用“以存代算”的方式。</p>
  <p>简单来说，就是将原本需重复计算的中间数据或预计算结果存储起来直接复用，大幅减少数据搬运与算力消耗，显著提升推理效率与降低成本。</p>
  <p>在传统架构中，存储是成本项，厂商拼命压价。</p>
  <p>在“以存代算”架构中，存储成为了核心性能的决定项，价值飙升。</p>
  <p>一台典型的AI服务器对DRAM需求量约为普通服务器的8倍、NAND Flash需求量约为普通服务器的3倍。</p>
  <p>人工智能企业不惜重金抢购顶级存储芯片来构建自己的优势，推高了存储需求和价格。</p>
  <h2><strong>03 突围</strong></h2>
  <p>存储芯片涨价，整个市场的主导权就由买方转向了卖方。</p>
  <p>当前，全球存储市场被美、日、韩厂商主导。</p>
  <p>存储芯片，按“断电后数据是否保留”分为两大类。</p>
  <p>断电后数据丢失的，称之为易失性存储器，例如电脑和手机中的运行内存DRAM。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_ddb1140a49084f63a80e3aa5806e5f20@000000_oswg75704oswg1080oswg615_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">DRAM主要厂商的市场份额</p>
  <p>其中，韩国三星、SK海力士和美国美光合计市场份额超93%。</p>
  <p>断电后数据保留，称之为非易失性存储器，例如电脑、服务器的固态硬盘NAND。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f941bc7495814dcb8111e326701700e6@000000_oswg80125oswg1080oswg615_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">NAND主要厂商的市场份额</p>
  <p>其中，韩国三星、SK海力士和美国美光、西部数据以及日本的铠侠合计市场份额超92%。</p>
  <p>由此可见，韩美日厂商占据垄断地位，掌控了行业命脉。</p>
  <p>中国长鑫存储与长江存储虽然成为新兴力量，但与头部企业之间的差距依然很大。</p>
  <p>特别是被誉为AI时代“算力血液”的HBM（高带宽内存），99%的市场份额被SK海力士、三星、美光三家垄断。</p>
  <p>为了争取货源，国际大厂纷纷与存储芯片厂商达成协议。</p>
  <p>英伟达与SK海力士签订2025-2027年超过100亿美元的HBM3E/HBM4包销协议，锁定其60%以上HBM3E产能，成为全球最大HBM买家。</p>
  <p>微软、谷歌、Meta等企业财大气粗，也已通过长期协议提前锁定了产能。</p>
  <p>中国企业的议价能力较弱，即使愿意支付高溢价，受“出口管制+产能垄断+技术壁垒”三重制约，也难以获得稳定的供应。</p>
  <p>也就是说，中国存储芯片，有被“卡脖子”的风险。</p>
  <p>这也在倒逼中国产业链实现加快国产替代进程。</p>
  <p>需要清醒认识到的是，存储芯片的国产化是一项极其复杂的系统工程，其挑战是系统性、多层次的。</p>
  <p>上游在设备与材料环节严重受制于人，存在明显的“卡脖子”环节；同时，还面临由国际巨头构筑的严密技术专利壁垒。</p>
  <p>行业具有典型的资本密集型特征，国内企业面临着投资回报周期长、资本成本高于国际同行的压力；在人才方面，则存在从顶尖研发到高端工艺的全面生态短板。</p>
  <p>地缘政治扰动频发，带来了高度的不确定性。</p>
  <p>一个典型案例是，2022年，长江存储被美国列入实体清单，无法购买用于生产128层以上3D NAND闪存的先进制造设备。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e23509730c624a588ed8f9db35181f54@000000_oswg88837oswg930oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">长江存储</p>
  <p>受此影响，长江存储二期工厂原定10万片/月的产能被迫腰斩至4万-5万片。</p>
  <p>这一事件深刻揭示了我国存储芯片产业在迈向高端化过程中所面临的现实困境。</p>
  <p>面对封锁，加速设备国产化成为突破困局的必然选择。</p>
  <p>长江存储迅速与国内半导体设备厂商组成协同攻关体系，从光刻、刻蚀到薄膜沉积、清洗，针对各个关键工艺环节展开设备替代研发。</p>
  <p>至2024年，长江存储生产线的设备国产化率已显著提升至45%，成为中国大陆设备国产化程度最高的晶圆制造厂，展现了在外部高压下加速自主替代的决心与能力。</p>
  <p>本轮存储涨价潮，是挑战，亦是机遇。</p>
  <p>它迫使中国企业正视自身短板，加速技术迭代与效率提升；同时，全球存储产业的格局调整为国产替代提供了历史机遇。</p>
  <p>突围之路没有捷径！</p>
  <p>唯有依靠持之以恒的战略投入、全产业链的协同创新，中国存储产业链才能突围。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MTU3Mzk2OA==&amp;mid=2654916369&amp;idx=1&amp;sn=096c03b1c610e499a4ce3aabf21a6b0c&amp;chksm=bc9e056fc75a97c45260d167224383c71ae938750ad24e21648e06dc104bde22909817dda729&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“正解局”（ID：zhengjieclub）</a>，作者：正解局，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627692646450179</id>
            <title>英伟达自动驾驶新模型来了</title>
            <link>https://www.36kr.com/p/3627692646450179</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627692646450179</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 10:02:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>美东时间周一（5日），英伟达在2026年国际消费电子展（CES）上高调宣传了两大最新科技进步——人形机器人技术以及名为Alpamayo的全新自动驾驶汽车模型系列。</p>
  <p>据公司首席执行官黄仁勋透露，从波士顿动力公司和卡特彼勒公司，再到LG电子和德国机器人公司NEURA Robotics，众多企业都在使用英伟达的机器人技术来开发和驱动其各种机器人。</p>
  <p>英伟达声称，物理人工智能（AI）可以彻底改变规模达50万亿美元的制造业和物流业，而该公司希望成为这一切的核心。在今年CES展会上，英伟达发布了一系列新的AI模型，以帮助训练机器人与周围的世界互动，以及驱动其数字大脑所需的硬件。</p>
  <h2><strong>自动驾驶模型“会推理”</strong></h2>
  <p>除了人形机器人，英伟达重点展示了名为 Alpamayo 的全新自动驾驶汽车模型系列。据该公司称，<strong>Alpamayo采用了一种基于思维链推理的视觉-语言-动作（VLA）模型，旨在加速下一代安全、基于推理的自动驾驶汽车（AV）开发。</strong></p>
  <p>这听起来很复杂。但简单来说，就是<strong>这些模型可以识别在正常驾驶过程中可能不会出现的独特驾驶情况，并找出正确的行驶方式。</strong>例如，当车辆接近十字路口时，该模型可以检测到交通信号灯故障，识别出问题所在，并尝试找出下一步该怎么做。</p>
  <p>黄仁勋介绍称，Alpamayo平台使汽车能够在真实世界中进行“推理”，<strong>首款搭载英伟达技术的汽车将于第一季度在美国上路。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_cc5b7870533947dfb846965cc1a689ba@5888275_oswg214782oswg900oswg1072_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达在一份声明中解释称：</p>
  <blockquote>
   <p>自动驾驶汽车必须在极其广泛的驾驶条件下安全运行。罕见且复杂的场景，通常被称为“长尾”，仍然是自动驾驶系统安全应对的最大挑战之一。传统的自动驾驶架构将感知和规划分离，这会在出现新的或异常情况时限制系统的可扩展性。尽管端到端学习技术的最新进展已取得显著成效，但要克服这些长尾极端情况，需要模型能够安全地进行因果推理，尤其是在情况超出模型训练经验范围时。</p>
  </blockquote>
  <blockquote>
   <p>Alpamayo系列引入了基于推理的VLA模型，将类人思维引入自动驾驶汽车的决策过程。这些系统能够逐步思考新颖或罕见的场景，从而提升驾驶能力和可解释性——这对于增强智能汽车的信任度和安全性至关重要——并且由NVIDIA Halos安全系统提供支持。</p>
  </blockquote>
  <p>黄仁勋说道：“<strong>物理人工智能的ChatGPT时刻已经到来——机器开始理解、推理并在现实世界中行动。</strong>无人驾驶出租车是首批受益者之一。Alpamayo为自动驾驶汽车带来了推理能力，使它们能够思考罕见场景，在复杂环境中安全驾驶并解释其驾驶决策——这是安全、可扩展自动驾驶的基础。”</p>
  <p>与此同时，<strong>英伟达将免费开放Alpamayo模型，允许潜在用户自行对模型进行重新训练。</strong>英伟达表示，这些模型旨在作为“教师大模型，开发者可以对其进行微调，并将其提炼成其完整（自动驾驶）堆栈的骨干”。</p>
  <p>换句话说，Alpamayo的作用是帮助开发者不断改进他们的自动驾驶汽车技术。</p>
  <h2><strong>业界支持</strong></h2>
  <p>英伟达表示，包括 Lucid、捷豹路虎、Uber和Berkeley DeepDrive等车企，都对Alpamayo表现出兴趣，希望开发基于推理的自动驾驶堆栈，以实现L4级自动驾驶。</p>
  <p>Lucid Motors高级驾驶辅助系统和自动驾驶副总裁Kai Stepper表示：“向物理人工智能的转变，凸显了对能够推理现实世界行为（而不仅仅是处理数据）的人工智能系统的日益增长的需求。先进的仿真环境、丰富的数据集和推理模型是这一演进过程中的重要要素。”</p>
  <p>捷豹路虎产品工程执行总监Thomas Müller表示：“开放、透明的人工智能开发对于负责任地推进自动驾驶至关重要。通过开源Alpamayo等模型，英伟达正在帮助加速整个自动驾驶生态系统的创新，为开发者和研究人员提供新的工具，以安全地应对复杂的现实世界场景。”</p>
  <p>Uber全球自动移动出行和配送负责人Sarfraz Maredia表示，“应对长尾和不可预测的驾驶场景是自动驾驶面临的关键挑战之一。Alpamayo为行业创造了令人兴奋的新机遇，可以加速物理AI、提高透明度并增加安全的L4级部署。”</p>
  <p>标普全球高级首席分析师Owen Chen表示：“Alpamayo 1使车辆能够解读复杂环境，预测新情况并做出安全决策，即使在以前从未遇到过的场景中也是如此。该模型的开源特性加速了整个行业的创新，使合作伙伴能够根据自身独特需求调整和改进该技术。”</p>
  <p>Berkeley DeepDrive联合主任Wei Zhan则称，“Alpamayo产品组合的发布对研究界来说是一次重大飞跃。英伟达决定将其开源具有变革性意义，因为其提供的访问权限和功能将使我们能够以前所未有的规模进行训练——这为我们提供了将自动驾驶推向主流所需的灵活性和资源。”</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/go-XRpOOZC-uwifAqchPbw" rel="noopener noreferrer nofollow" target="_blank">“科创日报”</a>，作者：黄君芝，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627692986254600</id>
            <title>今夜无显卡，老黄引爆Rubin时代，6颗芯狂飙5倍算力</title>
            <link>https://www.36kr.com/p/3627692986254600</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627692986254600</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 09:38:03 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>刚刚的CES 2026上，老黄带着Vera Rubin超算架构向全世界走来！Rubin的推理性能比Blackwell提升了5倍，训练性能提升3.5倍，成本降低10倍，已经大规模投产，将于2026下半年面世。没有新显卡的昨夜，老黄表示all in AI！</strong></p>
  <p>天空一声巨响，全新版本的「皮衣老黄」闪亮登场。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_190b915e8eb14d339210ad1115dc76fc@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在本次CES演讲中最为激动人心的瞬间，就是英伟达全新一代芯片架构——Vera Rubin正式登场！</p>
  <p>全球AI算力告急？老黄霸气回应：Vera Rubin已全面投产。</p>
  <p>这是新一代的算力怪兽，也是对上一代霸主Blackwell的降维打击——</p>
  <p>推理Token成本直接暴降10倍，算力性能狂飙5倍。</p>
  <p>就连训练MoE模型所需的GPU数量，也直接减少了4倍。</p>
  <p>曾经，Blackwell终结了Hopper；如今，Rubin亲手埋葬了Blackwell。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_12e99b558d4c4afcaba2216248257587@5888275_oswg631106oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>全程近两小时演讲，老黄提及重点包括——</p>
  <p>下一代Rubin平台亮相：六颗芯片，推理狂飙十倍</p>
  <p>自动驾驶端到端模型：AlphaMayo会思考、自主推理，全程0接管上路</p>
  <p>物理AI全家桶开源：基础模型、框架</p>
  <p><strong>玩家彻夜难眠：CES 2026，没有显卡</strong></p>
  <p>至于游戏玩家？</p>
  <p>对不起，这次真的没有新显卡。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_1427d1b842e84fcb968f2b970ab6fa52@5888275_oswg40269oswg729oswg248_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达在X上的一纸公告，彻底击碎了「攒机党」最后的幻想：<strong>CES 2026将没有任何新GPU发布。</strong></p>
  <p>这意味着，英伟达自2021年以来连续五年在CES发布新硬件的传统，就此终结。</p>
  <p>传闻已久的RTX 50 Super系列，受困于GDDR7显存的「产能地狱」，大概率已经胎死腹中。</p>
  <h2><strong>Rubin炸裂登场，6颗芯片，10倍推理，AI超算变工厂</strong></h2>
  <p>去年10月，老黄曾预计：未来五年，将有3到4万亿美元砸向AI基础设施。</p>
  <p>Vera Rubin的大规模投产，可谓生逢其时。</p>
  <p>如果说Blackwell打破了单卡性能的极限，那么Rubin解决的则是<strong>系统规模化</strong>的难题。</p>
  <p>从此，算力将像电力一样廉价，AI的大爆发已近在咫尺！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_89196b489c0b4cbc8f599f99419fba74@5888275_oswg240139oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2024年，Vera Rubin架构首次亮相。</p>
  <p>等了两年，现在它终于正式投产了！</p>
  <p>Blackwell架构，从此将退出历史舞台。</p>
  <p>演讲现场，老黄告诉大家：AI所需的计算量急剧飙升，怎么办？不用怕，Vera Rubin，将解决我们面临的根本性挑战！</p>
  <p>这套为万亿参数模型的海量推理而生的平台，会彻底让算力低成本、规模化、工业化生产。</p>
  <p>Rubin架构，以天文学家Vera Florence Cooper Rubin而命名。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d08a9cd6958440508d9738e271605242@5888275_oswg259660oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>可以说，Rubin是英伟达第一次把CPU、GPU、网络、存储、安全，当成一个整体来设计。</p>
  <p>核心思路就是：不再「堆卡」，而是把整个数据中心变成一台AI超算。</p>
  <p>整个Rubin平台，由这6个关键组件构成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2e870e641ade407ca56e992a9c3784a7@5888275_oswg42020oswg1080oswg536_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2176780191834f29ba99021cd4c62c64@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其中，Rubin GPU是整个平台的核心。它搭载第三代Transformer引擎，为AI推理提供50 PFLOPS的NVFP4算力。</p>
  <p>之所以能达到Blackwell GPU性能的5倍，是因为它的NVFP4张量核心，后者能分析Transformer各层的计算特性，动态调整数据精度与计算路径。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_c0ffc3402cb84f1ebc3d386364057ee7@5888275_oswg299959oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另外，该架构还引入一颗全新的Vera CPU，专为智能体推理而设计。</p>
  <p>它采用88个英伟达自研Olympus核心，完全兼容Armv9.2，并具备超快的NVLink-C2C 连接，能实现176个线程的全性能执行，I/O带宽和能效比直接翻倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_0aa2b893e7c2462ca3d04f1fb602b4fe@5888275_oswg247939oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当我们在Agentic AI或长期任务中启用全新的工作流时，会对KV cache造成很大压力。</p>
  <p>为了解决存储和互联的瓶颈，Rubin架构特别改进了Bluefield和NVLink系统。它通过外部方式和计算设备相连，这样就能更高效地扩展整体存储池的规模。</p>
  <p>BlueField-4 DPU是一个数据处理单元，它能卸载网络、存储和安全任务，还能管理AI的上下文记忆系统。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_3fa4f258c1b049efaf742866b4c5dcc9@5888275_oswg255338oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>NVLink 6中，单芯片就能提供每秒400Gb的交换能力。每块GPU提供3.6TB/s 的带宽，而Rubin NVL72机架提供260TB/s，带宽超过整个互联网。</p>
  <p>通过3.6 TB/s的带宽和网络内计算能力，它能让Rubin中的72个GPU像一个超级GPU一样协同工作，直接把推理成本打至1/7。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_612e2ae97cb64f19862410e27660266f@5888275_oswg309536oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>现场，老黄给我们展示了Vera Rubin的托盘。小小的托盘上集成了2颗Vera CPU、4颗Rubin GPU、1颗BlueField-4 DPU和8颗ConnectX-9网卡，整个计算单元算力达到100 PetaFLOPS。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e916770341ec4fe9833d65b7a5338347@5888275_oswg331268oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_bc3e2f932b5e4d8689e6b79af73d9941@5888275_oswg343065oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Rubin的目标，是解决MoE和万亿参数模型的训练成本，它做到了吗？显然，成果是显著的。</p>
  <h3><strong>训练、推理效率暴增</strong></h3>
  <p>测试结果显示，Rubin架构训练模型时的运行速度，直接达到上一代Blackwell架构的3.5倍（35 petaflops），推理任务的速度则高达5倍，最高可达50 petaflops！</p>
  <p>同时，它的HBM4内存带宽提升至22 TB/s，达到2.8倍，单GPU的NVLink互连带宽则翻倍到3.6 TB/s。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4ac16becc1154dc0991c7c4a1bd15fcd@5888275_oswg150775oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在超大规模MoE训练中，Rubin所需的GPU数量相比Blackwell可减少至1/4，同时整体能耗显著下降。</p>
  <p>这背后，就有三大功臣。</p>
  <p>NVLink 6，让GPU间互联带宽再次大幅提升，多卡训练不再被通信拖慢；Vera CPU与Rubin GPU的协同调度，可以减少「GPU等数据」的空转时间；而ConnectX-9与Spectrum-6的深度协同，也让大模型训练不会再被集群规模限制。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b8e738d4923047ac9f7d3dcfc6ab0ef1@5888275_oswg264544oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_a4b31cd9600e460cb6d93b2b1ea666fa@5888275_oswg350312oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从此，训练万亿模型，不再是「堆钱」，只会是工程问题。</p>
  <p>训练解决了，那推理呢？</p>
  <p>结果显示，在推理侧，Rubin平台单位token的推理效率提升最高可达10倍！同样的模型和响应延迟，算力成本可以直接下降到原来的1/10。</p>
  <p>所以，模型可以跑得起百万token的长下文，企业级AI应用也可以部署了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_155c7529d5c94795b90b8d049403781b@5888275_oswg275886oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_35bebb524c4a417bbb8f5c772b290127@5888275_oswg194791oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>存储瓶颈解决</strong></h3>
  <p>如上文所言，让AI模型多跑一会的关键挑战，就在于上下文数据。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_87946981c3f947a6a3d579196a3c38b2@5888275_oswg157534oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>大量KV Cache该如何处理？英伟达推出了由BlueField-4驱动的推理上下文内存存储平台。</p>
  <p>这个平台在GPU内存和传统存储之间创建了「第三层」，直接让每秒处理的 token数提升高达5倍。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_328c8d4a826c47e0bc731557a9b80159@5888275_oswg300845oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>DGX Super POD</strong></h3>
  <p>本次CES上，英伟达还推出了新一代DGX SuperPOD。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_1be341a707ac48db9495cadc2f5a8e0b@5888275_oswg325879oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>它把多个装有72个GPU的Rubin NVL72连接起来，形成了更大的AI计算集群。</p>
  <p>在这次的DGX SuperPOD中，共有8个Rubin NVL72机架，相当于有576个GPU。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f38b8e39a65e4210b2beec7e5c157457@5888275_oswg150775oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>NVIDIA Vera Rubin NVL72 提供统一、安全的系统，集成了72 块Rubin GPU、36块Vera CPU、NVLink 6、ConnectX-9 SuperNICs和BlueField-4 DPUs</p>
  <p>这样，SuperPOD就可以处理数千个Agentic AI智能体，以及数百万token上下文。</p>
  <p>可以说，英伟达一次性解决了数百个GPU相连、管理存储的问题，直接给我们提供了开箱即用的AI基础设施。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_5e4d1632adea47318318d090a3da582e@5888275_oswg449104oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_bb1cdcafee78429190d8736315533e33@5888275_oswg104389oswg656oswg1661_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>第三代机密计算平台</strong></h3>
  <p>更为重要的是，Rubin是首个支持第三代机密计算（Confidential Computing）的AI超算平台。</p>
  <p>模型参数、推理数据、用户请求都会被全链路加密，即使的云厂商，也无法直接访问明文数据。</p>
  <p>这就解决了「敢不敢把核心AI放到云上」的问题，对于金融、医疗、政府、企业私有模型都非常重要。</p>
  <h3><strong>这些大厂，第一批用上Rubin</strong></h3>
  <p>老黄介绍说，Rubin会由AWS、Microsoft Azure、Google Cloud、Meta、OpenAI这些头部厂商先部署。</p>
  <p>而到2026年下半年，Rubin平台就会进入大规模商用阶段。</p>
  <p>所以，下一代GPT、Gemini、Claude模型，大概率都会运行在Rubin架构上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_beed34bf711a4a46ac2df5f098903cf2@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>全程0接管，自动驾驶AI「会思考」</strong></h2>
  <p>如何教会AI物理学的基础事实？</p>
  <p>英伟达给出的答案是，把算力变成高质量的数据（Compute is Data）。</p>
  <p>在这一体系中，「世界基础模型」Cosmos扮演着重要的角色。</p>
  <p>交通模拟器输出的信号，被送入Cosmos再生成合理、运动上连贯的环绕视频，让AI学习其中真实世界的行为模式。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f568a43286d34ff68db71266a1f5b19a@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如今，Cosmos已被全球下载数百万次，成为物理AI时代的重要基础设施。在英伟达，内部也在用其做自动驾驶研究。</p>
  <p>在此基础上，今天，英伟达正式发布了「端到端」自动驾驶AI——AlphaMayo。</p>
  <p>它是一个会思考、会推理的自动驾驶AI。从摄像头输入到车辆执行动作，全流程由模型完成。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d41b51d230244c27988d95a97e8f9e0c@5888275_oswg352789oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AlphaMayo独特之处，在于它具备了显式推理能力。</p>
  <p>系统不仅执行转向、制动、加速动作，还会给出即将采取行动的理由，以及对应的形式轨迹。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d77157efea32473fb2931603879f092a@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>自动驾驶最大挑战，来自于「长尾场景」，几乎不可能覆盖所有国家、所有道路的数据。</p>
  <p>AlphaMayo的策略是将复杂场景，拆解为多个熟悉的物理与交通子问题，通过推理将罕见情况分解为常见组合，完成应对。</p>
  <p>在演示中，车辆可以在全程0接管状态下，完成路径规划与行驶，顺利抵达目的地。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_1028996ffafd4ac4961d3e4d9016d01b@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在自动驾驶领域，英伟达投入持续了八年，如今第一次把AI「五层架构」完整跑通。</p>
  <p>由下到上：实体本身、芯片体系、模型层、基础设施层、应用层，构成了一套完全贯通的AI系统栈。</p>
  <p>AlphaMayo构成模型层，梅赛德斯-奔驰汽车构成应用层。</p>
  <p>这一次，老黄还官宣了，NVIDIA DRIVE AV软件首次搭载全新梅赛德斯-奔驰 CLA，提供L2级端到端驾驶。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_a6a8d460b66c44e89109a4d47b4029f8@5888275_oswg233389oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更重磅的是，Alpamayo家族全部开源。这一整套方法论，并不只适用于汽车，同样适用于机器人、机械臂等各类系统。</p>
  <h2><strong>全家桶开源，机器人ChatGPT时刻</strong></h2>
  <p>下一阶段，机器人将以各种形态进入现实世界，前提是，它们首先在Omniverse中学会如何行动。</p>
  <p>现场，老黄又召唤来了机器人瓦力登台配合演出，这里他讲了一句意味深长的话：</p>
  <p>未来的系统，都诞生在计算机里。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_6d91b6532503416492983806809da35d@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达正把自身能力嵌入到，计算密度最高、最复杂的工业体系统，就像此前与Palantir、ServiceNow的集成一样。</p>
  <p>如今，这一模式正被复制到了工业仿真与设计领域。</p>
  <p>在具身智能领域，老黄直接扔下了一套针对物理AI（Physical AI）的「开源全家桶」——模型、框架及基础设施，应有尽有。</p>
  <p>机器人的ChatGPT时刻已经到来！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_df7e11832b394a4399c527b88f5c614b@5888275_oswg469625oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，所有新模型均已上线Hugging Face，拿来即用：</p>
  <p>NVIDIA Cosmos Transfer/Predict 2.5，这是完全可定制的世界模型，专门在虚拟世界里生成符合物理规律的数据，训练机器人的大脑。</p>
  <p>NVIDIA Cosmos Reason 2，让机器像人一样「看懂」世界并进行逻辑推理。</p>
  <p>NVIDIA Isaac GR00T N1.6，专为人形机器人打造，解锁全身控制，让机器人不再四肢僵硬。</p>
  <p>为了解决机器人开发中「各自为战」的痛点，英伟达发布了两大神器：</p>
  <p>Isaac Lab-Arena：这是GitHub上的开源框架，连接了主流基准测试，确保机器人在进厂打工前，已经在虚拟世界里经过了千锤百炼。</p>
  <p>NVIDIA OSMO：无论是在工作站还是混合云，它都能统一调度数据生成、模型训练和测试，大幅缩短开发周期。</p>
  <p>机器人技术已是Hugging Face上增长最快的领域。英伟达这次不仅是提供模型，更是深度集成：</p>
  <p>LeRobot集成：Isaac和GR00T技术直接通过LeRobot框架即可调用。</p>
  <p>硬件互通：Hugging Face的开源机器人Reachy 2和Reachy Mini现已完美适配英伟达的Jetson平台，语音、视觉、大模型能力瞬间拉满。</p>
  <p>软件强还不够，硬件必须硬。如今，全新的Jetson T4000模组，直接将Blackwell架构带到了边缘端：</p>
  <p>算力高达1200 FP4 TFLOPS，是上一代的4倍。</p>
  <p>1000台起订单价仅1999美元。</p>
  <p>70瓦功耗，简直是为能源受限的自主设备量身定做。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_831be3098d8a43cd92baee0cd4b86e21@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>老黄震撼预言，未来所有应用，建在AI之上</strong></h2>
  <p>每隔10-15年，计算产业就会重来一次。</p>
  <p>演讲伊始，老黄还回顾了计算产业过去数十年的演进路径——</p>
  <p>从大型机到CP，到互联网、云计算，再到移动计算，每一次平台级跃迁，都会催生一整套全新的应用生态，软件开发方式也随之重构。</p>
  <p>而这一次，变化来得更加猛烈。</p>
  <p>他提到，当前产业正同时经历两次平台级转变：一是从传统计算走向AI，另一个是整个软件、硬件栈的底层重塑。</p>
  <p>AI正成为全新的「底座」，应用开始建立在AI之上。同时，软件开发与运行方式、应用生成方式发生了根本性变化。</p>
  <p>这一切，共同推动了「加速计算+AI」对整个计算体系的重塑，五个层级正在同时被重新发明。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_bd180a5ef1594b3a830dc75afaa8a711@5888275_oswg285052oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2022年ChatGPT爆发后，AI才真正走进大众视野。一年之后，推理模型首次登场，引入了「测试时Scaling」这一概念。</p>
  <p>模型不仅在训练阶段学习，还在推理阶段实时计算和推演。预训练、RL、推理这些阶段，都需要机器庞大的计算资源，也同时推动模型能力持续提升。</p>
  <p>2024年，另一项突破开始显现，直到2025年，智能体系统（Agentic AI）才迅速扩散开来。</p>
  <p>老黄再次提及，在英伟达内部，像Cursor这样的Agentic工具已深刻改变了软件的开发方式。</p>
  <p>智能体AI之后，下一个前沿便是物理AI（Physical AI），理解自然规律和物理法则，为AI打开了全新疆域。</p>
  <p>除此之外，过去一年，另一个具有决定性意义的变化来自「开源模型」。</p>
  <p>DeepSeek R1的出现，作为首批开源推理模型之一，给行业带起来巨大震动。</p>
  <p>但不可否认的是，其仍比前沿模型落后六个月。每隔半年，就有新模型涌现，而且越来越智能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_b604c681ac4b42e38da3103d8c0f08a4@5888275_oswg180148oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_dcb94a8b1ae04d9e8321e9e1361c9cd5@5888275_oswg100380oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达，正引领着开源模型的生态，遍布多个领域。而且，在多个榜单上取得了亮眼的成绩。</p>
  <p>最具代表性的包括多模态Nemotron 3、世界模型Cosmos、机器人模型GR00T、蛋白预测模型OpenFold 3......</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9502e12e200e42ccad6c277c530756c3@5888275_oswg287084oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2ca073b2210d43bcac610f0d0e2c47cb@5888275_oswg351308oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>老黄现场表示，以上一切成果，都为构建AI智能体服务，这是真正突破性的发展领域。</p>
  <p>当前AI模型已变得极其强大，智能体的推理能力为各类应用开启了大门。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4e440ef4e9484131bafb712f692d33df@5888275_oswg190313oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>令老黄深感震惊的是，首次在Perplexity见证了其同时调用多个模型——AI在推理任何环节，直接调用最顶尖的模型。</p>
  <p>这背后本质上是「多云协同」，同时还具备了混合云特性。</p>
  <p>老黄明确地表示，这就是未来AI应用的基本形态。或者说，因为未来应用都构建在AI之上，这就是未来应用的基础框架。</p>
  <p>一方面，AI可以被深度定制。另一方面，系统始终保持最前沿。「定制+前沿」能力在同一架构中同时存在。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_05a2784df1df4665b8ac14646819f98d@5888275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在软件世界之外，更大挑战来自于现实世界。为此，物理AI需要三台计算机——</p>
  <p>第一台计算机：用于训练模型</p>
  <p>第二台计算机：用于推理，运行咋i汽车、机器人、工厂等边缘环境</p>
  <p>第三台计算机：专门用于仿真、模拟</p>
  <p>老黄提到，仿真是整个体系的核心，只有在可控的数字环境中，AI才能反复尝试、评估行为后果，并逐步建立对世界的理解。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9e45176c9be047a4910848b4af5d1f79@5888275_oswg289386oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>彩蛋</strong></h2>
  <p>演讲最后还有一个幕后花絮，DGX Station台式AI超算将在2026年春季上线。</p>
  <p>届时，英伟达还将同步推出更多针对GB300系统的实战手册（Playbooks）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_c595e31682c54812b95aa5576ba0d4a5@5888275_oswg331761oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>如果说DGX Spark是开发者的入门首选，那么DGX Station就是一台放在你办公桌上的微型数据中心：</p>
  <p>搭载<strong>GB300 Grace Blackwell Ultra</strong>超级芯片。</p>
  <p>配备高达<strong>775GB</strong>的FP4精度一致性内存（Coherent Memory）。</p>
  <p>拥有Petaflop级AI算力，支持在本地运行高达<strong>1万亿（1T）参数</strong>的超大规模模型。</p>
  <p>得益于强大的硬件基础，DGX Station实测威力惊人：</p>
  <p>LLM预训练速度高达<strong>250,000 Token/秒</strong>。</p>
  <p>支持对数百万数据点进行聚类和大型可视化。</p>
  <p>从DeepSeek R1的开源震动，到Agentic AI的全面爆发，计算产业正在经历一场前所未有的重塑。</p>
  <p>在这个只有玩家落泪的早上，一个由物理AI驱动的全新世界，正在Vera Rubin的轰鸣声中，加速向我们走来。</p>
  <p>参考资料：HYZ&nbsp;</p>
  <p>https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer&nbsp;</p>
  <p>https://www.nvidia.com/en-gb/data-center/vera-rubin-nvl72/&nbsp;</p>
  <p>https://blogs.nvidia.com/blog/dgx-superpod-rubin/&nbsp;</p>
  <p>https://www.nvidia.com/en-us/events/ces/&nbsp;</p>
  <p>https://youtu.be/0NBILspM4c4&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/EprbrMBArltI_YUhNqrY5A" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627692432950280</id>
            <title>上海剑指“世界eVTOL之都”</title>
            <link>https://www.36kr.com/p/3627692432950280</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627692432950280</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 09:36:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上海对低空经济的表态，正在从方向性布局走向产业化兑现。</p>
  <p>近日，上海市经济和信息化委员会等部门联合印发《上海市关于链接长三角加快建设低空经济先进制造业集群的若干措施》（下称《若干措施》），首次以先进制造业集群的方式，对低空经济提出清晰的阶段性目标：到2028年，上海低空经济核心产业规模达到800亿元左右，形成低空新型航空器完整产业链体系，建设低空经济国家先进制造业集群，加快迈向比较优势凸显的“世界eVTOL之都”。</p>
  <p>这是继2024年上海系统部署低空经济发展路线图之后，又一份更具“产业落地指向”的政策文件。多位业内人士认为，新政标志着上海低空经济正从“规划期”和“概念期”，加速迈入以制造能力和商业化为核心的实质推进阶段。</p>
  <h2><strong>先进制造业集群框架成型</strong></h2>
  <p>本次上海低空新政，并非一次孤立的政策发布。</p>
  <p>2024年7月，上海曾发布《上海市低空经济产业高质量发展行动方案（2024-2027年）》，从产业定位、发展路径和重点方向上，为上海低空经济画出一张“路线图”。彼时，政策更多回答的是：上海为什么要做低空经济、重点做什么。</p>
  <p>而此次出台的《若干措施》，则更像是对上述行动方案的补充，直接指向制造能力、企业梯队、应用场景和区域协同等核心问题。</p>
  <p>“这次新政是为了支撑行动方案出的产业配套扶持政策，eVTOL之都的目标明确了。对上海低空企业是实打实的利好，满足条件的企业都可以去申报。”御风未来相关负责人表示。</p>
  <p>在时的科技创始合伙人蒋俊看来，上海市本次关于低空经济先进制造业集群的《若干措施》的发布，是继中央十五五规划后，又一重大举措。“给我们低空经济企业的发展注入了‘强心针’。每一条措施都体现了政府把产业的发展阶段研究的透彻，不同阶段能够得到对应的产业支持。“</p>
  <p>蒋俊表示，上海乃至长三角地区具备建设“世界eVTOL之都”的显著产业优势。其核心在于依托雄厚的航空产业与先进制造基础，以及丰富的人才优势，上海已汇聚了中国大部分头部主机厂，并引领全国50%的相关头部企业在此集聚。在此坚实基础上，区域协同优势正在不断得到强化。上海市也正在构建技术攻关、产业链配套和基础设施共享的高效网络。</p>
  <h2><strong>制造端前置，整机能力量化</strong></h2>
  <p>从内容来看，《若干措施》围绕低空经济先进制造业集群建设，提出了三方面重点任务。</p>
  <p>在提升高端制造能级方面，上海给出了明确的量化指标。</p>
  <p>按照《若干措施》，上海将瞄准eVTOL、工业级无人机、新能源通航飞机等主流技术方向，培育和招引10家整机领军企业，形成超过500架新型航空器的批量化制造能力，并带动产业链实现新增投资200亿元以上。</p>
  <p>这组数字背后，指向的是低空经济发展过程中一个绕不开的现实问题：制造规模和产业化能力。</p>
  <p>过去几年，国内低空经济更多停留在技术验证和样机阶段，企业数量不少，但真正具备持续交付能力、可以向规模化制造迈进的整机厂商并不多。相比之下，上海在高端制造、工业体系完整性方面具备基础，但在低空新型航空器领域，仍需要通过政策牵引加快“补课”。</p>
  <p>此次政策明确将“整机领军企业”和“批量化制造能力”作为核心指标，也被视为上海对低空经济产业成熟度判断发生变化的重要信号。</p>
  <p>相比制造端的量化目标，《若干措施》在第二个层面，更强调体系能力的构建。政策强调放大区域协同优势，通过市区联动、与长三角城市协作，在产业链分工、制造配套和产能协同方面形成更大合力。</p>
  <p>政策提出，将强化市区协同和长三角联动，基本建成1个国家级低空新型航空器中试验证平台，并重点推动低空智慧物流、公共治理、生产作业等应用场景，构筑从研发制造到中试适航、再到场景应用和生态融合的核心竞争力。</p>
  <p>蒋俊告诉《科创板日报》记者，长三角地区集聚了全国最完整、最成熟的航空产业体系和高端制造基础，是我国发展低空经济最具综合优势的区域之一。此次政策明确提出“建设低空经济长三角协同高地”，为企业在更大范围内整合资源、优化布局、提升效率提供了制度保障和发展空间，也为低空经济企业深化区域协同发展带来了实质性利好。以时的科技为例，依托上海在科技创新、产业组织和制度供给方面的核心引领作用，时的科技已深度融入长三角航空产业生态。</p>
  <p>在供应链端，公司与区域内中航机载等航空领域龙头企业建立了战略合作关系，在飞控、航电、配电系统等方面深度合作。与华模科技围绕eVTOL领域的模拟装备研发、训练体系建设及海外市场拓展三大核心方向展开深度协同，共同推动eVTOL产业商业化运营体系的完善。在材料端，充分利用长三角领先的碳纤维复合材料产业集群优势，为eVTOL产品实现高强度、轻量化结构提供了有力支撑。</p>
  <p>总体来看，“以上海为创新策源和产业统筹中心、长三角区域协同制造与配套支撑”的发展模式，正是对政策中“建设长三角低空经济协同高地”的积极实践。同时，通过长三角协同，上海也在试图解决低空经济天然具有的跨区域属性问题——制造、试飞、应用场景并不一定集中在一个区域完成。</p>
  <h2><strong>真金白银落到研发和取证</strong></h2>
  <p>从企业端的反馈来看，此次新政最直观的变化，在于对研发和取证环节的资金支持更加明确。</p>
  <p>御风未来认为，政策明确了对研发、取证等环节的真金白银支持，直接降低了创新型中小企业在前沿技术攻关和市场验证阶段的现金流压力和试错成本，标志着上海低空行业从“概念与规划期”正式迈入“规模化落地与商业突破期”。</p>
  <p>在业内看来，中试和适航环节投入大、周期长、风险高，是低空经济企业最难独立承担的阶段。地方政府通过政策介入这一环节，本质上是在为企业“分担风险”，加快技术从实验室走向市场的节奏。</p>
  <p>从全国层面看，低空经济已连续两年被写入重要政策文件，地方政府的行动也在明显加速。2024年以来，多地围绕空域管理、应用场景和产业集群展开竞争，而上海的特点在于，始终将低空经济放在先进制造业和未来产业体系中统筹推进。</p>
  <p>资本市场的关注度同样在抬升。2025年6月，中国证监会发布实施《关于在科创板设置科创成长层 增强制度包容性适应性的意见》。意见明确，扩大第五套标准适用范围，支持人工智能、商业航天、低空经济等更多前沿科技领域企业适用科创板第五套上市标准。</p>
  <p>蒋俊告诉《科创板日报》记者，公司正持续推进适航工作，将继续推进全机系统级试验、材料与部件验证试验，完成更多适航验证工作。</p>
  <p>加快公司上海的总部基地和制造基地的选址工作，落实进博会期间与市区两级政府签约的战略合作协议，真正的实现研发、制造、交付都在上海一体化实现。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/AV5ncNX1dHGtAkTTt5mD1Q" rel="noopener noreferrer nofollow" target="_blank">“科创日报”</a>，作者：张洋洋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627665741677569</id>
            <title>不止昆仑芯，李彦宏最该放权的还有萝卜快跑</title>
            <link>https://www.36kr.com/p/3627665741677569</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627665741677569</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 09:33:21 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>1月2日，百度公告称，旗下AI芯片业务主体昆仑芯科技有限公司已于1月1日通过联席保荐人，以保密形式向香港联合交易所提交上市申请表格（A1表格），拟申请昆仑芯股份在港交所主板上市及交易。</p>
  <p><strong>消息一出，百度的（港股）股价就跟着库库往上涨，当天涨幅甚至达到了9.35%！</strong></p>
  <p>为什么资本市场这么兴奋?</p>
  <p>原因有很多，但最直接的一个理由是：</p>
  <blockquote>
   <p>从寒武纪爆发到摩尔线程起飞，再到沐曦股份爆火，现在国内行情几乎已经到了沾芯片就是牛股的“夸张”地步。那么作为出货量国产第二的昆仑芯，是不是也非常值得期待呢？</p>
  </blockquote>
  <p>只不过如此一来，这也让很多人不禁好奇：</p>
  <p>百度另一个最靓的仔——<strong>萝卜快跑，会不会也走上这条分拆独立上市之路？</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_44eec3344aec4c8797d197f1d473bb5e@000000_oswg83189oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>毕竟，作为自动驾驶出行服务的标杆，萝卜快跑同样备受外界市场的关注和估值认可。</p>
  <p>百度发布的2025年第三季度财报电话会上，李彦宏透露，<strong>萝卜快跑已有少数城市的该业务实现正向单位经济效益，预计2026年将有更多城市达成这一目标</strong>。截至2025年10月，萝卜快跑已进入全球 22 座城市，在欧洲、中东地区及中国香港市场均取得重大进展。截至11月，<strong>累计服务订单量超 1700 万单，这一成绩在全球范围内都屈指可数。</strong></p>
  <p>再加上作为初创企业的小马智行，文远知行们已经先一步完成了上市，并在资本市场上获得了充足的战略弹药……</p>
  <p>那么作为robotaxi领域的领头羊，萝卜快跑好像也确实不应该缺席这样一个，向上冲击更大市场想象力的机会？</p>
  <h2><strong>分拆、独立，百度价值回归的开始</strong></h2>
  <p>从昆仑芯开始，为什么有人会建议萝卜快跑也分拆独立？</p>
  <p>我们大胆假设、小心求证，可能有三个原因：</p>
  <p><strong>分拆原因一：从市值维度看，现在百度值多少钱？我们不妨先用STOP法来估算一下。</strong></p>
  <p>天眼查APP显示，百度的业务分为几大块：一是在线营销业务：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4c0bef55b5a1457b845e44ec593f6fdf@000000_oswg53753oswg1080oswg581_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>考虑到AI转型影响，假设2025年广告收入约635亿元，净利润率25%，以保守的5倍市盈率计算，<strong>核心广告业务保守估值114亿美元。</strong></p>
  <p>二是AI云业务：</p>
  <p>云业务方面，增速一直都不错。据申万宏源发布研报指出，百度智能云业务2025年前三季度营收193.3亿元，同比增长31%。预估2025年收入260亿元，约合37亿美元。按照此前华泰研报给出的7倍市销率计算，<strong>AI云业务的大概估值为259亿美元。</strong></p>
  <p>三是自动驾驶业务：虽然没详细数据，但根据营运订单规模，我们保守估计萝卜快跑2025年收入20亿元，约2.8亿美元。参考此前华泰、摩根大通的估值，按照25倍市销率计算，对应估值为70亿美元。</p>
  <p>当然，如果按照海外研究机构TD Cowen预测Waymo的750亿美元估值，那么萝卜快跑成本更低，给到400亿美元也不为过。</p>
  <p>四是芯片业务方面：假设2025年收入预期与寒武纪相当，如果给予市销率20倍，以9亿美元的营收计算，保守估值在180亿美元。</p>
  <p>爱奇艺约40亿美元营收，1倍市销率，与其他业务估值之和约80亿美元。</p>
  <p>此外，百度账上至少还有超过178亿美元的现金及短期投资额。</p>
  <p><strong>所以保守计算，百度的合理估值线应该在881亿美元往上。但截止2026年1月5日收盘，百度美股市值却仅为514.56亿美元，整体依然处于被严重低估状态……</strong></p>
  <p>为什么理想和现实会差这么多？</p>
  <p>主要是在实际判断中，<strong>百度的不少创新业务，其实都被当成了“负估值”表现。</strong></p>
  <p>比如昆仑芯，在此前没有崭露头角的时候，芯片市场的客观情况就是发展周期长，投入规模大，且未来还有很多不确定性因素。</p>
  <p>所以彼时，<strong>这种创新业务带来的就不是投资想象力，而是实实在在的资产负担。</strong></p>
  <p><strong>相同的处境，还发生在百度的云、自动驾驶等业务板块。</strong></p>
  <p>这也使得百度的资本叙事逻辑，一度陷入了“传统业务估值压制+前沿业务价值折损”的矛盾局面。</p>
  <p>但如果分拆就不同了：<strong>一方面无论是昆仑芯还是萝卜快跑，分拆上市就可以把业务潜在波动风险与百度集团整体进行切割，从而避免局部利空持续影响集团系统性估值</strong>；</p>
  <p><strong>另一方面昆仑芯们独立后，资本市场也能用科技企业估值框架重新定价，这就可以规避百度传统广告业务放缓对整体估值的拖累……</strong></p>
  <p>所以这个角度看，<strong>昆仑芯和萝卜快跑们分拆，本质上是为了让百度更好地实现价值回归，让合则一盘散沙的局面，变成分则雄踞一方的全新故事。</strong></p>
  <p><strong>分拆原因二：</strong></p>
  <p><strong>从过去百度的业务发展历程看，分拆独立也是一件被验证过的、利大于弊的事儿。</strong></p>
  <p>先说正面案例：比如度小满，2018年，百度宣布旗下金融服务事业群组正式完成拆分融资协议签署，拆分后百度金融将启用全新品牌“度小满”，实现独立运营。</p>
  <p>如今八年过去了，分拆后的度小满不仅活得不错，甚至在国内信贷业务规模还仅次于蚂蚁等头部梯队，合作银行机构超百家，保险机构超三十余家……</p>
  <p>又比如“作业帮”，2015年，百度曾提出了一个“航母计划”，旨在剥离包括百度外卖、作业帮、百度音乐在内的众多资产。</p>
  <p>作业帮在彼时独立，然后在外部融资的支持下，很快就开启了从单一工具向综合教育平台的转型，最终赶上后来的K12教育市场爆发……</p>
  <p>再来看悲剧案例：最典型的就是小度科技，在独立之初，“小度之父”景鲲就曾表示，<strong>小度是真正TO C的AI公司，独立是成体系的一个操作和思路。</strong></p>
  <p>但后来，或许是在对推动小度融合文心一言能力的速度上，景鲲选择了持谨慎态度，而和当时追求快速落地的百度高层意见相左，最终景鲲选择了离职。</p>
  <p>结果很快，小度科技就用市场份额的下滑、掉队，向外界证明了谁对谁错。</p>
  <p>这让很多人都惋惜道，<strong>如果当时百度愿意给景鲲足够的独立性，那么现在小度会不会就是第二个阿里夸克了？</strong></p>
  <p>此外还有百度健康，2021年，市场曾盛传百度健康正在需求独立融资，甚至是IPO，估值一度喊到了300亿美元。</p>
  <p>但直到今天，百度健康不仅没有走出自己的独立路线，甚至就连市场存在感也都所剩无几了。</p>
  <p>正是有着这些前车之鉴，所以，作为“后车之师”的昆仑芯和萝卜快跑们也不能不对独立重视起来……</p>
  <p><strong>分拆原因三：去大公司病。</strong></p>
  <p>不可否认，现在很多互联网公司都或多或少地存在一些大公司病，包括但不限于“划地盘、设门槛，各自为战协同难”“向上哄好、向下唬住，加班彰显工作态度”“上级沟通全靠下级传话，结果烂尾还说漂亮话”……</p>
  <p>对于这一点，业务分拆实际上也是一种治疗方法。</p>
  <p>毕竟，<strong>它意味着砸破大锅饭，也意味着更多的功劳簿</strong>，上下各级都可以靠自己去选择未来命运。</p>
  <p>这对正处在市场上升期的昆仑芯、萝卜快跑们来说，无异于一次生产力和生产关系的大解放。</p>
  <h2><strong>萝卜快跑，驶入“分拆独立”的快车道？</strong></h2>
  <p>其实顺着逻辑看，现在萝卜快跑也确实应该和昆仑芯一样，共同分拆独立上市。</p>
  <p>一是前边提到的小马、文远们都已经上市，并且受到了资本们的追捧。</p>
  <p>而萝卜快跑比他们都强，整体能力也更胜一筹，但却迟迟不见太多动静，这不免有点打击士气……</p>
  <p>二是从短期来看，<strong>分拆后，萝卜快跑就可以掌握决策独立性，这在自动驾驶技术快速迭代的竞争中至关重要，不仅有助于抢占关键时间窗口，更能够通过股权激励等方式吸引顶尖人才，构建出更稳固的技术护城河。</strong></p>
  <p>或许正因如此，早在2016年，<strong>谷歌的Waymo就实现了独立。</strong></p>
  <p>反观之，<strong>现在百度apollo官网上甚至还停留着已经倒闭的、极越品牌的合作展示。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_61510e7bdbe84719a89288496cab7cc4@000000_oswg25023oswg1080oswg444_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这种不上心的表现，也引得部分投资者吐槽：现在萝卜快跑就缺一个更有独立积极性的组织团队，或者说一种激励方式，不然（萝卜快跑）实际上还能做到更好……</p>
  <p>此外从长远竞争看，<strong>现在萝卜快跑革新的是运力，但供需匹配度，依旧掌握在滴滴们的手中。</strong></p>
  <p>两者乍一看好像能够互补合作，但如果这么做，萝卜快跑们能分到的，就只有制造端的微薄利润。这对于任何一家烧钱无数的robotaxi企业来说，都是无法接受的。</p>
  <p>未来，网约车与robotaxi们也就可能会爆发一场入口和运力抢地盘的打车大战。</p>
  <p>而参考25年的本地生活大战，第一轮外卖高地争夺，各方投入资金就超过了千亿元。</p>
  <p>在这方面，虽然百度的血条并不薄，但却需要输血给多个创新业务，再加上大模型时代，传统搜索广告的业绩下降速度是不可逆的，所以现在萝卜快跑也应该趁着当下的资本热潮，及时上市融资，以储备无限火力。</p>
  <p><strong>三是投资维度，如果萝卜快跑能分拆上市，也就能给资本市场吃一颗定心丸。</strong></p>
  <p>主要是过去百度总被诟病“起大早，赶晚集”，战略摇摆不定。</p>
  <p>就连现在看来无比正确的All in AI路线，李彦宏也曾有过反复横跳。</p>
  <p>2018年年初，李彦宏在极客公园大会上，就一改过去All in AI的态度，公开表示“我这人说话还是倾向于留有余地，我是非常相信AI的，但是没有这样说（All in AI），我希望大家不要把一件事情绝对化。”</p>
  <p>“<strong>我不希望大家说出来百度All in AI的时候，指的百度所有的资源都去做无人车、度秘，其实不是的，我们大多数的资源可能还是在百度搜索、信息流等相对比较核心的业务上。</strong>”</p>
  <p>所以某种程度上，<strong>萝卜快跑能做成，比在谁手里做成，对于中国乃至世界范围内的robotaxi更有现实意义。</strong></p>
  <p><strong>过去，百度一度被称为自动驾驶时代的黄埔军校。</strong></p>
  <p>比如地平线创始人余凯、小马智行创始人楼天城、文远知行创始人韩旭、黑芝麻智能联合创始人刘凡平等等。</p>
  <p>一众业内大牛，都曾是百度核心技术部门的关键人物。</p>
  <p>对待这样的人才，聪明的互联网科技公司们要做的就一件事<strong>：在顶层战略规划上统一战线，然后权力下放，以最大化地发挥出组织管理的积极性。</strong></p>
  <p>从表面看，百度就是这么做的。无论是余凯，还是被李彦宏从微软拉过来的陆奇们，在离开前几乎都身居高位。</p>
  <p>但从这些人出走的结果来看，又很难不令人多想：<strong>是不是李彦宏的放权还不够？又或者是内部管理阻力太大了呢？</strong></p>
  <p>毕竟，陆奇在上任百度时，“打工皇帝”唐骏曾给他写过一封公开信。</p>
  <p>唐骏认为，陆奇在百度会遇到自己在盛大同样的烦恼。同事和下属可能会听对自己的策略“很听话”，<strong>但一到执行层面就变得很难，他们只会听从“那个人”的指示和态度……</strong></p>
  <p><strong>在百度，“那个人”指的就是李彦宏。</strong></p>
  <p>结果不必多说，上任仅一年多，李彦宏的二十年老友——陆奇就选择了离开，然后很快加入了美国著名创业孵化器公司YC……</p>
  <p>所以很明显，作为中国自动驾驶的创新标杆，百度和萝卜快跑都是不缺人才吸引力的。</p>
  <p>只不过从过往的经验教训来看，李彦宏想要把这群有着更高追求的大牛们留住、用好，则可能还需要百度进一步放权，甚至是分拆独立，来充分发挥出“人”的能动性……</p>
  <p>试想一下，<strong>如果当初的陆奇们都没有离开，那么现在百度和萝卜快跑又会来到一个什么样的时代高度呢？</strong></p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5NzE0MjM5Nw==&amp;mid=2649568738&amp;idx=1&amp;sn=56a2e6af92bf606ac2a615e0f255d60a&amp;chksm=f52759bd185f5b66ac38b9140c0d2592c7acf426487bc1cf126c64b08c06900525068b1d9d77&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“谈擎说AI”（ID：Mr-dushe）</a>，作者：谈擎说AI，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627681849033737</id>
            <title>消费存储的「冠军」之路：雷克沙用三十年重新定义高端持久战</title>
            <link>https://www.36kr.com/p/3627681849033737</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627681849033737</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 09:33:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>将时针拨回2025年下半年，半导体存储市场经历了一场近乎疯狂的“过山车”。受上游原厂减产效应的滞后释放，叠加AI存储需求的暴增，半导体存储市场迎来了一轮史诗级的涨价潮。短短数月内，晶圆价格飙升数倍，厂家经营节奏从上半年的“去库存”切换至“抢供应”的模式。对于大多数消费类存储品牌而言，这是一个令人窒息的时刻：供应成本被动拉抬，利润空间被极度压缩。在这一轮周期中，行业的集体本能是“降成本、砍预算、收缩战线”，试图通过涨价将成本压力简单地传导给下游，在这场博弈中生存。</p>
  <p>然而，就在这股寒流尚未散去的2026年开年，CES（国际消费类电子产品展览会）开展前夕的拉斯维加斯，聚光灯却打在了一个看似“反常识”的组合上：</p>
  <p>雷克沙（Lexar）宣布了一项大手笔的战略动作——正式成为阿根廷国家队的官方全球合作伙伴，“中国存储品牌”与“世界冠军球队”的名字并列出现在大屏幕上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_07b16e118102494c9c07acbad4883b9a@6062546_oswg105964oswg1080oswg724_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>外界看到的是逆势扩张的豪赌，但在行业视角下，这是品牌发展到特定阶段的必然选择。在产品同质化严重、容易受到供应周期波动的存储行业，究竟什么样的品牌才能穿越周期，活得更久？</p>
  <h2><strong>01 三十年积淀下的底气与博弈</strong></h2>
  <p>雷克沙选择了一条难而正确的路：以高端价值定位对抗成本波动，以用户情感共鸣穿越行业周期。雷克沙CEO钟孟辰告诉36氪：“要在竞争激烈的红海市场找到‘蓝色’的部分。”此时重金押注阿根廷队，也是以攻为守。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9a07e33bcd44485dacb3e046c2374877@6062546_oswg77276oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，存储行业正处于供需结构性调整的剧烈波动周期，因此不少厂商忙于投机抢货、降质降本、跟风涨价来获取短期利润的现状。但如果将时间轴拉长，不难发现消费级存储市场其实长期面临一个悖论：产品同质化严重，厂商较难做出溢价空间。一旦供应端涨价，没有品牌护城河的厂商只能被动承压，要么亏损，要么因涨价失去用户和市占。市场并不一定会奖励勇气，更多的是奖励做好准备的人。雷克沙之所以敢于在行业焦虑和浮躁的喧嚣中沉下心来做品牌，打一场关于高端价值定位的争夺战，则是来自于三个方面的“底气”。</p>
  <p>第一重底气，来自母公司江波龙电子的完整产业链硬核支撑。</p>
  <p>品牌的高端化叙事，从来不能建立在空中楼阁之上，它离不开硬核技术与供应链的底层支撑。尤其是在高端消费类存储领域，技术实力是一切品牌建设的根基。当下能做到“研产销”一体化的品牌凤毛麟角，而这正是雷克沙最深的护城河。</p>
  <p>背靠江波龙的雷克沙，拥有了从自研主控芯片、固件核心算法到高阶封测制造的“全产业链能力”。这种能力不只体现为效率与成本上的优势，更重要的是雷克沙能够对用户做出更加长期主义的承诺——这个品牌始终有能力将工业级、企业级的严苛标准“降维”应用到消费级产品中。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_05ca5e07bd1541d1afdc024e9fc26779@6062546_oswg138915oswg1080oswg719_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以雷克沙推出的全球首款1TB microSD Express游戏存储卡（2025）为例，在友商还在为良率和发热头疼时，雷克沙依托自研技术和封测工厂，率先完成技术突破与规模化量产。这种垂直整合能力，保障了雷克沙在不同的市场周期下，能够在用户和市场端体现出高价值（人无我有），从而也让供应端更加从容应对。</p>
  <p>第二重底气，源于雷克沙品牌30年积淀的专业与创新基因。雷克沙并非新晋玩家。从1996年诞生至今，其品牌30年的历史几乎就是一部移动存储的发展史。在摄影师、创作者等专业群体中，雷克沙积累了极高的信赖度——这种信赖往往意味着数据安全和卓越性能。作为存储行业的“创新老兵”，雷克沙曾参与制定CF卡读写速度标准，推出了行业第一款金属三防卡（2024）、第一款1TB SD影像卡（2019）等里程碑产品。钟孟辰直言：“我们不是为了卖便宜货而存在的。”长期引领行业标准的专业性与不断突破极限的创新力融合在一起，才能构成其冲击全球顶级IP的信心来源。雷克沙不需要通过最低价来讨好市场，它有资格通过高品质和创新来定义市场。</p>
  <p>第三重底气，则是国产半导体快速崛起的时代机遇。在全球存储产业的版图中，中国正在从制造中心向创新中心转型。雷克沙作为中国存储出海的代表，正站在这一产业升级的潮头。背靠中国日益完善的半导体供应链体系，雷克沙得以整合最优质的生产要素。对此，钟孟辰表示：“中国今天拥有全球最好的工程师红利，我们有全世界最勤奋的工程师们和最完备的供应链体系。”时代趋势的加持，让雷克沙在面对全球竞争时拥有了得天独厚的纵深性。</p>
  <p>产业链的硬实力、品牌的厚积淀与时代的红利三者叠加，雷克沙的“逆周期”投入便不再是冒险，而是一次水到渠成的爆发。</p>
  <h2><strong>02 从“让世界看见”到“让世界共鸣”</strong></h2>
  <p>雷克沙牵手阿根廷队的战略意图清晰可见——这是一场关于中国科技消费品牌如何实现“心智全球化”的路径探索。在过去的很长一段时间里，中国品牌的出海大多停留在“产品出海”阶段。依靠高性价比和高效的渠道铺货，中国制造迅速占领了全球货架。在过去的八年里，雷克沙也已经成功重建了覆盖全球六大洲、70多个国家和地区的销售网络。在竞争激烈的消费类存储市场，酒香也怕巷子深。单纯靠渠道“推力”的边际效应正在递减，品牌需要一种强大的“拉力”，让消费者在琳琅满目的货架前，主动寻找雷克沙。这正是雷克沙选择阿根廷国家队的深层逻辑：寻找用户情感价值共振的落脚点。阿根廷国家队不仅是流量的代名词，更是“热血、坚韧、冠军”的精神图腾。从低谷到巅峰，从质疑到加冕，阿根廷队的故事本身就具有跨越国界、打动人心的力量。雷克沙选择与之站在一起，是为了将冷冰冰的存储参数，转化为“记录荣耀时刻”的情感价值。</p>
  <p>能成为阿根廷国家队的官方全球合作伙伴，门槛极高，得益于雷克沙在全球市场具备的三大深厚基础：</p>
  <p>首先是覆盖全球核心市场的区域基础。雷克沙的业务版图已深耕全球核心市场，其存储卡、固态硬盘市占率在多个区域名列前茅，并屡获福布斯等国际权威媒体的认可。这种扎实的物理网络，承接了阿根廷队遍布全球的2亿粉丝版图，确保了营销声量能转化为实实在在的市场渗透。</p>
  <p>其次是渗透高端零售体系的渠道基础。除了传统全球电商渠道，雷克沙还渗透进Costco、B&amp;H、Apple授权店、DJI大疆店等全球核心高端渠道，具备了在全球主流商业世界中与一线品牌同台竞技的话语权。</p>
  <p>最后是获得行业巨头背书的伙伴基础。存储产品作为核心配件，获得主机厂商的认证至关重要。雷克沙不仅进入了相机厂商Nikon、Canon、Fujifilm的AVL（合格供应商列表），更获得了运动相机厂商DJI、Insta360、GoPro的官方推荐，同时也成为众多新能源汽车品牌的出厂标配。这些硬核的“朋友圈”，证明了其在全球产业链中的不可替代性。</p>
  <p>当2亿粉丝的狂热注入70+国家的销售网络，雷克沙构建起了自己的“拉力”。同时，这也是一种商业模式的进化。它向全球消费者证明：中国制造，不只是好用的产品和工具，更能够在全球市场范围内，成为承载人文记忆与情感的高端首选。</p>
  <h2><strong>03 定义AI时代的“记忆守护者”</strong></h2>
  <p>站在品牌30周年的新起点，雷克沙的企图心不止于当下。面对席卷而来的AI浪潮，这家存储品牌正在从技术研发、应用场景、市场趋势多个方面，重新定义自己在用户生活中的角色。雷克沙敏锐地捕捉到了AI端侧存力的关键缺位。</p>
  <p>设想一下，未来的AI智能驾驶在高速移动中需要实时决策，如果完全依赖5G通信连接云端计算，毫秒级的延迟都可能带来致命风险；未来的机器人将在高温、高湿等恶劣环境下作业，对存储的耐用性与稳定性提出了远超消费级的要求。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_4d011d2a5f6a4d9db9ae1c754234032c@6062546_oswg495775oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这些场景揭示了AI时代存储的三大核心需求：</p>
  <p>极致性能以匹配算力、超低响应延迟以保障实时性、高耐用性以适应边缘环境。</p>
  <p>基于此，雷克沙前瞻性地布局了“AI Storage Core”战略。这并不是为了技术炫技，而是为了解决真实痛点。</p>
  <p>例如，在当前的存储芯片涨价周期中，PC厂商为了控制整机成本，被迫对硬盘容量进行“降配”。而AI模型的本地运行又需要海量的高速存储。矛盾之下，雷克沙基于AI Storage Core架构推出的Storage Stick提供了一种革命性的解法：它支持热插拔与灵活的外置扩展，用户无需拆机即可低成本升级大容量、高性能存储。</p>
  <p>此外，该架构还可延展出下一代存储卡形态，其性能将远高于目前最快的CFexpress卡，为8K超高清视频录制及复杂的AI摄影实时运算提供了前所未有的带宽和响应时延。正如钟孟辰所言：“我们不是等用户提需求，而是先把未来的‘路’修好。”技术趋势上的前瞻性，让雷克沙从一个被动的“配件厂商”，进化成为主动的AI基础设施建设者。其次是场景落地的极致化：为“关键时刻”而生。</p>
  <p>技术愿景最终需要落实到具体产品上。无论是全球最快的存储卡带来的极速连拍体验，还是双加密移动固态硬盘提供的数据安全感，雷克沙的产品始终围绕用户的核心痛点。而在“AI+体育”的场景中，这种结合更为紧密。随着战术模拟、动作分析等技术的普及，海量赛事数据的实时捕捉与处理成为刚需。雷克沙通过高性能存储提前卡位，从“存数据”进化为“懂数据”，为体育科技提供底层算力支持。</p>
  <p>与此同时，通过与阿根廷队的联名，品牌进一步打破了“专业配件”的高冷标签。以Lexar Air小轻块等产品为代表，雷克沙正在以更亲民、更具收藏价值的形态进入大众消费者的视野，实现破圈增长。存储卡不再只是冷冰冰的芯片，它可以是球迷胸前的挂饰，是记录冠军时刻的信物。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2917b900536a4f19b925f27ef547ec0c@6062546_oswg495069oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后是全球市场导向的本地化经营：做当地用户的朋友。</p>
  <p>“真正的全球化，不只是把货卖出去，而是把根扎进去。”钟孟辰表示，雷克沙坚持的是“本地化”的经营路线——在欧洲、北美、南美、亚太、中东非，雷克沙都坚持用当地的语言、当地的团队、融入当地的文化去服务当地市场。把根扎下来的姿态，让雷克沙不再是一个外来者，而是全球各地用户值得信赖的“老朋友”。</p>
  <p>未来3-5年，消费类存储行业将面临更残酷的洗牌。而雷克沙的逆势突围，提供了一个穿越行业周期的“中国样本”，也为中国科技消费品的全球化提供了一个清晰的注脚：产业链与技术决定了能走多远，品牌用户心智与情感共鸣决定了能站多高。</p>
  <p>从依靠渠道推力的野蛮生长，到构建心智拉力的品牌跃迁；从释放工程师红利的技术自信，到掌握高价值定位的商业博弈。雷克沙品牌正在用30年的积淀证明，中国品牌完全有能力从全球供应链的“搬运工”，转型为全球用户生活方式的“定义者”。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627641301878021</id>
            <title>新年最牛天使轮诞生了</title>
            <link>https://www.36kr.com/p/3627641301878021</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627641301878021</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 09:23:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2026开年，依然很燃。</p>
  <p>投资界获悉，东昇聚变（上海）技术有限公司（简称“东昇聚变”）已完成数亿元天使轮融资，红杉中国、IDG资本、中科创星、高瓴、鼎晖百孚、龙芯创投等联手入局。如此豪华阵容在以往天使轮中并不多见。</p>
  <p>东昇聚变，一支来自上海杨浦的队伍，由复旦科创、上海市未来产业基金、海桐国际创新中心、中科创星、启盈同创共同孵化。复旦大学现代物理研究所许敏教授带队，团队已启动第一代科学实验装置“晨光”项目，旨在推动氘-氦3聚变走向工程实现。</p>
  <p>业内流传着一句话：AI的尽头是能源，能源的尽头是可控核聚变。在这场攸关人类未来能源命运的赛跑中，上海又一次冲在了前头。</p>
  <h2><strong>超级天使轮，红杉IDG高瓴鼎晖都投了</strong></h2>
  <p>东昇聚变有何来头？</p>
  <p>我们从复旦大学磁约束聚变团队说起。这是一支由复旦大学现代物理研究所核科学与技术系教授许敏带队，聚焦高温强磁场磁约束聚变和人工智能驱动的聚变物理研究的队伍，致力于推动核聚变能源的工程实现。</p>
  <p>2025年7月，复旦大学磁约束聚变团队主导东昇聚变在上海成立，背后支持方还有<strong>复旦大学、上海市未来产业基金、海桐国际创新中心、中科创星、启盈同创</strong>等，其核心技术团队来自于国内外顶尖的大学和研究机构，他们长期从事磁约束核聚变科学和工程技术研究，具有丰富的大型聚变装置设计建造、实验运行和工程管理经验。</p>
  <p>不同于国际主流的氘-氚路线，<strong>东昇聚变选择无中子氘-氦3聚变路线</strong>（D+3He-&gt;H+4He+能量）——基本不涉核和氚，安全性高且综合成本低，更“干净”，也更“未来”。</p>
  <p>项目主要包含两大核心技术突破，一是高温超导强磁场磁体，采用先进高温超导材料，实现装置紧凑化和强磁场约束，显著提升等离子体稳定性和聚变效率。二是人工智能赋能等离子体控制，通过AI算法实现等离子体的长时间精确控制与运行优化，构建智能化实验平台。</p>
  <p>未来12年，东昇聚变计划分三阶段实现氘-氦3聚变净能量增益（Q&gt;1）的目标。目前，第一代“晨光”实验装置项目已正式启动。</p>
  <p>一旦成功，将通向近乎无限的清洁能源。</p>
  <p>这也意味着，东昇聚变的起点远比主流路径更艰难、更陡峭。“我们都是为了人类能源的终极梦想在努力，走的过程中就会相互融合，至于谁先谁后不重要。走到最后，各个路线都会趋同，很自然地就选择社会、老百姓、国家最为期待的一种形式呈现给大家。”许敏曾在复旦科创的访谈中表示。</p>
  <p>VC投资人也加入到这一人类颠覆式的科学技术浪潮中来。正如成立仅半年时间，东昇聚变便收获了天使轮，集结了红杉中国、IDG资本、中科创星、高瓴、鼎晖百孚、龙芯创投等一众知名机构。</p>
  <h2><strong>上海，正在重仓核聚变</strong></h2>
  <p>透过东昇聚变，一座“聚变之城”跃然眼前。</p>
  <p>印象深刻的一幕是去年7月，中国聚变能源有限公司挂牌成立大会正式在上海举行，公司将以磁约束托卡马克为技术路线，按照先导实验堆、示范堆、商用堆“三步走”发展阶段，最终实现聚变能商业化应用的任务目标。</p>
  <p>身后7家投资方随之浮出水面——中核集团、中国核电、中国石油昆仑资本、上海聚变、国绿基金、浙能电力、四川聚变，宣布共同投资114.92亿元。</p>
  <p>其中，上海聚变成立于2024年，由上海未来产业基金与上海国投、上海电气、闵行金投、申能集团等联合设立，实控人为上海市国资委。在此之前，<strong>上海未来产业基金宣布拟战略投资聚变公司，这是其成立以来的首个直投项目，也是上海国投公司在未来能源领域的重大战略布局。</strong></p>
  <p>不止于此，一批核聚变明星公司在上海诞生。去年11月，核心成员脱胎于上海交通大学高温超导团队的翌曦科技完成新一轮融资，由上海科创集团、上海未来产业基金、交大母基金共同投资。这是2025年内，翌曦科技完成的第三轮融资，其身后还站着中科创星、鼎晖百孚、道禾长期投资、复容投资、华控基金、福道乐呈、闵行金投、锡创投、成都空港等机构。</p>
  <p>同样在上海，成立仅4个月的诺瓦聚变便收获5亿元天使轮融资，创下了当时国内民营核聚变企业单笔融资新高，投资方名单中既有社保基金中关村自主创新专项基金、临港科创投等国资，也有高榕创投、君联资本、光合创投、华控基金、明势创投、云启资本等知名创投机构。<strong>当初决定创业时，团队在讨论把公司设在哪座城市时，他们一致选择了上海。</strong></p>
  <p>诞生于上海，能量奇点也接连完成了两轮融资，身后云集蔚来资本、红杉中国种子基金、蓝驰创投、米哈游等。2025年，能量奇点研制的大尺寸高温超导环向场磁体——经天磁体成功励磁至21.7特斯拉，创下大孔径高温超导D形磁体最高磁场纪录。</p>
  <p>还有上海星环聚能，身后簇拥着红杉中国种子基金、中科创星、英诺天使、水木清华校友种子基金、九合创投、顺为资本、险峰、联想之星、和玉资本、元禾原点等机构身影。除此之外，上海还涌现了专注于核聚变技术的超磁新能、鸿鹄聚变等，以及超级龙头上海超导早在2011年就在张江诞生，如今在冲刺科创板IPO。</p>
  <p>凡此种种，是上海全力布局未来产业的一缕缩影。正如能量奇点创始人杨钊此前谈起——</p>
  <p>“到2035年，中国或将迎来可控核聚变发出的第一度电。做成这件事，似乎只能在上海。”</p>
  <h2><strong>人类理想终极能源，正走向现实</strong></h2>
  <p>为何是上海？</p>
  <p>先解释下概念。所谓核聚变，通俗的解释是指两个较轻的原子核聚合成一个较重的原子核，并释放巨大的能量。因与太阳燃烧机制相同，可控核聚变装置常被称为“人造太阳”，但仍处于实验阶段。</p>
  <p>几乎零成本、零污染且无限获取，可控核聚变也被视为“终极能源”。理论上只要有几克反应物，就有可能产生一太（万亿）焦耳的能量，大约是发达国家的一个人在60年内所需要的能量。</p>
  <p>可以说，一旦可控核聚变商业化大规模实现后，人类生产生活方式将被彻底颠覆。因此，看似科幻、前沿的核聚变成为兵家必争之地。今年，“十五五”规划更是首次将聚变能列入“未来产业重点领域”，提出“推动核聚变能等成为新的经济增长点”。</p>
  <blockquote>
   <p>上海正不遗余力，此前就接连发布了《上海打造未来产业创新高地发展壮大未来产业集群行动方案》《上海核电产业高质量发展行动方案（2024—2027年）》等文件，将可控核聚变列为重点培育的未来能源产业，推动磁-惯性约束核聚变等关键技术研发。</p>
  </blockquote>
  <p>与此同时在科研端，上海已形成聚变领域人才与技术的密集供给优势：复旦大学、上海交通大学、上海科技大学及中国科学院上海光学精密机械研究所等高校院所，布局了多个聚焦不同技术路线的聚变研发团队，一个围绕着核聚变的产学研创新生态圈浮现。</p>
  <p>如今成效初显，一批核聚变创业团队纷纷选择把公司落在上海。“除了突破性研发创新能力外，政府重视、资本助力、产业链完善也是企业落地迅速成长的关键。”超磁新能CEO王超在接受媒体采访中表示，很多上下游客户也都集聚在这里，上游集聚了大部分高温超导带材供应商，下游则集聚了多种路径的聚变公司，为企业研发、生产和合作提供了便利。</p>
  <p>全球科学家探索可控核聚变已久。但由于技术难度空前，“商业核聚变发电何时实现”依然模糊不清。业内流传着这样一句调侃：<strong>核聚变是一项始终距离成功“永远还有50年”的前沿技术。</strong></p>
  <p>这意味着，可控核聚变技术门槛极高，产业化周期漫长，注定是项跨越数代人的事业。而放眼创投圈，敢真金白银投资可控核聚变领域的机构似乎变得多了起来，“抢份额”一幕开始上演。中科创星创始合伙人米磊提醒，<strong>（这一领域）不仅需要情怀，更需要耐心，我们必须尊重客观规律。</strong></p>
  <p>前路漫漫，但总有人敢于押注颠覆式创新。正如许敏教授的畅想，“我们期待着战争、饥饿的消除，沙漠可以变绿洲，人类离开地球、到宇宙深空中探索，找到我们新的家园。这些都需要能源的支撑。而聚变在目前看来，是人类认知边界内够得着的唯一选择。”</p>
  <p>浩浩汤汤，未来已来。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247709122&amp;idx=1&amp;sn=79549a315625954663b9460a90101a94&amp;chksm=edc63ec552b4ef03e54ac819a1417ed13d6bcb3128d0ba73f96a7728bd1d9f65987e397c819c&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：周佳丽，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627636625437447</id>
            <title>2026年，车路协同还能翻盘吗？</title>
            <link>https://www.36kr.com/p/3627636625437447</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627636625437447</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 09:21:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>不知道大伙有没有发现，最近车路协同这个词，好像越来越少提了？</p>
  <p>曾几何时，它被描绘成未来出行的关键一环：让车能提前知道红灯还剩几秒变绿，前方弯道是否有来车，甚至施工路段何时恢复通行。这种“车与道路对话”的能力，就是所谓的车路协同（V2X）。</p>
  <p>2018到2022年，它几乎无处不在。地方政府争相建设智慧高速，科技公司高调布局路侧单元，车企新车发布会必提V2X功能。一时间，车路协同一度成为中国智能交通和自动驾驶领域最炙手可热的概念之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_490fb9ffcf43447ea662565af2639ea0@6123248_oswg191855oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而近几年，这一概念在公众舆论的热度显著降温。资本转向大模型，车企聚焦端到端智驾，连行业展会都鲜有提及。曾经备受追捧的技术路线，仿佛已经淡出公众视野。</p>
  <p>资本退潮、项目停滞、车企转向……人们不禁要问，这项曾被寄予厚望的技术，是否已经彻底失宠？2026年，它还有没有可能重新回到舞台中央？</p>
  <h2><strong>从爆火到静默，车路协同的核心设想很直接：让车和路共享信息。</strong></h2>
  <p>交通信息不再只靠车载摄像头来猜，而是由路边的传感器实时感知，并推送给车辆。</p>
  <p>这听起来比单车智能更稳妥。如果路能提前“告诉”车，是不是就能避免很多事故？</p>
  <p>一时间，V2X（车联网）被视为破解高阶自动驾驶难题的中国方案。政府、科技巨头、车企纷纷发力，相关概念股一度暴涨。</p>
  <p>2020年，国家发展改革委等十一部委联合发布《智能汽车创新发展战略》，将“车路协同”提升至国家战略高度。随后，“智慧城市基础设施与智能网联汽车协同发展”（即“双智城市”）试点在北上广深等16个城市铺开，中央财政配套专项资金，地方争相申报示范区。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_c49d54f79243422abf049be16d3786e7@6123248_oswg714806oswg861oswg492_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>科技巨头闻风而动。华为推出“车路云协同”全栈解决方案，涵盖路侧感知、通信模组、边缘计算到云控平台；百度Apollo在全国首个“车路云一体化”高级别自动驾驶示范区亦庄部署329套智能网联标准路口；阿里云依托城市大脑布局车路协同数据中台……这场围绕新型数字基建的生态战，谁都不想缺席。</p>
  <p><strong>但短短几年，它就退出公众视野了。</strong></p>
  <p>如今，打开车企官网，V2X功能悄悄从配置表里撤下，支持C-V2X技术的车型不过二十余款；行业展会上，曾经占据C位的车路协同展台，被“端到端大模型”“AI座舱”“BEV感知”取代；主流汽车网站销量排行榜上，支持C-V2X的新车销量长时间吊车尾。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_7eb92b33d66b49e9bc2c3d6e568c0338@6123248_oswg108894oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>不仅车企热情削减，市场反应也变得冷淡。</strong>不少负责人透露，车路协同研发预算已经大规模削减，核心成员也多做其他技术线了。就连政策文件也不再提全面推广，而是改用“试点探索”“稳步推进”这类温和措辞。</p>
  <p>这不是错觉，车路协同确实没声音了。它没有轰然倒塌，却在无声中退场，像一场热闹的派对散场后，只剩下空荡的街道和几盏未熄的路灯。</p>
  <p>那么，到底发生了什么，让这个曾一度占据新闻头条的技术概念退居幕后？</p>
  <h2><strong>一场生态战的多方缺位</strong></h2>
  <p>看到这里，你可能会忍不住问：既然车路协同当初被捧得那么高，又是国家战略，又是巨头押注，怎么短短几年就悄无声息了？</p>
  <p>是技术不行？还是我们高估了它的价值？</p>
  <p><strong>其实，答案比技术失败更复杂，也更真实。它不是被某一个环节击垮的，而是在一场本该全员上场的生态战中，几乎所有角色都缺席了。</strong></p>
  <p><strong>最初设想的图景很动人：车要能听，路要会说，云要懂调度，网络要快如闪电，政府得持续投入，用户还得愿意为此买单。</strong></p>
  <p>可现实是，这套系统里，几乎没有哪一环真正跑通了闭环。</p>
  <p>困扰车路协同的第一个问题是，先有鸡、还是现有蛋？</p>
  <p>政府希望路上有足够的V2X车辆，才愿意大规模建设智能道路；车企则认为，路侧设施不完善，装了终端也用不上，不如暂缓标配。结果双方都做了一些尝试，政府建了几条示范路段，车企在部分高端车型预埋了硬件，但不够快、不够深，难以形成规模效应。</p>
  <p><strong>而这种渐进式推进的僵局很快暴露了一个更根本的问题：整个体系缺乏真实的用户驱动力。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_81a0459d71ec47adb17c3d9de51832bb@6123248_oswg737347oswg860oswg511_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>车路协同的可用性极度受限于基础设施的覆盖范围。截至目前，真正部署了路侧感知与通信设备的区域，几乎只集中在北京亦庄、上海嘉定等少数“双智城市”试点的核心路段。全国绝大多数城市，甚至这些试点城市的非示范区道路，车路协同依然缺位。这意味着，哪怕用户买了一辆支持V2X的车，离开那几公里示范路，功能就立刻失效。</p>
  <p>即便在这些有限的试点内，各方采用的技术标准和数据接口也各不相同。华为、百度、阿里等科技公司各自推出自己的协议栈，地方政府又倾向本地化方案，导致设备之间难以互通，车企不得不面对碎片化的适配环境。没有统一的语言，协同就无从谈起。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_49ac8cdfd3bd41bcba0cd893c71deca2@6123248_oswg619823oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>这直接传导到了产业链最敏感的一端——车企。</strong>毕竟，无论技术多前沿，车企的最终目标始终是卖车。如果一项配置不能提升产品竞争力、不能打动用户掏钱，就很难获得持续投入。当市场调研反复显示“用户不愿为V2X多花几千元”，而现有路侧覆盖又不足以支撑可靠体验时，车企的选择就很务实：保留硬件接口以备未来，但不再将其作为核心卖点宣传，甚至悄悄从配置表中淡化处理。</p>
  <p>就在车路协同无法带来实际商业价值的同时，以端到端为代表的单车智能快速发展、已经在市场积累了不少的真实口碑。城区NOA、高速领航、自动泊车……这些由单车智能驱动的功能，已经成为高端智能电动车的核心溢价点。相比之下，车路协同显得遥远、抽象，且依赖外部条件。当有限的研发资源必须分配时，车企自然把重心转向见效更快、用户更认可、商业回报更明确的单车智能路线。</p>
  <p>于是，曾经热火朝天的车路协同，慢慢淡出了主流叙事。它的遇冷看似偶然、实则必然，是一场系统性协作的失灵。</p>
  <h2><strong>翻盘无须重回C位</strong></h2>
  <p>到这里，你大概会忍不住想：既然车路协同连最基本的生态协作都难以建立，各方又都不愿真金白银投入，那它是不是已经彻底没戏了？</p>
  <p>这个问题，连很多从业者自己都在犹豫，但事实或许没那么悲观。<strong>车路协同的问题，从来不是有没有用，而是用在哪儿和谁来买单。</strong></p>
  <p>实际上，政府仍在推进“车路云一体化”试点城市建设。全国已建成17个国家级测试示范区，试点城市达20个，累计装配5G/C-V2X的车辆已超过300万辆。</p>
  <p><strong>可以说，车路协同想要翻盘，现阶段的务实之举是搁置宏大叙事、聚焦具体价值。</strong></p>
  <p>比如，在高速公路、港口、矿区、物流园区这类封闭或半封闭环境中，道路结构固定、管理主体清晰、安全容错率低，恰恰是车路协同最能发挥价值的地方。例如，京雄高速的部分路段已部署了路侧感知设备，并通过C-V2X向车辆推送异常停车等预警信息。这些地方不需要全民普及，也不依赖消费者选择，只要运营方认可价值，就能形成小而稳的闭环。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_8319d4d013964af6a0f10b504b0c71f6@6123248_oswg894615oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>而在开放城市道路中，车路协同也并非全无机会，关键在于聚焦高价值、低复杂度的公共安全任务。</strong>比如在大型广场周边、事故多发弯道、施工区域等特定点位部署轻量级感知设备，向路过车辆推送行人横穿、锥桶位置或湿滑路面预警。这类应用投入可控、社会效益直观，更容易获得交通管理部门的长期支持。</p>
  <p>更重要的是，车路协同正在调整自己的角色定位。它不再试图与单车智能一较高下，也不再宣称要替代车辆自身的感知能力，而是转向一种更务实的思路：<strong>在单车智能难以覆盖的边缘场景中提供补充信息。</strong>比如暴雨天摄像头失效时的雷达预警，或是密集车流中突然窜出的行人，这些正是路侧设施可以发挥作用的地方。</p>
  <p>可以说，2026年的车路协同，大概率不会重回C位，但也不会彻底沦为历史的注脚。它将在技术的洪流中渐渐清醒，寻找到自己的最佳位置。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/53FDCQfqyry14oL0R6KToQ" rel="noopener noreferrer nofollow" target="_blank">“脑洞汽车”</a>，作者：珊瑚，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627603272971009</id>
            <title>无人机订单量超谷歌，PR却“低调”：美团在筹备什么？</title>
            <link>https://www.36kr.com/p/3627603272971009</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627603272971009</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 08:33:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>2025年12月19日，本应是美团无人机业务一次对外“交代成绩”的节点。</p>
  <p>按照原定安排，这是一场对媒体开放的年终沟通活动。但在临近举办时，公关侧不再对外沟通，最终流出的信息只剩下零散的官方表述。</p>
  <p><strong>这并不常见。</strong></p>
  <p>尤其考虑到三个背景：</p>
  <blockquote>
   <p>其一，无人机是当前政策高度关注的低空经济赛道；其二，这是美团内部推进多年的核心自研项目；其三，从时间点看，本应是一场“年度成果展示”，而不是探索期的内部交流。</p>
  </blockquote>
  <p>但如果只盯着“发布会宣不宣传”，反而容易看偏。</p>
  <p>真正值得注意的是——发布会虽然被按下了“静音键”，但业务本身释放的信息，并不算差。</p>
  <p>美团无人机已经跑出了明确的运营数据：在多个城市形成稳定航线，累计商业订单数达到数十万量级，自研机型拿到了全国低空物流运营许可，也在香港、深圳、上海等地完成了长期试点。</p>
  <p><strong>美团似乎并不急着把这件事说清楚，甚至刻意选择了不说。</strong></p>
  <h2><strong>01 为什么美团选择秘而不宣？</strong></h2>
  <p>如果只从外部理解，美团对无人机的低调显得反常。</p>
  <p>但放回到美团自身的业务结构里，这种克制反而更容易理解。</p>
  <p>美团无人机并不是一个“对外服务”的独立业务，而是深度嵌入即时零售履约网络的一环。它解决的不是“能不能飞”，而是“在什么场景下，飞比人更合适”。</p>
  <p>作为高度依赖骑手体系的平台，美团的任何自动化尝试都天然带有公共议题属性。在当前的社会语境下，“技术是否替代就业”远比“技术是否先进”更容易成为讨论焦点。</p>
  <p>高调展示无人机配送能力，容易被解读为对现有履约人力的潜在冲击，甚至引发不必要的情绪对立。相比之下，保持克制、弱化传播，将无人机限定在高风险、高难度或特殊场景下的补充方案，更符合美团对自身社会角色的长期认知。</p>
  <p>一旦对外过度渲染无人机的规模化前景，很容易被解读为对骑手体系的替代信号，这在当前平台劳动力高度敏感的环境下，并非美团愿意主动释放的叙事。</p>
  <p>从商业层面上看，过去一年，即时零售赛道的竞争强度明显上升，淘宝闪购、京东到家等对手在补贴与供应链侧持续施压，履约效率重新成为核心变量。</p>
  <p>在这样的环境下，无人机这种尚未形成规模化成本优势的探索性业务，一旦被放在聚光灯下，极易被市场简化为远期叙事，并引发对研发投入回报周期的集中审视。</p>
  <p>将原本面向公众的发布活动收缩为更封闭的行业沟通，本质上是一种信号管理——美团不再急于讲故事，而是试图把讨论拉回到更具体的成本结构、工程效率和可复制性问题上。</p>
  <h2><strong>02 点对点的胜利，还是系统性的挑战？</strong></h2>
  <p>从客观数据看，其实美团无人机并不“拉胯”。</p>
  <blockquote>
   <p>美团自研第四代无人机获得了中国民航局颁发的全国低空物流运营许可，可以在全国主要城市开展商业配送，旗下的Keeta Drone自2017年启动探索以来，截至2025年在深圳、北京、上海、广州、香港等地已开通约65条航线，累计完成约74万单商业订单。</p>
  </blockquote>
  <p>而在2025年10月20日美团举办的机器人年会上，美团副总裁、无人机业务部负责人毛一年透露，截至9月底，美团无人机配送商业订单超过67万单，已经超过谷歌旗下无人机配送公司Wing Aviation的订单量，与12月19日发布会上的数据进行计算，这说明美团无人机的日均单量增长近800单。</p>
  <p>但这些成绩仍然存在明显的能力边界：</p>
  <p>无人机配送仍然高度依赖政策空域，航线以点对点为主，缺乏网络效应。载重与体积限制，决定了它只能覆盖有限品类，即便是最新发布的第四代无人机M4L长程版，标准工况下，载重也仅达4.5公斤，货箱容积达24升，有媒体计算，如果是餐饮配送的话，大约能装下3个10英寸披萨。</p>
  <p>目前尚未做到全程无人化，通常需要骑手从商家取货至起飞点，用户也需到指定空投柜取货，加之在楼宇密集区域飞行面临信号、安全、隐私和社区接受度等复杂挑战，每一点都需要不少时间来进行优化。</p>
  <p>这些问题并不新，也不是美团一家独有。</p>
  <p>但它们共同指向一个现实，无人机还不足以成为美团即时零售体系里的主力，在这个阶段，把发布会办成一场高调宣言，反而容易制造误判。</p>
  <h2><strong>03 无人机在美团内部究竟什么地位？</strong></h2>
  <p>美团做无人机，本质上并不是在赌一个独立赛道，而是不信任任何一家无人机公司能替它跑通履约路径。</p>
  <p>在2024年2月的架构调整中，王兴在内部信中点明：“无人机、境外业务汇报给我”。</p>
  <p>而现实却是美团在过去的两次财报中并没有单独拆出关于无人机业务的专栏。</p>
  <p>独立的营收贡献、成本结构、投资预算等并没有清晰的披露，相关投入仅仅被笼统归入研发费用、新业务探索等科目，未见具体营收或毛利数据的单列。</p>
  <p>也就是说，美团自己在官方对外报告中，暂时还没有给“低空经济”业务一个明确的经济体量标签。</p>
  <p>在资本合作上，美团也没有出现大手笔战略投资无人机制造商或底层空域服务平台的动作，现有的合作多是技术供应链层面，而不是战略性的资本押注。</p>
  <p>我们再将目光拉回到技术与运营本身，即便在政策积极推动低空经济的背景下，超大城市中的航路审批、安全冗余、末端起降条件，依旧是难以快速复制的系统性难题。</p>
  <p>目前美团的无人机配送仍主要停留在点对点、可控空域的试验阶段，单票成本尚未显著优于成熟的人力网络。</p>
  <p>而当配送场景越来越复杂，显然美团并不愿意把关键能力完全交给第三方无人机公司，这也是它选择自研、自造、自己跑航线的根本原因。</p>
  <p>从这个角度看，无人机更像是美团的一种底层能力储备。</p>
  <p>在这种现实之下，过早放大曝光，只会放大预期与现实之间的落差，降低关键信息外溢的风险，也更符合这一阶段“拼内功”的现实需要。</p>
  <h2><strong>04 在关键拐点前，选择沉默</strong></h2>
  <p>所以美团无人机这次的发布会主动收缩PR力度可以理解，和上下游供应商有了友好洽谈就足以达到美团的目的了。</p>
  <p>在低空物流赛道，美团与京东、顺丰等对手的竞争已经进入细节的比拼。无论是起降柜的标准化设计，还是复杂环境下的调度算法，都属于企业的核心资产。</p>
  <p>在业务尚未跨过行业关键拐点之前，不急着对外讲一个完整的故事，这似乎更符合美团长久以来的姿态。</p>
  <p>美团无人机已经证明了自己“能跑”，但还没准备好证明“值得被期待”。在一个高度监管、成本尚未塌缩、商业模式仍在打磨的阶段，沉默本身，可能就是它当前最稳妥的表达方式。</p>
  <p>真正的问题也许从来都不是美团无人机行不行，公关策略上的突然转变并非失误，而是美团在应对内外部多重挑战时，试图重新定义“科技叙事”的一种自我保护与战略收缩。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/TSi1l07ZScRJVRr5qGkPdg" rel="noopener noreferrer nofollow" target="_blank">“低空Future”</a>，作者：元素，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627594456663040</id>
            <title>清华挖出“幻觉”的罪魁祸首：预训练产生的0.1%神经元</title>
            <link>https://www.36kr.com/p/3627594456663040</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627594456663040</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 08:30:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>清华大学孙茂松团队从神经元角度研究幻觉的微观机制，发现极少数神经元（H-神经元）可预测幻觉，且与过度顺从行为相关，其根源在预训练阶段，为解决幻觉问题提供了新思路，有助于开发更可靠的大模型。</strong></p>
  <p>无论大型语言模型再怎么刷榜，但有一个幽灵「幻觉」始终徘徊在头上，让那些追求事实准确性的领域任务（如金融、教育、医疗）不敢轻易地把AI结合到业务中。</p>
  <p>幻觉是指模型生成看似合理但事实上不准确或缺乏证据支持的输出，比如GPT-3.5 在基于引用的事实性评估中约有40%的幻觉率，尽管GPT-4将幻觉率降低到28.6%，但仍然处于较高水平；以推理为中心的系统（如DeepSeek-R1）在复杂任务中表现出色，但也存在明显的幻觉模式。</p>
  <p>也就是说，无论模型架构如何，幻觉现象始终存在，是影响大模型可靠性的主要瓶颈。</p>
  <p>现有的研究结果表明，幻觉背后的机制和因素大致可以分为三类：</p>
  <p>从训练数据的角度来看，数据集分布不平衡和固有偏差使得模型难以准确回忆长尾事实；</p>
  <p>预训练和后训练阶段的训练目标主要是让模型能够自信地预测，而非表达对「不熟悉信息」的「不确定性」，促使模型输出错误的猜测。预训练中的「next-token预测目标」更注重「输出流畅性」而非「事实准确性」，指令微调和强化学习则倾向于生成「表面上有用」的回答。</p>
  <p>解码算法通过自回归生成中的随机性和误差累积引入不稳定性，使得微小偏差逐渐累积成幻觉。</p>
  <p>目前的研究大多将大语言模型看作黑盒，在宏观层面探讨幻觉的原因，而忽略了在神经元层面进行微观思考。</p>
  <p>通过研究神经元在幻觉中的激活模式，可以更深入地了解模型的可靠性；在可解释性方面，神经元层面的分析可以预测幻觉何时容易出现；对于对齐和行为控制，神经元提供了可操作的干预点，例如激活或抑制特定的神经元子集，从而可靠地修改模型输出。</p>
  <p>最近，清华大学孙茂松团队从神经元的角度出发，深入研究了LLM中幻觉的微观机制，从三个视角（识别identification、行为影响behavior impact和起源origins）系统地研究了幻觉相关神经元（H-Neurons）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_2cda93b6ce9a44ac856cdd64830272d8@5888275_oswg77566oswg1080oswg344_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">论文链接：https://arxiv.org/abs/2512.01797v2</p>
  <p>在识别方面，研究人员证明了一个极少数的稀疏神经元子集（少于总神经元数量的0.1% ）就能够可靠地预测幻觉，并在各种不同场景中展现出强大的泛化能力。</p>
  <p>在行为影响方面，受控干预显示这些神经元与过度服从行为存在因果关系。</p>
  <p>在起源方面，研究人员将这些神经元追溯到预训练的基模型，并发现这些神经元在幻觉检测中仍然具有预测能力，表明幻觉是在预训练过程中产生的。</p>
  <h2><strong>识别H-神经元</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_52cf24d428f74de2b39477503fdd3a5f@5888275_oswg404364oswg1080oswg989_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>为了从大型语言模型（LLMs）庞大的参数空间中识别出 H-神经元，研究人员采用了稀疏线性探测方法，先利用CETT指标（relu2wins）来量化每个神经元对生成响应的贡献，用于衡量神经元在生成过程中的激活水平。</p>
  <p>之后将幻觉检测视为一个二元分类问题，即根据神经元的激活情况预测响应是否为幻觉，使用L1正则化的逻辑回归训练稀疏分类器来自动选择最具预测性的神经元，其中权重非零的神经元被识别为H-神经元。</p>
  <p>那些权重非零的神经元被识别为 H-神经元。训练数据是从 TriviaQA 数据集中收集的，通过采样每个问题的多个响应，并根据事实正确性对它们进行标记。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_82e25826601e4605bd4ba76f16955500@5888275_oswg322535oswg1080oswg676_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>针对六个主流大模型的幻觉检测结果显示，H-神经元在检测幻觉方面表现出显著的鲁棒性，在所有模型和评估场景中均一致且显著优于使用随机选择的神经元构建的分类器，准确率提升超过10个百分点。</p>
  <p>分类器在不同场景下均展现出优越性能：领域内数据集（TriviaQA和NQ）上实现了高准确率，在跨领域的生物医学问题（BioASQ）上实现了泛化能力，并且在虚构问题（NonExist）上仍保持有效性。</p>
  <p>在熟悉的知识回忆、领域转移和完全虚构场景下的一致表现表明，H-神经元捕捉到了可泛化的幻觉模式，而非特定于数据集的特征。</p>
  <p>值得注意的是，H-神经元是模型总神经元中一个极为稀疏的子集，通常仅占模型中所有神经元的不到千分之一，但这一小部分神经元却提供了足够的信号来可靠地检测幻觉，表明模型参数的一个紧凑子集包含了大量关于幻觉倾向的信息。</p>
  <h2><strong>H-神经元的行为影响</strong></h2>
  <p>虽然预测准确性表明了相关性，但想确定「H-神经元在塑造模型行为中发挥了什么功能？」，还需要从观察转向干预。</p>
  <p>研究人员设计了一种系统性的扰动方法，在不重新训练模型的情况下调节神经元在推理过程中的贡献：</p>
  <p>对于每个目标神经元，将激活值乘以一个缩放因子α，其中α的取值范围是0到3；当α小于1时，会通过降低激活强度来抑制神经元的影响；当α等于1时，保持模型的原始行为；当α大于1时，通过增加激活幅度来增强其对模型回复的贡献。</p>
  <p>目前的研究普遍认为幻觉是模型为了追求更高准确率而倾向于冒险猜测，研究人员提出了一个补充性的观点：冒险行为是「过度顺从」，即模型倾向于满足用户请求，即使这样做会损害真实性、安全性或完整性。</p>
  <p>例如，当模型为了回答「一个无法回答的问题」而生成幻觉内容时，它是在优先考虑人类期望得到答案的潜意识，而非承认不确定或知识的边界，类似于人类可能因社交需求而撒谎的情况。</p>
  <p>如果H-神经元编码了过度顺从，那么操纵这些神经元不仅会影响模型在事实性问题上的行为，还会影响其他表现出过度顺从的任务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_5e6fcbdbdbc941aba5ffd5f3a5a01230@5888275_oswg395222oswg1080oswg793_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>实验结果来看，神经元的缩放因子与模型的顺从率之间存在一致的正相关，表明人为增强这些H-神经元的激活值会显著削弱模型对错误前提、误导性上下文、怀疑态度或有害指令的抵抗力，而抑制神经元则能有效减少过度顺从行为，从而恢复模型的稳健性和完整性。</p>
  <p>模型对神经元扰动的易感性通常与参数规模呈反比关系，表明较小的模型更容易在内部扰动下发生剧烈的行为变化，而较大的模型可能具有更强的内在稳健性，从而减轻了增强特定神经元群的影响。</p>
  <p>行为反应也并非在所有情况下都是严格单调的，某些模型在中间缩放因子时会出现顺从率的波动或临时下降。</p>
  <h2><strong>H-神经元的起源</strong></h2>
  <p>这些神经元是在预训练阶段产生的，还是后训练对齐过程中？</p>
  <p>确定时间线决定了未来是应该将缓解策略集中在「预训练过程」还是「对齐算法」上。</p>
  <p>如果H-神经元在基础模型中就已经显示出独特的激活模式，表明幻觉行为的根源在于预训练阶段的表示，而不仅仅是通过监督微调（SFT）诱导的对齐动态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_28b833c54c87445eb261f12e5d8a2216@5888275_oswg424032oswg1080oswg883_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>研究人员进行了两项实验来分析H-神经元，结果显示：</p>
  <blockquote>
   <p>H-神经元对基础模型的预测能力起到关键作用，证明了H-神经元在预训练阶段就已经建立，而非来自后训练对齐；</p>
  </blockquote>
  <p>归一化排名的分布表明，从基础模型到指令微调模型的转变过程中，H神经元的参数更新非常少，表明指令微调并不能重构底层的幻觉机制。</p>
  <h2><strong>结论</strong></h2>
  <p>研究人员对大模型中幻觉的微观机制进行了系统的神经元层面研究，通过弥合宏观行为模式与微观神经激活之间的差距，回答了三个问题：</p>
  <p>H-神经元的存在：模型中不到0.1%的神经元可以准确预测模型是否会生成幻觉响应；</p>
  <p>对模型行为的影响：H-神经元与大模型的过度顺从行为密切相关，包括对错误前提的过度承诺、对误导性上下文的更高敏感性、对有害指令的增加遵循以及更强的谄媚倾向。H-神经元不仅仅编码事实性错误，而是代表了一种更普遍的倾向，即优先考虑对话的顺从性而非事实完整性。</p>
  <p>H-神经元起源于预训练阶段，从学习理论角度提出的观点提供了实证依据，这些神经元在基础模型中保留了预测能，即使在微调之前也能成功检测幻觉。</p>
  <p>这项工作加深了对幻觉在计算层面产生的理解，并为开发更可靠的大模型提供可操作的研究方向。</p>
  <p>参考资料：</p>
  <p>https://arxiv.org/abs/2512.01797&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Wu-MpL89e9EtZH6-8u3A1A" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，作者：新智元，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627557447173128</id>
            <title>阿里字节们，谁能定义2026年AI之战？</title>
            <link>https://www.36kr.com/p/3627557447173128</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627557447173128</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 08:24:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>关于2026年大厂们的持续缠斗，不能绕开的关键词必然是 AI 。</p>
  <p>从2025年下半年开始，阿里对于 AI C 计划的集中猛攻就彻底拉开了这场序幕：</p>
  <blockquote>
   <p>千问、夸克眼镜再到蚂蚁集团的灵光、阿福，纷纷搅动了市场的关注度，而随后，字节旗下豆包手机的开辟式登场引发了全网关注，在两方纷纷拿出杀手锏的时候，上半年大力猛推元宝的腾讯，则被大众认为陷入了被动，直到年底27岁姚顺雨出任腾讯首席AI科学家并主导挖人计划的消息传出之时，腾讯对于 AI 的野心也彻底藏不住了。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f657c8c4af2345e199cf6b9406532df7@000000_oswg479434oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">豆包手机助手</p>
  <p>姚顺雨加入后，腾讯混元团队的新老交替正在进行中。最新消息是腾讯AI Lab副主任俞栋选择了离开。</p>
  <p>这和字节跳动 AI 研究大拿 吴永辉加入后的情况如出一辙。</p>
  <p>大部分声音也都集中在腾讯关于 AI 的反击号角即将吹响， 但如果以微软和谷歌合并作为全球大模型第一梯队的模式来看，腾讯连阵型还没摆好。</p>
  <p>这种模式就是ChatGPT和Gemini扩大影响，Azure和Google Cloud赚钱养家。</p>
  <p>腾讯云看起来还在按部就班，并没有被卷入一场大战， 也因此 ，<strong>腾讯的AI暗流何时涌动起来，现在还没有定论。</strong></p>
  <p><strong>阿里从投入上看倒是能和字节匹配</strong>，吴泳铭在一个多月前放言，未来三年AI泡沫“不太存在”。 但是，阿里在发力 C 计划的同时，“亲儿子”蚂蚁也同样在发力，“自家打自家”总有种力量分散的感觉，这或许是2026年阿里需要重新思考的如何整合与产品力升级。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f6a1e5b2d6a2450ca4c673ef85e09b77@000000_oswg76207oswg1080oswg820_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">蚂蚁阿福</p>
  <p>而字节跳动的 AI 部署， 除了C端付费，已经在模式上赶上硅谷同行了，最大的期望就是火山引擎如抖音一样走向世界， 其豆包能否链接出下一个决定变革的智能体。</p>
  <p>阿里、字节跳动、腾讯，市场等待着他们在2026年交出更多有关 AI 的战略答卷。</p>
  <h2><strong>AI产品阵型背后的战略、人才、投入</strong></h2>
  <p>不要说腾讯，就连阿里也才刚上线 升级版的 千问1个多月。阿里云确实赚了不少，但之前冲在C端最前方的却是夸克，并不是一个能和豆包或ChatGPT对标的应用。</p>
  <p>也许是因为吴嘉是吴泳铭手下AI to C的最佳人选。</p>
  <p>阿里的战略创新业务“四小龙”里，1688和闲鱼都是电商，钉钉和夸克都冲上了AI的前线，但钉钉是2B的。</p>
  <p>在千问app上线后不久，千问C端事业群也成立了，负责人还是吴嘉，不过至少战线已经和豆包对上了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_53ce77989a754ed4b572255bdad916fa@000000_oswg285740oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">千问app</p>
  <p><strong>阿里的AI打法越来越像字节和硅谷公司们，可是还有一点奇怪的地方。</strong></p>
  <p>那就是蚂蚁的灵光。 而 且，蚂蚁不光有灵光，还有医疗领域的阿福。</p>
  <p>灵光是在千问 升级 上线后5天发布的，两者基本上就是同步建设的，也是某种意义上的重复建设。</p>
  <p>这让人意识到蚂蚁和阿里还是两个集团。蚂蚁承载着阿里的分权实验。</p>
  <p>按照原先张勇的方案，阿里集团会被一分为六。如果这成为现实，现在除了千问和灵光，还可能会看到阿里系的其他5个C端AI助手。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_32fb22be15f04390b71855638b8e7110@000000_oswg78317oswg1080oswg640_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">灵光App</p>
  <p>随着拆分方案的叫停，至少在AI战场，阿里云才能在B端集中收割，阿里也保留了模仿AI硅谷模式的机会。</p>
  <p><strong>微软和谷歌在分权创新的玩法上确实比阿里更加娴熟。</strong></p>
  <p>他们也都没为了创新考虑过分拆，当然美国联邦贸易委员会从反垄断的角度替他们考虑过。</p>
  <p>他们大模型的研发团队分别是OpenAI和DeepMind。</p>
  <p>谷歌那个失败的Bard就是一个副总裁带着研发的，后来不得已才把Gemini交给了DeepMind。</p>
  <p>不仅如此，<strong>DeepMind还为字节贡献了Seed。</strong>当下的字节跳动 AI 一号位 吴永辉在加入 之前 就是DeepMind研究副总裁。</p>
  <p>他加入后，就从朱文佳手里接过了基础研发工作，把对方推到了模型应用这个夹在Seed和豆包之间的尴尬位置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_073990b767544c3196ebc75f3a19e615@000000_oswg243803oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">字节跳动官网截图</p>
  <p>众所周知，职场上这种不良态势是边缘化的前奏。</p>
  <p>果然，不到一年，现在朱文佳也开始向吴永辉而不是梁汝波汇报了。</p>
  <p>对比看，<strong>更加年轻、硅谷AI履历同样光鲜的姚顺雨在腾讯的权限要更小。</strong></p>
  <p>姚顺雨现在是双线汇报。总裁办公室首席科学家的身份能让他和刘炽平搭上话，但实际做产品还得听技术工程事业群总裁卢山的。</p>
  <p>而且吴永辉应该就是DeepMind的最强中国人了，但姚顺雨 过去 在OpenAI中的地位可不好说。</p>
  <p>在腾讯动手前，Meta先动手了。今年年中，后者就从OpenAI招募了4个华人大神。这四位从头衔和经理上看起来都要比姚顺雨更强。</p>
  <p><strong>腾讯看重的，也许是姚顺雨那代表着未来的agent方向吧。</strong></p>
  <p>没挖到姚顺雨，Meta也没闲着，他们用“数十亿美元”收购了Manus。对此，知乎上有条评论很有意思：“姚顺雨带几个人几周就能做出Manus”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_58145d410f9d4071a15eb8435590397f@000000_oswg185131oswg1080oswg978_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：网络</p>
  <p>所以，这不知道是姚顺雨能力太强，还是Meta实在太有钱， 又或者是小扎过于“病急乱投医”。</p>
  <p>一定意义上，<strong>姚顺雨就是腾讯混元大模型的一个常规补强。</strong></p>
  <p>而现在姚顺雨首先要面对的是如近期元宝被用户投诉这般被定义为小概率性的模型异常输出，不断调教元宝应对更多大小场面，毕竟隔壁的豆包大模型刚刚在罗永浩跨年分享会上完成一场激烈的辩论，豆包的思维能力受到了全网的高赞。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_d53624c2b4a34611942cbaf01aea10d8@000000_oswg30189oswg734oswg524_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">元宝宣传图</p>
  <p>关于 AI 投入指标， 三季度的腾讯资本开支同比下降24.06%，按环比算是32.05%。这 省 下的几十亿，即使姚顺雨的年薪是传说中的上亿，那么，腾讯的整个AI Infra都招姚顺雨这钱也够了。</p>
  <p>从近期财报来看， 腾讯对AI的整体投入在下降。与此同时，阿里2025年初宣布的是三年3800亿，据英国金融时报报道， 字节跳动2026 年是1600亿。 也许，<strong>腾讯需要到某个时间点重点宣布其对于AI投入的真金白银到底真诚不真诚了。</strong></p>
  <h2><strong>谁走的路更顺？</strong></h2>
  <p>所以， 在腾讯没有彻底展露对外明晃晃显示决心之前， 中国大厂AI战的“阿里vs字节”叙事从投入上来说是没毛病的。</p>
  <p>这场仗打到现在，阿里是BAT三家中唯一没有更换大模型团队负责人的。而Qwen大模型甚至和硅谷的一线大模型相比也毫不逊色，在大洋彼岸的知名度远强于字节的Seed。</p>
  <p>抛开商业化，单单是这份成绩就达到了马云心目中“凝聚人心的大仗”标准。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_1136a2beabbe4221bedcea12f91e3d86@000000_oswg121943oswg1080oswg422_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Qwen大模型</p>
  <p>不过，另一方面，豆包目前成了中国唯一一个用户数超越DeepSeek的独立AI原生App，而阿里才刚刚蹭着自己大模型的热度用“千问”命名了接下来C端的主力应用。</p>
  <p>这说明形势上，<strong>阿里是从B端打C端，字节是从C端打B端。</strong></p>
  <p>这种局面，按照互联网的普遍规律来说，得C端者得天下，字节在中国AI市场的强势似乎已经难以阻挡。</p>
  <p>在B端，火山引擎日均消耗T oken达50 万亿，按照调研机构英富曼的说法已经是 MaaS 市场的中国第一，世界第三。</p>
  <p>谈到这个问题，阿里云对《中国企业家》强调“ 有效的Token调用 ” 。</p>
  <p>要知道，解释本身就会显得无力。</p>
  <p>这种差距一时间还很难弥补，因为字节有豆包，还有抖音。</p>
  <p>视频才最好消耗Token。</p>
  <p>Sora2 在 2025 年 10 月发布后，字节做AIGC的必要性就看得更清楚了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_563f759c8b944ca19d58e884bc0fad23@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Sora2生成视频</p>
  <p>视频工具公司Kapwing研究发现，<strong>YouTube短视频推荐流当中有21%的内容是都是AI生成的。</strong>虽然无法清楚 抖音这方面的数据，但以中国人的内卷程度看应该比例也不会太低，比如泛滥的假孙子和假靳东。</p>
  <p>那么， 内容质量 呢 ？互联网发展史说明这根本不重要。 印度YouTube短视频频道Bandar Apna Dost专门播AI生成的假猴子，累计播放量20亿，年化广告收入425万美元。</p>
  <p>借助多模态大模型，这种内容形式绝对是比短剧成本更低。</p>
  <p>问题在于，大模型投入巨大，如果AI生成的无脑视频不成为主流，可能还是得不偿失。再者，YouTube针对AI内容的监管正在加强，UP主的商业模型还难言稳定。</p>
  <p>无论如何，字节在商业上已经基本赶上了硅谷的第一梯队，<strong>能否大成的关键系于生成式AI这项创新本身了。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9b1655aea69e4a8896b7d5cdf7a332ea@000000_oswg743256oswg1080oswg582_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">字节生成式AI App即梦</p>
  <p>2026年是关键一年。</p>
  <p>OpenAI、Anthropic都计划今年上市，两者预计估值之和超过万亿美元。独角兽IPO无疑是AI估值的试金石，在Oracle股价已露出疲态的当下，一场不少投资者心中有数的调整或将到来。</p>
  <p>潮水退去时大厂AI还能顶住，那才说明这个事真成了。很遗憾，这次的AI业务绝对会受到群体狂热退烧的影响。<strong>不过之于字节跳动而言，火山引擎的突破将成为最大的收获。</strong></p>
  <p>卷进其中的阿里，以及即便按兵不动但信号强烈的腾讯，究竟要在这场被定义谁都能 不能错过的未来战役里获得什么，而能否在潮水褪去之前，捕捞到自己所要的“无价之宝”，亟待这几位大厂里的 AI 一号位给出明确动向。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzkxNDIwODkwMA==&amp;mid=2247498949&amp;idx=1&amp;sn=18ac8c4cb242ec296e1e36bcb27ee2a7&amp;chksm=c0c58cc05b7753288fadcd247b16ecb2be0dcece3110fc81438870146731aa77fef4614e8d52&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“壹番YIFAN”（ID：finance_yifan）</a>，作者：壹叔团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627546400162818</id>
            <title>宝马降价，越降越贵？</title>
            <link>https://www.36kr.com/p/3627546400162818</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627546400162818</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 08:22:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“这一次降价是官方指导价下降，但在我们店里，（车辆）优惠完的价格和之前比没有太大变动。比如厂家指导价多优惠3万元，那我们就少优惠3万元。”北京北五环一家宝马4S店销售王宁（化名）4日对中新经纬说。</p>
  <p>1月2日，宝马中国宣布，自2026年1月1日起，对旗下超30款主力车型进行建议零售价调整，其中24款车型的降幅超10%，6款超20%，部分车型最高官降30万元。</p>
  <p>这波降价给终端消费市场带来了哪些影响？近日，中新经纬以消费者身份探访了几家位于北京的门店。</p>
  <h2><strong>到店消费者鲜有关注官降车型</strong></h2>
  <p>“这几天有很多人打电话来咨询降价事情，比平时多四五成，但大部分问完就没了下文。我手里已经订车的客户也来问这个事，不过店里确实给不到更多优惠，目前没有客户打算退订。”王宁说。</p>
  <p>在北京多家宝马4S店，中新经纬看到，大部分消费者进店后的目标是宝马3系、宝马5系等热销车型，而官降车型如宝马X1、宝马i7展车周围，鲜有消费者驻足。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_483f8651de5449e1b5b9919ddc81647a@000000_oswg100054oswg1080oswg700_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">展厅里的宝马7系 中新经纬摄</p>
  <p>从宝马官降产品类型来看，销量靠前的车型并不在降价范围内。参与降价的车型有油车也有电车，如宝马7系、i7、X7、X6、X2、X1，包含旗舰和入门版本，涉及轿车、SUV、高性能等多个细分市场。</p>
  <p>从降价幅度来看，绝大部分车型降价幅度超过10%，最高降幅达到24%。比如宝马iX1 eDrive25L，官方指导价由29.99万降至22.8万元。宝马i7 M70L指导价由189.9万元降至159.8万元，直降30.1万元，降幅达16%。</p>
  <p>王宁表示，此次官降未给其业绩带来影响，她手里的订单主要为宝马3系、宝马5系。“这两天成交的客户并不是看到官降消息才来找我买车，他们主要想在年前换个好车。”</p>
  <p>官降车型终端价格为何没太大变化？</p>
  <p>北京东四环一名宝马4S店销售孟震（化名）表示，厂家降价主要是为了缩小车辆指导价与4S店裸车价及落地价的差距，而非让消费者直接享受到更优惠的价格。</p>
  <p>而在北京东北五环另一家宝马4S店，销售张欣（化名）告诉中新经纬，<strong>消费者现在购买官降车型，最终落地价会略高于官降前的价格。拿X1举例，现在底价是19万元，官降前是18万元。厂家的操作，实际上是为了保障经销商的利润。</strong></p>
  <p>张欣提到的宝马X1是指宝马X1 2025款 sDrive25Li X设计套装/M运动曜夜套装，官方指导价由31.69万元降至25.8万元，直降5.89万元，降幅达19%。</p>
  <p>张欣表示，会有没看过车的客户，之前不了解车辆底价，他们看到宝马官降后觉得划算，到店后听到销售报底价后会决定买车。“我昨天就遇到了这种客户。不过我们会损失官降前就打听了底价的客户，他们会选择买其他品牌的车，但这并不重要，我们的利润会比之前高。”</p>
  <h2><strong>“将对部分热销车型提价”</strong></h2>
  <p>1月3日，宝马中国官方向媒体回应了官降一事，称此事不是价格战，宝马只调整了部分产品官方指导价，终端价格由经销商自行决定，是宝马针对市场动态的积极回应。宝马在华奉行长期主义的良性发展，而非短期盈利。</p>
  <p>宝马集团11月公布的财报数据显示，其前三季度营业收入为999.99亿欧元（约8157.02亿元人民币），同比下滑5.6%。其中，汽车业务板块收入为871.64亿欧元（约7110.05亿元人民币），同比下滑4.1%。</p>
  <p><strong>在市场表现方面，宝马集团前三季度全球销量为179.6万辆，同比增长2.4%。其中，中国市场前三季度累计销量为46.5万辆，同比下滑11.2%。</strong></p>
  <p>宝马集团在三季报中提到，中国市场竞争压力增加是其利润下降的主因。宝马集团董事长齐普策在财报业绩会上表示，不管是调整经销商网络还是推出更符合中国消费者需求的新车型，宝马集团已经做好准备，以应对中国市场持续变化的环境。“2026年和2027年，宝马集团在中国市场的销量不会实现快速增长。”</p>
  <p>在北京部分宝马4S门店，有销售表示即将上调部分车型底价。张欣说，该门店将对部分热销车型，如宝马3系、5系、X3，采取涨价举措，上涨幅度为1万元，“我们12月（销量）卖得比较旺，到年前买车的人也多，我们决定年前保利润”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_08379e66deac42b0b8bb11e4b8c429c7@000000_oswg126643oswg1080oswg700_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">北京一宝马4S店展厅 中新经纬摄</p>
  <p>孟震也表示，宝马部分畅销车型即将在店端涨价。“我们是根据车型资源来调价，如果爆库（库存过多）我们会压价格，客户的成交价会低一点，反之会涨价。”</p>
  <blockquote>
   <p>中国汽车流通协会2025年8月下旬发布的《2025年上半年全国汽车经销商生存状况调查结果》显示，上半年有74.4%的汽车经销商有不同程度的价格倒挂，43.6%的汽车经销商价格倒挂幅度在15%以上。</p>
  </blockquote>
  <p>中国汽车流通协会认为，严重的价格倒挂，吞噬了经销商的流动资金，导致经销商普遍反映资金压力大，特别是传统燃油品牌经销商，价格倒挂导致新车业务亏损严重。</p>
  <p>中国汽车流通协会2025年12月31日发布的《中国汽车经销商库存预警指数调查》显示，2025年12月中国汽车经销商库存预警指数为57.7%，同比上升7.5个百分点。其中，12月豪华及进口、合资品牌指数环比下降。</p>
  <p>中国汽车流通协会建议，经销商要根据实际情况，理性预估市场实际需求。同时要加大对“以旧换新和报废更新政策”的宣传，通过强化服务提振消费信心，把降本增效放在首位，防范经营风险。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI0NDU5OTAzMA==&amp;mid=2247601058&amp;idx=1&amp;sn=f2941c0cc67739838ad031911f58509f&amp;chksm=e8ac70c2c00beea94115c8fd76d7069b7485fe5e122d833901f47a4f77c199d3000c82339691&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“中新经纬”（ID：jwview）</a>，作者：龚宸芫，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627594654221569</id>
            <title>OpenAI推理第一人离职，7年打造了o3/o1/GPT-4/Codex</title>
            <link>https://www.36kr.com/p/3627594654221569</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627594654221569</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 08:20:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚开年，OpenAI再出人事动荡：推理模型第一人离职了！</p>
  <p><strong>Jerry Tworek</strong>——构建o3、o1、GPT-4、ChatGPT以及 OpenAI首个AI编程模型Codex的关键人物，OpenAI研究副总裁——<strong>宣布了他的艰难决定</strong>：</p>
  <blockquote>
   <p>离开OpenAI，去尝试探索一些在OpenAl难以开展的研究领域。</p>
  </blockquote>
  <p>好奇，他所说的“在OpenAI难以开展的研究”包括哪些部分？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e36074092d6347169e512cf606a396d1@5888275_oswg192834oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他表示，<strong>在OpenAI快七年</strong>的时间里，经历了许多美好和疯狂的时刻，但更多的是美好的时光。</p>
  <p>（大佬也和OpenAI有七年之痒？）</p>
  <p>不少OpenAI在职人员都在这篇推文上回顾了和Jerry共事的愉快经历。</p>
  <p>也祝他拥有美好的未来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_aef437c946c84acaa635199882b21d45@5888275_oswg287208oswg1080oswg690_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>网友看客们嘛，留言中的<strong>关键词主要是“感谢”和“赞叹”</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_1d0b92b00e884d26ba3ffb97e07e9132@5888275_oswg144197oswg1080oswg521_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>依旧有因<strong>OpenAI流失重要人才</strong>感到沮丧的朋友。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_331c31d1a55d4191bf35d681cabe44e2@5888275_oswg42814oswg842oswg304_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但这条朋友的评论区更好笑。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_9509c824108e46b9b3ee9b204385801c@5888275_oswg196809oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>很多人可能从Jerry断断续续的采访、演讲中认识他，了解得并不那么全面。</p>
  <p>现在，<strong>让我们正经全方位认识一下这位推理模型大佬</strong>，以此送别，并祝愿他开启一个新的航程。</p>
  <h2><strong>OpenAI推理模型第一人</strong></h2>
  <p>Jerry Tworek，出生、成长于波兰，在<strong>华沙大学数学专业</strong>取得硕士学位，属于强理论与数理功底出身。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_8408ddc185384825aba0e27d5afb8d23@5888275_oswg172070oswg438oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>他并<strong>不是一出校门就进入AI界打拼的</strong>。</p>
  <p>离开学校后的头五年，他先在阿姆斯特丹从事量化研究，主要研究期货市场的量化交易策略。</p>
  <p>这期间，Jerry使用优化理论和从噪声数据集中提取信号的技术来研究和开发期货市场的量化交易策略，这最终<strong>引导他开始研究强化学习</strong>。</p>
  <p><strong>2019年，Jerry加入OpenAI</strong>，担任研究科学家，主要方向是神经程序合成、强化学习等。</p>
  <p>当时GPT‑2刚发布不久，OpenAI还以非营利研究实验室为主，规模小，名气不算大。</p>
  <p>早期，<strong>他参与了机器人项目“用机器人手解决魔方”</strong>，并就这一项目在NeurIPS 2019深度强化学习研讨会作了展示。</p>
  <p>Jerry也<strong>是最早一批参与“大规模预训练+算力扩展”路线的研究者之一</strong>，并且在前ChatGPT时期，他就已经展现出对模型推理的极大兴趣，</p>
  <p>2020年GPT-3发布后，他开始着手研究评估和训练GPT-3以解决推理和逻辑问题。</p>
  <p>截至今日，Jerry在各种公开演讲和访谈中，多次强调对“推理”而不仅仅是“模式匹配式生成”的重视，倾向把大模型看作可以通过训练“学会思考过程”的系统，而不仅是一个黑盒文本预测器。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_89af137c7f6042c7ab138e4da8e60875@5888275_oswg426729oswg1080oswg590_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2019–2022年间，他在OpenAI做神经程序综合与大模型推理研究，涉及Codex、Copilot这类<strong>代码大模型，同时利用强化学习提升复杂任务上的推理与决策能力。</strong></p>
  <p>2022年起，Jerry开始担任OpenAI的Research Lead，负责带团队研究“如何让大语言模型使用工具、解决STEM领域的困难问题”，包括插件和Code Interpreter等等。</p>
  <p>ChatGPT出现之后，他逐渐被更多人认识——以ChatGPT和GPT系列模型主要贡献者之一的名义。</p>
  <p><strong>Jerry是GPT-4的首席研究员，领导了第一个推理模型o1的研究开发，对外被介绍为GPT-5推理机制和长思考能力的核心负责人。</strong></p>
  <p>还在各种各样的访谈、播客节目中系统讲解GPT-5的思考方式和推理模型的路线演化。</p>
  <p>2025年，Jerry升任OpenAI研究副总裁。</p>
  <p>2026年1月6日，Jerry宣布从OpenAI离职，并未公布具体去向。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_e69843418e53409f95ff278cebcea676@5888275_oswg145327oswg1080oswg690_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>下面附上Jerry离职小作文的翻译原文。</p>
  <h2><strong>Jerry离职小作文写了什么？</strong></h2>
  <p>大家好，我做出了一个艰难的决定——离开OpenAl。</p>
  <p>我在这里工作了将近七年，经历了许多美好和疯狂的时刻，但更多的是美好的时光。</p>
  <p>我非常享受在这里工作的日子。我曾在机器人上进行强化学习的早期开发工作，还训练了世界上第一个编程模型，这些模型开启了大语言模型编程革命。</p>
  <p>在DeepMind发布模型Chinchilla之前，我就发现了后来大家称为“Chinchilla Scaling Law”的现象。</p>
  <p>我参与了GPT-4和ChatGPT的开发工作，最近还组建了一个团队，建立了一个新的缩放训练和推理计算范式——现在，它通常被称之为推理模型。</p>
  <p>我结交了许多朋友，在办公室度过了许多个夜晚，参与并见证了数量可观的技术突破，还与许多被我视为亲密伙伴的人一同欢笑和担忧。</p>
  <p>我有幸组建并壮大了我认为世界上最强的机器学习团队。</p>
  <p>这是一段非常愉快的经历。尽管我要离开OpenAl去尝试探索一些在OpenAl难以开展的研究领域，但这是一家特殊的公司，也是世界上一个特殊的存在，它已然在人类历史的长河中占据了永恒的位置。</p>
  <p>非常感激多年来OpenAI和你们对我的信任。这类时刻总让人感觉不太自然，但从积极乐观的角度看待，它们却可能成为促成伟大事物的催化剂。</p>
  <p>我们一起让机器智能变得更加有用和可靠，我是忠实的ChatGPT推理模型用户。</p>
  <p>再次感谢，感谢千千万万次。</p>
  <p>保重身体，亲爱的草莓们。</p>
  <p>Jerry</p>
  <h2><strong>One More Thing</strong></h2>
  <p>本来吧，附上Jerry的小作文，这篇推文就该结束了。</p>
  <p>但被我翻到了一个粗看好笑，细想想又有点道理的留言：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_58405294603f4ed092c58357678b57e9@5888275_oswg107948oswg1080oswg254_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>仔细想想，OpenAI的朋友们离职时确实都有小作文，这是啥不成文规定吗？还是企业文化？</p>
  <p>好奇.jpg</p>
  <p>参考链接：</p>
  <p>[1]https://x.com/MillionInt/status/2008237251751534622?s=20</p>
  <p>[2]https://www.linkedin.com/in/jerry-tworek-b5b9aa56/</p>
  <p>[3]https://warsaw.ai/speaker/jerry-tworek/</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/N6esINF0t2Sh2ci7-foDwg" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3627462093206019</id>
            <title>疯狂的存储江湖：造富、混战和洗牌</title>
            <link>https://www.36kr.com/p/3627462093206019</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3627462093206019</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 Jan 2026 08:11:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>刚刚过去的元旦，一个近400人的深圳存储芯片资源群里，每天求料询价的消息依然刷个不停。</p>
  <p>“存储成品价格还在涨，至少还得半年，现在日子很难过，客户一问，要么是价格不合适，要么是没货。”</p>
  <p>说这话的人叫做李威（化名），是一位存储芯片分销商。从业五年，他从未有看到存储芯片有复杂的市场情绪，一边是价格上涨背后的乐观，一边则是「看不懂」的恐慌。</p>
  <p>一位存储芯片采购也感受到这种割裂的市场环境。据他观察，有存储芯片分销商和贸易商因踩中了存储周期的节点，靠超前备货和囤货，提前完成全年KPI，赚得盆满钵满；但也有受存储涨价影响的中小厂商，仍处于观望状态。</p>
  <p>“中小贸易商忙着终端客户极限拉扯，只能跟着行情走，小终端厂商因为接受不了芯片报价，不敢接新订单，也不敢备货，有的都提前放假了。”</p>
  <p>大多数人将这场存储芯片的暴涨效应归结于行业的「超级周期」。</p>
  <p>长期来看，是AI带来的结构性变化，AI应用、AI数据中心的扩容，算力狂飙带来存储需求上涨；短期来看，则是受巨头扫货抢货、DDR4停产以及部分存储厂商无节制抬高报价，导致了2025年以来存储涨价的涨幅远超行业预期。</p>
  <p>疯狂的存储，造就了一个折叠的造富江湖，它折射出的不仅仅是各种炒作乱象，还有更为复杂隐秘的洗牌期。</p>
  <h2><strong>存储暴涨，投机横生</strong></h2>
  <p>“长安米贵，也贵不过内存”。</p>
  <p>与曾经「缺芯危机」的造富神话一样，今年以来，暴涨的存储芯片里，也不乏类似的故事。在很多存储芯片分销商和贸易商看来，最疯狂的时间段是去年的5月至11月。</p>
  <p>李威记得，从2025年5月开始，身边入局存储芯片贸易的人越来越多。最疯狂的时候，一天一个价很正常，一些靠美光、三星等热门稀缺料号的溢价「倒一手」，几个月赚百万的也大有人在。</p>
  <p>到了2025年10月，存储价格更是成为社会话题，连他家门口的电脑店维修老板都来问一句：“（存储）还有没有入场机会？”</p>
  <p>一批头部存储芯片分销商也吃到了涨价周期的「头啖汤」。</p>
  <p>无论是从一家洗衣机配件厂成为股价暴涨明星标的的香农芯创（300475.SZ），抑或是江波龙（301308.SZ）、兆易创新（603986.SH）、中电港（001287.SZ）等存储企业，从设计、模组、代理到封测，相关产业链企业均受益于这股东风，业绩和盈利能力得到明显改善。</p>
  <p>以江波龙为例，因存储涨价潮，其2025年第三季度净利润同比暴增1994.42%。</p>
  <p><strong>但和每一轮行情的炒作起伏类似，热闹只是存储芯片市场的A面，B面则是很多行业从未有过的投机乱象。</strong></p>
  <p>存储芯片被视为「半导体的大宗商品」，和其他半导体品种相比，存储芯片的周期性更强，对供需关系的变化极其敏感。因为是高度标准化的通用元件，一颗符合JEDEC标准的DDR4或DDR5芯片，无论是来自哪个品牌，在容量、功能和接口都要满足规格标准，这种标品属性也意味着可以在客户侧互换来用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_03dadbfdab77408981645e35a669ab9d@5958598_oswg214035oswg972oswg558_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：CSDN</p>
  <p>换句话说，在存储芯片贸易中，交易双方更关注的也不是品牌差异，而是价格、速率、容量等，因此更容易形成标准报价，价格相对透明下，加上客户对规格、标签都有要求，存储芯片的分销生意并非一本万利，圈子也相对固定。</p>
  <p>但在暴涨的行情前，变化已经发生。</p>
  <p>据芯世相、芯存社报道，<strong>一些假冒存储产品的风险已经上升，涂标、假标和假货等问题也在变多。在社交媒体上，也有存储采购分享被卖翻新货的同行坑，而丢失客户信任的案例。</strong></p>
  <p>背后的关键原因是，随着入场的人越来越多，受市场价格情绪影响，原本存储芯片「原厂-代理商-贸易商-终端客户」间的交易链条越来越长，利益网络也日益复杂。</p>
  <p>李威告诉「硅基研究室」，这几个月成立的存储贸易新公司也很多，由于供需紧俏，出货单位KK（百万颗）转向K（千颗），大额订单也转向碎片化的小单，转手次数越来越多，很多交易也发生在贸易商和囤货商间，信息失真现象很正常。</p>
  <p>除此以外，还有故意抬价现象。</p>
  <p>有个别渠道厂商在业绩提前完成后，在控制接单量的基础上，依旧继续抬高报价来挑战新价格高度，并针对新成交订单延长交付时间，这也造成了个别品类的价格疯涨。</p>
  <p>好的信号是，<strong>2025年12月至今，这场由供需和情绪双重影响下的存储暴涨，也回归了一丝冷静。</strong></p>
  <p>尽管存储芯片价格依然坚挺，但有芯片贸易商也已意识到，不确定的市场情绪和环境下，求稳还是关键。</p>
  <p>“货不在手、价格离谱的一律勿扰，现款现货现结”。李威说。据机构CFM闪存市场的观察，因年末部分贸易商需回笼资金、获利了结，市场炒作行为也已有所收敛。</p>
  <h2><strong>分化的市场，巨头的AI阳谋</strong></h2>
  <p>在分销商、贸易商忙着「赚差价」背后，这场涨价潮背后，更大的驱动力是存储行业的结构性变化。</p>
  <p>表面来看，涨价的导火索是来自原厂们的涨价、停产通知，但这些只是控量的手段，并非是巨头真正的战略意图。</p>
  <p>存储行业更深层的变化是来自需求侧，眼前的这场AI这股浪潮正将存储推向一个分化的十字路口。</p>
  <p><strong>首先是AI驱动下，需求分化拉动厂商出货结构的分化，存储巨头下游最大的买家已经变了。</strong></p>
  <p>和此前两轮存储周期依赖单一驱动逻辑（第一轮依赖消费电子需求，第二轮依赖线上经济拉动PC需求）不同，第三轮存储周期主要是源自云厂商加码资本开支、豪赌AI数据中心下，拉动AI服务器需求的高涨。</p>
  <p>TrendForce曾预测，2025年全球八大头部云厂商资本开支预计同比增长约65%，而作为数据中心投资重心的AI服务器，其存储系统无疑是关键环节。</p>
  <p>以一张英伟达B200显卡为例，最大头的成本来自HBM3E显存，成本在2800到3100美元，占了将近一半的成本，比GPU还贵。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_488059aef8f64e64b3bf009c1d9ba042@5958598_oswg55679oswg940oswg869_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>以一台英伟达8卡服务器为例，据国信证券测算，单颗B200配置HBM3E（180GB/s），则单台服务器（8颗B200）合计1.4TB/s；主板DRAM为2TB（可拓展至4TB，即System Memory），服务器本地SSD为8个3.84TB（合计30.72TB）。</p>
  <p>IBM也曾披露，如果英伟达DGX B200服务器搭配IBM存储系统，4U（约127个计算节点）需要配置一个IBM Storage Scale 6000存储系统（加装9个硬盘HDD，对应3.4PB存储），则单台服务器对应27.4TB HDD。</p>
  <p>这些都是算得出来的存储需求。</p>
  <p>除此以外，考虑到多模态模型的发展，大量生成的图片、视频数据都需要存储，存储单位有望往TB乃至EB增长，同时大模型KV Cache等聚焦推理效率的技术机制也在进一步放大存储需求。</p>
  <p><strong>当存储巨头的最大买家从过去的智能手机厂商转向数据中心买家，原厂也优先将先进制程的产能分配给HBM和服务器DDR5，这也导致了DDR5价格的连续上涨。</strong></p>
  <p>去年11月，出席台积电年度运动会的英伟达创始人黄仁勋就特别感谢了三星、SK海力士和美光三大存储原厂：“他们都是极其出色的内存制造商，并且已经大规模扩产以支持我们。”黄仁勋说。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_530f3314384a40a097efab5d26d860e8@5958598_oswg1008167oswg1010oswg784_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：网络</p>
  <p><strong>其次，AI也带来了一个愈发分化的存储市场，增量和存量的增长逻辑完全不同。</strong></p>
  <p>一方面，作为增量的HBM无疑是当红辣子鸡。</p>
  <p>据IDC数据，2024年全球HBM市场规模为179.62亿美元，受益于全球AI芯片对HBM的需求，预计2025、2026年需求加速增长，对应24-26年的年复合增长率为59.7%。</p>
  <p>而回望去年第三季度，TrendForce的一组调研显示，通用DRAM合约价上涨、出货量季增，且由于HBM出货规模扩张，推升DRAM产业营收较前一季增长30.9%，达到了414亿美元。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_729d68ffacf745ad95163c28901f8e71@5958598_oswg241879oswg659oswg380_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>传统DRAM市场中，作为出货主力的DDR5受益于AI服务器需求，也成为了拉动原厂营收的关键增量。</p>
  <p><strong>但另一方面，尽管均受AI需求拉动，但NAND闪存应用场景更分散，其需求恢复的速度和确定性也稍弱于DRAM。背后的关键原因有二：</strong></p>
  <p><strong>一是市场格局不同。</strong>DRAM市场集中度更高，原厂有更大话语权。DRAM市场上三星、SK海力士和美光三大原厂长期合计占据超九成市场份额，牢牢掌握议价权。</p>
  <p>而闪存市场前五被三星电子、SK海力士、铠侠、闪迪、美光把控，供应弹性更大。同时，相比AI对内存市场的影响，闪存虽也因AI服务器拉动了对大容量企业级SSD的需求，但整体需求缺口小于内存。</p>
  <p>因此，闪存价格涨幅和内存相比更温和。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_15969155bbd3469aa29ca9f59358eebd@5958598_oswg67174oswg1080oswg1371_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">从行业指数来看，NAND指数更为温和 来源：CFM</p>
  <p><strong>二是竞争现状不同。闪存市场的竞争更激烈，内部分化也更明显。</strong></p>
  <p>相比企业级SSD市场受数据中心的拉动，消费级SSD和NAND Wafer在去年经历了猛烈的价格战，为了降低库存，原厂甚至开始以低于合约价的价格销售，薄利多销赚辛苦钱，也拖累了整体产品组合的盈利能力。</p>
  <p>存储市场因AI进入「超级周期」的背后，其实是一场需求结构的转变和持续分化的市场——HBM等增量市场持续走高，消费级SSD等存量市场则面临温吞的复苏。</p>
  <p>有业内人士坦言：<strong>“行业现在最需要关注的不该是「存储需求到底有没有」，而是「需求来自哪里、有何结构性变化」。”</strong></p>
  <h2><strong>隐秘复杂的洗牌窗口</strong></h2>
  <p>存储巨头们集体爆单，渠道网络看不懂价格涨幅，终端厂商在「涨价出货」和「不涨降利润」间抉择，消费者则高喊「存储太贵」，谁也不知道，这场「非理性疯狂」最终会对行业产生何种影响。</p>
  <p>但一个确定性的信号是，<strong>当AI占据了行业大量产能，隐秘的洗牌已经开始发生。</strong></p>
  <p>去年12月，美光宣布退出Crucial（英睿达）消费级业务，以追求数据中心和企业级产品此类拥有长期合同、更高的平均售价和更可预测需求的业务。</p>
  <p>SK海力士CEO郭鲁正在近期的SKAI Summit 2025峰会上，也高调宣布「全线AI存储创造者」的新战略版图，剑指定制化HBM（Custom HBM）、AI DRAM（AI-D）和AI NAND（AI-N）三大主要业务。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_f304266ccace4557b984aaf5d1105ec8@5958598_oswg198566oswg768oswg431_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">SK海力士产品路线图 &nbsp;图源：网络</p>
  <p>和市场对高位价格的关注不同，存储原厂已经提前做出了选择：<strong>跟随AI算力的红利期，加码先进存力资源，聚焦高利润业务。</strong></p>
  <p>与此同时，即便存储原厂已于近期相继宣布扩产计划，上调资本开支，但一座内存晶圆厂从建设到投产至少需要一年半，因此巨头们的新增产能计划对当下的直接影响依然有限。</p>
  <p>谨慎的扩产源自寒冬里吃过的苦头。</p>
  <p>从2022年开始，存储芯片价格一路狂跌。2023年，三星利润暴跌97%、SK海力士更是创下有史以来最大亏损，美光、西部数据等存储大厂的库存水位也持续攀升。</p>
  <p>据「半导体行业观察」数据，2023年几家存储大厂集体经营亏损预估达破纪录的50亿美元，创下了过去15年来最严重的低迷。</p>
  <p>一边是巨头退出的细分市场，一边是新增产能释放尚需时间，这也给国产存储厂商带来了机会。</p>
  <p>中芯国际CEO赵海军就曾指出：<strong>“主流供应商逐步退出碎片化、少量多样的细分市场，这一转变给众多中小规模供应商带来重要机遇”。</strong></p>
  <p>国产存储厂商近期在资本、产能和技术侧的动作，也在猛刷存在感。</p>
  <p>DRAM龙头长鑫科技IPO获受理，并在去年11月推出了DDR5颗粒及模组新品。</p>
  <p>长鑫科技招股书显示，小米、vivo、OPPO等智能手机厂商均为其客户，据财新报道，2025年小米高端机型也搭载了长鑫LPDDR5X产品，长鑫DDR5新品PC端已面向联想等客户供货。而与AI相关的服务器业务，长鑫目前正与腾讯、字节等客户进行验证。</p>
  <p>NAND领域的长江存储从2018年就开始将名为Xtacking的混合键合技术应用于64层NAND，没有缺席3D NAND闪存技术的大厂竞争，在2022年底发布了232层的3D NAND芯片，首条全国产化产线也已启动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260106/v2_251eee13594040fe913bb0e79b635721@5958598_oswg65264oswg1080oswg615_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另一家存储企业江波龙在去年12月拟定募集资金不超37亿元，加码AI领域的高端存储器研发及产业化、半导体存储主控芯片系列研发和半导体存储高端封测建设三大项目。</p>
  <p>现阶段，国产存储厂商的主线任务，仍然是抓住中国市场的机会，一边是合理利用价格优势，努力扩大市场份额，一边缩小技术差距，提升良品率。同时，积极利用此轮周期，尝试切入更多的现货利基市场。</p>
  <p>有存储芯片代理商告诉「硅基研究室」，他在推国产存储芯片时仍觉很难：“也不是产品不行，而是客户不敢用，毕竟进口型号选择更多，品牌效应和技术成熟度也更稳。”这意味着，从能用到好用，存储芯片的国产替代还需更漫长的周期以及产业协同的耐心。</p>
  <p>对国产存储厂商而言，这将是一场更残酷的竞争，华为公司高级副总裁、云CEO、数据存储产品线总裁周跃峰就用「前有狼后有虎」来形容当前国内存储行业的格局——</p>
  <p><strong>“前有国际巨头的技术壁垒，后有内部价格战竞争的拖累”。</strong></p>
  <p>放眼存储这片江湖，眼前的这场「超级周期」更考验基本功和AI新能力。</p>
  <p>一方面，在高度分工和全球化的半导体市场，存储行业先后经历的两次区域转移，从美国到日本，从日本到韩国，本质上依然遵循基本的常识规律：根据市场需求制定扩产策略，利用规模效应降低成本，并敢于逆周期投资押注下一代工艺，不断改进技术和产品，由此形成正向循环，<strong>这是基本功。</strong></p>
  <p>另一方面，在AI时代，新的竞争变量涌现，存储厂商正从过去的买芯片转向嵌入AI计算体系，与AI芯片厂商间的绑定越发紧密，这对存储厂商们的产品组合和交付能力都提出了更高的要求，<strong>这是新能力。</strong></p>
  <p>当这些隐秘的行业结构变化落到存储产业链每一个人身上，只能一同被裹挟进变局之中，像李威这样的从业者日常仍是是每天盯盘，回复询价，年末拜访终端客户，互相安抚情绪。存储资源交易群里，每天依然蹦出“还涨吗”的消息，入场退场的人也进进出出。</p>
  <p>这些折叠的造富故事，只是存储产业漫长周期的一个注脚，它不会是第一次，也不会是最后一次。</p>
  <p>参考资料：</p>
  <p>1、爱建电子：存储芯片涨价将延续至2026年</p>
  <p>2、国金证券：AI驱动存储新周期</p>
  <p>3、芯世相：最近买存储芯片，遇到两次假标了。</p>
  <p>4、国信证券：AI拉动需求增长，存储大周期方兴未艾</p>
  <p>5、第一财经：华为周跃峰：中国存储产业内外承压，但依然有望全球争先</p>
  <p>6、财新：存储芯片进入超级周期</p>
  <p>7、界面：全球存储芯片涨价潮席卷深圳：模组厂利润翻倍，代理商满仓囤货</p>
  <p>8、半导体行业观察：存储芯片，苦尽甘来？</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/j-ljaadBNvY-pzXbvqYU3A" rel="noopener noreferrer nofollow" target="_blank">“硅基研究室”</a>，作者：kiki，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>