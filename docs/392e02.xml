<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 科技频道</title>
        <link>https://www.36kr.com/information/technology</link>
        
        <item>
            <id>https://www.36kr.com/p/3530194899410052</id>
            <title>AI独角兽的商业化元年：新一代创业组织的崛起</title>
            <link>https://www.36kr.com/p/3530194899410052</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530194899410052</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 12:06:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9d31cc5957de411fad29119b21e61541@46958_oswg171645oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">来源：界面新闻图库</p>
  <p>核心观点：进入2025年，AI创投生态的焦点正从技术炒作转向商业化落地，AI独角兽们开始证明其可持续的收入模式。AI Agent和“AI原生”独角兽商业模式的发展成熟为全新的企业形态和创业模式提供了可能。</p>
  <h2><strong>AI行业引领全球独角兽生态规模的增长</strong></h2>
  <p>2024至2025年，全球AI初创企业的融资规模呈现出指数级增长：在2025年迄今为止诞生的54家估值超过10亿美元的公司中，超过半数（57%）是AI公司。资本正疯狂涌入这一赛道，风险投资中几乎每两笔就有一笔流向了AI初创企业。仅2025年上半年的AI行业融资额，便已超过2024年全年总和（图1）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3d2de0d59d524dbf9b67b0d1c7f0c536@46958_oswg265732oswg2028oswg1180_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图 1：2025年上半年AI行业的融资额已超过2024去年&nbsp;资料来源：CB Insights</p>
  <p>早期的AI投资主要聚焦于“AI+行业”的赋能逻辑,投资人关注的是如何用AI改造现有业务流程。但2024年后,投资逻辑发生了根本性转变。资本开始追逐那些只有AI才能创造的全新价值——如ThinkinMachinesLab（由前OpenAI首席技术官MiraMurati联合创立）在未推出任何产品的情况下以120亿美元估值完成20亿美元种子轮融资，这在传统创投逻辑中几乎不可想象（表1）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_cc5bfb38219c47c58f9766957be64849@46958_oswg260431oswg2726oswg746_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">表 1：2025年新晋的前五AI独角兽 资料来源：Pitchbook</p>
  <p>超级独角兽的崛起是本轮AI投资集中化最直观的体现。在近一年来相继完成巨额融资之后，全球估值前十的独角兽之中，已经有四家AI企业（大模型开发商OpenAI、Anthropic和xAI，数据智能和AI平台服务商Databricks）。这些企业的核心价值在于它们对算力、算法和模型的掌握，它们代表了当前市场对于AGI（通用人工智能）潜力的最高定价（表2）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8e804bb1e0514041a368ca0dec69f49b@46958_oswg175363oswg2128oswg470_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">表 2：2025年AI领域融资规模前五公司 &nbsp;资料来源：根据公开资料收集整理</p>
  <p>这些市场风向反映了市场对AI技术“范式突破”的预期。投资人押注的不再是渐进式改进,而是指数级跃迁——从弱人工智能到强人工智能、从任务执行到自主决策、从工具辅助到智能协作。高估值背后的逻辑是：一旦技术突破实现，市场空间将呈现非线性扩张。</p>
  <p>从商业化水平上来看，目前全球约有15家AI公司的ARR（年度经常性收入）超过1亿美元。ARR突破10亿美元的有三家：大模型企业OpenAI（100亿美元）、Anthropic（40亿美元），和AI数据标注企业ScaleAI（15亿美元）。而ARR从5000万美元到10亿美元之间的AI企业则基本上以各类AI应用为主。</p>
  <h2><strong>AI Agent和AI原生企业逐步实现商业化能力</strong></h2>
  <p>2025年，AI行业的创投热点向平台层和应用层全面铺开，特别是AI Agent（AI智能体），催生了颠覆性的产品与体验。</p>
  <p>AI Agent是一个基于大语言模型（LLM）的系统，旨在通过推理、规划和与外部工具交互，代表用户独立执行任务。</p>
  <p>在不到一年的时间里，AI Agent领域已从大约300家企业发展到数千家。从电子商务到工业，Agent正在逐渐融入各个垂直行业的工作流程。而底层模型能力的每一次跃升，都直接转化为AI原生创企ARR的阶跃式增长。</p>
  <p>这些创企的产品价值主张完全建立在AI能力之上。Cursor的代码补全、Harvey的法律文书生成、Abridge的医疗记录自动化——这些产品的核心功能在没有AI的时代根本无法实现。它们的产品核心价值随模型的性能提升而提升，而非运营效率。</p>
  <p>例如，2024年9月，法务AI初创公司Harvey宣布，OpenAI的o1推理模型，加上特定领域的知识和数据，使其能够构建法律Aent。该公司于2025年2月以30亿美元的估值融资3亿美元，过去6个月其销售团队规模翻了一番，并达到了1亿美元的营收门槛（表3）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c70d9bb505544377bd8e0516b6704eb6@46958_oswg293103oswg2676oswg986_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">(选填)图片注：Cursor为Anysphere公司推出的AI智能体 &nbsp;资料来源：CB Insights描述</p>
  <p>2025年新晋独角兽中，五分之一正在打造AI智能体，这些独角兽展现出惊人的成长速度。Anysphere从成立到估值99亿美元仅用了3年,其产品Cursor的ARR已达5亿美元。Lovable成立仅2年即达到1亿美元ARR和35亿美元估值。这些数字在传统SaaS时代需要7-10年才能实现。</p>
  <p>快速增长背后是AI技术对产品开发周期的极度压缩。传统软件企业需要大量工程师、漫长的开发周期、反复的测试迭代。而AI原生企业可以利用基础模型快速构建原型、通过生成式AI自动化大量开发工作、依靠智能化产品实现自然增长。这种“AI加速的AI创业”形成了正向飞轮：更快的产品迭代→更好的用户体验→更快的营收增长→更多的资本支持→更强的技术投入。</p>
  <p>在商业化模式上，AI服务正在从早期的软件订阅转向结果导向型付费。对于能够完全自主执行复杂任务的AI Agent功能，则可能采用按任务成功率或计算时长按需付费。这种模式的灵活性能够更好地服务于不同规模和需求的客户。</p>
  <p>当AI Agent能够自主完成高价值任务（如自主生成法律文件、优化复杂供应链），收费将基于其交付的结果质量和业务影响，而非仅仅是使用时长或用户数量。这种结果导向的商业模式解决了传统软件订阅模式无法匹配AI所提供的非线性价值的问题。</p>
  <h2><strong>“数字同事”正在从概念走向现实</strong></h2>
  <p>AI Agent初创公司在2024年融资38亿美元（几乎是2023年总额的三倍），所有大型科技公司领先的大模型开发商都在开发通用的AI Agent或为其提供工具。更加自主的AI Agent将对企业产生深远的影响，从改变员工结构（建立由人类和AI Agent组成的新型混合团队）到通过完全自动化日常任务来最大化运营效率。</p>
  <p>由于大部分企业倾向于选择成熟的供应商，大型科技公司在AI智能体开发方面拥有显著优势。同样，像Salesforce（Agentforce）和ServiceNow（AI Agent Marketplace）这样的企业软件巨头已经推出了针对其现有客户群的智能体平台。</p>
  <p>然而，技术栈各层的初创公司正在通过解决特定技术挑战并突破智能体能力边界来建立市场地位，规模较小、专业化的参与者也拥有许多机会。在AI时代，专业化深度与生态位选择同样重要。</p>
  <p>以ARR已达1亿美元的AI+办公独角兽Glean为例，其核心产品包括Copilot产品Glean Assistant、Glean Agents、Glean Search等。Glean通过深度理解企业数据结构和权限体系，构建了一个“企业内部的Google”与ChatGPT通用大模型等不同，Glean基于对企业数据的整合+RAG（检索增强生成）技术，实现企业内部AI搜索。</p>
  <p>展望未来，值得关注的是Agent如何以更有突破性的形态出现。这方面的早期迹象体现在“AI原生”产品——这些工具和平台从一开始就围绕AI能力构建，而不是在传统产品上叠加AI功能。</p>
  <p>通用AI助手与企业工作流自动化：横向AI智能体创业公司目前在整个智能体市场版图中占比最高。这一细分领域主要包括面向企业的初创公司，提供跨行业的通用应用，横跨不同企业系统（包括ERP、CRM、HRM等），覆盖人力资源/招聘、市场营销和安全运营等各种工作职能。主打生产力与个人助理的公司，包括OpenAI及其Operator智能体，则直接面向消费者和员工。</p>
  <p>发展势头最强和竞争最激烈的AI智能体领域是客户服务和软件开发（包括编码以及代码审查与测试智能体），智能体能够为明确定义的工作流程和带来巨大价值。以软件开发为例，智能体的能力已从代码辅助工具发展到能够负责从需求分析、架构设计到部署监控的全流程自主软件开发。</p>
  <p>企业工作流自动化则聚焦于那些重复性高、规则明确、但仍需人工处理的任务。从发票处理到客户服务，从库存管理到合规审查，AI智能体正在接管这些“无人喜欢但必须完成”的工作。这些Agent不仅能执行单一任务，还能理解跨系统的业务逻辑，实现端到端的流程自动化。</p>
  <p>创意与开发辅助工具：AI编程Agent在商业化方面遥遥领先，其中6家软件开发代理名列前茅，包括Anysphere的Cursor（ARR5亿美元）和Replit（ARR1.5亿美元）等市场领先者。根据创投数据机构CB Insights的统计，客户服务AI Agent的估值溢价最高，平均为收入倍数的219倍。这种估值差距反映了投资者对该赛道的信心，以及企业将迅速用AI取代人工团队的预期。</p>
  <p>AI+编程场景渗透率高，海内外科技公司程序员普遍使用AI编程工具提质增效。其中佼佼者为2025年新晋独角兽Anysphere的产品Cursor。Cursor上下文管理能力较强，其功能出众的Tab键补全，可以精准预测用户下一次编辑，并且一次为用户提供跨多行代码建议，加强沉浸式代码创作体验，广受用户好评。</p>
  <p>垂直领域智能体：面向特定行业的垂直行业Agent也在不断涌现。初创公司通过解决特定行业的客户问题来开辟细分市场，特别是在监管严格和数据敏感的领域，例如前文提到的Harvey。Harvey在法律领域的成功证明：当AI掌握了领域知识、理解了行业工作流、并能生成符合专业标准的输出时,它可以承担律师助理、甚至初级律师的部分工作。医疗和金融领域的AI创企正在复制这一模式，通过“行业数据+合规框架+工具化能力”的深耕，吃下完整工作流。</p>
  <p>AI智能体的可靠性仍然是该领域面临的一大挑战。智能体一旦出现故障、出现幻觉或行为异常，就会立即带来业务风险。随着人工智能能力的提升，我们预计会有更多初创公司在自主性方面迈进。推理能力和记忆能力的提升将带来更复杂的决策、适应能力和任务执行能力。</p>
  <h2><strong>AI对创业组织形态和发展模式的革新</strong></h2>
  <p>随着基础模型能力的提升，智能体预计将变得越来越自主——从静态任务执行演变为更具适应性、以推理为驱动的系统，支持动态决策。随着AI智能体的不断发展，创业者将发现生成式AI使创业变得廉价和方便——任何人都能成为创业者，就像任何人都能成为自媒体博主一样。AI将信息密度和处理能力集中到极少数关键人才手中，赋予个体创业者相当于一个中型组织的生产力。这不仅显著降低了初创企业的资本需求，也使得组织决策和产品迭代速度实现指数级加快。</p>
  <p>AI原生企业的核心商业逻辑在于由“人机混合”团队构建组织杠杆：少量专家与大模型/智能体协作，完成过去需大规模人力的研发、客服、运营等。一旦基础模型和智能体架构发展成熟，其边际成本会极速下降。模型的每一次迭代都可能带来产品的非线性性能提升，而不需要传统企业那样线性地增加人力或运营投入。它们的价值增长依赖于对专有数据的捕获和利用，而非传统的渠道或人力规模。</p>
  <p>AI智能体和数字员工的发展将推动“AI平权”的新一波浪潮——创业者的技术背景将不一定最为重要，重要的是发现能够用AI解决的问题，这又要求创业者对AI的能力和局限有深刻的理解，以及能否构建出比通用模型更优越、更专业的产品。</p>
  <p>但另一方面，尽管生成式AI对创业者带来了可观的前景，但它也让快速复制创意变得更加容易。要想在AI创业生态占据一席之地，创业者需要花更多心思打造独特的竞争优势，比如能够解决ChatGPT和DeepSeek等通用型聊天机器人无法解决的问题，而非仅仅是提供边际效率改进。</p>
  <p>作者：滕斌圣，长江商学院战略学教授，战略研究副院长，新生代独角兽全球生态体系研究中心主任/何涧石，长江商学院新生代独角兽全球生态体系研究中心研究员</p>
  <p>本文来自<a href="https://www.jiemian.com/article/13544752.html" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，记者：滕斌圣、何涧石，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530204943850633</id>
            <title>美的的新竞争对手，为什么是小米？</title>
            <link>https://www.36kr.com/p/3530204943850633</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530204943850633</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 12:06:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>美的和小米，一个是制造业的王者，一个是互联网的翘楚，合作的余温尚未远去，竞争的寒光已经亮剑。</p>
  <p>2024年，美的清仓所持有的小米集团全部股份，结束了双方始于2014年的“联姻”。资本层面友好“分手”伴随着产品层面的直接竞争。2025年上半年，美的集团营收2523.31亿元，同比增长15.58%；小米以家电和可穿戴产品为主的IOT与生活消费产品收入710.51亿元，同比增加50.7%，其中智能大家电成为增长的核心引擎。</p>
  <p>虽然体量尚有差距，但是小米的增长速度远超传统家电品牌。“2030年进入大家电头部品牌，空调业务做到中国市场前二。”小米集团总裁卢伟冰如是说。</p>
  <p>中国家电市场并不是一个站在风口上的性感的领域，三十年的竞争洗牌，形成了美的、海尔、格力为主导的格局（CR1约25%-40%，CR3约60%-80%）。其中美的年营收约等于后二者之和，成为市场绝对的霸主。而当下，美的最担心的不是昔日对手的追赶，而是小米这个闯入者会使出什么招数。</p>
  <p>一场正在发生的商业奇袭，将如何改变稳固了十年的家电竞争格局？</p>
  <h2><strong>美的的对手为什么不是海尔格力</strong></h2>
  <p>以风扇工厂起家的美的，从1980年涉足家电行业，到2008年营收规模超越海尔，2014年市值超越格力，营收年均复合增长率达12.3%，全球份额7.1%，用四十年时间成长为中国制造业的优秀样本。</p>
  <p>其所在的家电行业，90年代初的萌芽起步期、2000年后的扩张洗牌期，在2010年前后进入龙头主导且市场集中度较高的阶段。美的、海尔、格力三巨头在技术积累、渠道建设、品牌认同和供应链管理等方面构筑的综合壁垒，使得新进入者难以撼动其市场地位。</p>
  <p>从规模上看，美的绝对领先，但是海尔、格力也各有所长。</p>
  <p><strong>美的如同装备精良、多航线并进的航母编队。</strong></p>
  <p>在C端，美的通过多品牌矩阵覆盖不同客群：COLMO对标高端市场，美的品牌主攻中端，华凌则瞄准性价比市场。企业官网数据显示，美的拥有空调产品568款；冰箱505款；洗衣机523款；厨房小电器1069款；厨房大电器277款；生活家电608款；热水/净水385款。</p>
  <p>在B端，美的布局新能源与工业技术、智能建筑科技、机器人与自动化三大板块，2024年to B营收首次突破千亿元规模，占公司总收入的25.7%，成为第二曲线。</p>
  <p>据产业在线数据显示，2025年上半年美的家用空调压缩机、家用空调电机、洗衣机电机的全球市场销量份额均稳居行业第一，冰箱压缩机的全球市场销量份额亦位居行业前列。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_13c0d7c85de240f2a03408d79750afc1@46958_oswg1133891oswg1080oswg2766_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>海尔是走高端路线，以卓越体验著称的豪华邮轮。</strong></p>
  <p>海尔智家在过去10年收购了美国GE、日本三洋、新西兰斐雪派克、意大利Candy、南非Kwikot，加上自有高端品牌卡萨帝与场景品牌三翼鸟。在中国市场，通过卡萨帝、海尔、Leader等三个品牌实现对高端、主流、细分市场人群的覆盖；在美国市场，通过Monogram、Café、GE Profile、GE、Haier、Hotpoint等六大品牌，覆盖高中低端各细分市场。在全球形成7+1（Haier、Casarte、Leader、GE Appliances、Fisher＆Paykel、AQUA、Candy+三翼鸟）的世界一流品牌集群。</p>
  <p>海尔智家旗下拥有空调产品256款；冰箱299款；冷柜192款；洗衣机517款；电视69款；厨电201款；生活家电394款；电脑及外设180款（企业官网数据）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c6c4598869774412991ba8500ef05137@46958_oswg653614oswg1080oswg2246_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>格力则深耕空调主航道，拥有"专业聚焦+渠道控制"的巡洋舰。</strong></p>
  <p>格力旗下有格力、TOSOT、晶弘三大消费品牌及凌达、凯邦、新元等工业品牌。格力具备核心零部件研发制造能力，有凌达压缩机、凯邦电机、新元电子、格力电工及格力模具等子公司处于行业前列，对产品承诺“十年免费包修”。</p>
  <p>格力拥有空调产品109款；中央空调28款；冰箱40款；冰柜8款；酒柜1款；洗衣机24款；热水器33款；智能产品25款；生活电器56款（企业官网数据）。</p>
  <p>格力对销售渠道掌控力强，同时与企业家形象深度绑定，通过“董明珠健康家”线下门店和线上自营及第三方电商平台协同布局，提升格力全屋智能家电的曝光度和关注度。但格力产品单一，2024年78%收入仍来自空调。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_98326f078afa4aa3a235eb3265e40b81@46958_oswg53291oswg1080oswg494_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从财报数据看，2024年，美的集团营收4071亿元，同比增长9.47%。智能家居业务占比65.9%，营收2695亿元，同比增长9.41%。海尔智家营收2859.81亿元，同比增长4.29%，白电占比超70%。格力电气营收1900.38亿元，同比下滑7.31%，空调业务占比超 70%。&nbsp;</p>
  <p>2025年上半年，美的集团营收2523.31亿元，同比增长15.58%；海尔智家营收规模突破1500亿元关口，同比增长10.22%；格力电器营收973.25亿元，同比下滑2.46%。<strong>美的全面领跑，海尔高端突围，格力则面临承压转型。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_36e36f03b3934649ad0efe5ce9260fa4@46958_oswg198589oswg1080oswg653_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>美的的增长更多来自市场份额的扩张和产业链效率的持续提升，海尔依赖于品牌价值的持续提升和高毛利产品的成功推广，格力则受困于产品单一，多元化受阻。</p>
  <p>作为没有短板的全能选手，美的的领先优势不断扩大，海尔和格力及其他第二梯队的家电品牌，已经很难超越它。</p>
  <h2><strong>美的对手为什么是小米</strong></h2>
  <p>上半年，美的集团董事长方洪波读了十几万字的小米研究报告，并对媒体表示，“<strong>我们所有的领域小米都进入了，空调、洗衣机全做了。战术上我重视小米，但战略上我并不害怕小米进来。</strong>”同时，美的要改变策略，往下走。“我不能坐视小米蚕食这个市场而不反应，我要往下走，拼成本，要跟他们干”。</p>
  <p>美的对小米的警惕，源自过去五年小米在家电领域高歌猛进。2018年，小米推出空调、洗衣机进入家电领域，瞄准年轻化与科技爱好者，采取爆品策略+低价高配+小米生态组合拳，以接近成本的价格销售硬件，快速获取用户，并将消费者纳入“手机×AIoT”生态，通过后续的互联网服务和生态产品实现长期盈利。</p>
  <p>2024年小米IoT与生活消费品业务收入达1041亿元，同比增长30%，成为公司第二大收入来源。空调出货量超680万台，同比增长超50%。冰箱出货量超270万台，同比增长超30%。洗衣机出货量超190万台，同比增长超45%。均创历史新高。</p>
  <p>2025年小米半年报显示，智能大家电成为推动该业务增长的核心引擎。第二季度，小米空调出货量超540万台，同比增速超60%；冰箱出货量超79万台，同比增长超25%；洗衣机出货量超60万台，同比增长超45%。IOT与生活消费产品业务的毛利润达到168.76亿元，超越智能手机业务的毛利润115.02亿元，成为小米集团利润贡献的首要主力。</p>
  <p>小米对家电业务野心勃勃。小米集团董事长、CEO雷军表示，“<strong>家电业务已经变成了小米的战略业务。</strong>”小米集团合伙人兼总裁卢伟冰则在Q1财报会上表示，米家空调2030年在中国大陆市场要做到数一数二，今年中国大陆公开市场销量目标第三，技术全面对标全球头部品牌。</p>
  <p>曾经，分属家电和互联网两个行业的美的和小米，也有过一段你侬我侬的甜蜜合作时期。</p>
  <p>2014年，美的与小米各自投资约12.7亿元进行交叉持股，方洪波当时将此称为“制造思维与互联网思维的化学反应”。双方希望实现优势互补，美的提供全品类家电产品与制造能力，小米贡献互联网思维、移动互联网入口和智能生态经验。</p>
  <p>随着小米在家电领域持续发力，美的逐步减持小米股票。美的2024年财报显示，美的清仓小米股票，套现9.02亿元。几次套现美的从小米股票上回笼的资金近20亿元。尽管美的声明是一次正常的财务投资，但市场不少观点认为，这标志着家电供应链从“合作”走向“博弈”。</p>
  <p>10月22日，国家知识产权局信息显示，美的集团旗下负责美的IoT全屋智能解决方案的子公司——广东美创希科技有限公司（统称“美的”）——已经向国家知识产权局对小米科技有限责任公司的一件名为“智能家电控制方法、装置及终端”的发明专利201410112307.0发起了专利无效挑战，并定于2025年11月26日在国家知识产权局进行口审听证。<strong>这也是今年3月美的彻底清仓小米股票后，双方之间爆发的首次专利纠纷。</strong></p>
  <p>在股东大会，方洪波对“战略上不害怕小米进来”做了进一步阐述：一是家电行业门槛较低、高度竞争，已经经历过多次红海竞争，打法固定，也没什么新的招数；二是家电行业的增长空间也比较小，价值链的降本增效你能做到，别人也能做到；三是即使有哪家企业可以胜出，都是一场巨大的消耗战，无论是小米还是追觅，或者是原来几个头部玩家。</p>
  <p>对家电行业来说，小米带来了一套完全不同增长路径。小米的互联网打法是一套高度协同的“组合拳”，通过论坛、社交媒体深度互动圈定用户，用高性价比的硬件产品（主要是手机）吸引流量，持续为用户提供高性价比的消费硬件（包括但不限于：平板、耳机、AI眼镜、插排、空气净化器、热水器、空调、冰箱、洗衣机、汽车等），通过互联网增值服务实现盈利。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6e352e0038324c8c9b3434e339174f50@46958_oswg38878oswg1080oswg236_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图：小米家电全部品类</p>
  <p>小米家电SKU数量较少且产品线清晰，以爆品为主，通过供应链和生态链企业，快速推出高性价比产品；通过米家APP和小爱同学语音助手，提供全屋智能解决方案。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_fd2f90b56e65414ebef5355442df5e60@46958_oswg493128oswg1080oswg1479_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在渠道上，小米凭借线上渠道优势和粉丝经济高速增长，线上市场份额一度超越格力。今年8月中旬，卢伟冰转发了奥维云网数据“小米空调线上销量超越格力”的消息，力证小米要当“空调二哥。”</p>
  <p>小米也在补足自身在制造及品控的短板。10月28日，小米智能家电工厂一期竣工，这是小米空调的主要生产基地，预计每6.5秒即可下线一台高端空调，每平米年产能达51台，峰值年产能可达700万套，预计年产值140亿元，将于明年开启空调产品的大规模量产。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8b6cf1c689f64d02ae5eab3b3dc5d158@46958_oswg223085oswg1080oswg1520_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>在增长见顶的家电存量市场中，小米作为强劲的“分食者”，每一口增长，都意味着其他玩家碗中的份额在减少。</strong></p>
  <p>截至2023年末，我国城镇空调、冰箱、洗衣机及彩电的百户保有量分别为148.3台、102.5台、99.2台及122.8台，农村相应品类的百户保有量分别为71.3台、98.6台、91.6台及117.6台。考虑到冰箱、洗衣机及彩电多数情况下为“一户一机”，这三类产品基本已经实现普及。</p>
  <p>但是，空调有“一户多件”属性，可对标的日本及中国台湾地区当前空调百户保有量分别约为280台及240台，空调及厨电仍有一定普及空间。这是为什么小米强势进入空调领域，“手撕”格力，追赶美的。</p>
  <h2><strong>以小米为对手，对美的来说意味着什么</strong></h2>
  <p><strong>就像曾经在手机领域的策略一样，小米在家电领域先打出了“性价比”牌。</strong></p>
  <p>卢伟冰认为，一些传统家电品牌利用高利润驱动，将价格高昂的产品推向市场，损害了消费者的利益。小米空调的利润率仅为10%左右，远低于传统家电行业普遍存在的30%至40%的利润空间。</p>
  <p>过去十年，家电企业忙于高端化，海尔在全球“买买买”，美的也收购COLMO进入高端市场，小米则凭借极致性价比，在2500元以下价格段如鱼得水。奥维云网数据显示，2024年小米空调线上均价为2364元，显著低于格力（3544元）和美的（3191元）。</p>
  <p>美的也在2025年半年报中表示，空调行业均价明显下探，中高端需求承压，其中线上市场的2200元以下的价格段销售份额提升至35.2%，而2200-3000元的中端价格段份额则快速收窄。</p>
  <p>面对小米的性价比攻击，美的并未让主品牌与小米直接血拼，而是派出子品牌“华凌”在线上市场与小米正面交锋，同时利用制造优势，给出具有杀伤力的价格。小米1.5匹空调价格集中在1699-2399元，华凌则强调“性能不输高端，价格更亲民”，1.5匹空调价格集中在1699-2799元。</p>
  <p><strong>小米的另一张牌是“互联网思维”和生态链。</strong></p>
  <p>截至2025年6月底，小米AIoT平台已连接的IoT设备数（不包括智能手机、平板及笔记本计算机）增长至989.1百万台，同比增长20.3%；AIoT平台连接的IoT设备总数9.89亿台，创历史新高。</p>
  <p>而美的也有对应的智能家居生态（M-Smart）。截至2025年6月底，美居APP注册用户规模突破8000万，月度活跃用户超过2000万。美的物联网平台累计联网设备超过1.2亿台，月均在线设备数达4300万。已应用于空调、冰箱、洗衣机、烤箱等产品，为用户提供语音控制、家居知识问答、场景生成等服务。</p>
  <p>以高性价比硬件为起点圈定用户，以后续互联网服务持续转化用户，这是小米不同于家电企业的商业策略，但是互联网模式追求"快速迭代"和"流量变现"，并不能补足工业制造注重"技术沉淀"、"品控一致性"和"供应链韧性"。</p>
  <p>消费保投诉平台数据显示，2025年前三季度，家电行业总投诉量为4576件，小米2404件，其中Q3环比增长690%。格力、美的、海尔分别有投诉量725件，美的477件，海尔163件。投诉主要主要聚焦于产品质量，其次是售后服务。</p>
  <p><strong>从方洪波对小米竞争的阐述可见，美的并未跟进小米的方法论，而是在制造这一主航道上坚持深化布局，以不变应万变。</strong></p>
  <p>2025年上半年，美的在全球新增18个海外制造基地，目前全球制造基地总数达到63个，并深入推行“区域供区域”模式，以应对贸易壁垒和供应链风险。同时，美的力推DTC模式转型，旨在缩短与消费者的距离，更快速地响应市场。</p>
  <p>家电同时具有工业品和消费品双重特征。作为工业品，家电有一定的制造门槛，但技术壁垒不高，核心技术迭代速度较慢，供给端具备规模经济和较高集中度，一旦竞争格局成型，马太效应将会持续显现。作为消费品则意味着，如果制造不构成瓶颈，销售就成为首要问题，关注需求、品牌和渠道就尤为重要。</p>
  <p>随着小米业务从3C扩展到家电、汽车等更为复杂的领域，"人车家全生态"战略创造了协同效应，但不同品类有其专业壁垒。如何在推动生态互联的同时，确保每一款产品在各自领域都能达到顶尖的专业性能，而非止步于"生态入口"，是小米需要持续证明的。此外，不同业务线的风险叠加，小米经典的粉丝经济也面临新的挑战。</p>
  <p>能打败的美的的，或许并不是小米，而能打败小米的，只有它自己。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/lVskI3eiFJz7JtPuFQl1Lw" rel="noopener noreferrer nofollow" target="_blank">“亿邦动力”</a>，作者：胡镤心，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530194299034497</id>
            <title>AI爆点转移至多模态，体现了什么行业趋势？</title>
            <link>https://www.36kr.com/p/3530194299034497</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530194299034497</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 12:03:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8aa2368f87cb4d2b82f4b64bd24acaf1@46958_oswg97008oswg700oswg398_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：界面新闻</p>
  <p>2025年的AI爆点正在发生转移。</p>
  <p>自DeepSeek R1上半年引爆行业情绪之后，“纯文本+推理”范式下的模型鲜少再现重量级成果。进入下半年，话题重心明显滑向多模态领域。</p>
  <p>Sora 2被封装成可交付应用、谷歌推出图像编辑能力更强悍的Nano Banana；AI Agent这端同样如此，在Manus这样文本属性更突出的通用型产品之后，达到相近级别热度的是主攻视觉创作场景的LoveArt。&nbsp;</p>
  <p>在这背后，文本模型的迭代进入一种基线较高、小步抬升的阶段，而多模态理解与生成能力在可用性上，向“破圈”层级又近了一步。</p>
  <p>一名从事模型训练的研究人员对界面新闻记者指出，要理解这个现象，首先要认识到文本与多模态两个方向的研究是并行而非串行。</p>
  <p>经过GPT-3、GPT-4、OpenAI o1等重大节点之后，大模型的语言理解能力足以交付C端（用户）应用，后续优化集中在稳态工程，例如对齐、降本、延迟优化、鲁棒性等等，这些能够进一步优化C端应用体验和B端（企业）商用价值，但用户感知不再像GPT-4来临时那样有强烈冲击。</p>
  <p>一个典型的例子是DeepSeek-OCR。这是一个在话题性上不足以震撼人心的demo，但有其长期影响力。</p>
  <p>DeepSeek-OCR在10月20日推出，定位于探索文本的视觉压缩能力（光学上下文压缩，Contexts Optical Compression）。简单而言，随着上下文输入增多，模型计算量以平方级陡增，但通过将长文本转化为图像识别，可以大幅压缩token计算数量。这一思路得到验证的成果是，它一旦落地到应用端，也是一个前景颇为确切的降本增效方式。</p>
  <p>多模态这一侧完全不同，其能力曲线仍在还可以被更多人感知的区域内。不过，前述受访者指出，从并行的思路来看，多模态模型这端还未实现架构层级的突破，更多是足够的数据累积和训练技巧提升。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_27de5636eb314bd295846cfb48332414@46958_oswg3744574oswg5376oswg3584_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源：界面新闻</p>
  <p>正如他对Sora 2和Nano Banana的判断，除去OpenAI对多模态生成类产品的初步构想成型，以及谷歌对图像编辑器现阶段用户需求的把握（例如锚定一个点进行针对性修改），两款产品在生成质量上并未实现飞跃。&nbsp;</p>
  <p>并且，在很大程度上，以“文生图、文生视频”为代表的多模态生成领域，其表现优化是以文本模型性能提升为前提。阶跃星辰创始人兼CEO姜大昕此前在接受界面新闻记者采访时指出，理解与生成之间的关系是，理解控制生成、而生成监督理解。</p>
  <p>一级市场也在见证这种关注点切换。一名AI投资人对界面新闻记者表示，他的体感是今年行业整体投资事件增多，但投资规模在降低，这是投资重点由模型层向应用层过渡后，后者的市场规模及估值所决定的。</p>
  <p>在这之中，今年最显眼的一笔来自应用层视觉创作领域的LiblibAI。10月23日，LiblibAI宣布完成1.3亿美元B轮融资，红杉中国、CMC资本等参与其中，促成今年国内资本市场AI应用赛道最大的一笔融资。这意味着相较其他赛道，团队的PMF（product-market-fit）更大程度受到资本认可。</p>
  <p>在往后很长一段时间，业界能够期待的“爆点”或许都将更多来自于多模态领域。&nbsp;</p>
  <p>姜大昕一直强调的观点是，光有语言的智能不够，多模态是大模型的必经之路。而在这片领域，理解与生成的统一仍是现阶段的突破点。&nbsp;</p>
  <p>多名受访者曾对界面新闻记者表示，站在模型训练角度，视觉模态比文本模态面临的挑战更大。单从数据上来看，文本的表征可以在语义上自闭环，但视觉信息的表征需要先与文本对齐，不存在天然自闭环的数据，“可能需要几次像ChatGPT、强化学习范式这样的大技术变迁才能解决。”一名受访者说。&nbsp;</p>
  <p>而一派观点认为，基于更好的多模态模型，世界模型、具身智能、空间智能等才能得到长足发展，行业才能进一步靠近AGI（通用人工智能）。&nbsp;</p>
  <p>更现实的考量是，模型决定应用能力上限，在文本模型集中火力降本增效和缓慢提升性能的同时，多模态模型的突破有望给市场带来更多PMF机会，这将是创业者和投资人眼中更具实际价值的关键变化。</p>
  <p>本文来自<a href="https://www.jiemian.com/article/13554463.html" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，记者：伍洋宇，编辑：文姝琪，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530189976492931</id>
            <title>因人工客服无法接通，爱奇艺、转转等互联网企业被工信部点名</title>
            <link>https://www.36kr.com/p/3530189976492931</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530189976492931</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 12:02:37 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_20b030840f364dc2b9c638d2be69d1e6@46958_oswg41995oswg640oswg364_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：界面图库</p>
  <p>10月29日，界面新闻了解到，“工信微报”近日发布消息称，工业和信息化部发布《关于2025年第三季度电信服务质量的通告》（下称《通告》）。</p>
  <p>《通知》提到，组织第三方机构对部分重点互联网企业客服热线进行拨测，搜狗浏览器、嘀嗒出行的客服热线未提供人工客服，爱奇艺、转转、搜狐新闻的人工客服无法接通，已督促相关企业进行整改，切实提高服务能力。</p>
  <p>《通知》还指出，组织开展APP技术抽测47批次，责令整改1970款，公开通报203款，下架76款。推广“二次号码焕新”服务，深入推进一键解绑历史互联网应用账号工作，目前已覆盖230余款主流应用，处理解绑申请超2.6亿次，累计服务用户超430万人。</p>
  <p>2025年第三季度，全国电信用户申诉中，涉及服务争议的申诉占比42.1%，涉及资费争议的申诉占比37.3%，涉及营销的申诉占比10.1%。各级电信用户申诉受理机构按照《电信用户申诉处理办法》相关规定，对用户申诉进行处理和调解，有效维护了电信用户合法权益。</p>
  <p>互联网信息服务投诉平台收到的互联网用户投诉中，服务功能类投诉占比47.2%，客服渠道类投诉占比18.2%，个人信息保护类投诉占比17.9%，其他类投诉占比16.7%。在接入平台的178家互联网企业中，多点等3家企业投诉处理及时率较低，工业和信息化部已督促相关企业妥善处理用户反映的问题。</p>
  <p>不良手机应用投诉中，涉及网络安全问题的投诉占比49.7%，涉及个人信息及权限问题的投诉占比29.6%，涉及信息安全问题的投诉占比20.7%。中国互联网协会联合应用商店、安全检测厂商对存在问题的142款不良手机应用进行下架处理。</p>
  <p>7月30日，工信部曾通告2025年第二季度电信服务质量情况，提到第二季度责令整改1449款、下架50款App。好看视频、哈啰、网易云音乐、优酷视频的客服热线无法找到人工客服，豆瓣、酷狗音乐人工客服接不通，已督促相关企业提高服务能力。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UIQxDoc1yb2wrYf0BBBI-Q" rel="noopener noreferrer nofollow" target="_blank">“界面新闻”</a>，作者：江怡曼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530164535794566</id>
            <title>站在内容创作者与机器人的交界处：聊聊3D数字人的进化</title>
            <link>https://www.36kr.com/p/3530164535794566</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530164535794566</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 11:20:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在人工智能的浪潮里，3D数字人正在悄然改变着我们内容创作和互动的方式。你或许已经发现，数字人主播和虚拟偶像们，看起来越来越流畅自然了。这背后是一场数字人的技术革命：如今的3D数字人不再是那个表情略显僵硬、只能按预设脚本运行的“木偶”；它们能够根据指令，实时地生成丰富的语音、精准的表情，协调的肢体动作，并且成本变得可被接受。</p>
  <p>进化的数字人，不仅活跃在当下的直播间和客服中心，未来更将在3A级游戏和影视工业领域大展拳脚。然而你可能不知道的是，3D数字人滥觞于机器人领域。在计算机图形学与机器人学之间，存在着一道打通虚拟与现实的“旋转门”，几十年来不断有学者穿越这道门走向另一端去寻求突破之道。</p>
  <p>过去，研究者们用驱动机器人的方式，驱动虚拟世界中的数字人；如今，数字人所积累的经验，又反过来帮助机器人去理解物理世界的错综复杂。</p>
  <p>本期《硅谷101》，主播泓君邀请了魔珐科技创始人兼CEO 柴金祥教授 。柴教授从2000年左右便在卡内基梅隆大学机器人研究所投身3D数字人研究，已经从事该领域二十余年。泓君与柴教授深入聊了3D数字人的前世今生，它取得了哪些突破性的进展，又面临着哪些挑战，以及数字人的数据和模型是如何加速具身智能进化的。</p>
  <p><strong>以下是这次对话内容的精选：</strong></p>
  <h2><strong>01 数字人：下一代内容生产者</strong></h2>
  <p><strong>泓君：前几天，硅谷大家都在关注Sora2，好像每个人都会拿它去做一段Demo，包括我们前几天刚刚开了《硅谷101》的科技大会，我们就生成了一段让Sam Altman帮我们去宣传我们大会的Sora2的视频。看起来他在屏幕里面的形象就是一个比较数字人的形象，这个对你们的业务会有影响吗？</strong></p>
  <p><strong>柴金祥：</strong>我觉得Sora2相比Sora1，进步是蛮大的，Sora1还是以风景为主，Sora2主要的形态是以人为中心的，可以让视频里的人做各种各样的事情。我也大概用了一下，第一个感觉，视频生成现在还是10秒钟的时间，还是没有跳出被时间的限制文生视频。第二个点其实也特别重要，就是物理上的一致性，基本上大家看刷屏的时候很多效果其实还是蛮好的，但你真正自己做的时候还是有很多瑕疵。</p>
  <p><strong>泓君：</strong>问题太多了。它那个视频里面有皮卡丘跟一个唐老鸭在总统竞选的一段辩论，可以在原视频上改，我就说把这个辩论变成一个在《硅谷101》上关于AGI的辩论，我们活动的主题是“Alignment2025”，但你仔细去看的话，它后面的Alignment那个字就是错的，就开始乱码了。</p>
  <p><strong>柴金祥：</strong>对。创作者除了生成视频，还需要能修正错误、调整细节，这能力它还没有。更重要的是，它无法精细控制人的动作和表情。<strong>不过，Sora2第一次让人看到了用大模型驱动人物多样动作的可能性。</strong></p>
  <p>我们做的是3D数字人，如果最终目标是让人能交流、跳舞、娱乐，那大模型会是什么形态？训练数据又是什么？Sora2说它用所有视频作为训练数据。最近Genie3出来，是3D的生成，给你一种交互型的感觉是吧？但它不是人，它是关于场景相关的。</p>
  <p><strong>我们觉得，最终可能需要2D+3D的训练技术结合，我们希望生成的人没有10秒限制、没有瑕疵、物理准确、可控制、实时且成本低。</strong>所以我们除了3D训练数据，也开始结合大量视频数据来训练大模型，提升数字人的表达力。视频数据如果模型做得好，是有生成能力的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_35bb8ebf23e6439cb44e0a005d83baf4@46958_oswg76841oswg1080oswg549_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Sora2</p>
  <p><strong>泓君：</strong>我简单总结一下：<strong>Sora2是文生视频，你们是文生3D。</strong>这个3D它可以是在VR领域里面进行展示的，比如说我戴着一个VR头盔，我可以360度地去看到这个人。</p>
  <p><strong>柴金祥：</strong>是，就是2D和3D的区别。Sora2是文生2D视频。3D放在VR/AR里，就跟现实一样。3D还有一个好处，它能控制，就像人一样，你让它怎么动就怎么动。但2D在像素层面，要对它进行动作、表情的精准控制，会比较难。</p>
  <p><strong>泓君：</strong>我看到很多公司展厅屏幕上的数字人是你们做的，有一点我可能很难区分，假设我进到一个展厅，看到一个屏幕上的非常立体的数字人，它有动作、声音、表情，跟我看到Sam Altman在一个视频里的数字人，除了时长的区别，它在核心的技术上它的区别是什么呢？</p>
  <p><strong>柴金祥：</strong>第一个区别是，屏幕上这个数字人是人机交流的载体，人跟机器交流的时候，其实你是实时互动的，<strong>我们希望端对端延时一般要小于2秒或1.5秒</strong>，不能像生成视频等10分钟、5分钟。</p>
  <p>第二个区别是，当你用文生视频去做的时候，手指是个特别难的事情，经常多一根或少一截，但如果是展厅里，数字人为你讲解产品，你肯定是不希望这个体验很差的，<strong>它的动作不能有瑕疵，物理上要准确</strong>，表情、动作要一致。</p>
  <p>最后一个区别，<strong>把3D数字人部署在终端上，成本不能高。</strong>终端屏幕可能就一万人民币，如果生成视频交互了20分钟，即使它能实时做，一年放在那也得花很多钱，长期也负担不起。但从Sora2文生视频的角度来说，这个成本它是不能scale up的。</p>
  <p><strong>泓君：</strong>它的成本是多高？用你们的这个成本是多高？为什么成本之间会有这样的一个差距？</p>
  <p><strong>柴金祥：</strong>我不一定能给具体数字，但可以告诉你一个量级：<strong>与大模型做的语音合成相比，我们的成本可能是几十分之一。这里核心是2D和3D的区别。</strong>3D描述人的动作表情，只需要几百个参数，人的肌肉可能就是大几百块，你只要去控制一些肌肉就可以了。下一步是用3D渲染把3D内容变成视频，还有3D解算，包括头发、衣服的物理解算。如果用AI做渲染和解算，成本就主要是生成这几百个参数的成本，和大模型生成Token一样，所以它的成本就非常非常低。文生视频没有结构化信息，全是像素，推理和生产成本就会非常非常高。</p>
  <p><strong>泓君：</strong>所以你们能把成本降下来，是因为有一个自己的端模型，可以这样理解吗？</p>
  <p><strong>柴金祥：</strong>是的，<strong>我们有一个把文本变成3D多模态表达能力的模型。从文本生成语音、表情、动作、手势的参数，传到终端屏幕上，我们用AI渲染和解算，把它变成视频。</strong>AI渲染对终端算力要求极低，现在用国内几百块钱的芯片，比如瑞芯微的RK3566，我们在端上就可以跑了。</p>
  <p><strong>泓君：</strong>比如说它要跟人做实时互动跟问答，这种还是在端模型上，还是说你后面除了你自己的这个端模型，在表达的内容上你会去接大模型？</p>
  <p><strong>柴金祥：</strong>好问题。人和数字人交流需要两个模型：一个像ChatGPT的多模态到文本模型，现在你ChatGPT的话，你可以输入声音、图片，它最后输出文字。</p>
  <p>另一个是从文本到3D多模态的模型，我们做的是文字到3D多模态输出，输出语音、姿态、动作、表情、手势，让生成的数字人更像真人交互，</p>
  <p>我们有自己垂域的大模型，也可以接国内千问、DeepSeek、豆包等模型，形成端对端的人与数字人像真人一样的交流体验。</p>
  <p><strong>泓君：</strong>所以你们从多模态到文本可以利用大模型，从文本到多模态是自己的端模型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7ca63295c0f04e949bac7bbbe0a28ed3@46958_oswg719885oswg1080oswg709_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：魔珐星云-具身智能数字人开放平台</p>
  <p><strong>柴金祥：</strong>我们叫它“文生3D多模态大模型”。</p>
  <p><strong>泓君：</strong>这已经是一个产品“星云平台”，可以发布了吗？</p>
  <p><strong>柴金祥：</strong>是的，我们10月发布，现在在测试。有几百个B端企业客户在测试，有的已付费。我们预计两周后发布我们这个文生3D多模态模型。因为我们自己在做的过程做了很长很长时间，从我20多年前读研开始做，花了很多精力。我们希望大家不要重复造轮子，能够把能力提供给所有开发者，集成到他们的应用中去。</p>
  <p><strong>泓君：</strong>了解。我觉得很有意思的一点就是，随着星云平台发布，你们从3D数字人公司变成了3D数字人平台公司，我这样理解是对的吗？</p>
  <p><strong>柴金祥：</strong>差不多，对，是的。</p>
  <p><strong>泓君：</strong>之前在NVIDIA发布会上，黄仁勋很自豪地说“你看到的我不是真的我”，他坐在一个壁炉前，是一个虚拟3D数字人在跟大家介绍，渲染得非常非常真实。他经常用他自己的虚拟人去讲他们的显卡性能有多强大，他那个成本大概有多少？</p>
  <p><strong>柴金祥：</strong>这个成本蛮高的。他做的其实还是视频输出，<strong>如果造一个老黄这样的虚拟人，需要研发团队配合美术团队，在美国找顶尖的美术团队做，成本大概10万美金左右</strong>，做到发布会那种逼真效果。</p>
  <p>这还只是造出这个人，做视频可能要按秒算成本。<strong>这属于专业级内容生产，还没到人人可用的阶段。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_43fd31637b4b4926abefbc2964b7bba2@46958_oswg864141oswg1080oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：NVIDIA Blog</p>
  <p><strong>泓君：</strong>对，每次去游戏展会感受明显，大家怎么去造那个3D数字人。以前造3D数字人，是让演员穿动作捕捉服，用环形摄像机拍每个部位，再建模，一步一步地把它还原出来。这是好莱坞或游戏公司常用的方式吧？</p>
  <p><strong>柴金祥：</strong>对，专业级造人包括3A游戏公司和好莱坞，比如Avatar，或老黄的数字人。整体来说它是两部分的东西。</p>
  <p>第一部分是造人，一般叫扫描，用很多相机，你坐在那，做各种表情，把人的几何形状和表面纹理重建出来，包括肌肉，学术上叫建模和绑定。</p>
  <p>第二是让它动起来，穿动捕服，用相机捕捉动作，驱动刚才造的那个人，用渲染引擎输出视频。</p>
  <p>整个过程从建模绑定到动画再到输出视频，都非常昂贵。</p>
  <p><strong>泓君：</strong>这是大模型之前，好莱坞和游戏公司常用的方式。现在有了模型，这套方式还是主流吗？还是说他们其实也在探索能不能用3D直接去生成人？</p>
  <p><strong>柴金祥：</strong>这问题特别好。<strong>3D内容的AI化取决于两件事：高质量数据，和AI算法能否对3D内容做大模型。</strong></p>
  <p>咱们今天看到了，所有的影视动画和游戏公司，擅长做内容，把美术和3D模型做得很逼真，但绝大部分AI能力缺乏，因为他们和互联网、科技公司是两条线，交叉很少。他们当然想拥抱AI，但能力欠缺。</p>
  <p>AI公司算法强，但其实是没有数据的。3D内容必须先有大量高质量3D数据才能做大模型，这是他们的目标，但现在两个行业没有交叉。</p>
  <p><strong>泓君：</strong>大模型公司缺好莱坞的数据，好莱坞制作公司缺AI算法，可以这样理解吗？</p>
  <p><strong>柴金祥：</strong>是，基本是这样。</p>
  <p><strong>泓君：</strong>但我看也有公司开始尝试。你们在AI浪潮之前，做数字人和积累数据也很久了吧？</p>
  <p><strong>柴金祥：</strong>是的，我们2018年成立，最初为B端公司，如游戏、影视、动画、或做3D虚拟偶像的公司，提供3D内容制作，用AI+美术一起来提升效率和质量。在这个过程中当然AI的能力也在提升，<strong>但大家都要突破的点是3D内容的高质量数据。没有数据，AI算法再厉害也没法干。</strong></p>
  <p><strong>泓君：</strong>从2018年到2025年，你们大概积累了多少数据？可以透露吗？</p>
  <p><strong>柴金祥：</strong>拿动画数据来说，前面我们为企业服务，后来我们自己来做了些动画数据。现在3D高质量动画数据，我们有1000多个小时。这个数据可能跟视频的数据或者文本的数据来讲是小的，但如果考虑到成本，<strong>高质量的人脸动画、手势、表情等动画数据，一秒钟成本至少1000人民币左右。</strong>在国内成本高是一方面，另外你还得找到团队有非常强的能力把质量做得这么高，所以这个数据量是很难在短时间内积累起来的。</p>
  <p><strong>泓君：</strong>很有意思，所以数据是你能训练成这样的一个模型的一个核心要素。</p>
  <p><strong>柴金祥：</strong>我觉得数据是最核心的。如果没有数据，其他任何研发都没法做。除了刚才讲到的3D数据，我们也有其他的视频数据。这些是纯粹的视频数据，比如有人在走路也好，有人在跟人交流也好，它没有3D信息，但我们开始把这两者融合起来去做模型的训练。</p>
  <h2><strong>02 虚实之间诞生的“双生学科”</strong></h2>
  <p><strong>泓君：</strong>你当初为什么会选择进入3D数字人这个领域？</p>
  <p><strong>柴金祥：</strong>我2000年去卡内基梅隆大学（CMU）读博士，在机器人研究所做的就是这个方向。我的博士论文就是关于如何创建一个可交互的3D数字人，以及如何用AI去做动画。<strong>我们团队应该是世界上最早用AI做动画的，因为也刚凑巧，2000年左右运动捕捉技术出现了，有了动画数据就可以做AI了。</strong>从那时起，我就专注于3D动画和数字人。2006年毕业去德州农工大学（Texas A&amp;M）当教授，也一直做这个方向。那时动画研究属于图形学领域，是专门为影视动画公司游戏公司这个行业服务的。那时候我们发表了很多论文，全是关于3D数字人跟3D动画相关的。到2018年创业，我也继续做这件事，所以我在这个领域坚持了二十多年了。</p>
  <p><strong>泓君：</strong>我知道您的博士导师是杰西卡·霍奇斯（Jessica Hodgins），她主要研究人形机器人和3D数字动画。而且她的博士生导师是马克·雷伯特（Marc Raibert），是波士顿动力（Boston Dynamic）的创始人，现在最有名的机器人公司，也是特别早的一家机器人公司。所以看起来整个的3D生成它最开始的应用就是在好莱坞领域的。</p>
  <p><strong>柴金祥：</strong>我导师杰西卡·霍奇斯，她也是卡内基梅隆大学1989年博士毕业，她在读博时是做机器人的。当时的人形机器人只有“单脚”，因为双足平衡太难了。她那时候是用物理运动控制动力学的方式，控制机器人走跑跳。</p>
  <p>她毕业后，很奇怪地，进到的方向是图形学和动画领域，<strong>她的想法是：既然能在现实世界控制机器人运动，是否能用同样方法驱动虚拟世界的3D数字人？</strong></p>
  <p>她是全世界第一个用物理运动控制方法做数字人动画的学者。她在佐治亚理工学院（Georgia Tech）做教授，基于物理的仿真跟控制做动画，然后2000年她回到CMU任教，2000年动画数据慢慢有了刚才讲的运动捕捉的出现。我就是她在卡梅带的最早的博士。我们是那时候是最早用AI做动画的。<strong>后来大家发觉得，这个动画用AI做挺好的，反过来是不是还能去做Robotics这个行业？</strong></p>
  <p><strong>现在大家可能知道的很多做Robotics做很厉害的人，其实以前都是做动画的。</strong>比如PI（Physical Intelligence）联合创始人、伯克利教授Sergey Levine，但你肯定都不知道，他是在斯坦福拿的博士学位，并且他是用物理的方式，用运动控制动力学的方式来做动画的。他毕业了以后说，我这个能做动画，我也能做机器人，他后来当教授的时候就是开始做机器人。</p>
  <p><strong>泓君：</strong>难怪PI他们的核心思路是解决机器人的“大脑”问题，就是软件层的问题，他就是希望通过模型层来指挥机器人，我觉得这个跟他最开始不是从硬件研究开始的，而是用机器人去做动画，听起来是一脉相承的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0879108cb94647989ea39e32cb53365b@46958_oswg538570oswg1080oswg609_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：PI</p>
  <p><strong>柴金祥：</strong>的确是的。再举一个例子，我还有一个好朋友Karen Liu，她现在在斯坦福当教授，以前是在佐治亚理工学院（Georgia Tech）当教授，她同时做Animation和Robotics。</p>
  <p>我们那批做动画的人，后来很多都转向机器人领域，因为<strong>这两个领域高度相通——都是驱动“人”，一个在虚拟世界，一个在物理世界。</strong>动画相对更容易入手，因为机器人是有本体的，你搭个硬件就老半天。另外现实世界受很多限制，比如重力、房间限制、机器人硬件限制。动画实际上没有这些限制。所以那时候很多做物理的人开始做动画。</p>
  <p>动画这方面也分成几派，一派用物理方法做，Jessica肯定是其中之一。还有CMU的Michiel van de Panne，他是我博士委员会成员，一直做Controller、运动控制。那时候做动画的中心也在卡内基梅隆大学。Karen Liu的导师Zoran Popović也是卡梅毕业的。当时做动画的学者很少，国内基本没人做，欧洲也没人，主要集中在美国两三个研究组。</p>
  <p>后来动画有个大飞跃是从2000年，运动捕捉有了数据后，大家慢慢开始用AI做。那时比较早的，现在叫强化学习，我记得最早的动画论文是2004年还是2005年就用强化学习做动画。<strong>虚拟世界与实际世界的底层运动控制逻辑非常相似，都属于“小脑”范畴的动作规划与运动控制。如今新兴的VLA模型则更偏向“大脑”层面。</strong></p>
  <p><strong>泓君：</strong>很有意思。我们讨论好莱坞技术时，常有听众问为什么科技节目关注电影工业。其实好莱坞一直是推动技术发展的重要力量，许多AI技术最早都应用于电影制作。你们有没有想过，把你们的3D数字人产品用于好莱坞造人？比如用生成式技术让静态演员动起来，这可能对传统制作方式形成“降维打击”。</p>
  <p><strong>柴金祥：</strong>这里面涉及几个关键点：质量、成本和应用场景。好莱坞质量可能最高的，再往下是3A级游戏，再往下是生活中一些交互比较简单的场景。如果你要做好莱坞方向，它的高保真、质量可能特别重要，他们可以等100个小时、200个小时，花更多钱等你的高质量。但在实时交互里，可能等不了那么多时间，要马上看到结果能够交互，质量上不一定要像好莱坞那么高。</p>
  <p><strong>泓君：</strong>但是可以做好莱坞IP的衍生。</p>
  <p><strong>柴金祥：</strong>对，衍生品肯定可以，但需要更高质量的3D数据来做AI大模型。这块在我们自己的行进路径上，有先后顺序，对我们自己来说，可能<strong>先运用到日常生活中，比如交互、服务、陪伴，再到游戏，再到好莱坞。</strong>因为难度来说，好莱坞如果要做到那个水平，难度很高很高，质量要很高，能生产这种高质量数据的人，全世界可能就没几个。</p>
  <h2><strong>03 AI渲染结算带来的成本革命</strong></h2>
  <p><strong>泓君：</strong>问一个稍稍敏感的问题，你可以选择不答。你们现在把API接口开放出去，肯定有基础接入成本。你觉得这个模式能赚钱吗？</p>
  <p><strong>柴金祥：</strong>这肯定能。因为在正式发布平台之前，我们已经有了B端客户。在国内做AI公司，商业上的账必须算得过来，除非你是字节、阿里、腾讯那样的大厂。所以这里面有一个核心点，也是我们过去半年最大的突破。半年前我们的交互能力和API就做好了，但那时成本非常高。当时服务一个数字人需要一张显卡，成本差不多两三万。很多B端客户来问，一听到这个价格就不用了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_e40d6b2276814360ae4d22c9fbcaa2ac@46958_oswg105541oswg1080oswg687_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：魔珐科技</p>
  <p><strong>泓君：</strong>这个成本是怎么降下来的？</p>
  <p><strong>柴金祥：</strong>因为我们是3D内容，所有影视动画公司、游戏公司都逃不开一点——必须要有渲染引擎和解算引擎。</p>
  <p><strong>泓君：</strong>这个我太懂了，我们做视频，渲染真的太耗时间了。</p>
  <p><strong>柴金祥：</strong>对。如果要支持3D内容实时交互，每一路都需要一张显卡负责渲染和解算。我们当时用了可能最好的Unreal引擎，但成本就摆在那里。我们一直在想，如果不解决这张显卡的成本问题，谈应用落地根本不可能，无论是展厅大屏、手机还是平板上都用不起。</p>
  <p>我原本觉得这个问题很难解决，但技术有时很奇妙，我们突然想到了一个方法。<strong>很幸运地，我们用AI技术完成了渲染和解算，不再需要传统的渲染引擎和昂贵的显卡。</strong>现在在非常便宜的终端芯片上，一两百、两三百块钱的，就能跑起来。</p>
  <p><strong>泓君：</strong>所以你们用端到端的AI模型，解决了渲染问题。</p>
  <p><strong>柴金祥：</strong>渲染只是其中一部分。完整流程分两步：第一步是用模型从文本生成语音和3D表情、动作的参数；第二步是把这些参数通过AI渲染和解算转换成实时视频。这样整体成本比语音生成还要低。</p>
  <p><strong>泓君：</strong>如果你们真能做到大幅降低渲染成本，这次的生成式AI技术会对Unreal这样的游戏引擎公司造成冲击吗？对NVIDIA可能就是一个左手跟右手的关系。</p>
  <p><strong>柴金祥：</strong>对Unreal不一定是好事，我认为对游戏公司来说更多是机会。现在3A级游戏都需要云端有显卡，或者手机上得有比较强的算力，不然玩起来会发烫。<strong>如果将来能用AI方式解决渲染和解算，不需要引擎和显卡就能玩游戏，那游戏就能无处不在。或者将来真正实现元宇宙时，虚拟世界的参与成本也许会变得很低很低。</strong></p>
  <p><strong>泓君：</strong>现在用AI方式解决渲染问题，质量能达到传统游戏引擎的水平吗？大概到了一个什么样的进度位？</p>
  <p><strong>柴金祥：</strong>在我们这个特定应用场景下，质量基本一样。因为我们的训练数据就是用最高质量的游戏引擎渲染的，AI模型是在大量数据基础上逼近原来的效果。我们做过并列对比（Side-by-Side Comparison），左边是游戏引擎渲染，右边是AI渲染，没有一个人能看出左右之间的区别。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8b18523e3c8d42d0b8ecf490ff2da77f@46958_oswg353167oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Unreal</p>
  <p><strong>泓君：</strong>这非常颠覆。如果我们综合评估你们模型的能力，你觉得最强的一点是什么？比如现在看2D视频渲染，最大的痛点可能是口型对不上、眼神空洞，这种虚假感。你们在将3D数字人应用到不同行业时，遇到的最大痛点是什么？怎么解决的？</p>
  <p><strong>柴金祥：</strong>这个问题很好。我们收到的客户反馈主要集中在三个方面。第一是质量，包括语音、动作、表情、唇形是否自然逼真？是不是像真人一样？第二是延时，我跟它交互聊天时，不能一句话等5秒钟才回应，那我肯定没有这个耐心了；第三是客户非常关心的成本，如果太贵，即使体验好客户也不愿意投入。</p>
  <p><strong>质量、延迟、成本——这是我们规模化落地要翻越的“三座大山”。</strong>还有个关键点是让数字人支持多终端——大屏、小屏、手机APP，支持并发，这涉及不同操作系统、不同芯片算力。</p>
  <p>我们解决质量和延时问题，主要靠大模型提升能力。质量方面当然训练数据最重要——如果3D人的质量很差，根本做不好。另外就是大模型本身的能力：能否通过文本生成语音、表情动作和匹配的唇形？能否从文本中提取情绪（比如笑或打招呼）自动生成关键意图？TTS语音生成是否也有情绪的？这些都关系到如何让大模型产生高质量输出。</p>
  <h2><strong>04 加速具身智能突破泛化</strong></h2>
  <p><strong>泓君：</strong>我们刚刚聊了很多AI技术如何应用于虚拟世界。那反过来，你们现在训练的模型能操控机器人吗？你们试过吗？&nbsp;</p>
  <p><strong>柴金祥：</strong>我们试过。3D数字人和3D动画的一个优势就是能够驱动机器人。比如一个3D数字人能跟你交流，听懂你的问题，生成相应的语音、动作、表情和姿态。<strong>对机器人来说，我们可以用同样的技术驱动它，让机器人实现实时语音、动作和手势。</strong>只是现在的机器人没有脸部肌肉，所以表现不出表情。</p>
  <p>现在的机器人更像是蓝领工人。如果将来要做陪伴型机器人，或者做白领工作，比如销售、老师，可能就需要表情了。首先我们要知道机器人在交流时，手势该怎么动？表情该怎么变化？姿态该如何调整？下一步就是通过模仿学习，像NVIDIA的方法那样，通过仿真实现直接驱动和交流。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_70bb545c475a4594bc1d114e131e2891@46958_oswg50831oswg1080oswg514_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">3D数字人驱动机器人 图片来源：魔珐科技</p>
  <p><strong>泓君：</strong>太有意思了。在实际应用中，你们将模型数据接到机器人上，觉得对哪部分提升最大？机器人没有表情，但手势可以动，你们能同时驱动手和脚吗？还是只能驱动上半身？</p>
  <p><strong>柴金祥：</strong>我们可以同时驱动手和脚。告诉你个有意思的事，在国内合作中，我们生成的动作数据包含脸部、手部和腿部的完整动作。</p>
  <p>其实现在很多机器人公司在平衡性方面还不够完善，即使我们通过API提供了动作数据，他们也需要结合强化学习和仿真来实现。如果在这方面做得特别好的，可能也能够驱动起来。上身其实有很多动作，有一定的泛化性。</p>
  <p>这个事情其实我觉得这没有那么难，就像我们爬楼梯一样，我的动作能够通过我们的能力生产出来，然后在仿真环境中加上强化学习，让它复制这些动作，一点问题都没有。</p>
  <p><strong>泓君：</strong>所以机器人的平衡问题在于，我们收集的3D数据只是动作姿态，没有力的反馈。一旦加入力的因素，就会出现平衡问题、摔跤问题。</p>
  <p><strong>柴金祥：</strong>我觉得你好专业，<strong>这里有两个核心点：驱动机器人需要运动学（Kinematics）和动力学（Dynamics）</strong>。第一步是运动学，比如要抓杯子，需要知道手的pose是什么，该怎么动去抓住它。第二步是动力学，解决需要用多少力、按什么路径去抓取的问题。我们先做运动学，也就是运动规划，这两者可以结合起来。</p>
  <p><strong>泓君：</strong>所以我理解其实机器人公司寻求合作时，两者都需要。如果从零开始做机器人公司，最缺的就是数据，而你们有数据的模型就已经训练好了。</p>
  <p><strong>柴金祥：</strong>是的。因为我们聚焦于交互，下一步我们今年会发布一个3D动作大模型。比如你告诉它“往前走五步，趴下再爬起来跑”，它就能自动生成3D动作数据。这些数据可以用来训练机器人，有了这样的动作大模型，甚至不需要动作捕捉，因为捕捉也是为了获取类似数据。</p>
  <p><strong>泓君：</strong>波士顿动力的机器人爬楼梯、旋转、搬箱子已经很成熟了。但这是在大模型出现之前，他们研发了很多年，用了各种方法。你现在用AI模型驱动爬楼梯动作，这两者技术路径是完全不同还是相似？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7205d993cdec40219f334cabddca0bae@46958_oswg952020oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Boston Dynamics</p>
  <p><strong>柴金祥：</strong>你提到一个有意思的点，波士顿动力以前能爬楼梯，但泛化能力不强。比如你给它不同高度的楼梯，它不一定每种楼梯都能爬好。他们展示demo时总是用同一个楼梯。</p>
  <p>这就是泛化性的重要性。今天做人形机器人都要面对这个问题：生成数据后，能否处理数据之外的情况？比如爬楼梯，每个楼梯高度、层数、摩擦系数都不同，这些都是一些要泛化的参数。</p>
  <p>那今天你有没有能力，给任何一个楼梯都能爬得稳？另外能否控制爬快一点，或爬慢一点？这仍然是个难题，根源还是数据。我们要做的核心就是在虚拟世界中，通过3D动画大模型生产出动画的数据，让它爬楼梯，让它见过所有情况。机器人动作的泛化性和数字人动作的泛化性，其实这两件事是一样的。</p>
  <p><strong>泓君：</strong>你觉得用AI做机器人经历了哪些变迁？就像你说的，最早可能没人想到用AI做机器人，后来开始加入强化学习。</p>
  <p><strong>柴金祥：</strong>最早的时候，AI机器人这个方向很难很难，尤其是人形机器人，我们叫Biped，最难的问题就是双足平衡。另一个难题是抓取。那个时候做人形机器人最有一段时间日本很火，比如本田的ASIMO。工程师要调整走路参数，你都不知道后面有多少工程师在调这个参数。这些参数还不稳定，把地面稍微改一改，它就可能跌倒了。那时AI和学习的方法用得不多，主要做控制器。</p>
  <p><strong>泓君：</strong>所以早期机器人发展主要关注控制，为了让机器人不跌倒。</p>
  <p><strong>柴金祥：</strong>如果能走，不跌倒，就已经很了不起了。后来大家觉得光这样走不行，你能不能有一定的泛化能力？在不同平面、不同表面，以不同速度行走。如果不用AI方法，这几乎不可能实现。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_fe72902287704c5aad43fb6efef53274@46958_oswg171640oswg911oswg512_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">ASIMO告别演出 图片来源：Honda</p>
  <p><strong>泓君：</strong>你觉得现在的机器人相比20年前进化了多少？</p>
  <p><strong>柴金祥：</strong>我的进化还是蛮大的。以前让双足机器人走跑跳，觉得好难好难，但现在看国内很多人形机器人公司，运动会上拿遥控器控制，大部分走跑问题都解决了。这在20年前基本不可能，balance太难了。</p>
  <p><strong>泓君：</strong>但这是通过远程操控实现的。</p>
  <p><strong>柴金祥：即使远程操控，还是要解决动力学控制的问题。</strong>我觉得如果有视觉语言动作大模型，就不需要那个遥控器了。但用小脑控制这个事情，让它走，不跌倒，仍然很难。现在的进步在于数据、强化学习、仿真环境，像NVIDIA。技术进步后，能力开放出来了，大家都能在仿真环境里做，你就发现其实没那么的难了。</p>
  <p><strong>泓君：</strong>机器人走路不摔倒，是现在机器人公司的普遍水平，还是只有头部公司能做到？</p>
  <p><strong>柴金祥：</strong>对稍好的团队应该没问题。但关键点，就是你的泛化能力有多强？在日常训练的特定场景中不摔倒，如果在新场景搞不定，还是会摔倒。</p>
  <p><strong>泓君：</strong>那你觉得世界上有多少公司能在部分场景实现机器人不摔倒？</p>
  <p><strong>柴金祥：</strong>如果完全不摔倒，在新的应用场景其实蛮难的，我不知道现在有没有公司能做到很强的泛化能力和鲁棒性。如果有，我肯定要学习一下的。就拿爬楼梯来说，如果设置没见过的楼梯情况，我不相信现在世界上有任何一个人形机器人公司能做到。</p>
  <p>还有个问题是抓取，早期用人形手抓取的研究不多，机器人整个业界多用吸盘来吸。但现在很多人研究灵巧手，让机器人一样用筷子夹东西，这非常难，需要大脑加小脑配合。大脑要先识别物体和抓取方式，小脑控制筷子夹取。我认为现在看到的都是demo，在特定应用场景下可能有些泛化性，但再扩展就很难。</p>
  <p><strong>泓君：</strong>我们10月5日的活动您也去了，现场有机器人开可乐。彩排时我放了瓶可乐，他们说要把拉环对准手指方向，否则那个机器人的手的灵活度还很难去把可乐转一个方向打开。</p>
  <p><strong>柴金祥：这还是在特定布置好的环境里，更不用说进入家庭后各种复杂情况。</strong>大家现在看到VLA模型可能解决这个问题，但能否100%解决，其实也没人知道。如果能，需要多少数据才能达到足够的泛化能力和鲁棒性？大家相信扩展定律（Scaling Laws），相信大模型总有一天能解决，但这里面的挑战是很大很大。</p>
  <p><strong>泓君：</strong>从你的角度看，现在世界上最好的机器人公司是哪家？为什么？</p>
  <p><strong>柴金祥：</strong>做机器人有不同的流派：有做本体的、做硬件的、做小脑的、做大脑的。我觉得很难说谁最好，因为“好”有不同的定义。是在研究上有突破，还是已经落地商用？也许某条路看起来很有希望，但最后发现是死路，暂时的领先不一定是最终领先。国内也有不同流派，比如宇树做机器人本体加小脑，它不做大脑。</p>
  <p><strong>泓君：</strong>大脑指什么？</p>
  <p><strong>柴金祥：</strong>大脑是处理VLA、叠衣服这类任务。小脑是处理爬楼梯、跳舞、跑步等。我觉得目前还没看到真正的曙光，可能我比较悲观。就像其他领域，VR/AR、自动驾驶都有起起落落，AI领域也会这样。<strong>这是机器人第一波浪潮，长期前景光明，但短期挑战很多。</strong></p>
  <p><strong>泓君：</strong>你觉得机器人模型达到GPT-3时刻需要多久？</p>
  <p><strong>柴金祥：</strong>我没有那么强的认知。我觉得今天的数据要泛化能力，还需要很长一段时间。我看到的情况还无法清晰判断是2年还是3年，但我觉得10年内有希望解决。</p>
  <p><strong>泓君：</strong>所以你们公司没有直接切入机器人赛道，而是选择3D和机器人的交叉领域。</p>
  <p><strong>柴金祥：</strong>如果让3D数字人在数字世界、在VR空间或屏幕上与人交流，能够抓取、走路、爬楼梯，在数字世界里已经很有用，它已经可以有实际应用和商业落地了。</p>
  <p>反过来，做这些对机器人也很有价值。因为在小脑控制方面，你需要先知道怎么动，再用强化学习决定用多少力。从研究角度，机器人是个好方向，有太多可探索的，但从商业化角度，我自己觉得其实挑战很多。<strong>如果真要商业化落地，人形机器人在白领领域可能比蓝领更快。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3523a5bc07b04dcbb19ba608b839f5a2@46958_oswg1092908oswg1080oswg556_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：宇树</p>
  <p><strong>泓君：</strong>你提到数字世界也会涉及力的反馈，比如好莱坞动画里面，我们把一个苹果、一个南瓜甩出，去变成酱，怎么炸开？</p>
  <p><strong>柴金祥：</strong>那个就是物理。还比如说，你是一个数字人或3D的角色，从二层楼跳到一层楼，你跳下去的时候，跟地面的反馈和滚动必须符合物理。我们的大模型生成动画后，它本身就可以用物理方式在虚拟世界中仿真它。同样的方式，也可以用强化学习的方式去生成这个控制器，我可以在实际世界中这么做，因为这个逻辑是相通的。</p>
  <p><strong>泓君：</strong>但我有个问题。如果我们收集动画世界的数据来学习，我知道一个人从楼梯摔下后怎么弹、怎么滚的，只是看到现象并用这些数据训练大模型，能反馈，能模拟，但我们还是不知道力是多少。</p>
  <p>就是我们说Scaling跟这个所有的大模型，都是黑盒模型。但是我们再把这个场景拉回到现实，我们要让机器人砸到或拿到一个东西，这个力的大小，我不知道需要通过反复调控计算得出，所以需要力的数据。其实人在现实生活中举杯子也不需要计算力，靠经验习惯和感知就好了。</p>
  <p>我的总体意思就是，过去机器人研究包括力学反馈，都是用白盒方法，但现在模型用黑盒和一套更加经验主义的方法去做。</p>
  <p><strong>柴金祥：</strong>这就是为什么在泛化到现实世界时挑战很大，因为泛化涉及的因素太多，整个的过程中你要学力的控制的函数。</p>
  <p><strong>泓君：</strong>以前是要自己计算吗？</p>
  <p><strong>柴金祥：</strong>对，现在用强化学习，只要有足够多的数据跟它reward，它就能慢慢能够做。但问题是，我说的抓杯子只是个小例子，这个世界上有多少种情况？所以我希望将来有一个基座大模型，有足够多数据后，在特定场景下我能去调优这个模型，把它慢慢做好。</p>
  <p><strong>泓君：</strong>我听下来觉得，<strong>机器人领域这波最大进展是研究方式从白盒模型的研究，变成了黑盒模型的研究。</strong>从必须知道每个细节的受力点，靠计算和细节调配的研究，变成了端到端的模型，我们不知道内部是怎么运作的，但它可以工作。</p>
  <p><strong>柴金祥：</strong>是的，这条路确实打开了新局面。以前的时候，那套东西更多是显式的，那种方法肯定不能规模化，所以我们觉得做机器人太难了，怎么做也没有希望的那种感觉。</p>
  <p>但是今天我作为一个外行，我觉得虽然很难，但长期来看是有希望的。这套方法在大语言模型和其他领域已经展示了能力。如果在机器人这个方向上，如果你有足够多数据，是有可能解决这个问题的，但中间会不会遇到意想不到的问题和低谷，我不知道。</p>
  <p><strong>泓君：</strong>看起来现在是刚找到一条新的路的那个兴奋感的时候，但结果能否收敛？能否持续看到效果？这中间肯定会有起起落落。</p>
  <p><strong>柴金祥：</strong>是的。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Dyw2uWJJEK_ocjv5l4CW0Q" rel="noopener noreferrer nofollow" target="_blank">“硅谷101”</a>，采访：泓君；图文：朱婕，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530081809603714</id>
            <title>站在长辈肩膀上的人工智能</title>
            <link>https://www.36kr.com/p/3530081809603714</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530081809603714</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 11:16:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>我们常习惯把老年人视为新技术的“被动接受者”，但事实上，老年人在漫长的人生中积累了丰富的情绪智力、生活阅历和沟通智慧，这恰是当前AI所不足。老年人可以为AI做什么？他们于AI时代的独特价值是什么？</p>
  <p>腾讯研究院与北京邮电大学张为威团队，在2025年重阳节联合推出AI X 老龄研究年度报告<strong>《站在长辈肩膀上的人工智能》</strong>。本研究在腾讯AI向善语料库（老年库）的基础上，进一步搜集了1408条由老年人撰写的优质语料，用9455条真实且带有丰富场景信息的语料（包含AI向善语料库老年库中的8047条），构建了一个系统化的 “长者智语”数据集。</p>
  <p>研究团队还邀请了44位老年人以“情感专家”的身份重新审视这些问题。老年人从被动的提问者转变为情感洞察的诠释者与共创者——他们不仅剖析了问题中隐藏的情绪，还敏锐地指出其中所映射的群体性困境。</p>
  <p>我们倡议，把老年人视作“人工智能的积极合作者”，为AI注入温度与厚度，使其可逐渐发展为理解和陪伴人类的伙伴。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ffe2d17669ed43328f323c9410e6eaa1@000000_oswg1132332oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>一、老年人的独特价值</strong></h2>
  <p>在人工智能的发展路径中，逻辑与计算始终是核心优势，但<strong>情绪知识（Emotional Knowledge）</strong>却仍然是其需要提升的能力。情绪知识在于对他人情绪的识别，包括沟通、冲突调解和人际关系维系中展现出的同理心与理解力。</p>
  <p>对于长辈而言，这种能力的形成并非一蹴而就，而是在几十年的社会交往与人生历练中逐渐沉淀下来的“隐性智慧”。他们熟悉人际互动的微妙变化，懂得在不同语境下调节情绪与关系，因此在这一维度上具有天然优势。</p>
  <h3><strong>1.1 情绪知识</strong></h3>
  <p><strong>长辈们的人生经验是整个社会的宝贵智慧财富。</strong>在家庭纽带、社会角色与历史纵深的交织中，他们沉淀出对人际情绪与社会关系的敏锐感知与把握。使其能够通过细节判断他人心理，从语气的波动、眼神的闪烁推测出未说出口的感受。能以含蓄而稳定的方式传递关怀，让信任在长期互动中自然沉淀。</p>
  <p>这些能力是在漫长时间和经历中沉淀而成的，很难被算法或数据积累复制。人工智能即使在模式识别上高效，也难以短期轻易获得这种“人情世故”的智慧。</p>
  <p>如果说AI在很多方面仍像一个刚起步的学习者，那么长者的经验就是最值得参考的教材。将这些经验转化为AI的训练资源，意味着让技术逐步具备对人类情境的理解力。即AI像孩子向长辈学习一样，逐渐习得更深的理解与更稳的分寸。</p>
  <h3><strong>1.2 生活智慧的纵深价值</strong></h3>
  <p><strong>长辈们的人生智慧不仅体现在丰富的经验积累，更在于他们对社会变迁、日常实践和价值取向的深刻理解。他们承载着历史的纵深，能够把个人故事与时代脉络连接起来，为人工智能补充了超越即时数据的时空视角。他们在日常生活中的调适与妥协，则展现了现实世界的弹性逻辑，</strong>让AI能够学习到“非理性中的合理性”，更贴近真实的社会运行方式。</p>
  <p>更重要的是，大部分的长辈们形成的价值判断往往强调稳定、责任与长期性。引入长辈通过时间沉淀的时间智慧，可以让AI突破即时数据的局限，在历史积累与现实情境之间找到可持续的判断逻辑，逐渐具备社会化的判断力。</p>
  <p>生活智慧因此不仅是一种记忆或经验，而是一种能赋予AI纵深与温度的框架。正是在这种框架下，人工智能才能真正从“运算的工具”迈向“理解人类的伙伴”。</p>
  <h3><strong>1.3 独特的回应方式</strong></h3>
  <p>老年人在长期的社会生活中，逐渐形成了属于自己的回应方式和行为准则。他们往往不急于直接表达，而是通过含蓄、迂回或带有经验暗示的语言来传递真实想法。这种回应方式背后是一套自洽的生活逻辑：既维护了关系的和谐，又保持自我尊严。正因如此，他们的交流中常常包含丰富的潜台词与分寸感。</p>
  <p>如果人工智能要真正被老年人接受，就需要在数据层面深入理解这种独特的语言与行为模式。换句话说，AI需要学习的不只是“听懂话”，而是“听懂人”。当AI的回应方式能够体现出类似的智慧，即尊重节奏、保留余地、懂得迂回。老年人会更容易感受到熟悉感与亲切感，也更愿意与之互动。</p>
  <p>构建带有“老年知识”的AI，是技术上的改进，也是赢得老年群体信任与使用意愿的关键因素。</p>
  <h2><strong>二、老年人参与Al训练的路径</strong></h2>
  <h3><strong>2.1 数据共建</strong></h3>
  <p>在面向老年群体的人工智能建设中，数据质量决定了系统的可用性与可信度。目前腾讯与百余家社会组织公益共创的AI向善语料库（老年文本库）已完成的 8047组老年人与社工的日常生活常见问题问答对，覆盖了健康管理、心理支持、家庭关系、社会参与等多个方面。</p>
  <p>AI时代没有旁观者｜AI向善语料库开放发布会实录</p>
  <p>这些数据的独特价值在于，问题来自老年人，真实的呈现了他们的生活需求与表达逻辑。回答由社工提供，体现了专业化的回应与服务经验。这一组合<strong>让AI学习到“老年人如何提问”</strong>，也学习到<strong>“社会服务如何回应”</strong>，形成了真实、双向的语料。</p>
  <p>在此基础上，本研究又进一步收集了<strong>&nbsp;1408条</strong>由老年人针对老年人问题的回答。与社工的专业解答相比，老年人之间的互答更贴近日常语境，往往包含个人经历、生活智慧与情感支持。这类回答呈现出高度的经验性与人情味，为AI提供了更加接近真实社交互动的训练素材。</p>
  <p>通过这两类数据的结合，共计<strong>9455条</strong>真实且带有丰富场景信息的语料，可以逐步构建一个系统化的 “长者智语”数据集。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_d664d30c75b54b6eb1258824df31f314@000000_oswg112397oswg1080oswg650_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">本研究中老年语料的来源、分析和评估</p>
  <h3><strong>2.2 情绪知识挖掘</strong></h3>
  <p>老年人的情绪知识蕴含于日常认知与表达中，需通过科学方法系统挖掘以转化为 AI 可学习的知识资产。</p>
  <p>研究团队采用邀请老年人给出回复并解释的半结构化访谈作为核心手段，构建&nbsp;<strong>“初始应答 - 深度追问 - 逻辑拆解”</strong>&nbsp;的三阶挖掘框架：首先引导老年人围绕特定问题给出回答，自主表达观点与感受，形成基础应答数据。随后以 “为什么这样说”、“当时更关注什么” 等开放性问题进行追问，层层剥离表层语言背后的情绪逻辑。</p>
  <p>例如，老年人向 AI 倾诉&nbsp;“子女在国外工作，家里就我一个人，遇到事儿都没人搭把手”，并询问 “这种情况我该怎么办？”。</p>
  <p>&nbsp;从表层看是寻求生活难题的解决方案，但其深层情绪逻辑中，隐藏着 “希望得到‘自己培养出优秀的子女，是教育成功’的认可与肯定” 的心理需求，然后再解决他的问题。</p>
  <p>这种&nbsp;<strong>“话外之音”&nbsp;</strong>正是当前 AI 难以精准捕捉的核心，最终通过文本分析与情感标注，将这些隐性的情绪动因、价值判断与经验逻辑，转化为结构化的训练样本。</p>
  <h3><strong>2.3 共创与反馈机制</strong></h3>
  <p>老年人参与 AI 训练不应止步于 “数据提供者”，更需通过共创实验与反馈机制，深度介入 AI 优化过程，实现从 “使用者” 到 “训练师” 的角色升级。</p>
  <p>研究团队在 AI 模型迭代的关键阶段，邀请老年人参与场景化测试，例如模拟 “智能医疗咨询中表达身体不适”、“智能养老设备操作遇阻” 等真实情境，让老年人直接评估 AI 回应的语气适配度、情感共鸣度与解决方案有效性，帮助老年人清晰表达对 “AI 回应过于机械”、“用词不够亲切” 等问题的改进意见。</p>
  <h2><strong>三、适老化数据集的分析与拓展</strong></h2>
  <h3><strong>3.1 对原始8047组问答对中的提问分析</strong></h3>
  <p>研究团队以 8047 组老年人与社工的日常生活常见问题问答对为研究样本，通过系统性内容分析开启数据解构工作。这些问答数据并非简单的 “问题 - 回应” 集合，而是老年人真实生活需求的直接映射，同时暗藏其独特的提问逻辑，如倾向于以生活场景描述替代直白诉求，习惯围绕具体事件展开提问等。</p>
  <p>为精准捕捉需求特征，团队构建了多层级场景分类体系：在一级主题层面，明确划分出人际关系处理、身心健康维持、兴趣社交活动、经济社会保障、科技生活支持、死亡议题关注六大类别。基于一级主题，进一步拆解出 16 个子类，例如 “人际关系处理” 下细分 “亲子关系”、“邻里互动” 等。最终，通过三级标签细化为 37 个具体项。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c688928b31ba452db75dab2101ec9399@000000_oswg148703oswg1080oswg676_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">对8047 组问答对中提问的整理与分析</p>
  <p>在场景分类之外，研究团队特别引入 “情感维度” 标注，构建 “场景 + 情感” 的双重分析框架，以破解老年人需求表达中 “功能诉求与情感诉求绑定” 的核心问题。值得注意的是，老年人的提问常呈现&nbsp;“积极与消极情绪交织”&nbsp;的特征，需通过细致分析精准识别 。</p>
  <p>例如，有老年人提及&nbsp;“孙子教我用视频电话，现在能天天看见他，但是也害怕麻烦他”&nbsp;时，既流露出 “能与晚辈互动” 的愉悦积极情绪，又夹杂 “怕下次忘操作，给孩子添麻烦” 的担忧的消极情绪。</p>
  <p>考虑到这类情绪交织的复杂性，团队选择在第三级场景分类，即 37 个具体项中嵌入精细化情绪效价标注：针对每条提问，不仅明确其所属具体场景，更通过文本语义分析、语境判断及语气词解读，同时标注出并存的积极与消极情绪，而非简单归为单一情绪类别。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_e5e04eea981f4363be90924053c73bd7@000000_oswg282460oswg1080oswg701_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">对8047 组问答对中提问的三级分类与情感标注</p>
  <p>通过对 “场景 + 情感” 双重标注数据的交叉分析，研究团队得出两项具有实践意义的核心发现。第一项发现聚焦老年人需求的 “多维度交织性”，老年人的问题普遍存在 “表层场景 + 深层情感” 的双重诉求。例如，部分老年人在咨询 “高血压用药调整”时，会反复提及 “子女最近忙，没敢跟他们说”，这本是一个健康的话题，但实则隐藏着 “担心子女担忧却又渴望陪伴” 的情感需求。这一特征表明，简单的功能归类无法真正理解老年人需求，必须立足其整体生活情境进行综合判断。</p>
  <p>第二项发现则揭示了不同话题之间的关联度，如 “技术适应” 与 “临终关怀” 的强关联。不少提及 “智能手机操作困难”、“智能家电不会用” 的老年人，在对话中会自然过渡到 “年纪大了学不会，以后可怎么办” 的衰老焦虑，进而延伸至 “对于死亡的恐惧” 等临终关怀议题。</p>
  <p>基于上述研究发现，研究团队向银发经济领域从业者提出重要的实践建议：面向老年人的服务设计与适老产品开发，须完成从 “功能驱动” 到 “尊严与情绪体验导向” 的转型。过往诸多适老产品仅聚焦 “功能简化”，却忽视老年人使用中的情感体验，过度强调 “适老化” 反而让老年人产生 “自身脆弱” 的负面感知，最终导致使用率低下。 &nbsp; &nbsp;</p>
  <p>对老年人而言，功能满足仅是基础门槛，其背后承载的情感需求，如通过技术使用获得 “自主感” 而非 “依赖感”、通过服务参与获得 “社会价值认同” 而非 “被照顾者” 标签。才是决定接受度与持续使用率的关键。因此，建议从业者在产品开发前期全面捕捉老年人情感诉求，并将 “尊严维护” 融入产品全生命周期，推动银发经济向更具人文关怀的方向发展。</p>
  <h3><strong>3.2 拓展与分析长辈的回复</strong></h3>
  <p>在对原始数据进行系统性分类与情感标注后，研究团队进一步聚焦于六个最具代表性的生活场景中筛选出32个典型情感色彩的日常问题，以此呈现老年人在真实生活中的心理轨迹与情绪反应模式。</p>
  <p>为了更深入地理解老年群体如何识别、感受与回应情绪，研究团队邀请了44位老年参与者，他们的年龄从55岁到78岁，平均年龄为65岁。以“情感专家”的身份重新审视这些问题。通过这一角色转化，老年人从被动的提问者转变为情感洞察的诠释者与共创者。</p>
  <p>在共创过程中，他们针对每一个问题给出了自己的理解与回应。许多老者不仅剖析了问题中隐藏的情绪，还敏锐地指出其中所映射的群体性困境。</p>
  <p>例如，一位参与者在探讨“如何平衡子女忙碌、无法常伴”的情境时，结合自身子女在外地工作的经历，分享了如何通过丰富自己的生活与社交活动来转移孤独感。他认为种情绪的核心并非孤独本身，而是“需要被关注与陪伴”的情感能量，需要通过主动创造生活充实感来实现情绪转化。</p>
  <p>在对 1408 条长辈回复进行系统性内容分析后，研究团队进一步总结出老年人回复的四种回应风格：共情支持型、理性劝导型、经验分享型与实用指令型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ad848a6452bc4e2dbedc996a30e69688@000000_oswg105262oswg1080oswg686_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">对1408条老年人回复内容的风格分析</p>
  <p>共情支持型语言逻辑以“情绪感知”为基础，通过温和的理解与陪伴化解焦虑，再用安抚性语句稳定情绪，强调“被理解”和“被共情”的安全感。经验分享型则以“自述经历”传递生活智慧，通过“我以前也…”等句式分享个人经验和应对策略，鼓励他人。实用指令型则直接、简明，关注具体行动方案。理性劝导型则倾向于理性分析，提供结构化建议，体现老年人务实的生活态度。</p>
  <p>在明确四种常见回应风格后，研究团队进一步探索老年群体在不同场景与话题下的偏好及其形成原因，旨在揭示老年人“希望怎样被回应”。这为构建具备情绪智力与个性化表达能力的适老化对话系统奠定了实践基础。</p>
  <p>在此阶段，研究团队邀请老年参与者以“回答质检员”身份参与评估任务，对六个大场景话题下的十个具体问题，针对每种回答风格进行打分，评价维度包括：1. 回答是否理解提问者的问题与困境；2. 是否传递共情与情绪价值；3. 是否提供具体可行的帮助。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9f45906dda694a95a54f620a6e8f622a@000000_oswg90028oswg1054oswg628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>老年参与者以“回答质检员”身份，对四种不同回复风格在理解度、共情度和帮助度三个维度上的评分。总分在十个话题场景下的均分，满分 30 分，采用量表打分。</p>
  <p>在对评分和反馈的数据进行深入的混合分析后，研究团队得出了三项核心发现。首先，老年人在不同生活场景下展现出明显的回应风格偏好；其次，共情支持型表达成为最受欢迎的回答类型；第三，老年人对“理解”、“帮助”、“共情”三项维度的评价高度一致，表现出整体性判断的特征，即他们将“被理解”、“被帮助”与“被共情”视作同一体验，而非割裂的评价维度。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_aab635dffe404c74be58b449efb95f80@000000_oswg76640oswg1080oswg643_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>老年参与者对十个话题中，四种不同回复风格在理解度、共情度和帮助度三个维度上的评分均值。每个维度满分 10 分，采用量表打分。</p>
  <p>值得注意的是，在临终关怀等高度情绪化的话题中，老年人的偏好呈现出理性与情感并重的特征。理性劝导型回答在此类话题中获得最高评分，参与者认为这种回答既提供了面对死亡的哲思与理性建议，又保留了足够的情感温度。</p>
  <p>一位参与者在评价时提到：“我喜欢这个回答中蕴含的哲理，它让我觉得死并不可怕，是一种自然的规律，重要的是如何转变自己的心态，丰富自己的生活。”这种回应在安抚焦虑的同时，也帮助他们重建对生命终点的理解与掌控感。</p>
  <p>整体来看，共情支持型和理性劝导回答在多数话题中保持稳定优势，不仅平均得分高，波动也最小，显示出其广泛的适应性与普遍吸引力。无论是科技学习、健康咨询，还是代际沟通，温柔、理解和专业的语气始终构成老年人最重视的心理支撑。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_19411e5449c749c1a964002b305575d1@000000_oswg90855oswg1080oswg771_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>老年人对不同话题的问题，在三个维度上的打分总分的均值。</p>
  <p>满分为30，打分形式为量表。</p>
  <p>这些发现共同揭示了老年人沟通需求的深层逻辑：他们并非只是被动的“接受建议者”，而是积极寻找情绪共鸣与自我价值的“对话参与者”。在他们看来，理想的回应不仅应当传递理性的信息，更应贴合不同话题情景给出最恰当的回答，在语气与情绪中体现理解与体谅。正因如此，共情的力量成为连接情绪与行动、理解与信任之间的关键纽带，也为未来的适老化对话系统提供了极具启发性的方向。</p>
  <h2><strong>四、意义与未来</strong></h2>
  <h3><strong>4.1 &nbsp;发展有丰富“情绪知识”的大模型</strong></h3>
  <p>将老年人的情绪智力与生活智慧纳入 AI 训练体系，是提升 AI 能力的有效路径。长者经验中的非结构化情感判断、柔性调解策略及隐性同理心，能为 AI 提供 “从工具到伙伴” 的转型支撑。</p>
  <p>通过学习长者对人类情感与社会互动的理解，AI 可突破技术局限，在医疗陪伴、养老服务等场景实现更具温度的交互，推动人工智能从 “功能实现” 向 “情感共鸣” 的深层次发展，拓展其在银发经济领域的应用边界与价值空间。</p>
  <h3><strong>4.2&nbsp;从边缘到智慧贡献的重塑角色</strong></h3>
  <p>这一过程更重塑了老年人在技术发展中的角色定位 ：<strong>从被动的 “被服务者” 转变为主动的 “知识与智慧贡献者”。</strong></p>
  <p>以往老年人常因数字鸿沟处于技术边缘，而参与 AI 经验供给，使其拥有了技术发展的 “话语权”：在分享情感识别技巧、冲突调解经验的过程中，老年人不仅能通过技术参与获得自我价值认同与尊严感，更能将个人数十年的生活智慧转化为可传承的社会资产。</p>
  <p>这种角色转变打破了 “技术只属于年轻人” 的刻板认知，让老年人在数字时代找到新的社会参与方式，实现个人社会价值的延伸与再创造。</p>
  <h3><strong>4.3&nbsp;推动代际共创的包容智能社会</strong></h3>
  <p>长者经验与 AI 技术的结合，本质上是一场 “代际共创” 的实践，推动技术发展从 “单向创新” 走向 “跨代协作”。</p>
  <p>一方面，老年人的生活经验被纳入技术研发体系，使其智慧得以通过 AI 载体实现跨代传承，这不仅契合我国 “敬老、爱老” 的文化传统，更让技术发展承载了更多人文温度；</p>
  <p>另一方面，基于长者经验优化的 AI 技术，能更精准地匹配银发群体需求，让老年人平等享受智能服务带来的便利，真正实现<strong>&nbsp;“AI 发展成果由社会共享”</strong>。</p>
  <p>这种模式既缓解了数字时代的代际隔阂，也为构建更包容、更具人文关怀的智能社会提供了可行路径，对推动社会可持续发展具有重要现实意义。</p>
  <h2><strong>五、结语</strong></h2>
  <p>岁岁重阳，今又重阳。这一承载 “登高望远、敬老怀思” 的传统节日，既是仪式性的文化纪念，也在提醒我们尊老敬老的本质，是珍视岁月沉淀的智慧，让每一代生命经验都成为社会发展的动力源泉。当人工智能浪潮席卷而来，银发群体不该是技术的 “旁观者” 与 “边缘人”，他们经岁月沉淀和历史印记的人生洞察与处世智慧，是所有人都值得学习的“情绪知识”。</p>
  <p>正如重阳登高需以坚实石阶为基，AI 的适老之路也需依托这份 “情绪知识” 与长者智慧方能行稳。将老年人经验纳入 AI 发展的进程中，让 “被看见、被倾听、被吸纳”&nbsp;成为技术迭代底层逻辑，AI 才能读懂银发群体情感需求，银发经济才能突破 “功能适老”、抵达 “尊严适老” 境界。</p>
  <p>这正是重阳文化在智能时代的全新诠释，以敬老之心承智慧之重，以包容之姿启未来之程。让每一份岁月沉淀的 “情绪知识”，都在技术发展中绽放照亮代际的光芒。</p>
  <blockquote>
   <p>研究团队：腾讯研究院 陆诗雨、张鸿茹、何婧文(实习) 北京邮电大学 张为威、刘蓓佩、张伟珍</p>
   <p>项目参与者：李可昕、邓佳昕、包涵、李晨阳</p>
   <p>图文编辑：张为威、包涵、刘蓓佩</p>
  </blockquote>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5OTE0ODA2MQ==&amp;mid=2650993386&amp;idx=1&amp;sn=9cbe52427f621b18d219cb24461b1923&amp;chksm=bd6447b6f94d4d134093a04bd10534a033760c77a35abbeeb3c9c60aa29bf6f782c24652fe2d&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“腾讯研究院”（ID：cyberlawrc）</a>，作者：腾讯研究院，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530150849387652</id>
            <title>深圳千亿IPO来了</title>
            <link>https://www.36kr.com/p/3530150849387652</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530150849387652</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 11:14:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>巨无霸IPO来了。</p>
  <p>投资界-天天IPO获悉，近日“医疗器械一哥”迈瑞医疗披露公告称，公司拟发行境外上市外资股（H股）股票并在港交所主板挂牌上市。如今74岁创始人李西廷依然坐镇，迈瑞医疗再次奔赴IPO。</p>
  <p>迈瑞的故事定然不陌生。1991年，深圳三位同事放弃高薪离职创业，李西廷、徐航、成明和组成迈瑞“三剑客”，开启中国高端医疗器械之路。巅峰时刻，迈瑞市值一度突破4000亿。</p>
  <h2><strong>迈瑞崛起史</strong></h2>
  <p>改革开放的第九年，深南大道全线贯通，36岁的李西廷“调干”南下深圳。</p>
  <p>出生在安徽宿州砀山县一个农村家庭，早年参军入伍。1973年，他抓住唯一一次高考机会，考入中国科学技术大学物理系，此后前往巴黎访问学习，成为改革开放后最早一批留洋人士。</p>
  <p>1986年，中科院在深圳与美国公司Analogic成立中国医疗器械领域首家合资企业——深圳安科，从事复杂医疗器械的进口贸易，一年后，李西廷从中科院“调干”到这家新公司。</p>
  <p>在李西廷考入大学的6年后，一个来自广州的年轻人以全省重点中学第一的成绩考上清华大学。那年徐航17岁，同时选择进修计算机和生物科学两个专业，随后赴美留学。1987年，徐航硕士毕业，回国加入了深圳安科，两人自此相识。</p>
  <p>彼时，国内医疗资源稀缺，行业处于空白阶段。一次回乡探望同学，李西廷看到县城手术台边连最基本的急救设备都没有，创业的念头燃起。于是他叫上徐航，再找来另一位同事——毕业于上海交通大学的生物医学硕士成明和，三人一起创业，这便是日后“迈瑞三剑客”的故事。</p>
  <p>1991年，还在开发中的南山蛇口太子路金融中心，迈瑞悄悄落地。“迈瑞的发展是随着深圳特区抓高科技，一波一波政策节拍走过来的。”李西廷曾在一次采访中回忆。彼时改革开放的步子刚刚迈开，深圳只有一批加工型企业，亟需孵化高科技项目，李西廷就是在这一背景下注册了迈瑞医疗。</p>
  <p>随后，拿着向深圳市科技局借来的95万，三剑客带领团队开发出第一款产品——血氧饱和度监护仪。产品经专家检测尚可，但钱一时半会儿也还不上，于是，三人又向深圳借来500万，正式生产并投向市场。</p>
  <p>就这样，迈瑞的齿轮开始转动起来。</p>
  <p>迈瑞医疗是第一批进军高端医疗器械市场的中国企业，彼时国内只能做消毒柜、病床、镊子、针管等简单的医疗器械，而其他进口设备价格昂贵。团队三人身兼技术工程师、销售业务员多职，最终利用价格差打开了市场。</p>
  <p>迈瑞成立的前几年，为了应对资金困境，李西廷曾前往华尔街寻找风险投资，但吃了不少闭门羹，他在回忆中提到，“华尔街的美国人都不理我们，当时很灰心”。不过并非没有收获，此次华尔街之行，李西廷结识了华登国际的一位中国人茅道临。</p>
  <p>1997年，迈瑞因代理业务受损再次陷入困境，茅道临为李西廷从华登国际争取到了200万美元，这是迈瑞拿到的第一笔风险投资，也是VC进入中国的早期案例之一。</p>
  <p>后来，华登国际又联合KTB投资集团、JAIC等注资600万美元。从2000年代开始，迈瑞逐渐走入正轨，相继推出多个“中国第一台”医疗设备仪器。国产医疗器械一哥，徐徐崛起。</p>
  <h2><strong>创业板曾经年度最大IPO</strong></h2>
  <p>30多年历程中，迈瑞经历了美股、A股、港股三次跳跃。</p>
  <p>2004年，已经离开迈瑞的徐航、成明和去而复返，三剑客再聚首决定启动IPO。年初，高特佳投资进场，次年高盛进入。</p>
  <p>彼时的“股权分置改革”使得国内上市大门暂时关闭，侧面引发了中国企业海外上市潮，迈瑞就是其中一个。2006年9月，迈瑞医疗成功登陆纽交所，成为中国第一家医疗器械海外上市公司。</p>
  <p>在纽交所上市期间，迈瑞市值最高达到35.9亿美元，后期一直处于低迷状态。恰逢中概股掀起回归热潮，2015年，李西廷、徐航、成明和三位联合创始人作为买方集团，向董事会提交了拟收购迈瑞国际在外流通股份的要约，私有化正式开始。这是完全由公司管理层发起的私有化MBO，买方团里没有一个私募股权基金的身影，而私有化资金主要来自银行贷款。</p>
  <p>次年3月，迈瑞医疗以33亿美元（约200亿元人民币）的市值完成私有化，正式从纽交所退市。随后公司又进行复杂的股权结构调整，开始引入其他投资者方——深创投、国中创投、基石资本、弘晖基金、时代伯乐、君盛投资等一批本土VC/PE就是在此时拿到份额。</p>
  <p>2018年，迈瑞医疗登陆深交所创业板，募资额接近60亿元，创下当年创业板最大IPO纪录。</p>
  <p>此后，迈瑞业绩一路飞涨，市值水涨船高，曾超越温氏股份、宁德时代等登上创业板市值榜首。尤其在2020年医疗器械需求激增的背景下，迈瑞医疗市值一度超过3200亿元。至今有所回落，总市值超2700亿元。</p>
  <p>如今A+H热潮之下，迈瑞将下一个目标定在港股。公司在回应投资者提问时提到，港股上市将深度推动“业务全球化”与“资本全球化”的战略协同。此番赴港上市是迈瑞推进国际化战略的一步，出海野心已然显现。</p>
  <p>这在迈瑞医疗2025年半年报也可一窥一二：报告期内，公司国际业务同比增长 5.39%，国际业务收入占整体收入的比重进一步提升至接近50%，预计下半年国际业务增长还将有所提速。此前迈瑞医疗管理层也曾透露，公司计划将海外收入占比提升至70%以上。</p>
  <p>股东大会上，74岁的董事长李西廷还在台前，如多年前那样宣布了迈瑞新的战略目标——在未来五年内（即2030年前），成功跻身全球医疗器械企业综合实力排行榜前十。</p>
  <h2><strong>深圳第一批造富者</strong></h2>
  <p>回过头来看，迈瑞成就了一批创富者。</p>
  <p>A股IPO前迈瑞招股书曾披露过，李西廷通过Smartco Development间接持有公司29.8944%的股份，徐航通过 Magnifice (HK) 间接持有27.1413%的股份，成明和则通过Ever Union间接持股5.8829%。加上三人通过另外两大主体合计间接持有的股份，迈瑞接近70%的股份都在三位联合创始人手中。</p>
  <p>2018年登陆深交所后，迈瑞医疗的股价从50多元一度飙升至180元左右，三位创始人的身家水涨船高。这一年，李西廷和徐航分别以604.6亿元和597.5亿元的财富值跻身福布斯中国富豪榜第27和第29名。</p>
  <p>2021年迈瑞股价更是到达巅峰。这一年，李西廷以215亿美元（以彼时汇率计算约1400亿人民币）财富位列福布斯全球富豪榜第82名，徐航身价也达到了千亿级别。</p>
  <p>另一边，徐航的财富故事里不止有迈瑞。2004年，徐航在友人帮助下顺利拿到了深圳前海的一块地皮，多年后，这里被开发成著名的“深圳湾1号”。</p>
  <p>带迈瑞上市之余，徐航开始进军房地产行业，并在2007年一手创立鹏瑞地产。直到2012年，徐航辞去迈瑞联席CEO职位，次年深圳湾1号发售，开盘单价高达6万元至17万元，轰动一时。</p>
  <p>造富潮不止显现在“三剑客”身上。这里有一个插曲：早年迈瑞深陷资金困难，一位在深圳的工程老板通过熟人机缘巧合投了100万，后来迈瑞成功上市，这笔投资回报超亿元。这位老板由此转行，创立一家医疗投资机构。</p>
  <p>90年代的深圳，遍地创富传奇，正如在迈瑞成立前后，华为、比亚迪、腾讯相继诞生。</p>
  <p>转眼30多年过去，深圳湾海岸被填平，崛起一家又一家高新科技企业，前海后海从一片滩涂到如今高楼迭起。</p>
  <p>最早造出“深圳梦”的创业者老去，一波年轻人正在赶来。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/UzphnWxNEBDZKpx5vxng_g" rel="noopener noreferrer nofollow" target="_blank">“投资界”</a>，作者：杨文静，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530151056628871</id>
            <title>全球首个家务机器人开卖，月租3600，拿瓶水要1分钟，还得真人遥控</title>
            <link>https://www.36kr.com/p/3530151056628871</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530151056628871</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 11:11:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全世界第一款，真正面向消费者，能做家务的人形机器人来了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6db156ce0af34bc7b46eb22321895e35@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p><strong>这次不跳芭蕾、不展示功夫，真的能给我们打扫卫生、随叫随到。</strong></p>
  <p>只需要喊一声「Neo，帮我叠衣服」，一个 1 米 68 的人形机器人，就会从角落里转身，轻轻俯下身，双臂「灵活」地折叠好衣物。&nbsp;</p>
  <p>三月份的时候，它更是直接给黄仁勋买了一件皮夹克，亲手送给了他。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_829cae4eb63f4199ad3b203aa44eb987@46958_oswg1630819oswg1080oswg1350_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>经过大半年的优化，现在我们也能把它买回家了。&nbsp;&nbsp;</p>
  <p><strong>由 OpenAI、NVIDIA 和三星等巨头支持的机器人公司 1X 宣布，其人形机器人 Neo 在今天正式开放预订。</strong></p>
  <p><strong>售价 20000 美元（约 14.5 万人民币）买断服务，或选择每月 499 美元（约 3600 人民币）的订阅服务</strong> ，两种支付方式。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5caced17e2054289bce6a963b100773d@46958_oswg167458oswg1080oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">官网购买页面，有浅棕色、灰色、深棕色，三种不同的颜色可选择。https://www.1x.tech/order&nbsp;</p>
  <p>目前已经可以在 1X 官网进行预订，第一批支持美国用户，在明年开始逐一送货；预计 2027 年扩展到全球用户。&nbsp;</p>
  <p>虽然每月订阅费，可能比聘请一个保姆更便宜，但是 Neo 能做的事情，真的能像人一样，处理好那些又细又杂的家务活吗？&nbsp;</p>
  <h2><strong>请把它当作一个家电，而不是「终结者」&nbsp;</strong></h2>
  <p>Neo 身高 1.68 米，重约 30 公斤，全身覆盖柔软聚合物外壳，穿着针织高领衫与运动鞋。&nbsp;</p>
  <p>1X 公司的创始人说，这样可以让它看起来更不像是一个终结者，只是一台能做家务、会聊天、还挺有性格的机器人。&nbsp;</p>
  <p>在设计上，Neo 的手臂拥有 22 个关节，接近人类灵活度，能提起大约 45 斤重的物体。&nbsp;</p>
  <p>作为对比，之前宇树发布的 H2 相关的参数是，高 180cm，重 70kg，关节总数 31 个。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_19ecbcfe94e34a4098c916187532aa16@46958_oswg513332oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在 Neo 体内，搭载了 3D 视觉摄像头、麦克风阵列和 NVIDIA Jetson 平台，让它能识别语音、理解物体、甚至回答问题。&nbsp;</p>
  <p>基于这些形态和能力，1X 介绍 Neo 的核心功能，就是自动化日常家务。我们可以给它一个任务清单，或者通过简单的语音命令，让它处理各种各样的琐事。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1a83d0bb49574b468ad5ca1a7be4c5d9@46958_oswg837790oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>家务处理</strong> ：比如折叠衣物、整理书架和桌面、收拾杂物。&nbsp;</p>
  <p><strong>日常协助</strong> ：帮我们取东西、在门口迎接客人、晚上关灯。&nbsp;</p>
  <p><strong>智能交互</strong> ：Neo 不仅仅是「动手」的。它也内置了大型语言模型，可以像一个智能音箱一样，和我们自然地对话。&nbsp;</p>
  <p><strong>情境感知</strong> ：它配备了视觉和听觉智能。这意味着它能看到厨房台面上的食材并建议食谱，也能在我们和别人聊天时，知道何时该插话，何时该保持安静。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_067bfd3555524d2585b6e5e994912e07@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>记忆能力</strong> ：它能记住过去的对话，提供连贯的个性化帮助，比如帮我们管理日程、设置提醒或跟踪你的语言学习进度。&nbsp;</p>
  <p>值得一提的是， <strong>Neo 的胸部和骨盆区域还内置了三级扬声器</strong> 。当它不忙时，它就是一个可以移动的家庭娱乐系统，一个行走的智能音箱。&nbsp;</p>
  <p><strong>不只机器人，还有一个背后操作机器人的人。&nbsp;</strong></p>
  <p>看到这里，你可能真的准备去看看，能不能下单了吧。但注意了，Neo 能在 2026 年就交付，背后有一个关键的「捷径」：<strong>它并非完全自主</strong>。&nbsp;</p>
  <p>1X 坦诚，Neo 在交付时只能处理一些基本任务。当它遇到一个它不知道如何处理的复杂任务时，比如操作家里某个型号独特的洗衣机，它会怎么办？&nbsp;</p>
  <p><strong>答案是：「摇人」。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_4ea2ea6377704bbc982c28bcd836f592@46958_oswg481192oswg1080oswg523_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">Neo 的两个眼镜会变成远程操作员的摄像头，远程操作员给 Neo 下指令如何操作&nbsp;</p>
  <p>Neo 有一个「杀手锏」功能： <strong>用户可以召唤一名远程的「1X Expert」（1X 专家）。</strong></p>
  <p>这名训练有素的人类操作员，将通过互联网（Neo 支持 WiFi 和 5G ）， <strong>实时接管并远程遥控 Neo</strong> ，通过它的摄像头获取当前环境，控制它的身体来完成任务。&nbsp;</p>
  <p>好处是，Neo 可以「边做边学」。机器人在观察人类操作员完成后，会学习这项技能，以便未来自主完成。&nbsp;</p>
  <p>坏处是，<strong>这带来了巨大的隐私问题</strong>。&nbsp;</p>
  <p>想象一下，一个陌生人通过机器人的摄像头和麦克风，在你的客厅、卧室里自由活动，观察你家中的一切。网友的脑洞已经快进到，把系统黑掉，然后操控机器人来时时各种破坏。&nbsp;</p>
  <p>这个机器人，倒是很像网上经常看到的自动售货机，说背后都有一个人在控制，并不是靠机器识别到买家拿了什么东西。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_dd9334911e294470b3af4674288c31fe@46958_oswg659823oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>《华尔街日报》的记者在体验时，让 Neo 去冰箱拿瓶水。它能走过去，但打不开门，于是需要远程人类接管操作，这瓶水最终花了一分钟才拿到手。&nbsp;</p>
  <p>在另一场演示里，它试着吸尘，却因为吸尘器没电而放弃。&nbsp;</p>
  <p>Neo 目前能处理的，大多是可预测、低复杂度的任务。真正需要判断的场景，仍要靠「远程人类」帮它完成。&nbsp;</p>
  <p>相当于每个月 3600 块的订阅费，是支付给那个背后操纵机器人的「人类专家」。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_e311446a467041dbbf6cde323f6beb8c@46958_oswg1168174oswg1080oswg721_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>1X 公司的 CEO 花了非常多的时间来解释这件事情的可靠性，例如用户可以划定区域，哪些地方是幕后操作员不能让 Neo 进去的；还有幕后操作员的每次行动，都必须先得到用户的许可；Neo 身上的麦克风什么时候被唤醒；数据的加密等等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2bfdbe72518e43508dea4278d5b880b1@46958_oswg50526oswg854oswg670_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">商品页面问答部分，解释「专家」不能随时接入机器人进行指挥&nbsp;</p>
  <p>他还提到， <strong>这是为了训练</strong> ，Neo 不必像其他机器人那样在实验室里练上百万次。它可以直接在真实家庭中学习，用无数家庭的生活细节，训练出更通用的智能。&nbsp;</p>
  <p>1X 对此也直言不讳， <strong>称早期用户实际上是「Beta 测试者」</strong> ，他们购买的产品，将通过不断的软件更新和训练来扩展能力。&nbsp;</p>
  <p>合着今天的开售，就是招募小白鼠，收集用户的影像、声音、隐私，来作为它学习的资料。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6234118c03d543c7951305c89cf4e0c1@46958_oswg456456oswg1080oswg1148_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前他们的 X 账号，官宣发售的推文，已经获得了千万次的浏览，在评论区，也有一些用户晒出了自己的预订记录截图。&nbsp;</p>
  <p>人形机器人赛道的火热，完全不亚于 AI 大语言模型。马斯克一而再的强调说，自己的特斯拉 Optimus 机器人，未来可能给公司带来的营收占比 80%。&nbsp;</p>
  <p>同样有 OpenAI 和英伟达支持的 Figure AI，在 9 月份以惊人的 390 亿美元估值融资 10 亿美元。这个月 9 号，还发布了旗下第三代人形机器人 Figure 03。国产机器人宇树科技的存在，更是不可忽视。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_dacda846c6e44994a42886c25e60d551@46958_oswg724809oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>和体验视频里，那位记者说的一样。虽然是能做家务，但是背后还有一个人在遥控，就会感觉特别奇怪。&nbsp;</p>
  <p>人要一个 AI Copilot 来帮助自己，所以机器人也要一个 Pilot 来指导它动作。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_e39a3ac676714964bf01a9b05c520c06@46958_oswg665174oswg1080oswg636_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">右图为幕后操作机 Neo 器人的助手，也叫图灵&nbsp;</p>
  <p>我只能把这当作是家务机器人迈出的第一步，之前我们写了很多世界生成模型，提到 &nbsp;<strong>AI 生成的世界，可以成为自动驾驶等任务的训练环境</strong> 。&nbsp;</p>
  <p>现在看来，机器人领域也是这样，没有虚拟的训练环境，就先把它们放出去，在真实的世界里接受复杂的训练，然后慢慢成长。&nbsp;</p>
  <p>最后附上华尔街日报的<strong>体验视频</strong>，字幕由 AI 转译。&nbsp;视频来源：https://youtu.be/f3c4mQty_so&nbsp;</p>
  <p>小彩蛋一个，马斯克表示，我知道我的机器人要怎么做了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8699f48556924ebdae13838bcb383fc9@46958_oswg41702oswg962oswg550_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：x@ djcows&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/bIWuLMgE93BGtmMAG1X-Eg" rel="noopener noreferrer nofollow" target="_blank">“APPSO”</a>，作者：发现明日产品的，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530164578147461</id>
            <title>高通新发AI推理芯片，瞄准每年3000亿美元市场</title>
            <link>https://www.36kr.com/p/3530164578147461</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530164578147461</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 11:11:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2e979ed110a8436ba79f468071dcae71@46958_oswg150508oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>北京时间10月27日晚间，高通发布了AI200及AI250两款AI数据中心芯片，以及基于两款芯片的加速卡和机架级解决方案；两款芯片计划分别于2026和2027年投入商用。</p>
  <p>这也是继高通在2019年发布Cloud AI 100、2023年发布Cloud AI 100 Ultra后，又一次推出数据中心AI推理新品。</p>
  <p>消息发布当天，高通股价急剧拉升，盘中一度飙升22%达205美元，这也是高通自2024年6月下旬以来的最高股价，最终闭盘收于每股188美元，涨幅为11.09%。包括摩根大通、美银证券、TD Cowen等多家投行更新了对高通的评级并维持买入，最高买入价格看至200美元。</p>
  <p>同一天，高通还宣布将与沙特阿拉伯AI企业“HUMAIN”合作，推进AI200和 AI250落地应用。</p>
  <p>随着AI应用需求暴增，市场对AI推理芯片需求水涨船高。今年英伟达、谷歌、华为均已公布AI推理芯片新品。面向AI推理的蓝海市场，各家比拼的将不仅是技术能力，更是跑马圈地的速度。</p>
  <p>对高通而言，此次对AI推理的发力不仅是涉足热门方向，也是推进其数据中心业务布局的最新一步。近年，高通曾多次公开展露其对数据中心市场的兴趣，除了AI推理芯片，高通同样在数据中心CPU等方向展开了产品布局。</p>
  <p>在官宣AI200及AI250发布的新闻稿最后，高通也写道：高通致力于制定一个按年推进节奏的数据中心路线图，专注于提供行业领先的AI推理性能、能源效率及TCO（总拥有成本）。</p>
  <h2><strong>跻身2025数据中心推理芯片竞速赛道</strong></h2>
  <p>“AI推理”指已经过训练的模型经过部署后，对新输入的数据进行逻辑推导与预测。与之对应的则是“AI训练”，指模型通过分析庞大的数据集、学习其中的模式与关系。</p>
  <p>在实际应用中AI训练与推理芯片之间并没有严格、明确的划分，但相较训练场景要求芯片具备绝对强大的并行计算能力，推理场景更强调芯片的能效、时延、成本等综合性能。本次发布的高通新品同样着力于针对总拥有成本 (TCO) 和性能进行平衡设计。</p>
  <p>据官方信息，AI200及AI250基于高通NPU技术，其中基于AI200的机架级AI推理解决方案支持每张卡768GB的LPDDR（低功耗双倍数据速率内存），以提高内存容量和降低成本；而AI250 解决方案将首次使用基于近内存计算的创新内存架构，有效内存带宽大幅提升且功耗更低。</p>
  <p>此外两种机架解决方案均采用直接液冷散热方案，采用PCIe进行纵向扩展，采用以太网进行横向扩展，采用机密计算以确保安全的AI工作负载，单机架功耗为160kW。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6124f70fdea94747abfb068c29b45d7c@46958_oswg199242oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>高通新品于此时亮相是想踩中AI推理市场爆发的宝贵时间窗口。</p>
  <p>今年以来，AI推理市场动态频出。比如9月份，AI推理创企Groq官宣已达成7.5亿美元的新融资，并称接下来计划建成“全球最大推理数据中心”。</p>
  <p>同样在9月份，OpenAI已与老牌云计算巨头甲骨文达成合作的消息在市场中广为流传，据称OpenAI已敲定将在5年内从甲骨文采购逾3000亿美元的推理算力——这也是有史以来经披露的最大云计算合同。消息一出，甲骨文股价一度急剧拉升，单日最大涨幅超36%。</p>
  <p>而据巴克莱银行旗下研究机构预测，到2026年，AI推理计算需求将占通用人工智能总计算需求的70%以上，推理计算的需求甚至可以超过训练计算需求、达到后者的4.5倍；而现有芯片资源可能难以满足这一需求，需增加当前预测4倍的芯片资本支出，总额或将接近3000亿美元。</p>
  <p>面向巨大的需求缺口，包括高通在内的许多厂商正在摩拳擦掌。</p>
  <p>今年4月，谷歌于Google Cloud Next 25大会上发布了TPU芯片“Ironwood”，号称其为首个专门为大规模AI推理而设计的TPU加速器。</p>
  <p>9月，英伟达发布了针对AI视频生成和软件开发等大规模上下文处理任务的“RubinCPX” GPU。后者基于Rubin架构打造，能够在计算密集型的上下文推理阶段实现突破性性能表现，计划于2026年底上市。</p>
  <p>同样于9月举办的华为全联接大会上，昇腾多系列新品亮相，其中“950PR”将于2026年第一季度对外推出、着力提升推理Prefill（AI推理过程中的关键阶段）性能。</p>
  <p>换句话说，从2026年开始，高通将与英伟达、谷歌、华为等企业在AI推理的赛场上同台竞技。以巴克莱所预测的3000亿美元资本支出推算，即便占据到1%的市场份额，对高通而言也是不容小觑的营收增长。</p>
  <h2><strong>“重返”数据中心市场，发掘业绩新引擎</strong></h2>
  <p>高通并未说明AI200和AI250所采用的制程及基本架构方案，但考虑到AI100并非GPU而是ASIC，新款产品有可能也采用了ASIC的基础架构。ASIC （专用集成电路）是一种为特定任务设计的全定制芯片，相较GPU，在能效方面表现更优。</p>
  <p>尽管已经在6年内推出多款AI推理芯片，高通AI推理业务贡献的营收几乎可以忽略不计。</p>
  <p>7月底公布、截至6月30日的2025第三财季业绩报告显示，高通QCT半导体业务该季营收为89.93亿美元，主要来自手机芯片、汽车芯片、物联网业务；QTL技术授权板块营收为13.18亿美元。</p>
  <p>过往多年，高通曾多番尝试开发数据中心产品，但成效甚微。2018年，高通服务器芯片负责人Anand Chandrasekher官宣离职，并传出整个服务器部门裁员50%的消息，被市场解读为高通已放弃这一业务方向。</p>
  <p>直到2024年，Amon于Computex 2024展会接受采访时确认高通将重返数据中心市场，并从2025年开始推进产品动作。</p>
  <p>2025年5月，高通表示计划采用英伟达技术，来定制生产数据中心CPU，用以搭配和连接英伟达GPU使用、助力英伟达GPU实现更加快速的通信。</p>
  <p>6月，高通宣布其间接全资子公司Aqua Acquisition Sub LLC将以24亿美元收购半导体IP企业Alphawave，后者的优势在于拥有高端接口IP，能够增强高通在数据中心市场的竞争力。此桩收购预计在2026年第一季度完成。</p>
  <p>此外，高通近日宣布与沙特阿拉伯的 HUMAIN 合作，HUMAIN 正在开发阿拉伯语多模态大语言模型（ALLaM），并计划将其与高通的边缘设备生态深度集成，形成从芯片到应用的完整技术闭环。</p>
  <p>而在与沙特阿拉伯公司HUMAIN的合作中，高通将为该项目提供“全球人工智能推理服务”，使之成为世界上首个完全优化的边缘到云混合人工智能（项目），使沙特阿拉伯成为全球人工智能中心。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_de6f6e371ee64886822f2adfe19a3a88@46958_oswg793781oswg1080oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左-HUMAIN CEO&nbsp;Tareq Amin；右-高通CEO Cristiano Amon</p>
  <p>尽管布局节奏紧凑，数据中心板块为高通贡献营收仍需时间。</p>
  <p>7月底，2025第三财季业绩说明会，高通总裁兼CEO Cristiano Amon曾在电话会中讲到，公司正积极拓展AI芯片布局，已经与一家超大规模云端服务供应商展开深入洽谈，最快将于2028会计年度开始贡献数据中心相关营收。</p>
  <p>除了AI，高通也在极力推进产品在智慧驾驶、物联网等多元化场景的落地。</p>
  <p>考虑到苹果与高通的基带购买协议将于2026年末到期，而苹果是高通营收占比约20%的单一大客户，“能否在苹果‘撤出’后培育新的营收支柱？”将是市场亟待高通解答的命题。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/VfdSMMkhsysXWOKeJkbXCw" rel="noopener noreferrer nofollow" target="_blank">“电厂”</a>，作者：董温淑，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530093530225539</id>
            <title>淘宝京东AI导购实测：谁才是最懂你的购物搭子？</title>
            <link>https://www.36kr.com/p/3530093530225539</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530093530225539</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 10:46:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>双十一的购物战场上，不只价格在卷，AI也在“卷”。</p>
  <p>今年各大电商平台纷纷上线智能购物功能，<strong>从淘宝的“AI万能搜”到京东的“京言AI助手”，AI正在接管我们的搜索、比价与决策过程。</strong>它们有的擅长“种草”，有的更注重理性分析，也都有各自的“幻觉时刻”。</p>
  <p>《IT时报》记者体验了一轮这些AI功能——看看谁更懂你的购物习惯，谁更靠谱，也看看AI能不能替你做决定。</p>
  <h2><strong>AI万能搜</strong></h2>
  <p><strong>淘宝版DeepSeek，能种草也有“幻觉”</strong></p>
  <p>AI万能搜的使用体验像“淘宝版DeepSeek”。在淘宝首页，点击搜索栏进入后，会出现一个全新的选项——AI万能搜。</p>
  <p>比如先问它，“想去东南亚某地旅游，行程包括爬山和去海边，需要准备哪些东西？”几秒钟后，AI生成了一份详细的出行清单，分类清晰，包括户外装备、防晒用品、实用配件等。更方便的是，在回答中点击蓝色关键词，就能直接跳转至搜索结果，便于你选购相关商品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_460d8e80c8344011959834023732ba64@000000_oswg340821oswg586oswg1086_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>紧接着，记者又试着问了一个问题：“能推荐几款轻薄的羽绒服吗？”</p>
  <p>AI的回答也十分专业——不仅区分了“日常通勤轻薄款”和“户外运动专业款”，还详细介绍了每一款的材质、适用场景和温度范围。</p>
  <p>过去要完成一轮购物流程，通常先去小红书或抖音搜“达人推荐”，再回到淘宝一个个比对。<strong>现在的AI万能搜感觉像把“小红书的种草力、AI的分析力和淘宝的购买力”都塞进了同一个页面，搜索、筛选、决策一步到位。</strong></p>
  <p>AI万能搜还提供“深度思考”和“购物偏好”两个选项。</p>
  <p>记者实测发现，开启“购物偏好”后，AI的推荐会更贴合个人习惯——它能捕捉你最近浏览或购买过的品牌，并在新推荐中优先展示。</p>
  <p>很明显，对于喜欢在社交媒体种草再回购物软件下单的攻略党来说，AI万能搜还是很方便的。</p>
  <p>但AI也不是万能的，幻觉依然存在。</p>
  <p>比如问它，“iPhone 17怎么买最划算？”AI很认真地列出了最佳购买时机和省钱组合方案，但并没有给出购买链接。那么换个问法，“最便宜的iPhone 17多少钱？”</p>
  <p>这次它回答：“通过官方渠道购买、叠加国补和以旧换新后，最低到手价约5199元”，依旧没有附上链接。</p>
  <p>当继续追问“哪里能买到”时，<strong>AI突然开始“胡言乱语”：“iPhone 17标准版最低到手价在3999元左右，即使双十一也难以达到5199元”，甚至还推荐了一些并不存在的购买方案。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c31406c2c2c945349bae8b52ffe69b3b@000000_oswg330538oswg586oswg788_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>整体来看，AI万能搜确实能在一定程度改变购物方式，它让搜索更智能、推荐更精准、路径更短，也让购物体验变得像一次“对话式决策”——问问题、得到答案、点链接、下单。</p>
  <p><strong>但它的缺点也相当明显：信息真实性和来源透明度仍需加强，尤其在涉及价格、渠道等具体内容时，AI很容易“想当然”。</strong></p>
  <p>大家在享受AI工具的同时，也要保留一点判断力，特别是购买大件时，还是应该多比对，以AI为参考，而不是轻信。</p>
  <h2><strong>拍立淘识图“找低价”</strong></h2>
  <p><strong>市场扫描式智能导购</strong></p>
  <p>虽然AI万能搜暂时还不能帮你精准找到“最低价”，但你或许还可以试试拍立淘识图功能的“找低价”入口。</p>
  <p>在淘宝首页点击搜索栏旁的相机图标，就能进入拍立淘识图页面。</p>
  <p>右下角的悬浮球上写着“找低价”，点击它，系统会自动识别商品并在淘宝全站范围内进行同维度比价。</p>
  <p>记者拿起手边的一个不锈钢杯子试了试。</p>
  <p>几秒钟后，AI识图系统识别出多款相似商品，并自动完成比价。它共对比了2147款商品，还根据价格与品牌将结果划分为不同层级：193元至256.5元的日本进口品牌；32.9元至79元的智能或特色功能款；21.8元至50.22元的高性价比日用款。</p>
  <p>AI甚至贴心地推荐了“304不锈钢保温杯”“双相不锈钢保温杯”等替代材质，并附上容量、保温性能等对照信息。<strong>与其说这是比价，不如说是一次“市场扫描式智能导购”</strong>。</p>
  <p>我又扫了一款奢侈品挎包。系统识别结果显示为同款专柜正品价格区间在14140.27元至35170元之间，AI特别提示：“均为品牌正品，多为海外直邮或旗舰店发货。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ae55cebbc902496fa2917a95f1816666@000000_oswg202781oswg983oswg2007_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但进一步观察后便可发现，售价最低的商品来自一家私人店铺，而排在其后的“淘宝全球购”渠道虽更可信，但版型略有差异，与拍摄的那款并非完全一致。</p>
  <p>同时，系统也推荐了几款平价设计款包包，价格在119元至169元之间。对于预算有限、但在意风格相似度的用户来说，这种延伸推荐颇具参考价值。</p>
  <p>由此看来，这项功能的优劣势同样明显：精准聚合同类商品，价格区间清晰，一目了然；通过识图算法实现“同款+相似款”联动，拓宽选择范围；缺点在于，其图像识别能力仍有待提升，部分结果仅为“相似”而非“同款”；<strong>并且对商品真伪与渠道可靠性判断有限，排序逻辑仍以价格为主</strong>；平价替代推荐虽有趣，但在品牌属性与品质匹配上仍有落差。</p>
  <h2><strong>京言AI助手</strong></h2>
  <p><strong>导购结果略显僵化，差评吐槽更具象化</strong></p>
  <p>打开京东首页，在搜索栏的右下角可以看到“AI”按钮，点击进入后，界面与淘宝的AI万能搜颇为相似。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0751a09a9eaf464a88aa46d8a76d5e7d@000000_oswg95448oswg1080oswg1843_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>照例向它提出同一个问题，“能推荐几款轻薄的羽绒服吗？”</p>
  <p>几秒后，AI直接给出5个品牌的具体产品，价格在139元至539元之间，并附上简短的选购建议，页面底部还可进一步查看“全部2900+相关商品”，点击任意一款即可跳转到详细介绍页面。整体体验虽然顺滑，<strong>但它的推荐显然比淘宝更“标准化”——商品类型偏少，个性化不足，AI感更浓，像是在与算法而非一个“懂你”的导购对话。</strong></p>
  <p>不过，京言AI助手在某些细节上做得更“理性”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3e4467d6a30f4702b6616c5cdbd6b925@000000_oswg268295oswg983oswg1810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如，它提供了两个很实用的功能：价格趋势和AI看评价。前者顾名思义，可以直观查看该商品在一段时间内的价格变化曲线；后者则通过自然语言分析消费者的评论内容，生成总结性意见。</p>
  <p>例如在我查看的一款轻薄羽绒服下方，AI看评价中写着：“气味敏感者慎选。部分用户反馈‘鸭绒味残留’，建议通风晾晒或机洗后再穿；对气味敏感者，可优先考虑无味款。”<strong>这种信息比单纯的星级评分更具参考价值，让评论区的信息不再是“碎片化的吐槽”，而成为真正的选购参考。</strong></p>
  <p>除此之外，京言AI助手还支持多商品智能对比。</p>
  <p>用户可以勾选几件商品，系统会从参数、总价、价格趋势等维度给出综合选购建议，对“选择困难症”用户来说，这无疑是福音——它帮你节省了大量切换页面、逐条比对的时间。</p>
  <p>目前看来，京言AI助手在“智能”程度上还比不上淘宝，但京东即将在其App 16.0上线的“爱购”功能或许会有不一样的变化。据京东介绍，该平台重构了电商的“人货场”连接方式。在传统搜索模式下，用户需要将模糊需求转化为精准关键词，而“爱购”通过自然语言交互实现了从需求到方案的直接映射——用户只需描述“三口之家、厨房预留60cm宽度、喜欢风冷无霜”，系统就能生成包含产品对比、定制详情页的完整解决方案。</p>
  <p>图片／ 淘宝 &nbsp;京东</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjM2MzEyNQ==&amp;mid=2651600795&amp;idx=2&amp;sn=248b678aaa04c05461a8c10ad3cf184d&amp;chksm=bc84bf256ffe7e3fab3f636482350ab4c1e50ac6782eb9ffbd876e50a30e30a1997821efed5f&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT时报”（ID：vittimes）</a>，作者：贾天荣，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530107364400256</id>
            <title>阿里新研究：统一了VLA和世界模型</title>
            <link>https://www.36kr.com/p/3530107364400256</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530107364400256</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 10:29:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果说视觉让AI看见世界，动作让AI改变世界，那么——</p>
  <p>WorldVLA正在让AI理解世界。</p>
  <p>顾名思义，<strong>WorldVLA</strong>是一个将视觉语言动作模型（VLA）与世界模型相融合的统一框架，由阿里巴巴达摩院、湖畔实验室和浙江大学共同提出。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7a91f8332f4f4dae8a05b4369bb55559@46958_oswg107650oswg1080oswg233_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在该框架下，</p>
  <p><strong>世界模型</strong>通过结合对动作与图像的理解来预测未来图像，旨在学习环境的潜在物理规律，以提升动作生成的准确性；</p>
  <p><strong>动作模型</strong>则基于图像观测生成后续动作，不仅有助于视觉理解，还反向促进世界模型的视觉生成能力。</p>
  <p>实验结果表明，WorldVLA的表现显著优于独立的动作模型与世界模型，充分体现了二者之间的相互增强效应。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5afe6b129f1f4b648977fa96f44f1ff1@46958_oswg119291oswg1080oswg214_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>下面具体来看。</p>
  <h2><strong>统一VLA与世界模型</strong></h2>
  <p>如今，VLA和世界模型虽在分头并进，但其在功能上的局限已成为制约发展的关键瓶颈：</p>
  <p><strong>VLA模型</strong>：基于预训练多模态大语言模型（MLLM）构建，虽具备跨机器人任务泛化能力，但仅将动作作为输出，未深度整合为输入进行分析，缺乏对动作的全面理解。</p>
  <p><strong>世界模型</strong>：能基于当前观测和动作预测未来视觉状态，理解视觉信息与行为动态，但无法直接生成动作，在需明确动作规划的场景中应用受限。</p>
  <p>为了解决上述难题，研究团队提出了WorldVLA——一种用于统一动作与图像理解和生成的<strong>自回归动作世界模型</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_d1e130dd60df4e0380115741e7f6ede3@46958_oswg249690oswg1080oswg548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>团队基于Chameleon模型进行初始化，让WorldVLA使用<strong>三套独立的分词器</strong>（tokenizer） 对图像、文本和动作进行编码。</p>
  <p><strong>图像分词器</strong>采用VQ-GAN模型（一种结合向量量化与生成对抗网络的图像生成模型），并针对特定图像区域（如人脸、显著物体等）引入了感知损失优化。</p>
  <p>值得一提的是，该分词器的压缩比为16，码本大小为8192。对于256×256的图像，会生成256个token；对于512×512的图像，则生成1024个token。</p>
  <p><strong>动作分词器</strong>将连续的机器人动作的每个维度离散化为256个区间，区间宽度根据训练数据的范围确定。动作由7个token表示，包括3个相对位置、3个相对角度，以及1个绝对夹爪状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2290cb788a904acb8c0d71efd44c4fcf@46958_oswg295778oswg1080oswg627_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>文本分词器</strong>采用训练好的BPE分词器，词表大小为65536，其中包括8192个图像token和256个动作token。</p>
  <p>所有文本、动作和图像都被离散化为token，并以自回归方式进行训练。</p>
  <p>自回归模型中的标准注意力机制通常采用因果注意力掩码（causal attention mask），即当前token只能访问前面的token信息，而无法获取后续token的信息，如下图 (a) 所示。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_e789c249e7994141ac1434cabff46048@46958_oswg58885oswg1080oswg418_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而，这种传统配置在生成动作块（即多个连续动作）时存在明显不足。在默认注意力掩码下，早期动作产生的错误会传递到后续动作，从而导致性能下降。</p>
  <p>为了解决这一问题，团队提出了一种针对动作生成的替代注意力掩码，如上图 (b) 所示。该掩码确保当前动作的生成仅依赖文本和视觉输入，而屏蔽之前动作的影响。</p>
  <p>这种设计使自回归框架能够并行生成多个动作，世界模型部分则仍遵循传统的因果注意力掩码，如上图(c) 所示。</p>
  <p>之后，团队通过融合动作模型数据与世界模型数据对WorldVLA进行联合训练。</p>
  <p>其中，引入世界模型数据以增强动作生成能力，主要基于三方面考量：</p>
  <p>1、<strong>环境物理理解</strong>：世界模型能够通过当前状态和执行的动作来预测未来观测，从而学习环境中的物理规律，这种认知对操作任务尤为重要。</p>
  <p>2、<strong>动作评估与规避风险</strong>：世界模型能够模拟并评估候选动作的潜在结果，有助于规避可能导致不良状态的动作。</p>
  <p>3、<strong>精确动作解析</strong>：世界模型需要对动作输入进行精确解释，这反过来支持动作模型生成更有效且符合上下文的动作。</p>
  <p>此外，动作模型也能增强视觉理解能力，从而进一步支持世界模型的视觉生成。</p>
  <h2><strong>动作模型与世界模型相互助力</strong></h2>
  <h3><strong>基准测试结果</strong></h3>
  <p>由下表可以看出，即使在没有预训练的情况下，WorldVLA模型也展现出优于离散化OpenVLA模型的性能，这证明了其架构设计的有效性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7376c5e4cab1429bb7c7653465023950@46958_oswg197066oswg1080oswg442_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，模型性能与图像分辨率呈正相关。具体而言，512×512像素分辨率相比256×256像素分辨率带来了显著提升。</p>
  <p>这一现象主要归因于Chameleon主干模型的预训练策略，其图像分词器与大语言模型组件在512×512分辨率下进行了优化。</p>
  <p>同时，更高的分辨率自然提供了更多的视觉细节信息，这对需要高操作精度的机器人抓取任务尤为重要。</p>
  <h3><strong>世界模型助力动作模型</strong></h3>
  <p>此外，研究还表明引入世界模型能够显著提升动作模型的性能。</p>
  <p>世界模型的核心功能是基于当前状态与执行动作预测环境状态变化，这一生成机制促使模型学习系统的底层物理规律，而掌握这种规律正是实现抓取等精细操作任务的关键前提。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_af43653a7ab64346a910dcf6bf20379d@46958_oswg43917oswg1080oswg262_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更深入来看，世界模型赋予系统前瞻推演能力：通过预判候选动作可能产生的后果，为决策过程提供关键信息，从而优化动作选择策略，提高任务成功率。</p>
  <p>下图的对比案例直观展示了这种优势。基线动作模型会直接移动到目标点位却未能成功抓取奶酪或瓶子，而WorldVLA会持续尝试抓取，直到确认操作成功后才移向目标位置。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1fa4ebe2489448c58d25cb1f20e7126f@46958_oswg912003oswg1080oswg816_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>动作模型助力世界模型</strong></h3>
  <p>在生成质量上，WorldVLA显著优于纯世界模型，尤其是在生成较长的视频序列时表现更为突出。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_dd3bccd63f0940e8ad1f572621cb553d@46958_oswg30211oswg1080oswg193_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此外，纯世界模型在多个场景中呈现明显缺陷：无法成功拉开抽屉（a）、移动盘子后导致碗消失（b）、未能将碗平稳放置在灶台上（c）。而动作世界模型在这些场景中均生成了连贯且符合物理规律的后续状态。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_97d18a58e8b54cf397687060fe14e91a@46958_oswg1302470oswg956oswg1096_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>核心作者介绍</strong></h2>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_243fc31489a94809896ac315c3e697da@46958_oswg1003713oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文一作为<strong>岑俊</strong>，2024年8月以阿里星入职阿里巴巴达摩院。本科毕业于浙江大学，硕士和博士均毕业于香港科技大学，2023年在新加坡南洋理工大学访问过半年，曾在微软亚洲研究院（MSRA）、上海AI Lab、海康威视和阿里巴巴通义实验室实习。</p>
  <h2><strong>One More Thing</strong></h2>
  <p>对于VLA与世界模型，小米汽车高级研究总监、主任科学家陈龙也发表了公开看法：</p>
  <blockquote>
   <p>VLA与WM不需要二选一，二者可以结合起来相互促进的。</p>
   <p>一个管“抽象思考”，一个管“物理感知”，VLA+WM的结合，才是通往具身智能（AGI）的答案。</p>
  </blockquote>
  <p>论文链接：https://t.co/ZgHyhqQnyf</p>
  <p>Github链接：https://t.co/SxDZGuhbL7</p>
  <p>参考链接：https://x.com/EmbodiedAIRead/status/1980216687124476256</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/IW6H33317ePE4PRI3lnCPA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：时令，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530107493866632</id>
            <title>不好美国要捧杀了，新研究：中国正在成为全球科学领导者</title>
            <link>https://www.36kr.com/p/3530107493866632</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530107493866632</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 10:23:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>发表于2024年6月，却在当下登上《美国国家科学院院刊》，然后还被硅谷热议了。</p>
  <p>究竟是什么论文？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2bfeeefe04ea4c829f212a83e806ba36@46958_oswg71042oswg210oswg191_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>答案揭晓：中美科技实力大PK，以及得出的结论是——<strong>中国正在成为全球科学领导者</strong>。</p>
  <p>和以往比比论文量、引用数不同，这项研究通过引入机器学习模型，分析了600万份论文的作者署名模式、通讯作者身份、机构影响力等多重线索，核心评估了<strong>“团队领导者”</strong>这一指标。</p>
  <p>研究人员表示，通过关注中国科学家在跨国合作中权力地位的变化：</p>
  <blockquote>
   <p>（我们）为研究中国在国际科学领域中的地位提供了一个新视角。</p>
  </blockquote>
  <p>而且他们还带来了一系列出人意料的发现——截至2023年，中美合作中中国领导者占比升至45%，且预计在2027-2028年达到相同水平。</p>
  <p>预计到2030年，中国将在AI、半导体、能源和材料科学等战略领域实现与美国平起平坐的领导地位。</p>
  <p>就是说，比人们预想的更快，中国将在科研力量上超越美国了？</p>
  <p>u1s1，虽然经彭博社报道后，外国网友们都在自嘲：西方科学无可争议的主导地位时代即将终结。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_d84a5b0bf0f04b34bf11e68de4766903@46958_oswg113809oswg1080oswg433_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但我们大多数人的反应be like：不好，美国要捧杀了！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0d21c296297940b3a6a98f9d089123fc@46958_oswg52274oswg202oswg194_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>咳咳，究竟是客观结论还是战略“捧杀”，还是先来看看论文是如何得出上述结论的吧——</p>
  <h2><strong>用AI模型分析600万篇论文</strong></h2>
  <p>通过分析OpenAlex数据库收录的近600万篇、涉及13个全球区域的双边合作出版物，研究人员想要弄清：</p>
  <blockquote>
   <p>中国科学家在国际科研团队中，到底站在什么位置？距离“世界领航者”还有多远？</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9c5bc7b1f8dd4d76b01d998ee5cad084@46958_oswg213274oswg1080oswg531_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而要量化“谁是团队领导者”，可不是简单看作者排序那么简单。</p>
  <p>研究团队用了一套<strong>「AI+多维度特征」</strong>的组合拳，把这个模糊概念变成了可计算的数字。</p>
  <p>具体主要分成三步走：</p>
  <p><strong>第一步，给“领导力”下一个可量化的定义。</strong></p>
  <p>他们先从Nature、Science、PNAS等顶刊中，扒出8.3万篇带作者贡献声明的论文，通过聚类分析把科学家的工作分成三类：</p>
  <p>领导角色：构思研究、设计方案、撰写论文、监督团队 （关键词为conceive、design、lead、write） ；</p>
  <p>直接支持：收集数据、执行实验、分析结果 （关键词为collect、perform、analyze） ；</p>
  <p>间接支持：参与讨论、提供意见、修改文字 （关键词为participate、comment、edit） 。</p>
  <p>随后给每个角色赋予“领导值”——做领导工作得1分，支持工作得0分，由此构建出训练AI模型的“标准答案”。</p>
  <p><strong>第二步，用9个维度给科学家“领导力打分”。</strong></p>
  <p>有了训练数据，团队又提炼出9个能预测领导力的关键特征，给590万篇论文的每一位作者“画像”。</p>
  <p>作者过往研究被该论文引用的次数 （体现学术影响力） ；</p>
  <p>论文关键词与作者过往研究的重合度（体现领域深耕度）；</p>
  <p>作者自引次数 （体现研究延续性） ；</p>
  <p>学术生涯年限 （体现经验积累） ；</p>
  <p>过往发表论文总量；</p>
  <p>累计被引次数；</p>
  <p>研究过的独特关键词数量 （体现研究广度） ；</p>
  <p>作者署名顺序 （如第一作者、通讯作者） ；</p>
  <p>所属机构的学术排名（体现平台资源）。</p>
  <p>用这9个特征训练的AI模型，精准度达69.2%，最终能给每位作者输出一个<strong>领导概率分数</strong>（leader probability score）——用于衡量某个作者在一篇论文中的主导程度。</p>
  <p><strong>第三步，从领导概率推断全球科研领导格局变化。</strong></p>
  <p>在获得领导概率后（以0.65为分界线区分领导者和支持者），他们将其应用于全球范围内的数百万篇合作论文，进一步构造两个关键指标：</p>
  <p>领导占比（Leader Share）：衡量某国家或机构作者在跨国合作团队中担任领导者的比例；</p>
  <p>领导溢价（Leader Premium）：领导占比减去支持者占比，反映人均领导力转化效率，比如同样100个合作者，中国能出多少领导者，美国能出多少。</p>
  <p>通过对多个国家和区域的对比，研究得以量化不同科研体系在全球合作格局中的主导能力、结构变化与未来趋势。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8f27a9239c80441ebee2419b8e4208d3@46958_oswg504689oswg1080oswg684_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而他们得出的最核心的一张结论图如下：</p>
  <p>（1）2010年，中美合作中中国占比仅30%，2023年快速升至45%。（2）通过线性回归预测，中美将于2027-2028年达到同等领导占比。（3）不过中国与美国的领导溢价平等需等到2087年后，说明中国在“人均领导力转化”上面临长期挑战。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_39ccb1a397d14537a296311c8dbecd67@46958_oswg238594oswg1080oswg794_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>老实说，这项研究之所以当下能在西方引起注意，实属意料之外，情理之中。</p>
  <p>不谈大道理，就拿最近陶哲轩遭遇经费断供一事就能窥见一二。</p>
  <p>时间回到今年9月，顶尖数学家陶哲轩在接受《华盛顿邮报》采访时亲口表示：</p>
  <blockquote>
   <p>研究所的经费仍然无法发放，连暑期工资都拿不到了。</p>
  </blockquote>
  <p>之所以会如此，是因为美国在今年的7月25日，突然暂停了国家科学基金会（NSF）、国立卫生研究院（NIH）等机构对UCLA的资助，金额高达5亿美元之多。</p>
  <p>即便后来事态有所好转，联邦法院在8月12日决定恢复部分拨款，但直到9月初，资金仍旧没有到位。</p>
  <p>好家伙，连陶哲轩都要被迫给自己和学生筹钱，这下西方学界和网友纷纷坐不住了——当时就有人直言这是“美国科学界的自我毁灭”，认为官僚体系正在扼杀创新。</p>
  <p>而现在这篇论文一出，网友们重拾焦虑也在所难免。</p>
  <h2><strong>作者之一来自武汉大学</strong></h2>
  <p>有意思的是，这项研究的作者之一也是来自中国（虽是同等贡献者但排在第一）。</p>
  <p><strong>Renli Wu</strong>，论文提及的所属单位为武汉大学信息管理学院&amp;芝加哥大学Knowledge Lab。</p>
  <p>不过可能由于相对低调，目前网上公开资料较少（只找到了相关𝕏账号，且未发布任何动态）。</p>
  <p>从已发表的论文推断，其研究方向偏向科学计量、信息管理、知识系统演化等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b17abde8283849c096cd1ef7460f7f99@46958_oswg225829oswg1080oswg636_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>Christopher Esposito</strong>，目前为UCLA安德森管理学院（加州大学洛杉矶分校顶尖商学院）博士后研究员。</p>
  <p>大约在2021年6月，他获得了UCLA地理学博士学位。</p>
  <p>他主要研究区域经济发展的成因，特别是技术变革如何塑造区域发展。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7033b08a263a4706a4781e8d94c95e36@46958_oswg746352oswg834oswg834_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>James Evans</strong>，目前是芝加哥大学Max Palevsky社会学、计算与数据科学教授，同时也是Knowledge Lab的主任。</p>
  <p>（注：Max Palevsky社会学是指，以硅谷初创先驱、风险投资奠基人Max Palevsky的人生轨迹和职业生涯为典型范例，来研究“硅谷精英”如何崛起以及影响社会的学科。）</p>
  <p>他主要关注“集体知识系统”、创新过程、注意力与认知的分布、科学体系结构、机器学习与大数据在科学研究中的应用等。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ef1bdca43f2b484d94d201e50b895eea@46958_oswg212442oswg548oswg548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>One More Thing</strong></h2>
  <p>说到中国科技力量的崛起，不知道大家有没有一个共同的感受：</p>
  <p>怎么哪哪都有华人？（手动狗头）</p>
  <p>不仅频频亮相大厂发布会C位（如OpenAI、马斯克特斯拉），而且还在硅谷抢人大战中备受瞩目，甚至连老黄也偏爱收购华人创办的初创公司……</p>
  <p>其影响力之大，甚至催生了AI内部梗：“以后Meta开会都是说中文了”…</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_67d64cc73b3449be991ac1d7e3ef581e@46958_oswg55694oswg224oswg192_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>好家伙，网友诚不欺我，世界真就是一个巨大的中国村呗~</p>
  <p>论文：https://arxiv.org/pdf/2406.05917</p>
  <p>参考链接：</p>
  <p>[1]https://www.pnas.org/doi/abs/10.1073/pnas.2414893122?download=true</p>
  <p>[2]https://www.bloomberg.com/news/articles/2025-10-28/china-is-about-to-lead-the-world-in-science-by-a-very-specific-metric?embedded-checkout=true</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/XxjTQLYiIpMA8dfDzaGE4Q" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：一水，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530110906735497</id>
            <title>14000人原地被裁，亚马逊今日：打工人水深，AI机器人火热</title>
            <link>https://www.36kr.com/p/3530110906735497</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530110906735497</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 10:23:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>亚马逊前几天宣布的「3万人血裁计划」，正式开刀了。</p>
  <p>刚刚，<strong>1.4万名亚马逊员工被宣布没了工作</strong>，而另一边，公司正在开足马力部署AI和机器人上岗。</p>
  <p>流程还没开始走，电脑账号直接锁死，很多人甚至还来不及备份自己的文件。</p>
  <blockquote>
   <p>我立刻就失去了对所有东西的访问权限 :(</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_615f2caadbde40d5ac19c0aafe8d5e21@46958_oswg100941oswg1080oswg376_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更狠的是见谁砍谁，管你业绩怎么样。</p>
  <blockquote>
   <p>3年内从L4升到L6，本以为自己是高质量人类，这下看来我也只是个可被AI取代的螺丝钉……</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c2b8d9a2b7d64fb0b78efbb490d7b952@46958_oswg74404oswg1080oswg201_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>离谱的是，消息一出，<strong>亚马逊股票当天立即上涨了1%</strong>。</p>
  <p>部分老员工苦笑道：</p>
  <blockquote>
   <p>如果裁员能继续推高股价，那我的股票收入就算是失业金了。</p>
  </blockquote>
  <p>这边亚马逊估计更是开心坏了，不仅能少开一大笔工资，还有投资人送钱。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5a20b6ab76b844f9a696eda479bc0405@46958_oswg126443oswg1080oswg680_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>跟量子位来看看，这到底是怎么一回事。</p>
  <h2><strong>1.4万人被裁</strong></h2>
  <p>10月28日，约1.4万名亚马逊员工在一封「致员工的信」中收到了噩耗。</p>
  <p>亚马逊高级副总裁Beth Galetti在信中遗憾地宣布，亚马逊将启动新一轮裁员——在35万名公司全职员工中，<strong>约有4%的同事要准备收拾行李走人</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1a371ab075a1409d9ff6093ea75af6d2@46958_oswg100625oswg1080oswg481_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得注意的是，这1.4万是净裁员人数——那些通过内部调岗成功「自救」的员工，并不算在内。</p>
  <p>据悉，本轮裁员后，亚马逊会为大多数受影响员工提供为期90天的「复活赛」。</p>
  <p>这段时间内，招聘团队会优先考虑内部候选人，尽量帮更多人留在公司体系内。</p>
  <p>而对于没能重新上岸的员工，亚马逊也将提供过渡支持，包括遣散费、再就业辅导、以及医疗保险延续等补偿措施。</p>
  <p>《商业内幕》的报道进一步揭开了这轮裁员的面纱。</p>
  <p>在首批收到通知的7500名员工中，超过78%是L5到L7级别的经理，也就是从初级到高级的管理层。</p>
  <p>更扎心的是，<strong>超过80%来自亚马逊的零售业务</strong>，涵盖在线商城、物流体系、生鲜杂货等核心部门。</p>
  <p>其实早在今年年初，亚马逊就已经悄悄冻结了部分零售业务的招聘预算，领导层强调要削减浪费，以腾出资金用于升级配送网络。</p>
  <p>遭殃的不止是零售业务的同事，7月份，连最赚钱的云计算部门AWS也曾面临裁员风波。</p>
  <p>外界普遍认为，亚马逊近期这一轮又一轮的「裁裁裁」，正是公司在降本增效道路上的重要发动机。</p>
  <p>今年6月，亚马逊CEO Andy Jassy在官网明确发文强调，公司需要重新找回盈利能力。</p>
  <blockquote>
   <p>未来几年，我们会使用AI来提高效率，这将减少我们公司的员工总数。</p>
  </blockquote>
  <p>话虽如此，但还是让人有点摸不着头脑。</p>
  <p>亚马逊这几年确实被微软Azure和新贵CoreWeave打得丢盔卸甲，可再怎么卷，也不至于真到「养不起人」的地步吧……</p>
  <h2><strong>新型的AI替代方式</strong></h2>
  <p>事实上，今年亚马逊的业绩并不算差。</p>
  <p>7月底，亚马逊公布了第二季度财报。</p>
  <p>虽然相比微软和谷歌，其云业务AWS的增速略显疲软，确实引发了一些投资者的担忧。</p>
  <p>但在整体表现上，亚马逊依然全面超出华尔街预期：<strong>销售额同比增长13%，达到1677亿美元</strong>。</p>
  <p>也正因如此，员工们才更觉得委屈：如果公司状况不好我可以理解，既然赚钱赚得挺香，为什么还要这么狠心？</p>
  <p>对此，副总裁Beth Galetti在裁员通知中给出了官方解释：</p>
  <blockquote>
   <p>有些人可能会问，公司业绩不错，为何还要裁员？需要记住的是，世界瞬息万变。AI是自互联网以来最具变革性的技术，为了更快驶向这片新蓝海，我们必须精简组织架构。</p>
  </blockquote>
  <p>CEO Andy Jassy此前的说法则更为直接：</p>
  <blockquote>
   <p>我们需要减少目前某些工作的人手，在另一些岗位上加人。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c709d5a60aca4db9a7650e7230093cfd@46958_oswg243504oswg682oswg682_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这么看来，亚马逊这轮裁员，<strong>与其说是为了「AI降本增效」，不如说是一场面向新方向的资源重组</strong>。</p>
  <p>省下来的薪资开支，并不是为了短期止血，而是要重新分配到新的增长引擎——固定资产投入、研发支出……以确保亚马逊在下一阶段的竞争力。</p>
  <p>目前，亚马逊公开的一大笔资本投入，正是押注在具身智能领域。</p>
  <p>一年前，公司斥资4亿美元收购了初创公司<strong>Covariant</strong>的核心团队及其技术授权。</p>
  <p>这家公司专注于研发机器人大脑，能够让机械臂自主学习和适应不同的作业场景。</p>
  <p>基于这项技术，亚马逊打造了新一代智能机械臂——Bluejay和Starling。</p>
  <p>它们能在更多样的环境中执行任务，灵活搬运不同尺寸、形状的包裹，大幅提升自动化水平。</p>
  <p>如今，亚马逊的仓储体系也已开启全面自动化阶段。</p>
  <p>在2024年启用的最新仓库中，上千台机器人正负责订单拣选与履约。</p>
  <p>按照规划，到2027年，这种高自动化仓库模式将扩展至近50个履约中心。</p>
  <p>如果这条路线图顺利推进，那么两年后，受影响的恐怕就不只是白领了……</p>
  <p>毕竟，亚马逊虽然名义只拥有30多万名员工，但其实<strong>还有超过120万的劳动力都在仓储与物流环节工作，属于合同工或外包人员</strong>。</p>
  <p>有分析指出，亚马逊持续引入机器人技术的结果，可能在未来几年内取代<strong>超过50万个蓝领岗位</strong>。</p>
  <p>虽然这场自动化转型看起来声势浩大，但目前没有引起太多担心，归根结底，这还只是蓝图。</p>
  <p>具身智能距离真正落地还有多远，没人能说得准。</p>
  <p>但值得注意的一点是，<strong>AI想要端掉咱们的饭碗，似乎不需要等到技术成熟</strong>。</p>
  <p>就像这次亚马逊的情况一样，某种意义上出现了一种新的「替代模式」：人类员工成了为AI让路、为AI提供资源的「可替代生产要素」。</p>
  <p>从中也不难看出管理层的野心，相比按兵不动的苹果，亚马逊显然在押注未来上表现得更为激进。</p>
  <p>但这么做也是很有风险的，<strong>要是哪天AI泡沫破灭、又迎来一场「寒冬」，岂不是还得求那批被自己开掉的员工回来？</strong></p>
  <blockquote>
   <p>我是真心好奇——如果他们一边喊着AI，一边把所有人都裁掉，那等大家都没钱了，他们那些愚蠢的AI产品又要卖给谁？</p>
  </blockquote>
  <p>一名PayPal小伙伴对于亚马逊员工的遭遇如此表示了愤慨。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1c123bfeece54345920bd295e098c985@46958_oswg68322oswg1080oswg208_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>One More Thing</strong></h2>
  <p>不过尴尬的是，如此惊人的裁员也带来了一些资源紧张——</p>
  <p>会议室资源。</p>
  <p>量子位听说，亚马逊的会议室最近都被HR占满了……</p>
  <p><strong>「3万人，咱们挨个谈」。</strong></p>
  <p>参考链接：</p>
  <p>[1]https://www.businessinsider.com/amazon-layoffs-what-we-know-teams-roles-affected-job-cuts-2025-10</p>
  <p>[2]https://www.aboutamazon.com/news/company-news/amazon-workforce-reduction</p>
  <p>[3]https://www.businessinsider.com/amazon-layoffs-hit-retail-managers-hardest-aws-could-be-next-2025-10</p>
  <p>[4]https://www.reddit.com/r/amazonemployees/comments/1oi5x5y/megathread_us_layoff_impact/</p>
  <p>[5]https://www.retailcustomerexperience.com/news/amazon-robots-may-replace-500k-plus-jobs-in-years-ahead/?utm_source=chatgpt.com</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/vIjM0P2FCRgNcvPRmLhWCA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：Jay&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529984255089801</id>
            <title>AGI有了「权威」新定义，图灵奖得主Yoshua Bengio等提出，GPT-5仅达57%</title>
            <link>https://www.36kr.com/p/3529984255089801</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529984255089801</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 10:07:06 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c0d038179cf4426e897b3014036e0984@000000_oswg48722oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>通用人工智能（AGI）或许将成为人类历史上最重要的技术突破，但由于&nbsp;<strong>AGI 缺乏明确的定义</strong>，当今专用人工智能（AI）与人类认知水平之间的差距变得模糊不清。</p>
  <p>为解决这一问题，人工智能安全中心（CAIS）主任&nbsp;<strong>Dan Hendrycks</strong>、图灵奖得主&nbsp;<strong>Yoshua Bengio</strong>&nbsp;联合众多业内企业家、学者提出了一个可量化框架，将 AGI 定义为：</p>
  <p>“<strong>在认知多样性与熟练度上，媲美或超过受过良好教育的成年人的 AI</strong>”。</p>
  <p>an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.</p>
  <p>这一定义强调，通用智能不仅要求在狭窄领域内的专业表现，还要求具备人类认知所特有的<strong>技能广度（多功能性）</strong>和<strong>深度（熟练度）</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_a6b263038d704d87aa0a26c0fe3fc361@000000_oswg216106oswg1080oswg743_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://arxiv.org/abs/2510.18212</p>
  <p>研究结果表明，在这一框架下，GPT-4 的 AGI 得分仅为<strong>&nbsp;27%</strong>，GPT-5 的得分也只有<strong>&nbsp;57%</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_eaaf37a423154dfdaf6f7b357c7ffbfe@000000_oswg32262oswg1080oswg110_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜GPT-4 和 GPT-5 的 AGI 得分。</p>
  <p>这表明，尽管当前的AI在复杂基准上表现出色，但它缺乏许多对类人通用智能至关重要的核心认知能力。</p>
  <p>更重要的是，<strong>这一框架提供了一个结构化、可量化、更具鲁棒性的方法来评估 AGI，超越了狭隘的、专业化的基准测试</strong>。</p>
  <h2><strong>AGI 的 10 个核心能力</strong></h2>
  <p>为系统检验 AI 系统的具体认知能力，研究团队基于<strong>卡特尔-霍恩-卡罗尔理论</strong>（人类智能最经实证验证的模型）构建方法论。该框架将通用智能分解为 10 个核心认知领域——包括推理、记忆与感知等——并采用成熟的人类心理测量测试套件评估 AI 系统。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_318ee4ed00eb4ebba88b1890357ab420@000000_oswg157677oswg1080oswg276_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜所提出 AGI 定义下的 10 个核心组成。</p>
  <p>具体内容如下：</p>
  <p><strong>1.通用知识</strong></p>
  <p>通用知识（General Knowledge），即“大多数受过良好教育的人所熟悉的知识，或重要到大多数成年人都接触过的知识”。在这一维度上，研究团队从常识、科学、社会科学、历史、文化等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 9%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_463155042ba14b76b5e62a3705b13f7a@000000_oswg305394oswg1080oswg664_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>2.读写能力</strong></p>
  <p>读写能力（Reading and Writing Ability），即“在阅读和写作中掌握所有陈述性知识和程序性技能”。在这一维度上，研究团队从常字词识别、阅读理解、写作能力、语法等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 10%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_f172592042cf4764bf9965bc71e35ec9@000000_oswg121255oswg1080oswg291_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>3.数学能力</strong></p>
  <p>数学能力（Mathematical Ability），即“数学知识和技能的深度和广度”。在这一维度上，研究团队从算数、代数、几何、概率、微积分等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 10%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3174b35e8d0c4a8eb3ef521acdab9e46@000000_oswg216043oswg1080oswg563_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>4.即时推理能力</strong></p>
  <p>即时推理能力（On-the-Spot Reasoning），即“审慎且灵活地控制注意力，以解决那些无法仅依靠以往习得的习惯、图式和脚本完成的全新即时的问题”。在这一维度上，研究团队从算演绎、归纳、心智理论、规划、适应等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 7%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_be2ed47cd42143d1b22d10a61011f608@000000_oswg306614oswg1080oswg604_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>5.工作记忆能力</strong></p>
  <p>工作记忆能力（Working Memory），即“在注意力集中状态下保存、处理并更新信息的能力”。在这一维度上，研究团队从听觉、视觉、跨模态模型等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 4%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_43c9fcde90d6457a92b29bc080bd0de6@000000_oswg180990oswg1075oswg740_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>6.长期记忆储存能力</strong></p>
  <p>长期记忆储存能力（Long-Term Memory Storage），即“稳定地获取、巩固并存储来自近期经验的新信息的能力"。在这一维度上，研究团队从联想记忆、意义记忆、逐字记忆等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率为 0%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_290a929c6af0433cb1025935e7a948cc@000000_oswg294608oswg1080oswg753_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>7.长期记忆检索能力</strong></p>
  <p>长期记忆检索能力（Long-Term Memory Retrieval），即“能够流畅且精确地从长时记忆中检索信息的能力”。在这一维度上，研究团队从提取流畅性、幻觉等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 4%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8f1048df7e3d43f18e4d690cdadbc7ae@000000_oswg302065oswg1080oswg587_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>8.视觉处理能力</strong></p>
  <p>视觉处理能力（Visual Processing），即“分析与生成自然或非自然图像和视频的能力”。在这一维度上，研究团队从感知、生成、推理和空间扫描等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 4%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_39f2323f2ccb4476af0f38e6dea77c41@000000_oswg278335oswg1036oswg805_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>9.听觉处理能力</strong></p>
  <p>听觉处理能力（Auditory Processing），即“区分、记忆、推理并处理听觉刺激的能力”。在这一维度上，研究团队从语音编码、语音识别、节奏、音色、音准等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 6%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_cb08096c18364f1cab7635d243c70a70@000000_oswg81739oswg1006oswg305_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>10.速度</strong></p>
  <p>速度（Speed），即“快速完成认知任务的能力”。在这一维度上，研究团队从语搜索、对比、阅读、书写、数字等方面对 GPT-5、GPT-4 进行了评估，结果显示，GPT-5 的整体正确率仅为 3%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_4e203a0ea8534ea8a4425d34b008affa@000000_oswg112487oswg1060oswg431_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更多评估细节详见论文。</p>
  <h2><strong>局限性与未来挑战</strong></h2>
  <p>以上结果凸显了当前 AI 与人类水平的通用智能之间的能力鸿沟，具体表现在：</p>
  <p><strong>1.关键能力欠缺</strong></p>
  <p>尽管当前 AI 在通用知识、读写能力和数学能力等方面表现出高熟练度，但它们在基础认知机制上依然存在严重缺陷；同时，长期记忆存储是亟需突破的瓶颈，当前 AI 的得分接近 0%；而且，当前 AI 缺乏持续学习能力，需要在每次交互中重新学习上下文，效率低下；此外，视觉推理能力的欠缺限制了 AI Agent 与复杂数字环境的交互。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_561ca8e8467d4f39bc53cb1a1f043e3a@000000_oswg149657oswg868oswg646_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图｜GPT-4 和 GPT-5 的能力分布。</p>
  <p><strong>2.能力扭曲与通用幻觉</strong></p>
  <p>AI 的“锯齿状”能力常常导致所谓的“能力扭曲”，即 AI 会利用某些方面的强项来弥补其他方面的弱点，比如依赖庞大的上下文窗口和 RAG 技术来掩盖长期记忆存储能力的缺乏。这种权宜之计制造出了一种脆弱的“通用智能幻觉”，最终导致对 AGI 何时到来的不准确评估。</p>
  <p><strong>当然，这一「AGI 定义」也存在一些局限性。</strong></p>
  <p>首先，这一定义并不全面，他们有意排除了某些类型的能力，如 Gardner 提出的多元智能理论中的动觉智能等。</p>
  <p>再者，研究框架的示例主要基于英语语境，未考虑文化差异。未来研究可将测试扩展至不同语言与文化背景；</p>
  <p>另外，研究团队的操作化存在内在限制：通用知识测试是选择性的，无法涵盖所有学科领域。“100% 的 AGI 分数”仅意味着在这些特定维度上表现优异，并不等同于“现实中的高学历或全面教育背景”。</p>
  <p>此外，当前方案为每项广泛能力分配相同权重（10%），以突出广度。然而，这种权重配置只是众多可能方案之一。未来可探索更具灵活性的权重方案和任务组合。</p>
  <p>最后，AGI 总分这种单一数值可能掩盖 AI 的严重缺陷。例如，一个 AGI 总分 90%，但长期记忆存储为 0%，实际上会表现出类似“遗忘症”的功能障碍。</p>
  <p>在论文的最后，研究团队表示，<strong>实现 AGI 依然需要解决诸多挑战</strong>：</p>
  <p>机器学习社区旨在测量抽象推理能力的 ARC-AGI 挑战赛，就体现在及时推理任务中；</p>
  <p>Meta 试图创建包含直觉物理理解的世界模型，这体现在视频异常检测任务中；</p>
  <p>空间导航记忆的挑战反映了李飞飞的初创公司 World-Labs 的一个核心目标；</p>
  <p>幻觉和持续学习方面的挑战，也需要被解决。</p>
  <p>因此，<strong>“AGI 得分在明年内达到 100% 的可能性不大”</strong>。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&amp;mid=2247599952&amp;idx=1&amp;sn=5ee533aff81000880534a41f0c88e86c&amp;chksm=ce21c54cc212f4649168ad3afd11782de8d1ded3dd0a29fc245e5cf41eecfd097c14de3f72bc&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“学术头条”（ID：SciTouTiao）</a>，整理：潇潇&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530009709157256</id>
            <title>中国成智能眼镜增长最快市场，谁能成为扛旗者？</title>
            <link>https://www.36kr.com/p/3530009709157256</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530009709157256</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:58:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Meta的AI眼镜又卖断货了。</p>
  <p>10月21日，Meta专为高强度运动员设计的Oakley Meta Vanguard正式开售，至此，其在今年9月份Meta Connect年度开发者大会上公布的3款产品已经全部问世。其中，升级后的第二代Ray-Ban Meta AI眼镜和内置显示屏的Meta Ray-Ban Display引发抢购潮。</p>
  <p>据外媒报道，9月底上市的Meta Ray-Ban Display 在线下零售店已卖断货，11月前的试戴预约爆满。根据测算，Meta全系列智能眼镜在今年第二季度的销量约75万副，较一季度增长了50%。</p>
  <p>今年上半年，Meta智能眼镜累计销量达126万副；去年全年，其销量突破了100万副。另有机构测算，截至目前Meta智能眼镜产品的总销量已接近300万副。</p>
  <p>Meta的热销引得国内厂商纷纷入场。10月24日，阿里巴巴首款自研的夸克AI眼镜在其天猫官方店铺正式首发；百度的AI眼镜项目“小度AI眼镜”则将于11月1日开启预售；小米AI眼镜也早于今年6月份发售。加之早已入局的雷鸟、Rokid、影目等新锐品牌，“百镜大战”的图景正徐徐展开。</p>
  <p>尽管玩家越来越多，但当下国内智能眼镜市场仍处于早期阶段，并未有绝对头部品牌出现。换言之，在智能眼镜的“IPhone时刻”到来之前，任何品牌都有机会成为扛旗者，会是谁呢？</p>
  <h2><strong>中国智能眼镜市场增速喜人</strong></h2>
  <p>从销量来看，仿佛人人都是扛旗者。</p>
  <p>今年618期间，雷鸟创新官方战报显示其在大促周期内销量同比增长3.36倍，3款智能眼镜均夺得所属品类Top 1的市场战绩，市占率达到了52%，并喊出了“每卖出两款智能眼镜，就有一款来自雷鸟创新”的口号。</p>
  <p>但雷鸟并未公布具体销量，且今年618期间小米、Rokid的AI智能眼镜产品尚未面世，没有销量数据支撑的“Top1”难免降低了其可信度。</p>
  <p>小米则公布了具体销量，今年6月份其产品发布后，小米官方公布了首周设备激活数，3万台的成绩创下了国内AI眼镜品类销售速度的新纪录。</p>
  <p>后续呈现高开低走的态势，蝉妈妈数据显示，在经历了发售首周的高峰后，小米眼镜在抖音的销量日渐走低，截至10月28日，日销量已跌至25副至50副区间，截至目前其在抖音总销量为2.5万至5万。</p>
  <p>Rokid是目前对外宣布销量最高的品牌，今年7月份，Rokid创始人祝铭明透露， Rokid Glasses 销量已达30万台。</p>
  <p>值得注意的是，祝铭明公布此数据时产品还未正式发售，作为其首款AI智能眼镜的Rokid Glasses在经历跳票、涨价等一系列事件后，直到今年9月份才全渠道上市，除了公布首销5日突破4万台的成绩后，Rokid再未对外公布过具体销量，30万台的说法也不免引起外界怀疑。</p>
  <p>“30万台应该是基于定金订单统计出的数据，实际的交付的数量远不及此，考虑到其交付周期，最终的销量应该与30万有不小的出入。”行业观察人士向鳌头财经表示。</p>
  <p>电商平台的销售数据或许更能反映真实的市场情况，据鳌头财经统计，Rokid Glasses在天猫、京东双平台旗舰店截至目前的累计销量为9000+；小米眼镜为6万+；雷鸟V3则为15000+。以此数据看，小米的市场反响最好，“Top1”的雷鸟和“销售30万台”的Rokid与之相比存在不小差距。</p>
  <p>“当下国内智能眼镜仍处于市场早期，公布不同维度的、有利于自身的销量数据有利于加深用户认知，类似于早期的手机营销一样。”前述行业观察人士表示，“但实际上行业远未到爆发阶段，销售数据也存在‘虚标’情况。”</p>
  <p>事实上，中国智能眼镜市场增速喜人，但整体规模并不高。</p>
  <p>IDC发布的报告显示，今年季度全球智能眼镜市场出货量激增82.3%，达到148.7万台，其中中国市场出货量49.4万台，同比增长116.1%；到了第二季度，中国市场出货量达到66.4万台，同比增长145.5% 。</p>
  <p>这一数据意味着，上半年国内累计115.8万台的出货量，仍不及Meta一家卖的多。同样是IDC的报告显示，今年第二季度全球智能手机出货量同比增长1%，达到2.952亿部。相比之下智能眼镜仍是小众需求。</p>
  <h2><strong>供应链环节仍待加强</strong></h2>
  <p>事实上，厂家“虚标”销量除了制造市场声量外还有另一目的，那便是在供应链谈判上拿到更多的主动权。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2e9c2beb4ce544d9b1ace0ec6ad0cad9@000000_oswg45289oswg1080oswg777_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>“目前还没有一家厂商能打通光学、材料、硬件、算法等全部环节。”行业内人士向鳌头财经表示，“单一厂商的出货量很难让供应商开辟专门的生产线或部门去配合研发和生产，一些关于产品的设想也会因供应链问题而无法实现。”</p>
  <p>这很现实，当行业没有足够的订单量时，供应商便没有动力去做技术突破和产能投入。</p>
  <p>以Rokid供应商蓝思科技为例，今年上半年，其实现营收329.60亿元，其中智能头显与智能穿戴类业务营收16.46亿元，总营收占比仅为4.9%。</p>
  <p>试想一下，供应商能为不足5%总营收占比的业务投入多少精力？Rokid延迟发货和涨价的风波，似乎说明了这一点。</p>
  <p>鳌头财经梳理发现，Rokid一开始对外表述的发售时间为今年第二季度，今年5月份，有传言称Rokid Glasses将推迟发货，祝铭明则在采访中公开回应“6月下旬开始发货”。事实却是，截至今年7月，仍有大量预定了产品的用户未收到设备，全渠道的公开发售也推迟到了9月份，进入了第三季度的最后一个月。</p>
  <p>更令消费者们气愤的是，该产品预售期间宣传价格为2499元，但正式发售时价格涨至3299元，涨幅达800元。</p>
  <p>“推迟发货、发售以及产品涨价，最大的可能性便是供应链出了问题，可能是良品率达不到标准堆高了成本，亦或是其对自身供应链整合能力没有充分预估。”前述行业内人士向鳌头财经表示。</p>
  <p>当下的业界共识是，智能眼镜面临着“不可能三角”，既性能、轻量、续航难以兼顾。这一问题的解决需要厂商与供应链共创，而单一厂商的销量并没有打动供应商的能力，“不可能三角”的破除便也无从谈起。</p>
  <p>除了供应链尚不成熟，行业还面临着发展路径不清晰的问题。产品的发展方向是成为高性能智能硬件还是成为生态载体？</p>
  <p>“就前者而言，AI智能眼镜缺乏‘杀手级应用’，其目前提供的翻译、导航、拍照、录像等功能，手机都能完成，智能眼镜在单一功能上表现也不如成熟设备；就后者而言，在生态和场景上大厂更具有优势，如小米眼镜是其‘人车家战略生态’的一部分，而Rokid等中小型厂商只能仰人鼻息。”行业分析人士向鳌头财经表示。</p>
  <p>事实如此，在Rokid此前的宣传中，搭载通义千问大模型、与支付宝合作的看一下支付都是其宣传的卖点，但当夸克AI眼镜问世，通义千问大模型、高德导航、支付宝支付、淘宝拍立淘等阿里生态的功能都成为“基础设施”，与阿里的“亲儿子”相比，Rokid此前宣传的生态优势将无从体现。</p>
  <p>在外界看来，随着大厂的进入，智能眼镜在国内市场的扛旗者还未出现便会经历一轮洗牌，而以往的行业案例则告诉我们，洗牌中，中小型厂商往往先下牌桌。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzU3ODQ5MjQzMQ==&amp;mid=2247580068&amp;idx=1&amp;sn=2e72ac36a19045f26631bfab6e12f33c&amp;chksm=fcc06bc6572e032a8761587b399f66d42c807144cfa519119912450b80041d9c225182086852&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“鳌头财经”（ID：theSankei）</a>，作者：张飞涛，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530039343061892</id>
            <title>一个螺丝钉不合格导致火箭发射失败，这家企业今年再融24亿元重新出发</title>
            <link>https://www.36kr.com/p/3530039343061892</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530039343061892</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:56:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近年来低空经济的政策引领下，这个赛道越来越火热，吸引了众多资本入局。</p>
  <p>据IT桔子统计，2025Q3国内低空经济赛道有96笔融资交易，同比增长显著；融资总额估算达到了100.81亿元，其中，有14家创业公司斩获单笔1亿元以上的融资，成为赛道内的 “融资主力军”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6057f791656d4b3d9499c5d1760f15be@000000_oswg536900oswg1080oswg1158_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>从融资金额分布来看，<strong>Q3 低空经济赛道的 “融资王者” 集中在商业航天领域</strong>——榜单前两名均为该领域企业，且核心业务聚焦低轨卫星与可复用运载火箭等关键方向，属于低空经济的关键基础设施领域，技术研发门槛较高，所需的资金规模体量也较大。</p>
  <p>例如，<strong>星河动力</strong>在9月宣布了24亿人民币的D轮融资，南京市创新投资集团、川创投和顺禧基金等国资基金纷纷参投，使其成为2025Q3国内低空经济赛道融资规模最大的企业。</p>
  <p>IT桔子注意到，在两年前，星河动力有过一次失败的火箭发射经历，追溯其失败原因竟然是一个不合格的螺丝钉。</p>
  <p>根据报道，2023年9月21日12时59分，谷神星一号（遥十一）运载火箭在中国酒泉卫星发射中心点火升空。然而，飞行约67.5秒后，火箭姿态失稳，导致发射任务失利。这次发射原本是该型号火箭的第十次发射，之前已经成功进行了九次发射任务。</p>
  <p>根据星河动力航天公司的调查，发射失败的主要原因是<strong>一级发动机喷管扩张段的烧蚀异常。</strong>在喷管扩张段组件的<strong>螺钉孔加工过程中，由于操作不当</strong>，导致碳布层产生内部缺陷，进而引发了扩张段的烧蚀问题，最终导致火箭的飞行姿态失稳。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_01572af18f854808a85b585433b63027@000000_oswg247547oswg832oswg548_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">谷神星一号发射失败图源：网络</p>
  <p>该事件也对搭载的吉林一号商业观测卫星产生了影响，通过这次事件，可以看出航天发射的复杂性和高风险性，每一个细节都可能影响最终的成功与否。</p>
  <p>而星河动力今年9月宣布拿下24亿元融资，资金主要就是用于加速其“智神星”系列可重复使用液体运载火箭和“谷神星二号”中型固体运载火箭的研制工作。</p>
  <p>另据最新消息，10月23日，星河动力同华泰联合证券签署上市辅导协议，正式启动A股IPO进程。</p>
  <p><strong>值得一提的是，四川今年在持续发力低空经济。</strong>一方面，星河动力的“谷神星一号”在四川省资阳市临空经济区落地制造，而今年四川国资（川创投）加码投资了星河动力。</p>
  <p>另一方面，成都国资今年还参与投资星际荣耀，成为这家民营商业航天独角兽的股东之一。</p>
  <p>公开信息显示，<strong>星际荣耀</strong>在今年9月宣布完成了D+轮融资的首批7亿元人民币资金交割，本轮融资由成都先进资本旗下的基金领投，多家具有成都国资背景的基金共同参与。</p>
  <p>募集资金将重点用于双曲线三号可重复使用运载火箭的研发、落地成都市双流区的火箭生产基地项目的建设，以及绵阳市涪城区发动机产线的建设。</p>
  <p>早在2020年12月24日星际荣耀就启动了IPO辅导，拟科创板上市。截至目前IPO辅导期已超四年半，天风证券、中信证券为辅导机构。&nbsp;</p>
  <p><strong>从产业链的维度观察，专注飞行器整机制造的企业颇受资本青睐。</strong>作为中国智能飞行汽车领域的代表性企业，<strong>小鹏汇天</strong>在今年三季度完成了B轮2.5亿美元总额中的剩余1亿美元的融资额，其表现颇为亮眼。</p>
  <p>小鹏汇天的旗舰产品“陆地航母” 是全球首款分体式飞行汽车，2024年1月首次在北美CES展亮相，预计将在2026年量产交付。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_4e25fb9aae38465a93952d7ab6650ba2@000000_oswg449867oswg832oswg462_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在产能这块，2024年10月，小鹏汇天飞行汽车智造基地正式动工，该基地位于广州开发区，将用于生产分体式飞行汽车“陆地航母”的飞行体部分，规划年产能1万台。</p>
  <p>国内市场方面，小鹏汇天优先在广东、海南、湖南等低空开放试点区域落地，已在湖南常德完成“陆地航母” 首飞，在海南签约超40个飞行营地；同时推进“享飞计划”覆盖更多城市，提前锁定C端用户，B端层面与应急救援、文旅集团探索合作场景。</p>
  <p>海外市场方面，小鹏汇天2025年重点突破中东、东南亚、欧洲市场，中东地区已获600台订单，阿联酋完成特许飞行证认证；计划 2026 年量产交付后，优先向海外高净值市场供货，同步推进欧洲EASA适航认证，目标3年内成为全球飞行汽车市场核心参与者。</p>
  <p>同样聚焦电动垂直起降飞行器（eVTOL）领域的还有沃兰特航空与亿维特航空，也在三季度顺利完成数亿元融资，是低空经济赛道中新锐的企业代表。</p>
  <p>2025年10月13日，<strong>沃兰特航空</strong>正式宣布完成数亿元B轮融资，本轮融资由华映资本领投，上汽创投等新投资方加入，老股东君联资本、鼎晖百孚、自贡创发持续追加投资。</p>
  <p>公司首款量产级产品——复合翼eVTOL“VE25-100天行”，可搭载1名飞行员+ 5名乘客，设计航程200-400km，巡航速度235km/h，纯电驱动，定位于商用客运领域，同时覆盖医疗急救、货运等多场景。</p>
  <p>在7月举办的2025国际低空经济博览会上，沃兰特与泰国泛太平洋公司（Pan Pacific）、中航工程签署三方合作协议，达成500架采购订单（总金额17.5亿美元），为中国高等级客运eVTOL迄今最大单笔国际订单；该批机型将用于泰国、马尔代夫的短途岛际、岛内运输与应急救援，中航工程同步配套低空基础设施建设。</p>
  <p>2025年8月28日，<strong>亿维特航空</strong>完成数亿元A轮融资，由金浦投资领投，精工科技、英搏尔电气（航空电驱领域企业）、盛景嘉成、拉尔夫创投跟投，老股东邦盛资本追加投资。</p>
  <p>公司自主研发的ET9型eVTOL，2024年3月完成首飞，2025年重点推进“政策适配场景”落地，如依托江苏“低空经济示范省” 政策，积极参与省内低空开放试点项目（如南京、苏州的短途低空运输示范线），通过“场景示范”验证产品可靠性，为后续大规模订单转化积累案例。</p>
  <p>国际合作方面，亿维特航空10 月与阿联酋上市新能源企业Robo.ai 签署战略合作，计划联合开发适配中东市场的eVTOL机型，借助Robo.ai的区域渠道，探索海外商业化路径。&nbsp;</p>
  <p>目前纯电eVTOL航程约150-200公里，到2030年前有望提升至300-400公里，但仍无法满足特种运输、应急管理和城际出行的需要，也难以在快充/换电设施不完善时实现短距离、高频次的经济运营。</p>
  <p>另一种技术路线——倾转旋翼随之出现了，相比多旋翼和复合翼构型，它能够实现更大速度、更高效率的飞行。</p>
  <p>今年9月，专注智能电动倾转旋翼飞机制造的江苏苏州<strong>追梦空天</strong>公司，也宣布完成Pre-A轮1亿人民币融资，由朝希资本领投。</p>
  <p>据悉，2024年8月，追梦空天科技完成吨级混动倾转eVTOL（DF600）第一阶段试飞，进度居于国内首位，是继美国JOBY公司后全球第二家进入试飞阶段的混动倾转eVTOL企业。</p>
  <p>低空经济的起飞，离不开上游供应链环节的联合发力和基础设施建设，多家关键零部件与核心技术企业在Q3获得资本加持。</p>
  <p>例如，研发低空固态锂电池的欣界能源（广东深圳）、设计高精度定位传感器的导远科技（广东广州）、主攻模拟与混合信号芯片的聚芯微电子（湖北武汉），均斩获单笔数亿元融资。</p>
  <p>此外，提供无人系统综合保障服务的飞鸿测试（内蒙古包头）、研发空中机器人大脑的微分智飞（浙江杭州），也分别获得2.91 亿人民币、2 亿人民币融资。</p>
  <p>这些企业的融资进展，体现了资本对低空经济上游核心技术的关注，也为整个产业链的稳定发展提供了关键支撑。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MjM5MjQ2NzA2Mg==&amp;mid=2649625222&amp;idx=1&amp;sn=de4cceeaa13bc49d5fd1a43d1b5c7a86&amp;chksm=bf7990395940b098371b8f2daa37706f8fdabd91a9f0deda75691dcb93ad0e327b81d1f1c1b8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“IT桔子”（ID：itjuzi521）</a>，作者：吴梅梅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530048223501448</id>
            <title>人民币兑美元汇率升至近一年新高</title>
            <link>https://www.36kr.com/p/3530048223501448</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530048223501448</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:40:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>中美贸易摩擦有所缓和，人民币兑美元汇率升至近一年新高。</p>
  <p>10月28日，离岸人民币率先升破7.10关口，当日收于7.0959，创2024年10月15日以来新高。10月29日早间开盘，在岸人民币一举升破7.10，截至16时，在岸人民币汇率为7.0985，创2024年11月5日以来新高。</p>
  <p>10月29日早间，中国人民银行（下称“中国央行”）发布的人民币对美元中间价调升13个基点，报7.0843，创2024年10月15日以来新高。前一交易日中间价报7.0856，在岸人民币16:30收盘价报7.1006，夜盘收报7.0989。</p>
  <p>“人民币汇率已回升至接近2024年秋季美国总统大选前的水平，这表明中国经济在特朗普第二任期中美贸易关系恶化的背景下仍具韧性。”惠誉评级经济学家亚历克斯·马斯卡泰利（Alex Muscatelli）对《财经》表示，“这也反映出，中国央行不愿将汇率贬值作为政策工具来抵消关税上调的影响。”</p>
  <p>西班牙对外银行亚洲首席经济学家夏乐对《财经》表示，本次推动人民币汇率升破7.10的主要动力是市场对中美贸易谈判的乐观预期。</p>
  <p>据新华社消息，当地时间10月25日至26日，中美经贸中方牵头人、国务院副总理何立峰与美方牵头人、美国财政部长贝森特和贸易代表格里尔在马来西亚吉隆坡举行中美经贸磋商。</p>
  <p>中国商务部国际贸易谈判代表兼副部长李成钢在磋商结束后对中外媒体记者表示，双方就妥善解决彼此关注的多项重要经贸议题形成初步共识，下一步将履行各自国内批准程序。</p>
  <p>贝森特会后表示，此次磋商有效解除了特朗普总统原定自11月1日起对中国进口商品征收100%关税的威胁。</p>
  <p>“在这样的情况下，市场对中美贸易关系趋稳，甚至关税下调存在憧憬。”夏乐表示，如果美方对中国的关税水平能够下调至与其他国家持平，中国出口部门的优势将进一步显现，支撑人民币汇率走强。</p>
  <p>事实上，早在10月15日，中国央行发布的人民币对美元中间价已突破7.10关口，并在接下来两周内进一步向强方调整。截至10月29日，人民币对美元中间价月内累计上调超250个基点。</p>
  <p>“整体上看，近期在美元指数震荡上行、全球汇市波动加大过程中，人民币中间价向偏强方向调整力度有所加大。”东方金诚首席宏观分析师王青撰文称。</p>
  <p>“中间价一般来讲是为了引导货币的走势，近段时间人民币对美元中间价持续向强方调整，一方面体现了中国央行对人民币汇率的走势预期，另一方面也释放了中国央行在中美经贸摩擦过程中维稳人民币汇率的强烈信号。”</p>
  <p>近日，中国央行行长潘功胜受国务院委托，向全国人大常委会报告2024年11月以来金融工作情况。报告中，潘功胜表示，下一步，将保持汇率弹性，强化预期引导，防范汇率超调风险，保持人民币汇率在合理均衡水平上的基本稳定。</p>
  <p>中金公司研究部外汇组在10月26日发布的报告中表示，中间价与上证指数均继续升至年内新高水平，对人民币汇率预期起到一定支撑。</p>
  <p>“从逆周期因子的角度来看，其在10月至今对中间价的升值起到了重要的引导作用。”前述报告称，“往后看，我们认为中间价将继续调节外汇市场供求及市场预期，保持人民币汇率偏稳波动。”</p>
  <p>北京时间10月30日凌晨，美联储将公布最新利率决议，市场普遍预期将再次降息25个基点。</p>
  <p>中金公司研究部总监、银行业分析师林英奇认为，若美联储如期降息，将进一步缓解人民币汇率的压力。</p>
  <p>“市场普遍预期美联储将降息，因此存在美联储降息步伐不及市场预期的风险。”亚历克斯·马斯卡泰利对《财经》表示，“若美联储维持利率不变，可能会对美元构成一定上行压力。”</p>
  <p>国家外汇管理局（下称“外汇局”）公布的外汇市场数据显示，9月代客净结汇517.6亿美元，为2020年后单月新高；结汇率升至71.1%，为近年来偏高水平。</p>
  <p>外汇局副局长、新闻发言人李斌表示，“9月银行代客结汇和售汇环比均明显增长，企业等主体根据自身需求灵活开展外汇买卖。9月结售汇顺差为510亿美元，其中上中旬净结汇较多，下旬结售汇差额趋向均衡。10月以来银行代客结汇和售汇大体相当，外汇市场供求基本平衡。”</p>
  <p>对此，中金公司认为，“净结汇规模稳定或体现目前市场对人民币汇率的升值预期较为稳定，例如人民币汇率隐含波动持续处于年内低点，境内外汇存款亦在9月减少，或显示过往累积外币资金的结汇倾向抬升。”</p>
  <p>从外汇供求来看，若中国出口商此前积压的结汇需求释放，未结汇资金可能成为推动人民币汇率进一步走强的增量动力。</p>
  <p>“目前，中国出口商在海外持有至少数千亿美元的未结汇资金，若人民币汇率持续偏强运行，出口商结汇需求可能释放，进而推动人民币汇率走强。”夏乐对《财经》表示。</p>
  <p>同时，夏乐认为，“人民币过强可能对出口造成压力，预计中国央行不会放任人民币汇率过快过急升值。”</p>
  <p>展望未来，包括中金公司在内的多家机构认为，人民币汇率有望保持偏强波动。</p>
  <p>中信证券首席经济学家明明认为，在出口不发生超预期变动的情况下，预计人民币汇率或整体呈现温和升值的态势。</p>
  <p>他特别提到，中国央行稳汇率政策工具储备充足，使用节奏张弛有度，2026年中国央行的稳汇率政策操作或仍是人民币汇率预期的重要因素。</p>
  <p>“今年迄今为止，人民币的坚挺表现令我们颇感意外。”亚历克斯·马斯卡泰利表示，“我们已经下调了对人民币贬值的预期，目前仅预计明年人民币将小幅贬值。我们预计美元兑人民币汇率不会突破7.0关口，尽管我们的预测存在上行空间（人民币走强）。”</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkyMjY5MTQ1Nw==&amp;mid=2247635820&amp;idx=1&amp;sn=e962488342751963b827546e12ddaf8b&amp;chksm=c0dbc34e4a3dfb812f29bd4b3fd553cf2ec0c238ec6c5eea216e6af4b26f089e8f6c7ee8d77a&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“财经五月花”（ID：Caijing-MayFlower）</a>，作者：唐郡，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530060058646659</id>
            <title>短剧行业再刮“风暴”，AI真人短剧从容入场</title>
            <link>https://www.36kr.com/p/3530060058646659</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530060058646659</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:39:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>没有一个短剧演员进组、没有灯光、摄影等工作人员、“导演”磨练几天就能上岗，凭借AIGC“生成”短剧内容的时代到了。</p>
  <p>最近，短视频平台上的《奶团太后三岁半》《九尾狐男妖爱上我》《兴安岭诡事》等剧均有不错的市场反应——<strong>前两部累计播放量突破2亿，超过了许多真人短剧，后一部仅在抖音就取得30万的付费收入，它均有一个共同的标签，“AI生成真人短剧”</strong>。</p>
  <p>相比于风头正盛、热度飙升的AI漫剧，AI真人短剧目前并未受到太多关注。虽然AI漫剧已经探索出了一套成熟的工业化流程，且找到了最为适配的题材类型，AI真人短剧在这两方面都仍处于探索阶段，且受制于目前AIGC技术的进展。</p>
  <p>如果说AI漫剧的出现是打开了一个新的内容赛道，与传统的短剧模式并行不悖，AI真人短剧则有着颠覆现有短剧生产形态的巨大潜力，且题材类型的适配度远超AI漫剧。因此，AI真人短剧还有着种种亟待突破的瓶颈，但无论是爱优腾芒、TVB等视频平台，百度、昆仑万维等技术公司，抑或是嗅觉敏锐的短剧创作者都已经纷纷入局。</p>
  <p><strong>AI真人短剧不会像AI漫剧一样在短时间内如火如荼，却可能会悄无声息地改变着短剧行业的内容生态。</strong>当用户察觉到热门短剧中AI浓度日益提高之时，应该也会从一开始的惊讶好奇回归到习以为常，直至越来越难以分清真人与AI之间的界限。</p>
  <h2><strong>AI真人短剧，正在“解锁”更多题材</strong></h2>
  <p>目前，AI真人短剧在短剧市场中仍然是凤毛麟角的存在。从观众反馈可见，大众对这种新生事物仍保持“围观者心态”。这既意味着超出内容质量之外的关注度，也意味着会被放在聚光灯之下仔细审视。</p>
  <p>在《奶团太后三岁半》的观众留言中，多数评价是积极和肯定的：“这下好了，都不需要演员了，演员要失业了”“除了嘴巴动得有点不太舒服，其它的都可以取代电视剧了”“厉害厉害，大师是用什么工具做的？”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b8e38525858444c7bbb69e9a59b80cb5@17104992_oswg135150oswg1080oswg1168_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>据媒体报道，该剧的制作方为“雪宝”，而他的另一重身份是短剧的导演和编剧，今年2月开始涉足AI真人剧。受限于当时的大模型底层技术，《奶团太后三岁半》在呈现上略有不足，例如口型对不上，语气和情感过渡上比较生硬等。即便如此，突破2亿的播放量至少意味着目前AI真人短剧足以胜任“萌宝”“宫斗”等题材。</p>
  <p>在新榜发布的“抖音AI短剧榜”中，我们还看到了另一部题材近似的作品《奶团太后宫心计》，应该是希望复制《奶团太后三岁半》的成功。我们可以把这份榜单视为观察目前AI真人短剧的一个“横截面”，与AI漫剧的热门榜单既有相通之处，又有着鲜明的反差。</p>
  <p>在AI漫剧领域，末日、重生等题材占据了热度榜的半壁江山，<strong>这主要是由于AI对于“废土场景、变异生物” 的低成本特效呈现，相比传统影视短剧，能够营造出观众前所未见的视觉奇观。在AI真人短剧榜单上，至少有两部末日题材高居前列。</strong></p>
  <p>与男频当道的AI漫剧不同，AI真人短剧基本上都是以女频为主，甚至末日求生的主角也换成了女性。我们猜想，在奇诡恢宏的视觉特效之外，AI真人短剧也适合细腻动人的情感表现，因此与女性观众的追剧需求更为契合。</p>
  <p>不仅如此，从这份榜单来看，无论是古装、现代、重生、玄幻等女频题材，AI真人短剧都有着吸引观众的潜力，蕴藏着比AI漫剧更大的创作可能性。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9b3226529063471ba9a7a0108b1fb771@17104992_oswg193320oswg1080oswg1203_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>过去很长一段时间，AI技术在影视剧制作中多处于辅助角色，直到“生成式人工智能”的出现，“AIGC+短剧”的碰撞，实现了AI对短剧制作的全流程渗透，使其在短剧创作过程中“变客为主”。尤其是今年国庆期间，Sora2推出后，其迭代功能之一就是在视频中自动添加音频、视频和对话。<strong>这意味着，AI真人短剧中，音视频同步更新的支持技术出现了。</strong>这无疑给短剧业打了一剂“强心针”，让业界捕捉到“AI真人剧爆发的节点，提前来临。”</p>
  <p>常规状态下，在AIGC的工具平台上，制作者输入一句话，机器学习后会自动分解出分镜头，最后再合成一段短视频。随着AI学习的深入，在某些专业的视频生成平台上，AI真人的表现效果已经可以以假乱真。</p>
  <p>举个例子，输入提示词：“女人深情的看着远方，眼角落下了一滴泪水，她缓缓地下了头，头发飘动，衣服飘动，雪花不停落下有一些落在他的头发上。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1934f59c34514c38a55a4b268b6e3685@17104992_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>技术条件的成熟，为AI真人短剧的落地提供了核心动力，行业困境也催生出一批业内人士尝试寻找新赛道。近两三年，<strong>短剧发展迅猛，成本却在节节攀升，2023年一部短剧的成本为二、三十万，到了今年上半年涨到七、八十万，</strong>红果短剧总编辑乐力在公开场合表示，“今年整个市场上还会量产两三百万元成本的微短剧，在我看来，未来一段时间成本还会增长。”</p>
  <p>AI真人剧在降本增效上更有优势。今年初，据创作团队夫子AI透露，其团队创作的十集短剧由3人十天内完成，仅耗资5594元。工作流程全程为AI辅助创作——AI取片名、辅助出剧情大纲，再用AI辅助做分镜，让AI生成详细的画面描述指令，Stable Diffusion软件生成图片，再用图片生成视频，之后输入人物对话音频，AI对口型，最后剪辑完成。<strong>夫子AI透露，5594元是可灵和即梦的包年费用。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b2bfa2d34019474eb07704fbe77c5ad1@17104992_oswg493116oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>另据《瞭望》新闻周刊报道，AI微短剧《白狐》的制作团队仅有4人，依靠ChatGPT生成剧本，通过AI工具创造视听画面，<strong>将传统需要三个月的制作周期压缩至两周，制作成本由每分钟数万元降至整体约万元</strong>。</p>
  <p>传统短剧的拍摄成本构成一般分为：剧本成本、制作成本、宣发成本。其中，制作成本包含导演、演员、摄影师、道具、化妆、场地租赁、后期制作的费用，占总成本的50%到80%。AIGC生成式真人短剧，基本上省去了制作成本的开销。<strong>就这样，影视工业出现百年以来的导演、演员、摄影师等“标配”，在AI真人短剧面前彻底被替换掉，一部剧的“拍摄”实现真正意义上的去剧组化</strong>。</p>
  <h2><strong>长视频平台“抢人才”，技术公司拼“一键成剧”</strong></h2>
  <p>如果说此前AI真人短剧还是少数创作者单打独斗的“技术实验”，随着爱优酷芒、TVB等视频平台的大举投入，百度、昆仑万维等技术公司的高调入局，在行业各方的合力鼓风之下，星星之火正在快速地在行业蔓延。</p>
  <p>最近，<strong>爱奇艺、腾讯视频“不约而同”地发起了AI短片创作大赛，正是想以此为契机，将AI创作领域的能人异士揽至麾下</strong>，从而在刚刚起风的AI真人短剧领域抢得先机。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ee8c7f283f40427dab6f2200a9eeeb4e@17104992_oswg139593oswg1080oswg879_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，两家平台都已经公布了AI短片创作大赛的入围作品，<strong>从这两份片单中可以看出相比画风“统一”的AI漫剧，两家视频平台都致力于挖掘AI视频创作在叙事影像上的潜力。</strong>值得注意的是，在两家的入围作品中除了赛博朋克、3D动画、水墨水彩等AI动画作品外，有近半数作品都在追求媲美真人的视觉表现力，可以归入"AI真人短片“的范畴。</p>
  <p>从这些入围作品中，文娱价值官看到只要剧本足够扎实，AI短片的出片效果和情感力度不亚于真人短剧。而且在奇幻、玄幻、科幻作品之外，完全能胜任现实题材，很难想象短片中有70%以上的内容由AIGC完成。</p>
  <p>以入围腾讯视频大赛的短片为例，《半岛长夜》讲述抗美援朝老兵战场上失去战友的故事，旁白为四川口音老爷爷的口述回忆；《贵客来茶楼》为民国故事，讲述了被欺压的茶楼老板设计杀害黑帮三恶的故事；《人之初》为纪实类故事，还原了2023年河北两个十三四岁的男孩杀害同班同学的事，引发了对未成年人量刑标准的讨论。</p>
  <p>不同于此前抖音发起的“AIGC微短剧大赛”、快手推出的“星芒短剧×可灵AI大模型‘AI创想剧场’”，爱奇艺、腾讯视频发起的AI短片创作大赛，更加追求通过AIGC还原传统影视的风格质感，也是在为AI真人短剧的题材可能性探路。</p>
  <p><strong>就连近年被唱衰的老牌电视台TVB，也在尝试通过AI真人短剧彰显“朝气”。</strong>今年9月，“TVB首部真人短剧”《在我心中，你是独一无二》上线，内容定位为校园青春剧。这部剧的场景的还原度，角色的仿真度获得了业界一致好评，“演员”的表情和动作栩栩如生，剧中的AI男主女主，还在中国香港地区开启了个人社交账号，与粉丝互动。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_df2472e133cf474e8a5a3cf75c5bfda9@17104992_oswg103615oswg1080oswg1264_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>值得一提的是，<strong>优酷虽然没有声势浩大地举办AI创作大赛，却在紧锣密鼓地将各个平台上优异的AI短剧作品收入囊中。</strong>今年4月，小红书博主@老杨AI利用Claude 3.7+Minimax，制作了一部6集AI真人短剧《白咒》，很快被优酷发现并纳入会员频道内容库中。对于在短剧领域发力较晚的优酷而言，发力AI真人短剧不失为一种弯道超车。</p>
  <p>国内不少技术公司也开始瞄准这块潜力巨大的新兴市场。比如，昆仑万维推出的AI短剧创作平台SkyReels，已经能支持30秒长视频生成、多主体场景搭建及首尾帧无缝衔接，为行业提供高效的创作工具。据悉，SkyReels的目标是“一键成剧”，也让“一人一剧”成为可能。10月，百度公司的短剧生成平台也官宣公测，百度公司不仅承诺资金支持、大流量扶持，还将帮助创作者孵化IP，达成IP长效变现等。</p>
  <p>技术趋势清晰明了，商业变现未来可期，AI短剧的升温，在旁观者看来，似乎是突入一夜春风来，唯有局内人、那些始终跟随着影视业发展的业内人士，才能敏锐感知质变的临界点。</p>
  <h2><strong>刚起步的AI真人短剧，还需打破哪些“瓶颈”？</strong></h2>
  <p>AI真人短剧之前，AI漫剧已经摸索过一段时间。从业人士称，“在AI世界里，做真人内容也好，做动漫内容也罢，流程高度相似，能力迁移的技术复用占比几乎达到七八成。”</p>
  <p>至此，在短剧领域集齐了真人剧、AI漫剧、AI真人剧的形态，<strong>《奶团太后三岁半》的制作团队坚信：“只要短剧市场还在，AI真人短剧就一定有出路”</strong>。</p>
  <p>的确，<strong>中国的短剧市场发展时间虽然不长，用户规模已达6.96亿，</strong>占网民总数比重接近七成（数据截至到2025年6月，来源：DataAye）。依据《2024年中国微短剧产业研究报告》，2024年我国微短剧市场规模已达到505亿元，首次超过电影票房规模。<strong>2025年市场规模将达到634.3亿元，2027年达到856.5亿元，年复合增长率达到19.2%。</strong></p>
  <p>这样的用户规模以及市场增速，为AI真人短剧的商业化创造了条件。然而，处于起步期的AI真人短剧也存在诸多有待打破的瓶颈。</p>
  <p>首先，题材侧有更大的拓展空间。今年四月，抖音的AIGC达人专场公开课上，就指出，当下AI短剧的两大内容风口是“男频”与“三幻”（玄幻、科幻、奇幻）。传统短剧，由于“三幻”题材所构建的奇幻场景需要大量烧经费，致使这类剧的发展受限，在AI短剧这里却得到反弹。尤其是AI漫剧，只要有足够的想象力，剩下的交给工具平台去完成。AI真人剧与AI漫剧还略有不同，它所呈现出来的写实风格，使其表现题材可以突破三幻，拓展到更多空间。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6d97e2c5686d477988eaf720195edf13@17104992_oswg85582oswg1080oswg498_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其次，创作者更注重技巧的展现，而忽略AI真人短剧的本质仍然是故事和角色。宫斗剧的很多场景和对话，仍然在向传统影视剧“偷师学艺”，过多的重复呈现很容易引发观众的审美疲劳；青春校园剧、甜宠剧，在短短等一分钟内，只有情绪的流动，而没有实质性的内容推进。<strong>总之，AI真人短剧还需在内容上向传统剧本“取经”，毕竟AI真人短剧的本质仍然是内容</strong>。</p>
  <p>AI真人短剧的出现丰富了短剧领域的表现形态，它是人工智能大模型技术与短剧业碰撞、融合而发生的化学反应，颠覆了传统影视剧的生产模式，重构了短剧的生产逻辑，由此带来的市场前景让站在产业前沿的玩家纷纷布局。</p>
  <p>然而，AI真人短剧站在技术前沿，却过度依赖技术，而忽略内容本质的一面，这将成为掣肘它走得更好更远的短板。</p>
  <p>参考文章：</p>
  <p>《AI重构微短剧产业》，瞭望新闻周刊，2025年4月</p>
  <p>《欢迎走进短剧的“辛苦钱”阶段》，壹娱观察，2025年7月</p>
  <p>《AI短剧：资本追逐的新风口》，Donews，2025年10月</p>
  <p>《Sora 2发布之前，国内已经有AI真人短剧拿下超2亿播放》，短剧自习室，2025年10月</p>
  <p>《成本降低70%，AI“导演”培训3天即可上岗，AI真人短剧进入爆发前夜》，AI新榜，2025年10月</p>
  <p>本文来自微信公众号“文娱价值官”，作者：天 一，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530044763691907</id>
            <title>AI强攻翻译行业，人工译员面临“生存大战”</title>
            <link>https://www.36kr.com/p/3530044763691907</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530044763691907</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:27:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在会被AI轻易取代的行业中，翻译长期被列为高风险领域之一。</p>
  <p>眼下，这一观点不再是人们对于未来的臆测，而是有数据和案例印证的事实：“翻译界哈佛”蒙特雷明德国际研究学院宣布关停，带来的震动犹如一颗重磅炸弹在翻译界炸开，这所久负盛名的学院走向衰败与AI浪潮的冲击密切相关；网易有道词典“AI同传”用户量突破2000万，引发外界对AI翻译商业化落地的广泛关注，原来AI的悄然下场已经将翻译的价格卷成了“白菜价”……</p>
  <p>现实是，如今的AI翻译工具，不仅能够实现多语种之间的快速转换，还能在翻译过程中自动识别并调整语境，使得翻译结果更加准确、流畅，这种技术上的突破，叠加来自互联网大厂、AI巨头以及初创公司这三方玩家积极下场布局，已经为翻译行业的市场竞争格局打开了新天地。</p>
  <h2><strong>AI同传截胡人工译员核心业务</strong></h2>
  <p>“AI翻译都已经发展到能提供同传的水平了，感觉对于大多数人来说，以后都不需要学外语了，甚至对于少数人来说，以后完全可以把学外语当做一门业余爱好，就像书法、绘画那样。”</p>
  <p>“其实国外大出版社已经在试用AI翻译了，他们有自己专门的AI，虽然现在还不太好用，但今后很有可能不需要专门的人工翻译，只需要做好审读工作就行了。”</p>
  <p>“别和AI比速度和精确度了，现在的翻译从业者应该考虑往AI暂时没办法替代的方向走，比如将游戏、歌词、品牌广告本地化的创译工作，或者法律、医疗这些有专业壁垒的高端需求，又或是直接成为评判AI翻译质量的审核员。”</p>
  <p>……</p>
  <p>其实在AI大规模爆发的2025年之前，坊间就对AI翻译是否会大规模替代人工有过非常激烈的讨论，随着这段时间业界接连迎来蒙特雷明德国际研究学院宣布关停，以及网易有道词典“AI同传”用户量突破2000万这两大标志性事件，让相关讨论再次甚嚣尘上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_40749f4015c54cccb200f3eff6850bf2@000000_oswg605710oswg813oswg1135_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>毫无疑问，<strong>在AI翻译的冲击下，翻译与语言专业正经历一场结构性的寒冬</strong>——有关数据显示，AI翻译效率提高近9倍，成本平均降低90%，“大模型初译+人工保障”逐渐成为主流。根据《人工智能与翻译报告》的数据，目前中国97.1%的翻译企业已采用翻译技术，其中26.0%的项目采用“全机器翻译交付”，另有33.2%采用“机器翻译+译后编辑”模式。</p>
  <p>北京大学国家发展研究院与智联招聘联合报告指出，编辑、翻译工作最易受大模型影响，岗位招聘量下降明显，要求也提高了很多。</p>
  <p>如此从业现状，反映到人才培养的源头，带来直观结果就是：在北京语言大学在2025年度硕士研究生招生中，停止了俄语笔译、日语口译、德语笔译、朝 鲜语笔译、西班牙语笔译等7个翻译专业招生；在2026年研究生招生调整中，东南大学拟停招俄语语言文学和西班牙语语言文学，河北大学拟停招英语口译和日语口译。</p>
  <p>看起来，<strong>人工翻译的生存空间似乎正被AI极速侵占着，尤其在同传这个翻译行业中最具挑战、也最具潜力的一环上，AI堪称势不可挡。</strong></p>
  <blockquote>
   <p>根据《2025年远程同声传译平台市场报告》，今年中国远程同传市场规模预计达到23.7亿元人民币，同比增长近 30%。在 AI 翻译的百亿级市场中，这一增速显著高于行业平均。</p>
  </blockquote>
  <p>网易有道词典的用户量迎来突破，证明AI翻译的商业化落地脚步也加快了。相较于传统同传高昂的价格，AI模型的边际成本更低，从两者的市场价格即可窥见其中端倪。</p>
  <p>同传作为翻译行业的高端服务，其价格受到译员资质、会议难度、语种稀缺性等多种因素的影响，人工收费价格普遍较高。以英语同传为例，单日收费价格在几千至上万元不等，而在同等需求条件下，小语种的同传价格普遍比英语高50%左右。</p>
  <p>而市场上的网易有道、百度翻译、讯飞同传等软件服务商，AI同传的商业模式基本都是提供一定时间的免费试用服务，进而吸引用户开通其月费或年费会员，尽管部分服务商限定了用量，可日均低至几毛钱的价格，也几乎被AI砍到底了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_024fbb0a637f424690123692d352a51e@000000_oswg643193oswg847oswg1271_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI同传价格普遍不高</p>
  <p>但要是粗暴将AI翻译与人工译员认定为非此即彼的关系，却又显得太过武断。不久前，在由中国翻译协会指导，北京外国语大学主办，中国翻译协会口译专业委员会等承办的“AI赋能口译教育与实践国际研讨会”上，多位业内专家分享了AI时代口译职业实践的新机遇与新挑战，并强调了人工译员的主导作用和AI的工具属性。</p>
  <p>上述业内共识，足以说明<strong>AI为翻译行业带来的颠覆性变革，意在优化行业生产力结构，而非单纯取代人工环节。</strong></p>
  <p>换句话说，能被AI轻易替代的那部分人工，本身在翻译工作中就承担着较为基础、重复且缺乏创造性的任务，而那些需要深厚语言功底、文化背景知识和创造性思维的环节，仍然是人工译员的“主战场”。</p>
  <h2><strong>“多强争霸”成型，或将迎来洗牌期</strong></h2>
  <p><strong>若是将AI翻译的工具属性拉满，决定其推广和应用速度的关键，还要看现阶段的“白菜价”是否长期可持续。</strong></p>
  <p>回归到市场层面，如今既有像网易有道这样的互联网大厂，凭借强大的技术实力和庞大的用户基础，在AI翻译市场迅速占据一席之地；也有如科大讯飞这样的AI巨头，靠着在语音识别与合成领域的深厚积累，不断优化AI翻译的语音交互体验，让AI翻译在实时场景下的应用更加流畅自然，进一步拓展了AI翻译的应用边界；还有依托于DeepSeek等通用大模型的创业公司，或聚焦于特定语种、特定领域的深度优化，或致力于开发具有个性化特色的翻译功能，试图在这片蓝海中分得一杯羹……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_a4f0f851d78c4d2d9ea549b576ae44dd@000000_oswg431695oswg1080oswg661_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在“多强争霸”的格局下，它们各自拥有独特的竞争优势和战略定位。</p>
  <p>先来看互联网大厂，其核心优势在于拥有庞大的用户基础和丰富的数据资源。这些海量的用户数据对于训练和优化AI翻译模型至关重要，能够让AI更好地理解不同语境下的语义和表达习惯。而且，大厂具备强大的技术研发能力和资金实力，可以投入大量资源进行AI算法的研发和升级。</p>
  <p>AI巨头的核心优势无疑是技术。它们在人工智能领域深耕多年，拥有顶尖的科研团队和先进的技术架构。在AI翻译方面，能够不断推出创新性的算法和模型，提升翻译的准确性和流畅性。例如，在端到端的同传技术取得重大突破，使得AI翻译在准确度、响应速度还有播报自然度等方面都取得了质的飞跃。</p>
  <p>初创公司作为其中的新锐力量，通常以其灵活的创新机制和对用户需求的敏锐洞察为优势。它们能够快速响应市场变化，推出一些具有特色的AI翻译产品，比如，面向特定行业或场景开发定制化的翻译解决方案，满足对应用户的个性化需求。</p>
  <p><strong>在商业化探索方面，这三类玩家的运营策略也各有千秋，呈现出多元化且富有针对性的特点。</strong></p>
  <p>互联网大厂以网易有道为例，其将AI翻译功能嵌入网易有道词典内的做法，其实是一种“生态融合”的策略，可以通过提供一站式服务来增强用户黏性；AI巨头以科大讯飞为例，其更注重技术创新，旗下AI翻译耳机作为软硬件服务相结合的产品，可以助力开拓高端商务市场；初创公司则主要聚焦于特定语种、特定领域或特定用户群体的需求，面向B端（企业端）开发具有高附加值的翻译服务或面向C端（消费者端）推出具有创新性和差异性的翻译产品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_61861a44989745ceaa59936070c09aff@000000_oswg376997oswg1080oswg612_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI商单广告</p>
  <p>由此可以看出，<strong>AI翻译行业其实正处于大浪淘金的初级阶段，使得这一时期充满了机遇与挑战。</strong>凭借快速、便捷以及成本相对较低的优势，AI翻译无疑能够迅速在市场上占据一席之地，成为众多企业和个人解决语言障碍的首选工具。然而，初级阶段也意味着行业尚未成熟，存在着诸多需要克服的问题。</p>
  <p>一方面，尽管AI翻译技术在不断进步，但在处理复杂语境、文化差异以及专业术语等方面，仍难以达到人工翻译的精准度和细腻度。这导致在一些对翻译质量要求极高的领域，如法律、医学、文学等，AI翻译的应用仍受到一定限制。而这一市场空档，也是留给相关从业者继续挣扎或转型发展的最后一点腾挪空间。</p>
  <p>另一方面，AI翻译市场的竞争必然会日趋激烈。随着技术的普及和门槛的降低，越来越多的企业和个人涌入这一领域，这虽然促进了市场的繁荣，但也带来了价格战、同质化竞争等不良现象，影响了行业的健康发展。以当前呈现出来的市场均价，在陷入盈利焦虑的情况下，难保该行业在未来不会出现大规模“涨价潮”。</p>
  <p>面对这些挑战，或许将AI翻译作为工具，由人工进行统筹使用才是当下翻译领域的最优解。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkzNjk3NTQ0OQ==&amp;mid=2247515644&amp;idx=1&amp;sn=0f0901afca292384cfe8e847f0f4a2c5&amp;chksm=c350ea4839b5033d27e07dc27f2d15e72d18431b6426d19cbba84b263fac49a39b25b8ba3345&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“锌刻度”（ID：znkedu）</a>，作者：孟会缘，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529959055072392</id>
            <title>中国股市10年来高位，IPO窄门难入</title>
            <link>https://www.36kr.com/p/3529959055072392</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529959055072392</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:16:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>上证综合指数处于10年来的高位，但1～9月的IPO筹资额与同期最高的2022年相比，大幅下降84%。IPO企业数量也仅相当于2021年的2成，集中在纯电动汽车、半导体相关等产业。从中可以看到政府的意向……</p>
  <p>中国的首次公开募股（IPO）正日益凸显政策导向。在中国大陆资本市场上，IPO集中于纯电动汽车（EV）、半导体相关等产业，IPO数量及筹资额持续处于低水平。这被认为是通过筛选IPO的对象，将资金优先引向具有发展潜力的制造业，从而加速相关产业增长。</p>
  <p>美国调查公司Dealogic的数据显示，1～9月，中国大陆市场上的IPO筹资额为100亿6500万美元，比上年同期增长约7成。但与同期筹资额最高的2022年（633亿4600万美元）相比，大幅下降84%。IPO企业数量也仅有75家，仅相当于同期最高的2021年（375家）的2成。</p>
  <p>IPO的主要目的是帮助企业通过资本市场从广大投资者手中筹集资金。通常而言，当股价处于较高水平时，企业更易实现大规模筹资，IPO数量也容易增加。目前，中国代表性股价指数——上证综合指数正处于10年来的高位。</p>
  <p>尽管如此，IPO企业数量和筹资额依然低迷。原因是金融机构“通过控制股票市场的供给规模，防止股市行情出现暴跌”（瑞穗证券的高级中国股票策略师王申申）。相关机构在让特定产业通过中国大陆的IPO容易筹集资金的同时，对市场供需影响较大的大型IPO项目以及非制造业领域的IPO则引导到香港市场。</p>
  <p>观察中国大陆1～9月IPO筹资额排名靠前的企业，可以发现EV等汽车相关企业表现尤为突出。例如，4月上市的黑龙江天有为电子主要从事汽车用液晶仪表等产品。QUICK FactSet的数据显示，该公司的客户名单中，比亚迪（BYD）、中国长安汽车集团等中国汽车制造商赫然在列。在筹资额排名前十的企业中，包括黑龙江天有为电子在内，有5家企业属于汽车零部件等汽车相关领域。</p>
  <p>成为中美间经济摩擦焦点的半导体相关企业似乎也被优先推动上市。半导体制造设备商北京屹唐半导体科技已于7月在上海证券交易所面向高科技新兴企业设置的板块“科创板”上市。</p>
  <p>被称为“中国版英伟达”的半导体企业中科寒武纪科技（Cambricon）也已经在科创板上市。科创板原本就作为让国家重视的企业上市的板块被广泛认知。在1～9月筹资额排名前十的公司中，有3家是在科创板上市的企业。</p>
  <p>在中国大陆，预计今后仍会有与尖端技术相关的企业上市。</p>
  <p>人形机器人企业宇树科技（Unitree Robotics）计划最早于今年年内向上海证券交易所提交上市申请文件。由出身于英伟达的人士担任一把手的GPU（图像处理器）公司摩尔线程智能科技（Moore Threads）也通过了上海证交所上市委员会的审核。由于3个月就通过了审核，很多媒体着眼于这一罕见的审批速度进行了报道。</p>
  <p>EV、半导体、机器人均为中国领导层重视的产业领域，可以称之为“国策股”。缩减IPO、支持尖端技术企业的做法，也有支撑整个股市行情的效果。</p>
  <p>除了IPO之外，日本综合研究所还以中国上市公司为对象，调查了2015年至2023年的补贴金额，发现制造业的补贴占销售额比例为0.63%。而非制造业的这一比例仅为0.20%。日本综研的主任研究员关辰一分析称：“在非制造业中，同样将补贴优先分配给了能够为提升制造业竞争力做贡献的行业”。</p>
  <p>中国召开的二十届四中全会对2026～2030年的经济运行方针等进行了讨论。中国的半导体和EV产业正在国家的支持下，稳步提高竞争力。未来，中国也很可能会继续采取重视高科技产业发展的措施。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MjM5MDI3Mzc0MA==&amp;mid=2651942929&amp;idx=2&amp;sn=d25a78c0ee4aab1caed961617288b344&amp;chksm=bcdc8592913c21d905d37c560762ee3580721455223211068ea0535e6bba39d75f2c1e1f10e5&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“日经中文网”（ID：rijingzhongwenwang）</a>，作者：日经中文网，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529986385648512</id>
            <title>在Minecraft里搭建一个ChatGPT，只需四步</title>
            <link>https://www.36kr.com/p/3529986385648512</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529986385648512</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 09:15:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>Minecraft可以说是近十年玩家数量最多的游戏之一，发售快15年了，月活跃玩家仍有1.5亿之多，大人小孩都喜欢。</p>
  <p>在Minecraft的像素方块世界里，你能砍树挖矿，打造神装，搭建基地，也能养马养鸡，探索世界，体验冒险人生。</p>
  <p>这样的开放世界游戏很多，但像Minecraft这么开放的没多少。当我还在地下深处的矿洞和绿皮僵尸激情肉搏时，<strong>博主Sammyuri已经在游戏里造出了一个能运行的简化版 ChatGPT</strong>，他将其称为CraftGPT。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b7e70e0ad3994afd863a568110441ed5@000000_oswg423328oswg1080oswg528_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">CraftGPT全貌</p>
  <p>在游戏里，CraftGPT的交互界面是一个显示器和一个键盘，玩家用键盘输入文字，CraftGPT通过显示器回复。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8b597a6df1b349b18459c2d95a72e9cd@000000_oswg746988oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">CraftGPT正在和你闲聊</p>
  <p>事情是这样的：Sammyuri团队在外部训练好了模型，<strong>把神经网络的计算图翻译成红石电路</strong>，使用了<strong>4.39亿个方块</strong>，把五百万参数的模型的各个成分导入了Minecraft中，直接用红石电路硬编码了神经网络。</p>
  <h2><strong>如何搭建缸中缸中之脑</strong></h2>
  <p>在游戏里追求真实本来就有点问题，在游戏里搭建一个AI更是有套娃一样的诡异效果。</p>
  <p>实现这个效果就好像把大象关进冰箱——在Minecraft中搭建大模型AI只需要四步。</p>
  <p>1：在外部训练好数据集；</p>
  <p>2：把训练好的数据编译成红石电路，导入Minecraft；</p>
  <p>3：把红石电路层层堆叠，组成神经网络；</p>
  <p>4：最后搭建输入键盘以及输出的屏幕，愉快地开始与大模型聊天。</p>
  <p>第一步是大模型数据集的训练。</p>
  <p>虽然叫做CraftGPT，但这个模型和ChatGPT关系不大，是Sammyuri从0搭建起来的。他用Python训练了一个参数为500万的小模型，可以识别1920个词、维度为240、6层、5头。</p>
  <p>一个参数可以看作是一种词与词之间的联系，参数越多，模型对语言的理解就越细致，而维度、层数、头数代表着模型思考的深度，数字越大，模型思考的深度就越深。</p>
  <p>在今天已经没人瞧得上的元祖GPT-1，都有着1.17 亿的参数，可以识别5万多个词、有着768个维度、12层和12头。并不是作者不想整个大活，Minecraft中的<strong>“模拟计算机”的计算速度远比不上真实电脑</strong>，为了在Minecraft中运行后，还能在有生之年看到结果，这个模型不得不经过相当的瘦身。</p>
  <p>右下角的蓝色曲线——训练损失（train loss）代表了模型对训练集的学习效果，而橙色曲线——验证损失（val loss）代表了模型在验证集上对新句子的表现。如果只有蓝色下降，橙色不变甚至升高，说明模型学傻了，只能死记硬背教材内容，出现了过拟合；但如果这两个同时下降，说明模型学得不错，不仅记住了知识，还对未知文本具备了理解力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1e1d8ac2d4f84ee5afc7ef27fcfda60e@000000_oswg461065oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">训练阶段的CraftGPT</p>
  <p>当这两条曲线都下降到稳定水平后，研究者会再拿出最后一部分从未使用过的测试集进行检验。不过，CraftGPT 在测试集上的表现，Sammyuri 团队并未公开提及。</p>
  <p>第二步就是逐步将训练好的神经网络大模型搬进Minecraft里。为了在Minecraft中能让AI跑起来，Sammyuri使用了游戏中一种叫做<strong>红石电路</strong>的玩意。</p>
  <p><strong>红石是Minecraft里的矿物</strong>，可以理解为一种兼具了导体和移动电源功能的资源，在红石之外还有不少配套的组件，比如开关、按钮、压力板等。</p>
  <p><strong>通过开关的通断，红石电路可以在游戏中模拟二进制的0或1</strong>，从而构建出基础的三种逻辑门。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_d43d4fd921b54e9190d446d89bd65931@000000_oswg126114oswg1080oswg429_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_fc450d41e9c14cefbff36b7aada6bbf8@000000_oswg143699oswg1080oswg311_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ef64c5dbf6bc4b8aa08a0bfc85647e9c@000000_oswg129778oswg1080oswg275_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">红石电路中的非门、或门、与门 ｜ 哔哩哔哩 @yhDAF</p>
  <p>三种门是所有计算机的基础，有了它们，任何逻辑关系都能被实现。不过这只是开端，想要做出更厉害的东西，玩家们还需要像乐高一样堆叠出能存储、计算、传输的复杂结构。</p>
  <p>在Python中训练完成的大模型仍然是一组组抽象的数字，如何在方块世界中赋予它们形状呢？</p>
  <p>第二步中，这些训练出来的数字就要被编译成红石电路。在编译过程中，每个参数的数值会被转换成红石信号的强弱，而参数在模型中的位置则决定了方块的摆放位置和连线方式。就这样，500万个参数都会变成Minecraft中的方块组合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_4788311b18654052a796c4037aed39c7@000000_oswg630258oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">CraftGPT宏大的结构，模拟了大模型的功能</p>
  <p>当数据全部完成了方块化，第三步神经网络的搭建就要开始了。<strong>Sammyuri团队选择与ChatGPT相同的transformer架构</strong>，这种架构会通过横向联想和纵向联想，让模型既能理解上下文，又语义丰富。最后，为了让语义关系更稳固，在输出前，纵横联想会重复六轮，逐层深化。</p>
  <p>最后，搭建完键盘与屏幕，CraftGPT的效果就可以展现在我们眼前了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_19bd39b3f18c4b10bff5e6a04cc8610a@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">虽然因为词汇量有限让孩子有点车轱辘话，但CraftGPT也有着自我认知</p>
  <p>CraftGPT的完成度相当高。</p>
  <p>虽然它的词汇量和生成的句子长度有限，但它依然能进行简单的对话，回答基础的事实问题。更有趣的是，由于游戏中的seed（在世界生成时产生的一种随机参数）不同，它给出的回答也会随之变化，这让CraftGPT的输出带有一定的随机性和多样性，而不是每次都一模一样。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9f1e25a3df7942d4b5fa81335aebf45c@000000_oswg631776oswg1080oswg602_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">虽然简单，但每次CraftGPT提供的户外活动建议都略有不同</p>
  <p>不过，<strong>它的运行效率极低</strong>。因为红石信号传播的距离有限——只能传播15个游戏方格的长度，15格后就需要中继器来延长信号。问题就在这里，通过中继器虽然会给信号再次续命15格，但是会产生0.1秒的延迟。一个复杂的计算模块可能包含成千上万个中继器，这意味着一次运算要等待几分钟才能完成。相对现实中接近光速的电子流动来说，红石电路简直是蜗牛蠕动。</p>
  <p>即便在经过特别优化，速度超快的服务器上，生成一个回答也可能需要耗费数小时；<strong>如果换到普通电脑上运行，回答一次的时间甚至可能长达十年</strong>。毕竟这是一个由红石电路堆出来的小模型，能运转就足够让人惊叹了。</p>
  <p>CraftGPT就像那位试图徒步环球的探险家卡尔·布什比（Karl Bushby），从智利出发，历尽艰难险阻，花了整整27年才在今年5月重新踏上欧洲大陆，就算加快脚步，坐上飞机绕地球赤道一圈，也需要约 42 小时。至于真正的计算机，它们的速度更像0.134 秒就能绕地球一圈的光。</p>
  <h2><strong>红石电路，三体里的人列计算机</strong></h2>
  <p>CraftGPT项目的核心——红石电路诞生于2010年的Minecraft Alpha 1.0.1版本。</p>
  <p>在一款冒险游戏里，红石原本应该是什么角色呢？</p>
  <p>一个2010年的攻略贴展示了当时最流行的红石用法：踩下踏板就会开的自动门、TNT地雷陷阱等，用来让生活更方便，或者坑朋友。</p>
  <p>红石在游戏里引发了第二次工业革命，很快，玩家们迈入了电气自动化的新时代。他们制造出了可以检测矿车经过的“自动地铁站”，能自动收集农作物、杀怪收集掉落物品的自动化农场，还有转动式灯塔、机关式雕塑等有趣又实用的建筑。</p>
  <p>这些用途是大多数玩家最早接触红石的起点。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c88c6a3d07b6434d8a3f821c31aabda9@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">当时的红石农场，红石实用派代表作之一</p>
  <p>Minecraft的最初创造者Notch从一开始就知道红石的潜力，他在一次访谈里提到，红石系统使得Minecraft具备了图灵完备性，也就是说，在Minecraft中只要有足够多的时间和储存，玩家理论上就能在游戏中计算出任何可计算的东西。</p>
  <p>早在红石刚推出的2010年，就有人跟随着《计算机系统要素》的指导，试图在Minecraft中模拟简单的计算机。从机关陷阱到逻辑电路，再到 CPU 雏形，红石的发展轨迹也从单纯的游戏机关，走歪出了一个“吃力不讨好”的模拟计算机之路。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7ec09f4db01f435894703c3cdea8ecf9@000000_oswg922803oswg1080oswg624_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">当时简陋的计算机结构</p>
  <h2><strong>超复杂结构，还真给他们手搓出来了</strong></h2>
  <p>在社区中，玩家们开始交流设计工具，优化红石电路的经验，大大推动了技术的发展，加上随着游戏版本更新，更多好用方便的红石组件加入了游戏，大型计算机项目的实现成为了可能。</p>
  <p>Minecraft项目的成型，就像原始人手搓喷气机，从炼铁开始。</p>
  <p>红石电路只提供了表现0和1的信号的功能，也就是开关的闭合与开启，更加进阶的逻辑门、寄存器、时钟电路则需要玩家自己搭建，让信号能计算、存储并循环。而上述结构只有继续堆叠成更加复杂的部件，才可以组成完整的系统。可以说，这其中每一步都必须从项目底层的计算逻辑以及原理出发，逐个组件拼接，可以说是费工又费力。</p>
  <p>不过，就是有这么一些团队痴迷于手搓一切，做出让人惊艳的杰作。</p>
  <p>WildEngineering手搓过GPU；MattBatWings 做出了8-bit 可编程计算机；而Craftgpt的创造者Sammyuri更进一步，做出过16 bit电脑，在那上面可以运行多种程序，<strong>甚至还能终极套娃，在Minecraft里玩Minecraft</strong>。</p>
  <p>看着他们的作品，仿佛是在上计算机组成原理。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_cf12b93962674110b022f5a36b82795a@000000_oswg540483oswg1080oswg500_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">WildEngineering的GPU，运算速度达到了惊人的5Hz（每秒计算五次），虽然现代GPU的运算次数以万亿次/秒计</p>
  <p>中国也有不少红石电路高手。</p>
  <p>2022年，up主辰占鳌头就早于Sammyuri，把神经网络搬进过Minecraft，并实现了堪称机器学习届“Hello World”的手写数字识别。除此之外，他还实现过汉字编码全像素显示屏，把中国特色创意发挥到了极致。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_a59eba6bcc754d688c7528a443ebaeff@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">辰占鳌头的汉字编码全像素显示屏</p>
  <p><strong>有意义吗？这是技术成为艺术的一刻</strong></p>
  <p>虽然这些红石作品在实用性上几乎没有意义，远不如现成的计算机高效，但他们展现出的好奇和探索，也是人类文明繁荣的源头所在。</p>
  <p>手搓电脑不是为了造出一台真正能使用的机器，只为了证明：即便是在像素方块的虚拟世界中，也可以从0起步，堆出复杂的逻辑和计算。</p>
  <p>这也是工程师的浪漫精神所在，拼接简单的开与关、0和1，直到成为让人直呼“漂亮”的精妙工程。这是一种浪漫，是对我们为什么要钻研技术的一种艺术性的回答。</p>
  <p>参考文献</p>
  <p>[1]https://www.youtube.com/watch?v=VaeI9YgE1o8</p>
  <p>3年手搓ChatGPT！剑桥天才少年在Minecraft游戏中爆火回归[2]https://mp.weixin.qq.com/s/fmgsWl-HNBlRo9O7V-gg1Q</p>
  <p>[3]https://Minecraft.fandom.com/wiki/</p>
  <p>[4]https://gaming.stackexchange.com/questions/7852/what-is-redstone-used-for-in-Minecraft</p>
  <p>[5]https://www.youtube.com/watch?v=LGkkyKZVzug</p>
  <p>[6]https://www.bilibili.com/video/BV1wP4y1s7jy/</p>
  <p>[7]https://www.bilibili.com/video/BV1JzNUeuEg2/</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MTg1MjI3MzY2MQ==&amp;mid=2652331508&amp;idx=1&amp;sn=724abefdebc540494aa9d717ba120663&amp;chksm=5c4c3900ede4b4ff1f955ada1c769c42f519577bfc039248fb9ca97373fb3ed330314973cb21&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“果壳”（ID：Guokr42）</a>，作者：李小雅，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530005084216197</id>
            <title>黄仁勋台上最强GPU炸场，台下感叹“中国芯片爆发”，瞄准6G投资诺基亚</title>
            <link>https://www.36kr.com/p/3530005084216197</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530005084216197</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:53:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>“中国芯片要爆发了。”</p>
  <p>官宣完“地表最强”的英伟达新GPU后，黄仁勋面对全球媒体的镜头如是说。</p>
  <p>他还大夸中国模型，直言Qwen、DeepSeek都是“世界级、革命性”的成果。</p>
  <p>近一个小时的接连提问，有一半的问题都关于中国，仿佛让人忘了英伟达的新成果才是这场发布会的主角。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_73adfd18c0c345c1802ad58d7402d57e@46958_oswg332846oswg1080oswg619_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>发布会上，老黄介绍了英伟达新核弹<strong>Vera Rubin</strong>，算力100PFLOPs，是英伟达首款专用AI计算机DGX-1性能的100倍。</p>
  <p>该款芯片也正是OpenAI英伟达千亿大单第一阶段要部署的芯片，现在老黄手里已经有了样品，预计明年实现量产。</p>
  <p>此外，老黄还官宣了英伟达在量子计算、6G通信、自动驾驶等其他领域的战略布局。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ebe5e649cdc54210bbbc824599f74613@46958_oswg302620oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>下一代芯片和超算</strong></h2>
  <p>Vera Rubin平台是继GB200（Grace Blackwell NVLink 72）之后的第三代NVLink 72机架规模的计算机，从芯片、系统、软件到模型架构都进行了全新设计。</p>
  <p>而最核心的Vera Rubin超级芯片则是搭载了一颗Vera CPU和两颗大型的Rubin GPU。</p>
  <p>英伟达已经收到了首批由台积电生产的Rubin GPU，每个GPU芯片都采用了HBM4高带宽内存，主板其他区域配备了32个LPDDR内存插槽，和HBM4内存协同工作。</p>
  <p>在FP4精度下，浮点计算性能可达50PFLOPs，相较于现有的GB300，性能有数倍跃迁。</p>
  <p>而Vera则采用Arm架构，搭载了88个核心以及176线程，NVLINK-C2C互联带宽可达1.8TB/s。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_537bcd09a5af4384ba9e3c7740a1ffa3@46958_oswg760394oswg1080oswg921_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>黄仁勋展示的Vera Rubin计算托盘则采用高度集成设计，是一个<strong>完全无线并且100%液冷</strong>的节点。</p>
  <p>这个计算托盘的核心处理器内置了两个Vera CPU和四个Rubin封装，形成了强大的算力核心。</p>
  <p>而为了应对AI日益增长的对于上下文处理的需求，英伟达还在托盘中新增了Bluefield 4数据处理器，配备了8个全新的ConnectX-9超级网卡。</p>
  <p>不过，老黄表示Vera Rubin计算托盘的安装过程极其简单，甚至调侃道：</p>
  <blockquote>
   <p>连我都能做到。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_43fa6833b1474c0c89662247a9b843d0@46958_oswg236559oswg1080oswg484_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>首代基于Vera Rubin的Vera Rubin NVL144平台计划于2026年下半年推出，可实现3.6Exaflops的FP4推理算力和1.2Exaflops的FP8训练算力，相较于GB300的NVL72提升约3.3倍。</p>
  <p>而升级版的Rubin Ultra NVL576将在2027年下半年推出，将NVL系统规模从144扩展到576，FP4推理算力可以达到15Exaflops，FP8训练算力达5Exaflops，相较GB300 NVL72提升14倍。</p>
  <p>英伟达科学家<strong>范麟熙（Jim Fan）</strong>评价：科幻场景与“真实的《黑客帝国》”相比黯然失色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9c2fd67b1f9d4c799b846da06ffaae4d@46958_oswg1059413oswg1052oswg1042_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>英伟达还规划和美国能源部合作新建7座超算集群。</p>
  <p>其中，Mission和Vision两台基于Vera Rubin平台的新超级计算机是与HPE合作，为洛斯阿拉莫斯国家实验室建造的，预计2027年投入使用。</p>
  <p>下一代超级芯片蓄势待发时，当前的Blackwell架构也实现了量产，正在大规模生产和部署。</p>
  <p>黄仁勋透露，涵盖至2026年的出货量，Blackwell和Rubin的订单总销售额将达到5000亿美元。</p>
  <p>现场老黄又搬出了GPU未来三年计划——到2028年推出Feynman。</p>
  <p>就像从Blackwell到Rubin的节奏一样，承诺每年一次重大更新。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5de6baca3282478ca840bf4412e89ad9@46958_oswg311245oswg1080oswg567_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除了官宣超级芯片，老黄也透露了英伟达在其他领域的计划。</p>
  <h2><strong>AI超算与量子处理器的无缝连接</strong></h2>
  <p>量子计算，一个获得诺贝尔物理学奖的热门课题，英伟达在这方面也有所布局。</p>
  <p>这次演讲中，NVIDIA发布了<strong>NVQLink</strong>，这是一种<strong>新的互连架构</strong>，可以直接连接量子处理器（QPUs）和NVIDIA GPU，首次实现了AI超算与量子处理器的无缝连接。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7aace542bbaa468fbd957bffee651ffa@46958_oswg299349oswg1080oswg612_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>它能够以每秒数千次的速度，在量子硬件之间传输高达TB级的数据，这是量子错误校正所需的关键速度。</p>
  <p>功能上，NVQLink负责量子计算机的控制和校准、量子错误校正，以及连接QPU和GPU超级计算机以进行混合模拟。</p>
  <p>并且该架构具有完全可扩展性，可以处理从当前的数百个量子比特扩展到未来数万甚至数十万个量子比特的纠错需求。</p>
  <p>为了实现这种融合，NVIDIA推出CUDA-Q，这是一个用于量子GPU计算的开放平台， 将CUDA扩展到支持QPU，使之能够与GPU协同工作。</p>
  <p>之前的GTC巴黎站上，英伟达宣布已经在Blackwell集成了CUDA-Q，通过GPU为量子计算加速，其功能主要有两大方面：</p>
  <p>如果没有真·量子计算单元，CUDA-Q可以在经典计算机上 <strong>模拟量子运算</strong> ；</p>
  <p>如果有了量子计算单元，CUDA-Q可以实现 <strong>量子与经典加速计算的协同</strong> ，也就是QPU协作。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2c9d22102cb3494fb81902c4117ecb45@46958_oswg366662oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>除了数据中心和量子计算，英伟达这一次也宣布将踏足新的领域——6G通信。</p>
  <h2><strong>投资诺基亚，入局6G通信</strong></h2>
  <p>英伟达认为，加速计算和AI给通信行业也带来了一场新计算模型所驱动的平台转型。</p>
  <p>为此，英伟达宣布推出新的产品线，名为<strong>NVIDIA Arc</strong>&nbsp;(Aerial Radio Network Computer)，专门用于6G。</p>
  <p>Arc由三项基础新技术构建而成——Grace CPU、Blackwell GPU以及ConnectX Melanox网络技术。</p>
  <p>Arc运行在CUDA X库中的无线通信系统Aerial上，目标是创建首个能够同时进行无线通信和AI处理的、软件定义的可编程计算机。</p>
  <p>具体来说，英伟达与诺基亚达成合作推出了支持AI原生6G的加速计算平台——Aerial RAN Computer Pro（ARC-Pro）。</p>
  <p>这是一款AI基站主机，搭载了6G-ready加速计算平台，并实现了无线+AI共生，把AI推理传统RAN处理跑在了同一套基础设施上。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7bc052edb76144c2a558043730876a32@46958_oswg264742oswg1080oswg641_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>技术合作的同时，英伟达还对诺基亚进行了投资，总金额为10亿美元，这一举措让诺基亚股价大幅度上涨，创下了6年多以来的新高。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_ee9baef0758c48ca8d29f98f19299c61@46958_oswg164647oswg1080oswg947_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>One More Thing</strong></h2>
  <p>无论是英伟达的“现金奶牛”数据中心，还是新布局的量子计算和6G，英伟达都不无对手、都有潜在挑战者。</p>
  <p>隔壁AMD刚刚拿下了两台超算订单，金额为10亿美元。</p>
  <p>这两台超级计算机的主要硬件部分将全部由AMD打造其中的首台名为Lux，搭载AMD Instinct MI355X加速器 ，每台板载功率高达1400瓦，预计将在六个月内投入使用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_893b2849bee442dc84fcc9738dba09f1@46958_oswg191815oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Lux的人工智能性能将是现有超级计算机的三倍，AMD CEO苏姿丰表示，这是同规模超级计算机中部署速度最快的一次。</p>
  <p>除了AMD，不满足于在端侧发展的高通也想要分一杯羹，宣布推出两款全新的AI芯片——<strong>AI200</strong>和<strong>AI250</strong>，正式进军数据中心市场。</p>
  <p>这两款芯片聚焦AI模型的<strong>推理阶段</strong>，主打行业最低的<strong>总拥有成本</strong>（TCO）、<strong>更高的能效</strong>与更强的<strong>内存处理能力</strong>，分别预计于2026和2027年实现商用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_af69afcfc61844b58eca82e094ff925b@46958_oswg252001oswg970oswg526_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>AMD、高通，还有老黄口中正在爆发的中国芯片，都有可能是英伟达面临的潜在竞争对手。</p>
  <p>还有老黄看好的量子计算领域，甚至出现了不同路线的竞争——</p>
  <p>英伟达认为GPU和QPU的组合是量子计算的未来，但IBM成功用AMD芯片实现了无GPU的量子计算。</p>
  <p>IBM的算法解决了量子计算中最核心的挑战之一——量子比特的脆弱性与高错误率。</p>
  <p>这套方案的运行速度比实际需求快10倍，而且不需要昂贵的GPU，只需要FPGA芯片与量子计算机配合。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_845b1dc834804b59a8028791b301baad@46958_oswg299373oswg1080oswg406_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>与诺基亚合作的6G同样存在激烈竞争。</p>
  <p>去年7月，北邮张平院士团队成功搭建了国际上首个通信与智能融合的6G试验网。</p>
  <p>今年8月，北京大学和香港城市大学合作的全球首款全频段6G芯片问世，利用光子技术实现了100Gbps的传输速率。</p>
  <p>该芯片只有11×1.7mm的尺寸，但融合了毫米波、太赫兹通信以及低频微波波段，覆盖了0.5-115GHz。</p>
  <p>这一成果被视为6G的关键突破，论文已经登上Nature。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_92e9da4037584e6c80d3db84b7f2122f@46958_oswg50858oswg1080oswg355_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>尽管在各个领域都面临竞争，但市场投资者还是选择看好英伟达——收盘时，英伟达股价上涨4.98%，达到201.03美元每股，盘后价格更是达到每股204.43美元，创下了历史新高。</p>
  <p>若以盘后价格计算，英伟达的市值增长了3154亿美元，折合人民币近3万亿，仅增长部分就相当于1.59个英特尔。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_dfcac77d5d324dc1b89907277fdd7774@46958_oswg170730oswg1080oswg946_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这场基础设施的全面竞争，究竟会鹿死谁手？</p>
  <p>参考链接：</p>
  <p>[1]https://www.youtube.com/watch?v=lQHK61IDFH4</p>
  <p>[2]https://wccftech.com/nvidia-shows-next-gen-vera-rubin-superchip-two-massive-gpus-production-next-year/</p>
  <p>[3]https://x.com/DrJimFan/status/1983232823784853998</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/b3KooA0Opv-il5eFDewhBw" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：克雷西 闻乐，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530005109857154</id>
            <title>14万，全球首款家务机器人开卖，OpenAI投资，萌脸翘臀会自己充电</title>
            <link>https://www.36kr.com/p/3530005109857154</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530005109857154</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:52:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>全球首款开卖的家务人形机器人来了！</p>
  <p>它就是<strong>1X Technologies</strong>（以下简称1X）<strong>公司推出的NEO家用机器人</strong>。</p>
  <p>来看，下面这个萌脸翘臀的家伙，很有可能是你会拥有的第一台家庭具身智能机器人——</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_234126bf4f174605a4f5a6175225ca24@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>说它脸萌，是因为它正脸长这样，没啥恐怖谷的感觉：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_79549d029e714f38ab16ad0108a603a9@46958_oswg66573oswg1080oswg711_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>当然，对人形机器人来说颜值不是正义。</p>
  <p><strong>能自主干各种各样的家务活，才是大家最盼望实现的：</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_e1fcd2cbba6f4f719a6081eb29c0d942@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>家里有大别野的也别担心，NEO自己会平稳地上下楼梯：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0ee441403e8b4aaba67a8c312d881041@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p>NEO今日开售，首发有米色、灰色与深棕色三种颜色可选，2026年发货。</p>
  <p>早鸟价格20000美元（约141978元）/台。</p>
  <p>嫌贵的话还可以月租，500美元（约3549.45元）一个月。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0e60b7e9d26b440982538ea48a17ec1b@46958_oswg301131oswg908oswg450_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>1X的AI副总裁Eriic Jang表示：</p>
  <blockquote>
   <p>这是一款超前时代的产品。我们仍在积极开发和完善部分功能，可能会出现失误，我们会迅速汲取经验，并利用用户的早期反馈来改进NEO。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_42d1bc74e44446aab9e80d3624256a1e@46958_oswg119086oswg1080oswg254_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我不少亲爱的网友，发出了和我第一眼看到视频时一样的感叹：</p>
  <p><strong>里——面——有——人！</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_32e81619b30745468124e215facc9dc7@46958_oswg94715oswg974oswg358_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而有的人已经手快下单了。&nbsp;</p>
  <p>一买就是两台，希望它们承包家里所有的家务活，以及在闲暇时刻打打架来让自己看个乐子。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8a3e054bbd3846b59bf2691be57b2db2@46958_oswg85761oswg1080oswg381_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>能帮我干很多家务活的机器人，终于来了</strong></h2>
  <p>NEO<strong>内置Redwood AI系统</strong>，可自动完成基础家务。</p>
  <p>而且开箱即用，开机后它会自动开始运行，并进入自主模式。</p>
  <p>“嗨，我是 Neo，我来帮你打理家务。你叫什么名字？”“Harry。”“很高兴认识你，Harry。当你需要帮助或想让我做点什么，只要告诉我就行。”</p>
  <h3><strong>家务功能</strong></h3>
  <p>既然话说到这里，这个主打家用的人形机器人，到底能帮我们做哪些家务？</p>
  <p>目前视频中展示的功能确实是有点令人心动。NEO能完成的家务包括但不限于——</p>
  <p>使用吸尘器打扫卫生：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_8789293b47274399b3e1c5a63c45a439@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p>把洗碗机里的锅碗瓢盆拿出来归位摆好：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_fe25acd45dc44c2182380ebc4f477b94@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>帮你喂猫喂狗（再也不用找人上门喂自家小毛孩了？）：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_92370750c4674958944bf281a486e516@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p>打扫卫生间时关抽屉，拔电吹风的插销：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_bad2752be9a4447ea348f6c46a531bad@46958_img_gif?x-oss-process=image/quality,q_90" /></p>
  <p>到处浇花：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_665d1613433b431e8f4af2edf897fb58@46958_img_gif?x-oss-process=image/quality,q_100" /></p>
  <p><strong>你可以列出家务清单，设定执行时间</strong>——无论是“每周二浇花”这样的具体任务，还是“打扫客厅”这样的泛化任务——<strong>Neo都能准时自动完成。</strong></p>
  <p>整个视频给人的感觉是，只有你想不到，没有NEO做不到。</p>
  <p>1X的创始人兼CEO Bernt Børnich表示，团队设计家务功能的<strong>初衷就是让用户把时间交还给生活。</strong></p>
  <p>如果遇到NEO还没学会的任务，可开启“专家模式”呼叫外援，1X平台的专业人员就会远程监督和指导，帮助NEO一边学习一边把你安排的活儿干了。</p>
  <p>有点好笑的事，整个过程，你可以从手机App上查看NEO在干什么、干得怎么样。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_38543f03d49e485f8bf9048884670cb1@46958_oswg287515oswg964oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>第一视角“监督”机器人干活</strong>，有种《重生之我变成自己家里的机器人在打扫家务》的滑稽感。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_815dca4451b5493f8f5fe9cdc74cdd65@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <h3><strong>AI陪伴</strong></h3>
  <p>视频中介绍，Neo是一款与你在现实世界共处，并<strong>可以语音驱动的AI伴侣</strong>。</p>
  <p>它能看、能听、能记住环境和细节——NEO内置的音频识别系统能判断你是在跟它说话还是在和别人聊天，从而决定是否回应你。</p>
  <p>NEO的头部两侧耳朵的位置各有一个光圈，和人交互以及开始自主作业时，灯光会对应亮起。</p>
  <p>同时，<strong>手势也和灯环一样，用来表达它的情绪与意图。</strong></p>
  <p>接收到“输入”后，NEO会贴心地提供帮助或给出自己的建议。</p>
  <p>Be like：</p>
  <p>“我找不到眼镜了——这瓶是辣椒粉吗？”“不，那是辣椒粉（cayenne pepper）。你的眼镜在衬衫上呢。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_41edfa93bca04f7ebe304254914182f4@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <h3><strong>拆解长任务并自我进化</strong></h3>
  <p><strong>NEO会将复杂请求拆解为简单步骤。</strong></p>
  <p><strong>随着经验积累，它就能处理更复杂任务。</strong></p>
  <p>视频中展示了一个非常适合使唤NEO帮忙的家庭场景。</p>
  <p>你正在切菜，背后锅还在灶上，此时此刻你接到电话，有人快来家里了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9c60e0f5286845a38d4655fee20ff38a@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>分身乏术的你，这个时候就可以大喊一声：“NEO，能不能去门那边？”</p>
  <p>得到指令后，NEO就会屁颠屁颠跑去门口——转动门把手——开门——退后——迎接客人进家里来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_24afb1a7a3f445c8b351ebbffede1cc3@46958_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>还有两项“贴心”的功能设置，一定要介绍一下。</p>
  <p>一个是，如果打扫卫生时把自己弄脏了，NEO会走到洗手池前，打开水龙头给自己“局部搓澡”：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_df51053807924f68a8409fea1a2dae7b@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>另一个是，如果没电了，NEO能自己走过去给自己充电：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_933ec490bcc54a41839e69130950555e@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <h2><strong>NEO，一台萌脸翘臀的家务人形机器人</strong></h2>
  <p>NEO身高168厘米，体重约30公斤，拥有22个自由度。</p>
  <p>官方称它“手部灵活性达人类级别”。</p>
  <p>它是1X早期机型NEO Gamma和NEO Beta的下一代产品，采用了全新的硬件平台，<strong>搭载英伟达面向物理AI与机器人应用推出的边缘计算平台Jetson Thor。</strong></p>
  <p>它穿着穿着针织连体服，使用这种布料既是出于安全考虑，也是为了让外观更亲和——因为没有什么比“柔软毛衣”更能表达“我很无害”。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3738c65d9e764f50b6088aff008ccb9e@46958_oswg602885oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2个180万像素鱼眼镜头成为了它的眼睛。&nbsp;</p>
  <p>NEO还内置了WiFi、蓝牙与5G通信模块，在腰部和胸部集成了三段式扬声系统。也就是说，它<strong>可作为移动家庭娱乐中心使用</strong>。</p>
  <p>官方资料显示，NEO目前续航时长为4小时。</p>
  <p>为了能胜任多种家务，NEO最大负载68公斤，可以搬运约25公斤的重物。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5af3db6e28964947833487223ba73220@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>此外，Neo采用肌腱驱动系统，能耗低、机身轻盈，确保家庭环境中的安全。</p>
  <p>而且它的动作非常安静，运行噪音仅22分贝——传到你耳朵里，差不多等于你听到1米外有人翻书发出的声音。</p>
  <p><strong>每台NEO的皮肤都是防水且可机洗的。</strong></p>
  <p>1X的产品设计副总裁Dar Sleeper表示，虽然首发只有三种颜色，但每台NEO的头部和鞋子都可以更换，用户可根据个人风格定制外观。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c777745c64c84b0fb0ab8309d0b39964@46958_img_gif?x-oss-process=image/quality,q_80" /></p>
  <p>官方消息，<strong>明年开始，NEO将在美国市场率先交付，而后计划在2027年开始拓展至全球其他地区</strong>（截至目前，中国仅香港地址可下单）。</p>
  <p>不过，华尔街日报的资深科技与个人科技专栏作家Joanna Stern在她的文章中分享了她提前在1X总部与NEO互动一整天后的体验。</p>
  <p>Joanna询问得知，为了确保安全性，在初期，Neo不会处理任何高温、重物或锋利物体。</p>
  <p>所以也就不会发生网友们用Sora 2生成的这个场景：</p>
  <p>她让NEO去完成以下三个任务：</p>
  <p><strong>从冰箱拿水：</strong>完成。和冰箱门“尬舞”一番后，NEO成功取出瓶水，并小心翼翼地走了约3米，把它递给我。</p>
  <p><strong>把餐具放进洗碗机：</strong>完成。它颤巍巍下蹲后，放进去一只叉子、两只塑料杯，总共花了5分钟 （Joanna为此鼓掌了） 。</p>
  <p><strong>叠毛衣：</strong>完成但“无法商用”。耗时两分钟，Joanna提到“手部灵巧性仍是难点”。</p>
  <p>最重要的是——</p>
  <p>她透露道，<strong>目前，NEO的所有动作都由1X的远程专家操作员通过VR头显和游戏手柄控制，</strong>“我没亲眼见到它自主完成任务”。</p>
  <p>CEO连忙解释，到2026年，NEO将能自主完成家庭中大部分事务。</p>
  <p>最终目标，“NEO将实现完全自主，能在家中帮助你完成几乎任何任务”。</p>
  <p>但Joanna整体还是呈看好态度，在最后写下这样一段话：</p>
  <blockquote>
   <p>当机器人关洗碗机需要一分钟时，请多多鼓励它，多一点耐心哦。</p>
  </blockquote>
  <h2><strong>NEO背后公司：1X</strong></h2>
  <p>1X Technologies，原名Halodi Robotics，2014年诞生于挪威。</p>
  <p>这家公司最初因开发安保与巡逻机器人而被业内熟知，如今，它正将重心转向家庭、工作与服务场景，试图让真正能帮人干活的人形机器人走进日常生活。</p>
  <p>创始人表示，让NEO成为现实的梦始于十年前，但对他个人来说，这个梦想始于我大约十岁的时候。</p>
  <blockquote>
   <p>我从小读各种奇幻的科幻小说、看科幻电影，<strong>那些故事里的未来世界总是讲述人类如何把时间花在真正重要的事情上。</strong></p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_781b9e15d2874dc089da9cb480259b8f@46958_oswg286145oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>自Halodi时代起，创始团队就坚持一个方向：让机器人真正具备与人类环境共处的能力。</p>
  <p>与其他人形机器人公司相比，1X并不急于追求仿人度或肌肉力量的极限，而是将“安全性、柔性外观”与“具身智能的学习与交互能力”作为核心竞争力。</p>
  <p>2023年3月，这家公司迎来了关键转折：<strong>OpenAI创业基金领投了2350万美元融资，并正式宣布双方将在机器人领域展开深度合作，共同开发、训练并部署 AI 模型</strong>。</p>
  <p>这意味着1X不仅获得了资本支持，更获得了全球顶尖通用智能技术的助力——</p>
  <p>OpenAI 需要真实世界的具身场景来训练 AI，而1X正好提供了这一通道，让语言模型、视觉模型与行动模型在物理世界中学习、感知与反馈。</p>
  <p><strong>目前，1X的产品线以两大主力型号为核心，分别是NEO与EVE</strong>，两款产品都面向实际使用。&nbsp;</p>
  <p>其中，NEO是双足机器人，承担家庭与服务场景的主要落地任务。</p>
  <p>EVE则是早期版本或辅助型号，用于验证人机协作、安全交互与控制系统等底层技术。</p>
  <p>按现有计划，1X将长期面向欧洲与北美市场进行产品测试与量产布局；未来几年，他们计划通过软硬件迭代与量产工艺优化，让具身智能以消费级价格走入家庭。</p>
  <h2><strong>One More Thing</strong></h2>
  <p>还记得扫地机器人是怎么大规模进入一个个小家庭的吗？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b82b75688acf43e3b2d6194faf98edd9@46958_oswg176835oswg1080oswg485_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Yesterday once more，<strong>没想到2025年，我们就能够买买买全球首款家务机器人了。</strong></p>
  <p>现在，我亲爱的鲁滨逊们，是时候轮到你选择你的硅基星期五了～</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_a09e75aff42c4fff9272873c03aa8bc9@46958_oswg465091oswg1080oswg722_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>参考链接：</p>
  <p>[1]https://x.com/1x_tech/status/1983233494575952138</p>
  <p>[2]https://www.wsj.com/tech/personal-tech/i-tried-the-robot-thats-coming-to-live-with-you-its-still-part-human-68515d44?st=guXssw&amp;reflink=desktopwebshare_permalink</p>
  <p>[3]https://www.wsj.com/tech/personal-tech/i-tried-the-robot-thats-coming-to-live-with-you-its-still-part-human-68515d44?st=guXssw&amp;reflink=desktopwebshare_permalink</p>
  <p>[4]https://x.com/jamescrawfordx/status/1983253968747934133</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/Ny1BVhnW7O1c0rD0d6jZNA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：衡宇，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3530004744854659</id>
            <title>单条演示即可抓取一切：北大团队突破通用抓取，适配所有灵巧手本体</title>
            <link>https://www.36kr.com/p/3530004744854659</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3530004744854659</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:52:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在灵巧手通用抓取的研究中，由于动作空间维度高、任务具有长程探索特征且涉及多样化物体，传统强化学习（RL）面临探索效率低、奖励函数及训练过程设计复杂等挑战。</p>
  <p>基于此，北京大学及BeingBeyond团队提出<strong>DemoGrasp</strong>框架——</p>
  <p>一种简单且高效的通用灵巧手抓取学习方法。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_71dedef882284081b0dd735b9266cc67@46958_oswg93153oswg1080oswg351_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>该方法以一次成功的抓取演示轨迹为起点，<strong>通过对轨迹中的机器人动作进行编辑，以适应不同物体与姿态</strong>：改变腕部位姿用于确定“抓取位置”，调整手指关节角度用于确定“抓取方式”。</p>
  <p>这一核心创新——将连续决策的多步MDP（马尔可夫决策过程）重构为基于轨迹编辑的“单步MDP”——有效提升了强化学习在抓取任务上的学习效率和迁移到真机的性能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2eff8b945664454e97b571604ecd52ee@46958_oswg114810oswg1080oswg509_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>核心设计：单条演示 + 单步 RL</strong></h2>
  <h3><strong>从“多步探索”到“全局编辑”</strong></h3>
  <p>传统RL的困境：高维动作空间的复杂探索</p>
  <ul>
   <li>动作空间：每一步都需要输出高自由度机器人所有关节的指令。</li>
   <li>奖励设计：需要设计极其复杂的密集奖励函数，引导机器人避开碰撞、接触物体、成功抓取、平滑运动等。</li>
   <li>课程学习：需要设计复杂的多阶段学习流程，帮助RL探索</li>
  </ul>
  <p>DemoGrasp 的核心创新在于用 “单条成功演示轨迹” 替代 “从零开始的探索”，将高维抓取任务转化为 “演示编辑任务”，再通过单步 RL 优化编辑参数，最终结合视觉模仿学习实现虚实迁移。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0a0c57f3d0da4df28ba77f7e27c4abf4@46958_oswg297616oswg1080oswg505_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h3><strong>单条演示和轨迹编辑</strong></h3>
  <p>一条抓取特定物体的成功轨迹包含了抓取任务通用的模式（如 “靠近物体→闭合手指→抬起手腕”），只需调整轨迹中的手腕和手指抓取方式，即可适配没见过的新物体。</p>
  <p>DemoGrasp只需要对一个物体（比如一个方块）采集一条成功抓取演示轨迹，即可通过物体中心的轨迹编辑做出新物体、新位置的抓取行为：</p>
  <ul>
   <li>手腕位姿编辑：在物体坐标系下，对原始轨迹中的每一个手腕位点施加一个统一的变换 T∈SE(3) ，通过灵活地调整手腕抓取方向和位置，适应不同大小、形状、合适抓取点的物体。</li>
   <li>手指关节编辑：对手指的抓取关节角施加一个增量 Δq_G，通过与演示轨迹的等比例插值，产生一条灵巧手从初始张开姿态平滑到达新的抓取姿态的动作轨迹。</li>
  </ul>
  <h3><strong>单步强化学习</strong></h3>
  <p>在仿真环境中，DemoGrasp利用IsaacGym创建了数千个并行世界，每个世界里都有不同的物体和摆放场景。</p>
  <p>学习过程：每一个仿真世界中，策略网络根据初始的观测（末端位姿和物体点云、位姿） 输出一组手腕和手指编辑参数，执行编辑后的轨迹，根据执行过程是否“抓取成功”和“发生碰撞”获得奖励。</p>
  <p>通过海量试错和在线强化学习，策略学会根据不同形状物体的观测输出合适的编辑参数。</p>
  <p>训练效率：在这个紧凑动作空间的单步MDP问题上，DemoGrasp使用单张RTX 4090显卡训练24小时即可收敛到&gt;90%的成功率。</p>
  <h3><strong>视觉蒸馏，虚实迁移</strong></h3>
  <p>仿真中的强化学习策略依赖精确的物体点云和位姿，这在现实中难以获取。DemoGrasp通过视觉模仿学习，将策略蒸馏成与真机对齐的RGB策略，实现从仿真到真机的直接迁移。</p>
  <ul>
   <li>数据收集：在仿真中运行强化学习策略，记录下上万条成功轨迹：包括渲染的相机RGB图像、每一时刻的机器人本体感知和关节角动作。</li>
   <li>模型训练：采用流匹配（Flow-Matching）生成模型的方法，学习从图像观测和机器人本体感知预测动作。为缩小仿真到真机的视觉图像差异，训练还使用了预训练的ViT提取图像特征，并在仿真数据收集时充分地进行域随机化（随机化光照、背景、物体颜色纹理、相机参数等）。</li>
   <li>多模态适配：DemoGrasp适配单目/双目、RGB/深度相机等多种相机观测。实验表明，双目RGB相机组合的效果最佳，能够更好地减少遮挡、利用纹理和轮廓等信息成功抓取小而薄的物体。</li>
  </ul>
  <h2><strong>实验结果：仿真和真机双优，全面提升灵巧抓取的泛化性和扩展性</strong></h2>
  <p>DexGraspNet是灵巧抓取领域的权威数据集（3.4K 物体）。</p>
  <p>DemoGrasp在该数据集上使用Shadow Hand抓取，性能显著优于现有方法：视觉策略成功率达到92%，训练集到测试集的泛化差距仅1%，且适应大范围的物体初始位置随机化（50cm×50cm）、具备更强的空间泛化能力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_a65c759cec0648bba7e05090c2403078@46958_oswg37528oswg1080oswg278_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p><strong>跨本体扩展：适配任意灵巧手和机械臂本体</strong></p>
  <p>DemoGrasp无需调整任何训练超参数，成功适配6种不同形态的机器人（五指、四指灵巧手，三指夹爪和平行夹爪），在175个物体上训练后，在多个未见过的物体数据集上达到84.6%的平均成功率。</p>
  <p><strong>高性能的虚实迁移</strong></p>
  <p>在真实机器人测试中，使用Franka机械臂和因时灵巧手，DemoGrasp成功抓取了110个未见过的物体。</p>
  <p>在常规大小的物体分类上，DemoGrasp成功率均达到90%以上；</p>
  <p>对于扁平物体（手机壳、剪刀等）和小物体（瓶盖、小黄鸭等）的困难抓取任务，策略能够准确地抓取物体、避免碰撞，成功率达到70%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_eadf1e42f6d34e8fa771ac96ac62cd74@46958_oswg58396oswg1080oswg631_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>DemoGrasp框架支持对真实场景更加复杂的抓取任务的扩展能力，支持 在杂乱多物体摆放的场景下实现用语言指令引导抓取，且达到84%的真机单次抓取成功率。对于光照、背景和物体摆放的大幅变化，策略的成功率没有明显下降。</p>
  <p>DemoGrasp是融合少量人类演示实现高效机器人强化学习的新起点，将在未来支持功能性抓取、工具使用、双手操作等更多灵巧手任务。</p>
  <p>训练时策略的闭环能力是当前方法的一个局限，后续研究将通过更加细粒度的演示轨迹拆分，增加强化学习策略的实时调整、错误恢复能力。</p>
  <p>此外，DemoGrasp可以结合多模态大模型，实现开放场景下的自主抓取智能体。</p>
  <p>项目主页：https://beingbeyond.github.io/DemoGrasp/</p>
  <p>论文：https://arxiv.org/abs/2509.22149</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/KvH5UjLVVNwh7_BdXY9Iog" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：DemoGrasp团队，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529983228763008</id>
            <title>美国AI公司们，开始青睐Made in China的大模型</title>
            <link>https://www.36kr.com/p/3529983228763008</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529983228763008</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:52:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>咱就是说啊，“媚外”的风，也是吹到大洋彼岸的AI圈儿了。</p>
  <p>这不，就拿<strong>Windsurf</strong>这个国外头部的AI编程产品来说，最近就被网友扒出来了个贼有意思的事。</p>
  <p>起因是它这两天在自家产品里上新了一个<strong>神秘模型</strong>，说是专门为了速度和Agentic而设计的模型：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9a0e0717ccba4b54b4d364a69e04a9d8@000000_oswg527701oswg1080oswg934_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后很多好奇的宝宝就开始疑惑了，<strong>这个神秘模型到底是谁家的哦？</strong></p>
  <p>按道理讲，它背后公司（Codeium）本身就是在美国土生土长的，那接的大模型大概率应该来自OpenAI、Anthropic或谷歌吧。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c8a82118cb9540f5a27ad5ef9f19063e@000000_oswg127475oswg1080oswg546_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而，有网友尝试越狱后发现……神秘模型，<strong>来自中国</strong>——</p>
  <p>正是<strong>智谱</strong>的<strong>GLM</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_d8ed4f7fb1914f43acff81af76587af4@000000_oswg268356oswg1080oswg555_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>紧接着，我们顺藤摸瓜还发现，别的网友在底下还提到个事儿：</p>
  <blockquote>
   <p><strong>这就像是，GLM 4.6在Cerebras上运行。</strong></p>
  </blockquote>
  <p>（Cerebras就是去年发过专门为训练AI用的全球最大芯片的那家公司，后来进军推理市场，推出AI推理服务。）</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1005e5b8b4a941ae905115c1c20d8c85@000000_oswg74337oswg1080oswg202_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>原来，它在前两天就已经发了邮件，称上架了GLM-4.6：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0f7143cf43f6464282f1dc2f76e41025@000000_oswg290012oswg1080oswg427_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>甚至现在随便搜搜油管的关键词，出来的就会是像昨天新出的<strong>“中国的MiniMax M2挑战了商业模式”</strong>等内容。</p>
  <p>以及更早的，像美国云服务平台Together AI也是在今年7月份官宣部署Qwen-3-Coder：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_91e0a61619a746ffbd6f8050185ecb9d@000000_oswg149358oswg1080oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>好好好，合着美国的AI公司们，现在都开始用中国的大模型了是吧。</p>
  <h2><strong>而且还不是个例</strong></h2>
  <p>刚才我们提到的几个例子，涉及到的模型包括了GLM和Qwen3，领域则是AI编程和AI推理。</p>
  <p>但继续沿着这个线索挖下去，我们发现，部署中国大模型这个事儿，已然不是少数的个例了。</p>
  <p>例如在<strong>AI Agent</strong>领域，估值93亿美元的公司Vercel就在今天表示：</p>
  <blockquote>
   <p>已经和智谱达成合作，提供GLM-4.6的API服务。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_bbc97f2e590b4bd4860226034ac85478@000000_oswg180549oswg1080oswg1085_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>它家老板Guillermo Rauch更是转发了这个帖子，并且还称赞了一波：</p>
  <blockquote>
   <p>GLM-4.6很好，在http://nextjs.org/evals上排名第三，还是前五名里唯一开源的模型。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_aa3aa94785554fd19da7384aa4ea2b9d@000000_oswg199776oswg1080oswg771_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>更早一点的，无服务器AI推理平台Featherless，此前在Kimi K2发布之际，也表示支持其新模型：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5671a44788f74b8792a43fa4f696131b@000000_oswg126935oswg1080oswg330_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在包括最近爆火的让AI们集体模拟炒股的玩法，各个国产大模型也是陆陆续续被容纳了进来：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_44b1124ef8904ba18d5119348f1d4c5e@000000_oswg144135oswg1080oswg362_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_7bf092d50bef442c8b80a6c3f63eaf8d@000000_oswg189589oswg1080oswg652_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>看到这里，很多小伙伴就要不禁发问了——</p>
  <p>美国的大模型们性能不都挺强悍的么，为啥都开始纷纷pick中国国产大模型了呢？</p>
  <h2><strong>量大管饱，还便宜</strong></h2>
  <p>一言蔽之，<strong>“量大管饱又便宜”</strong>的原则，在AI圈儿里也是蛮吃香的。</p>
  <p>首先，最最最关键的一个原因，还是<strong>性能够打</strong>。</p>
  <p>关于这一点，不论是从上面Vercel公司老板怒赞GLM-4.6，亦或是从今年年初以来的DeepSeek、Qwen、K2等等，频频榜上有名且在海外爆火，均能看出其实力的水平。</p>
  <p>国产大模型性能这一块，已然是得到了国内外AI玩家们的认可。</p>
  <p>其次，就是<strong>性价比</strong>。</p>
  <p>在一段采访视频中，Social Capital公司创始人Chamath Palihapitiya就直言不讳地表态道：</p>
  <blockquote>
   <p>我们在Groq上已经开始在用Kimi-K2了。</p>
   <p>OpenAI和Anthropic的模型虽然挺好的，但<strong>太贵了</strong>。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_6d9b3eb955624279839eadaf10f91c86@000000_oswg591572oswg1080oswg601_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Chamath进一步解释说，如果你用编程工具的时候，Groq默认的路由是Anthropic，“这没问题，毕竟它性能挺好的，<strong>但真的太贵了</strong>”。</p>
  <p>但当你的公司来到跨越式发展的时候，你很难决定把这些所有提示词都传给不同的LLM，毕竟它们需要被微调和设计才能在同一个系统中工作。</p>
  <p>而且这个过程往往需要长达几周或者几个月的时间，因此，Chamath感慨说，“作为消费者，我们真的挺痛苦、挺挣扎的。”</p>
  <p>总的来看，<strong>性价比</strong>，成了美国AI公司们纷纷选择部署中国大模型的关键原因。</p>
  <p>而且很巧的是，卷价格，中国AI厂商们可以说是驾轻就熟了，时至今日也是依然如此。</p>
  <p>就拿最近的一些动作来说：</p>
  <p>快手AT-Coder-Air-V1 宣布注册就直接给2000万token</p>
  <p>智谱在1024程序员节当天推出GLM Coding Plan包月套餐折上折的活动，新人更是5折优惠</p>
  <p>Kimi也在程序员节当天也推出了类似的针对程序员的优惠套餐</p>
  <p>MiniMax M2今天宣布限时免费的日期推到11月07号</p>
  <p>然后快手也跟着把免费日期推到了11月10号</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3a633e4edede41d287e10dda5880c7f1@000000_oswg111650oswg1080oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0163a9f3e7ac4d5bba54b45fe4add9a8@000000_oswg111091oswg1080oswg472_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>嗯，真的是有钱任性，壕无人性。</p>
  <p>但更深入的，这也反映了AI产业正在从技术炫技的阶段，加速迈向务实应用的阶段。</p>
  <p>当企业真正开始大规模部署AI功能时，成本、速度和可扩展性就成了压倒一切的现实问题。</p>
  <p>Vercel和Social Capital这类公司的选择，戳破了“唯最强模型论”的泡沫，证明了高性价比的适用技术才是商业落地的硬道理。</p>
  <p>因此，这不再是一个关于谁的模型更强的单一故事，而是一个关于谁能更高效、更经济地赋能开发者和企业的多维竞赛。</p>
  <p>这场由“太贵了”引发的务实选择，或许预示着一个更加多元化和激烈竞争的全球AI新时代的到来。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_599a23bb54c6477abb85d96b0aaeea60@000000_oswg840110oswg1080oswg605_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但总而言之，大模型圈的Made in China的含金量，还在上升。</p>
  <p>参考链接：</p>
  <p>[1]https://x.com/windsurf/status/1982619448352854428</p>
  <p>[2]https://x.com/rauchg/status/1982973728423325803</p>
  <p>[3]https://x.com/karminski3/status/1982945655548194923</p>
  <p>[4]https://www.reddit.com/r/LocalLLaMA/comments/1ohdl9q/silicon_valley_is_migrating_from_expensive/?tl=es-419</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247837671&amp;idx=1&amp;sn=c1385c9923a851fd40a4e03ea7293a62&amp;chksm=e9a230160454323194b24e273e82612a11f89499fc7f3e33ee43dc9f7e4393430026476db3af&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：金磊，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529960209881985</id>
            <title>新晋女首富诞生，1400亿</title>
            <link>https://www.36kr.com/p/3529960209881985</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529960209881985</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:51:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>最新发布的《2025胡润百富榜》显示，钟慧娟以1410亿元的财富取代宗馥莉，成为新晋女首富。</p>
  <p>钟慧娟，医药圈并不陌生——她是港股上市公司翰森制药创始人、董事会主席、首席执行官兼执行董事。早年毕业于化学专业，钟慧娟从教师岗位转战医药圈，最终坐拥一家上市公司。</p>
  <p>而她的丈夫孙飘扬，同样大名鼎鼎，如今管理着市值5000亿港元的恒瑞医药。夫妻两人分别做出了一家千亿上市公司，即便放眼整个中国创投圈也是绝无仅有。</p>
  <p>钟慧娟身家大涨背后，是她所执掌的翰森制药今年市值从900亿一路上涨到2000多亿港元，成为生物医药集体爆发的一抹缩影。</p>
  <h2><strong>市值2000亿，她成为新晋女首富</strong></h2>
  <p>一切始于三十年前。</p>
  <p>钟慧娟是江苏连云港人，1982年从江苏师范大学化学专业本科毕业后，成为连云港延安中学的一名化学老师。后来钟慧娟从人民教师转型创业，进军医药圈，这离不开她的丈夫孙飘扬。</p>
  <p>1995年，孙飘扬和一名香港投资人组建一家新企业——豪森药业，也就是翰森制药的前身。但当时孙飘扬已经是连云港制药厂厂长，抽不开身。于是，钟慧娟便辞掉老师的工作，加入翰森制药，承担起管理公司的重任。</p>
  <p>起初，翰森制药以仿制药起家。1997年，公司拳头产品、抗生素药“美丰”投入市场，当年实现收入3000万元。2003年，公司成为全国医药百强企业。</p>
  <p>但钟慧娟并未止步于仿制药，而是未雨绸缪——加大对新药物的研发投入。官网显示，翰森制药已成为一家创新驱动型制药企业，重点关注抗肿瘤、抗感染、中枢神经系统、代谢及自身免疫等重大疾病治疗领域。2019年6月，钟慧娟站上了港交所IPO舞台。</p>
  <p>钟慧娟财富大涨离不开创新药行业的爆发。</p>
  <p>今年初，翰森制药市值约900多亿港元，此后不少创新药企迎来估值修复，股价翻倍上涨。如今，翰森制药最新市值超2000亿港元，公司股价年内累计涨幅超100%。根据最新发布的“胡润百富榜”，钟慧娟财富比去年增长600多亿元，凭借1400亿元财富，首次问鼎中国女首富。</p>
  <p>在这个月，钟慧娟拿下一个大单——公司将一款在研CDH17靶向抗体偶联药物（ADC）HS-20110在大中华区以外的全球权益，授权给跨国医药巨头罗氏。翰森制药将获得8000万美元的首付款、最高14.5亿美元的里程碑付款。也就是说，仅一款药翰森制药就卖出百亿。</p>
  <p>尽管执掌着千亿医药帝国，但钟慧娟为人低调，鲜少露面。</p>
  <h2><strong>医药圈最牛夫妻档</strong></h2>
  <p>医药圈的“夫妻眷侣”不在少数，但像钟慧娟和孙飘扬这样，各自执掌一家千亿上市公司的并不多见。</p>
  <p>孙飘扬和钟慧娟同是江苏老乡。1958年，孙飘扬出生于江苏淮安金湖，本科就读于中国药科大学化学制药专业。毕业后，两人都被分配到连云港。孙飘扬来到连云港制药厂担任技术员，也是恒瑞医药的前身。</p>
  <p>1997年，连云港制药厂改制更名为江苏恒瑞医药股份有限公司，孙飘扬担任董事长一职。2000年10月，恒瑞医药登陆上海证券交易所，成为A股“药王”。</p>
  <p>今年5月，孙飘扬带领恒瑞医药正式登陆港交所，实现“A+H”两地上市，最新市值超5000亿港元。上半年，创新药行情走高，叠加恒瑞医药实现营收、净利润双创新高，再次带动一波涨幅。</p>
  <p>两人已年过花甲，此前孙飘扬还曾短暂“退休”。现在，家族二代悄然走向台前。</p>
  <p>女儿孙远，同样低调，只能从翰森药业公开年报看到她的成长轨迹——出生于1987年，毕业于剑桥大学生物医学专业。有意思的是，毕业后孙远曾在知名投资机构弘毅投资任职分析师。2015年，她担任翰森制药执行董事，主要负责集团研发战略、业务发展、投资战略及科学发展提供指引。</p>
  <p>根据公司年报，钟慧娟通过家族信托持有翰森制药的股份。而该家族信托的受益人正是孙远。不过目前她尚未在恒瑞医药任职，孙飘扬也曾透露，恒瑞医药今后运营将选择职业经理人模式。</p>
  <h2><strong>今年，医药盛产富豪</strong></h2>
  <p>这场医药财富盛宴，来得实在猛烈。</p>
  <p>不止钟慧娟、孙飘扬夫妇，今年创新药赛道，尤其是涉及抗癌药领域的几位企业家财富同样增长显著。比如，来自四川的企业家朱义，凭借一笔现象级License-out（对外授权）受到追捧，他执掌的百利天恒今年股价一度涨至超380元，个人登顶四川首富。</p>
  <p>还有康方生物，今年股价一路走高，从年初的58港元一度上涨至179港元，创下历史新高，这一幕也为创始人夏瑜带来超级财富。</p>
  <p>目之所及，今年医药圈涌现一波富豪。</p>
  <p>这背后，离不开生物医药爆发。随着中国资产重估，A股、港股市场均迎来不同程度回暖。其中又以创新药板块表现突出——歌礼制药、德琪医药、科济药业、和铂医药……十倍股频现，“赶上这波行情的人都赚翻了”。</p>
  <p>细究下来，推动这轮行情的核心动力，正是密集发生的超级BD交易。数据显示，今年上半年中国创新药BD交易总额达635.5亿美元，已超2024年全年，其中单笔超10亿美元的交易达16笔。就在上周，信达生物宣布与武田制药达成总金额高达114亿美元的合作交易，再次刷新中国创新药出海的金额纪录。</p>
  <p>用投资人的话来说，中国生物医药终于迎来厚积薄发的一幕。</p>
  <p>没人想错过这场盛宴。港交所门前，等候聆讯的公司早已排起长龙。仅9月，就有14家医药企业宣布赴港上市。而昨天，科创板就迎来两家生物医药公司，禾元生物和必贝特。</p>
  <p>不过，隐忧也开始浮现——最近几个月，创新药板块悄然进入调整期，部分头部创新药企业也出现明显调整。翰森制药宣布与罗氏BD交易后，股价上涨并不如预期中明显；9月16日，药捷安康一天之内从2600亿港元跌回700多亿港元，令人心有余悸。</p>
  <p>我们都在见证着这些激荡景象。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247701058&amp;idx=1&amp;sn=db07fdaa48cc0446453e067384c86e4d&amp;chksm=ed2e0dbdc9442730715e0cb3c0ea9601d9fc286d4c605c5c510a5fa253b281756157974b9939&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529750856948872</id>
            <title>人造卫星还在“拨号上网”？你没看错，但现在卫星终于要连宽带了</title>
            <link>https://www.36kr.com/p/3529750856948872</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529750856948872</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:13:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b684150dbd6b4260b680c33313f912e9@000000_oswg219684oswg1072oswg856_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">欧洲空间局Sentinel-2卫星拍摄的加洲大火 | NASA Earth Observatory</p>
  <p>森林大火在加州蔓延，消防指挥官盯着卫星传回的热成像图，试图判断火势走向。<strong>但这张图像已经是20分钟前的了</strong>。</p>
  <p>20分钟里，火头可能已经跨过山脊，改变了方向。设备和人员的部署，全凭这<strong>过时的信息</strong>做决策。这个困境即将成为历史。</p>
  <p>SpaceX刚刚宣布，商业卫星运营商很快就能用上星链的激光通信服务，把数据延迟从平均20分钟压缩到几乎实时。</p>
  <p>听起来只是个技术升级，但它揭示了一个出人意料的事实：<strong>绝大多数人造卫星，在绝大多数时间里，其实一直处于失联状态</strong>。</p>
  <h2><strong>天上的卫星，竟然还在用“拨号上网”</strong></h2>
  <p>我们习惯了手机随时在线，很容易以为天上那些卫星也是全天候联网的。实际情况恰恰相反。大部分卫星绕地球飞行时，<strong>和地面的通信断断续续</strong>。它们要等飞过地面接收站上空时，才能把数据传下来，顺便接收新指令。就像老式拨号上网，得等电话线接通那一刻才能收发信息。飞过去了，信号就断了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_0b9de884c9eb4c3d895642aae575ac90@000000_oswg97840oswg960oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">人造卫星通常只在飞过地面接收站上空时，才能与地面取得联系。</p>
  <p>唯一的例外是国际空间站。它享受着美国NASA专门部署的<strong>数据中继卫星群</strong>服务，能保持近乎不间断的通信。但那套系统<strong>造价高昂</strong>，只为政府任务服务，比如空间站和哈勃望远镜。普通商业卫星<strong>用不起</strong>。这种技术代差造成的后果很直观。野火监测卫星FireSat拍到火情，画面得在卫星存储器里憋着，等飞到地面站上方才能下载。这一等可能就是几十分钟甚至几小时。</p>
  <p>对森林火灾来说，每分钟都可能是生死之别。</p>
  <h2><strong>激光组网：把卫星变成太空路由器</strong></h2>
  <p>星链改变了这个局面。它本来是个太空互联网项目，用数千颗低轨卫星给地面用户提供宽带服务。但SpaceX在<strong>卫星之间加装了激光通信终端</strong>，让这些卫星能相互传递数据，织成一张覆盖全球的太空网络。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1091858e67104114b81df5610fea9f72@000000_oswg500121oswg1080oswg603_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">星链卫星之间通过激光通信织成了一张太空网络 | SpaceX</p>
  <p>这套激光通信系统的性能相当惊人。根据SpaceX公布的数据，单个迷你激光终端能在4000公里距离上实现25Gbps的传输速度。一部高清电影，几秒钟就能传完。</p>
  <p>更关键的是，激光通信不受无线电频谱管制约束。传统卫星通信用的无线电波段，各国都有严格的频率分配规定，带宽受限。激光走的是光学通道，理论上可以承载的数据量要大得多。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_2911b34b3a8b430e895345a886f7effb@000000_oswg60751oswg1080oswg582_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">星链卫星上的激光通信终端 | SpaceX</p>
  <p>现在，一家叫“μ子航天”（Muon Space）的创业公司成了第一个吃螃蟹的。他们宣布<strong>将在自家卫星上安装星链的激光终端</strong>。装一个终端，卫星就能保持70%到80%的在线时间；装两个，就能做到100%全时段连接。<strong>这意味着卫星第一次可以像地面服务器那样，随时响应指令、实时回传数据</strong>。用μ子航天公司总裁格雷格·斯米林的话说，卫星从孤立的飞行器变成了星链全球网络上的实时节点。</p>
  <h2><strong>从“拨号”到宽带，会发生什么</strong></h2>
  <p>这个转变带来的影响，可能比我们想象的更深远。最直接的受益者是那些对时效性要求极高的应用。除了野火监测，还有海上搜救、灾害评估、农作物病虫害预警。过去这些场景下，卫星数据往往姗姗来迟；现在信息几乎同步抵达。</p>
  <p>但<strong>更有想象力的是那些原本不可能的应用</strong>。比如太空直播。历史上只有载人航天任务或火箭发射时，我们才能看到太空传回的实时画面，因为那需要临时动用昂贵的中继系统。现在<strong>有了激光组网，任何装了星链终端的卫星都能开直播</strong>。</p>
  <p>高分辨率的地球实时监控、连续的气象观测视频，技术上都不再是问题。SpaceX自家的星舰火箭已经在用这套系统。最近的试飞中，星舰在重返大气层时全程直播，画面穿透了包裹火箭的等离子体层，<strong>这在以往是不可能的</strong>——高温等离子会屏蔽无线电信号，造成黑障。但激光穿透了这道屏障。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_1cfffac7083e401fb00fa88c67f95a20@000000_oswg39050oswg1080oswg626_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">星舰第十一次试飞中重返大气层的画面，就是通过星链卫星的激光链路传回来的 | SpaceX</p>
  <p>更激进的设想是在轨AI计算。既然卫星能随时连上网络，理论上可以把它<strong>当作太空数据中心的节点</strong>，在轨道上直接处理数据，必要时调用地面算力。这能大幅减少需要传输的原始数据量，也让一些对实时性要求极高的任务有了可行性。斯米林用了一个很精准的类比：这<strong>就像当年地面互联网从拨号升级到宽带</strong>。你知道它会改变很多东西，但具体会出现哪些应用，当时谁也说不准。BBS很快就被淘汰了，取而代之的是流媒体、社交网络、云计算，<strong>催生出了整个一代全新的互联网生态</strong>。</p>
  <h2><strong>一个值得关注的细节</strong></h2>
  <p>μ子航天公司的第一颗装配激光终端的卫星，要到2027年初才发射。但他们已经拿到了不少商业订单，其中一个客户的身份耐人寻味：<strong>美国国家侦察局</strong>。这个机构是美国政府的<strong>间谍卫星部门</strong>。他们宣布要购买FireSat野火监测卫星的数据。名义上是买火情监测服务，但那套热成像系统显然不只能看火灾。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_cc5f821add594083afcc51de6627ae70@000000_oswg98878oswg1080oswg810_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">μ子航天公司员工在今年发射的首颗FireSat卫星前合影，这颗卫星还没有安装星链的激光终端 | μ子航天</p>
  <p>这透露出一个信号：当商业卫星具备了实时联网能力，它们的价值边界就模糊了。一颗本来用于民用监测的卫星，加装了高速数据链路后，就可能被情报部门相中。技术本身是中性的，但它的普及会重塑很多游戏规则。μ子航天公司的另一个客户是谷歌支持的非营利组织“地球火焰联盟”。他们计划到2030年部署50颗FireSat卫星，织成一张<strong>全球野火预警网</strong>。如果每颗卫星都能实时回传数据，这个网络的响应速度将达到前所未有的水平。森林火灾的黄金扑救时间往往只有几小时，实时监控可能真的能救下很多生命和财产。一年多以前，SpaceX的龙飞船执行了一次私人太空行走任务，那是人类第一次在没有政府航天机构参与的情况下出舱。那次任务还测试了另一项技术：通过星链网络与地面通信。当时很多人觉得这只是个技术验证，没想到它会这么快进入商用。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_dbfc554f61564dd9adb5ee5723cfaab5@000000_oswg33888oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">2024年9月，私人宇航员贾里德·艾萨克曼在他个人出资的“北极星‧黎明”任务中完成首次商业太空行走 | SpaceX</p>
  <p>现在看来，那次测试的意义远不止于此。它证明了在太空中建立类似地面互联网的基础设施，在技术上是可行的。而<strong>一旦这个基础设施铺开，整个太空产业的运作逻辑都会改写</strong>。我们正在目睹的，也许不只是卫星通信方式的升级，而是太空从偶尔光顾的远方，变成随时在线的近邻。这个转变静悄悄的，但它的余波会持续很久。</p>
  <p>信源：ArsTechnica</p>
  <p>封面图来源：SpaceX</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MTg1MjI3MzY2MQ==&amp;mid=2652331464&amp;idx=1&amp;sn=d0212adb578f4b5aa21815edc02caa57&amp;chksm=5c76f9de059b7016a1dbed464f20ed5e7f89a01e43afeb00b01e86ff896c95a7aaf0d54fbae6&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“果壳”（ID：Guokr42）</a>，作者：Steed，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529916798966660</id>
            <title>晒算法、降抽佣、增权益，货拉拉的监管“投名状”是IPO的诚意还是代价？</title>
            <link>https://www.36kr.com/p/3529916798966660</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529916798966660</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:01:42 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>近年来，港股市场成为新经济公司IPO的热土，但并非所有企业都能一帆风顺。自2023年3月首次递交上市申请以来，货拉拉在两年多时间内五次更新招股书未果。</p>
  <p>日前，货拉拉再度出手递交招股书，并更新财报数据，申请以“拉拉科技”为上市主体上市港交所，保荐机构为高盛、美银证券和摩根大通。</p>
  <p>最新招股书显示，<strong>2025年上半年货拉拉营收同比增长31.9%至9.35亿美元，净利增长32.6%至2.44亿美元。</strong>这家网络货运平台巨头能否凭借新财报和业务调整赢得市场认可？</p>
  <h2><strong>红杉高瓴腾讯入局的货运革命代表</strong></h2>
  <p>创立于2013年，货拉拉从粤港澳大湾区起步，是一家从事同城/跨城货运、企业版物流服务、搬家、零担、汽车租售及汽车后市场服务的网络货运平台，致力于将公路货运这一传统线下货运行业数字化，营造出了全新的行业生态。</p>
  <p>货拉拉的发展史，可以说是中国数字物流平台的代表性缩影之一。截至2025年上半年，其平台已促成并完成订单超过4.55亿笔，全球货运GTV（交易总值）达55.36亿美元，拥有平均月活商户约1970万个、司机约200万名。</p>
  <p>根据招股书引用的弗若斯特沙利文数据，<strong>货拉拉是2025年上半年全球闭环货运GTV最大的物流交易平台，市场份额高达53.3%；</strong>也是同期全球闭环货运GTV最大的同城物流交易平台、同期全球已完成订单数量最多的物流交易平台及同期全球平均月活商户最多的物流交易平台。</p>
  <p>财务数据印证了其规模扩张成效。<strong>据招股资料数据，2022年至2024年，货拉拉年度营收分别为10.36亿美元、13.34亿美元和15.93亿美元；同期净利润则分别为-4909.1万美元、9.73亿美元和4.34亿美元，</strong>整体呈营收稳健扩张、盈利加速向正规驱使的趋势。</p>
  <p>该周期内货拉拉GTV、营收和净利润的持续增长，一方面得益于最近两年新开拓的跑腿业务等持续扩大规模，另一方面则是来自零担、企业版这样的多元化物流业务，以及海外业务增长带来的贡献。2025年上半年其在中国境内多元化物流服务收入占比达40.1%，较2024年同期增长近10个百分点。</p>
  <p>事实上，从成立后的6、7年中，货拉拉的成长潜力就可以从资本方的支持中看出明显的端倪。</p>
  <p><strong>在2015—2021年，货拉拉已相继获得顺为资本、高瓴资本、红杉中国等投资方累计8轮融资。</strong>截至此次IPO前夕，货拉拉主要股东包括高瓴、红杉、概念资本、顺为、清流资本、襄禾等；其余还包括光源资本、Epic Faith、Aplex Capital、腾讯、D1 Capital、博裕、Tiger、中银香港、中国平安、美团等股东。</p>
  <p>这种资本背书既用真金白银支持了货拉拉早期的增长扩张，也印证了市场对其商业模式的长期认可。</p>
  <h2><strong>监管常态化下，共赢意味着利益重新分割？</strong></h2>
  <p><strong>尽管货拉拉在业务规模和市场地位上表现突出，但其港股上市之路却异常坎坷。前后五次递表未果，背后反映的是公司在监管合规和商业模式可持续性方面的深层挑战。</strong></p>
  <p>监管压力是货拉拉面临的主要外部挑战。近年来，交通运输新业态协同监管部际联席会议办公室多次约谈货拉拉等货运平台，指出存在随意调整运营规则、侵害从业人员合法权益、潜藏安全稳定风险隐患等问题。</p>
  <p>为此，货拉拉在算法透明化、司机权益保障和业务多元化三大维度做出了一系列努力。</p>
  <p>事实上，货拉拉自2024年以来就在不断发起为司机降费的动作，且持续在司机权益保障上加大主动投入。2025 年 3 月，货拉拉进一步发布《关于推动算法公开透明、向上向善机制的公告》，首次公开核心算法规则，明确承诺定价不采用 “杀熟”机制，并加大订单补贴和降抽佣力度。5 月的算法专题研讨会上，货拉拉再度宣布2025年以来平台拼车、用户出价订单抽佣比例平均降低6%，100公里以上长里程订单抽佣比例平均降低4%，预计2025年将降低抽佣共2.3亿元。</p>
  <p>除持续降抽佣外，司机权益保障的投入力度显著加大。货拉拉在 2025 年 7 月签署《保障货车司机合法权益自律公约》，宣布投入不少于 5000 万元用于低流水司机的减佣卡折扣。8 月再发公告，明确长里程订单降抽佣方案，设定抽佣金额上限，并对部分城市暂缓上线收费减佣卡；在社会保障层面，公司将职业伤害保障试点扩至 17 省市，扩围后将覆盖货拉拉平台80%以上的司机，而此前三年已累计投入 1.5 亿元覆盖 170 万名司机，试图缓解“平台与司机对立”的舆论困境。</p>
  <p>这一系列动作直击此前被约谈提及的“规则随意调整”问题，也是对监管“推动平台规则和算法公平公正”要求的直接回应，更是直接表明了司机权益保障投入力度加大的态度。</p>
  <p>然而，即便如此，监管压力至今并未完全解除。2025年9月，市场监管总局再次约谈货拉拉。</p>
  <p>更重要的是，作为一个“商人”，这些监管动作除了反映平台经济治理的大趋势，也直指货拉拉商业模式的核心挑战——如何在保持平台盈利的同时，平衡司机、货主和平台三方的利益。</p>
  <p>抽佣降低、投入持续增加……这些举措显示了货拉拉改善平台生态的努力，但也增加了运营成本，影响了短期盈利能力。2025年上半年，货拉拉毛利率为52.3%，较上年同期的59.4%下降了7.1个百分点，部分反映了这种平衡策略的成本。</p>
  <p>由于主动调整佣金策略，货拉拉贡献九成以上收入的国内市场变现率近两年持续在下降。招股书数据显示，货拉拉在中国内地的货运平台服务变现率由2023年的10.3%微跌至2024年的9.6%，并由2024年上半年的9.7%减少至2025年上半年的9.2%。</p>
  <p>这一变化虽然幅度不大，但经GTV折算后影响显著。<strong>2025年上半年货拉拉在中国境内的货运平台服务GTV为45.67亿美元，</strong>如果以2023年的10.3%变现率计算，1.1个百分点的下降导致收入减少近5000万美元（约合3.57亿元人民币）。</p>
  <p>至于海外市场的变现率虽然高达15.9%且持续提升，但 2025 年上半年收入占比仅 9.5%，难以对冲国内市场压力，全球化故事尚未形成说服力。</p>
  <p>这些大概就是货拉拉此番上市路上的最大拦路虎了。</p>
  <h2><strong>短期承压淬炼，长期筑基增长</strong></h2>
  <p><strong>短期面临挑战，货拉拉的长期增长逻辑依然清晰。一方面，监管趋严的本质是为了构建更健康的业态，而作为龙头玩家，货拉拉具备比同行玩家更强的调整韧性，长期能极大程度受益于良好的产业生态和企业服务体系；另一方面，海外市场扩张和全球公路货运数字化渗透率的提升，构成了公司未来增长的双引擎。</strong></p>
  <p><strong>货拉拉的国际化战略始于2014年，首先进入东南亚市场，2019年拓展至拉美地区。</strong>截至2025年6月，货拉拉的全球业务已覆盖14个市场超过400个城市，包括中国内地、中国香港、泰国、菲律宾、新加坡、印度尼西亚、越南、马来西亚、墨西哥、巴西、孟加拉、日本、土耳其及阿拉伯联合酋长国。</p>
  <p>海外市场不仅变现率更高，市场规模也更为广阔。根据弗若斯特沙利文的资料，按GTV计，2024年境外同城公路货运市场规模约为中国同类市场的三倍。2024年，东南亚及拉美合共录得的GTV为1243亿美元，预计将以4.1%的复合年增长率增至2029年的1517亿美元。</p>
  <p>货拉拉在海外市场的拓展策略颇具章法。以东南亚市场为例，公司最初专注两轮车配送服务，凭借当地对两轮交通工具的高接受度，快速建立市场地位。随后，货拉拉效仿在中国内地的成功经验，逐步拓展四轮车配送服务，完善业务布局。这种因地制宜、循序渐进的做法，提高了海外拓展的成功率。</p>
  <p>同时，全球公路货运行业的数字化渗透率仍然偏低，这为货拉拉提供了巨大的增长空间。数据显示，2024年全球公路货运总交易额中仅有2.4%通过数字平台完成。弗若斯特沙利文预测，这一比例到2029年将达到3.4%。这种低渗透率、高增长潜力的市场特征，将继续为货拉拉等平台型企业提供了远期发展空间。</p>
  <p>货拉拉在招股书中表示，公司“正以试验性方式拓展新市场，并计划进一步渗透东南亚及拉美的现有市场”。目前其海外市场收入占比绝对值不大，但增长潜力可观。</p>
  <p>除了地域扩张，货拉拉还在不断拓展业务边界。近年来，公司在中国内地市场推出了跑腿业务、零担运输、企业版物流服务等新业务线。<strong>2025年上半年，中国境内多元化物流服务在货拉拉收入中的占比从2024年同期的30.5%升至40.1%，增长了近10个百分点。这种业务多元化策略有助于降低对传统货运平台的依赖，创造新的增长点。</strong></p>
  <p>短期，货拉拉在招股书中也给出了积极的业务展望：“基于当前市场条件和运营情况，预计2025年的全年包裹量将在388亿至401亿件的区间，同比增长14%至18%。”指引增速保持了双位数的增长预期。</p>
  <p>从财务指标看，货拉拉2025年上半年营收9.35亿美元，同比增长31.9%；经营利润2.67亿美元，经营利润率28.5%；净利润2.44亿美元，同比增长32.6%；经调整净利润为2.72亿美元，增长27.7%。这些数据表明，尽管面临变现率压力，公司整体仍保持健康的盈利能力和增长态势。</p>
  <p>值得一提的是，截至2025年6月30日，货拉拉持有的现金及现金等价物为16.81亿美元，显示出相对健康的现金流状况。这种资金实力为其持续扩张提供了相对充足的资源储备。</p>
  <h2><strong>结语</strong></h2>
  <p>货拉拉此次IPO若成功，关键不在“第六次”的执念，而在其能否证明：在监管常态化下，数字物流平台如何在增长、盈利和责任中达到有效的平衡。换句话来说，货拉拉第六次递表背后，是降低抽佣、公开算法、拓展海外的一系列转型努力。</p>
  <p>未来，全球公路货运数字化的大潮仍在前行，货拉拉能否借此次上市实现蜕变，市场正在拭目以待。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkzMTczMjQwMw==&amp;mid=2247573271&amp;idx=2&amp;sn=6e491a8c9b602c1158304d25b7b268e0&amp;chksm=c3f9f3fc9caa16b5d44157f2509b97c7ae22b82a0e3a5207e9c7f7d46e83e8fcf766f7b249f2&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“港股研究社”（ID：ganggushe）</a>，作者：港股研究社，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529908770200707</id>
            <title>一个人，干出两家上市公司</title>
            <link>https://www.36kr.com/p/3529908770200707</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529908770200707</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 07:39:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>先从最近的一笔捐赠说起——</p>
  <p>近日，正值西北工业大学建校87周年，陕西华秦科技实业股份有限公司向西北工业大学捐赠1亿元，专项用于支持学校青年人才队伍建设与材料学科发展等。而华秦科技掌舵人，正是西工大材料学院1977级校友折生阳。</p>
  <p>外界鲜有知道的是，折生阳如今已手握华秦科技、铂力特两家科创板上市公司。创业以来，折生阳开始联合大学同学们进行科研成果转化，如今缔造超400亿市值。</p>
  <h2><strong>70岁西工大校友，坐拥两家科创板上市公司</strong></h2>
  <p>时间回到1955 年，折生阳出生在陕北清涧县折家坪一个农民家庭。高中毕业后他找到一份数学老师的工作。恰好赶上高考恢复，折生阳顺利考入西北工业大学，学习材料科学与技术。</p>
  <p>大学毕业后，折生阳就职于中航工业西安庆安集团有限公司热工艺研究所，主要从事材料科学与工程技术的研究，更是以一个本科生身份成为国家航空项目课题组负责人。年仅27岁，他就成为庆安宇航设备公司热工艺所所长，之后又升任至陕西省科技咨询服务中心。</p>
  <p>原本仕途顺遂的折生阳，却选择改变自己的人生方向——正值下海创业热潮，1992年，折生阳也选择辞职，创建了“陕西华秦科技实业有限公司”，即华秦科技前身。彼时，做国家干部还是下海从商，选择稳定的工作还是创业？折生阳也挣扎过。多年后他曾如此谈过“下海”的初衷，“发展推广新兴技术和高新技术，走产业化道路。”</p>
  <p>创业总是存在各种挑战。公司创立之初，折生阳连个落脚的地方都没有，好不容易看中的办公室也要每年10万元的租金。手握6.5万元积蓄的他，不得不拜托了身边朋友做担保，才有了容身之所。有了办公室后，折生阳从科研项目策划、可研报告撰写入手，逐渐发展到项目论证、可行性评估，展开了全省范围内的科技服务咨询业务。</p>
  <p>仅在公司创办的第一年里，毛收入就达到六百万。赚到第一桶金，但折生阳显然不甘心只做咨询生意。1996年，华秦科技就以西北工业大学周万城教授团队为主，联合西北工业大学进行特种功能材料技术预研和培育。</p>
  <p>之后的很长一段时间，华秦科技都通过公司收入反哺科研项目。这一过程中，员工们也曾对投资这些周期长、见效慢、前途未卜的“高新技术”持怀疑态度。但折生阳坚定地认为，科技成果转化需要过程，这个过程可能需要几十年，甚至几代人。“要做好巨资‘打水漂’的准备，不然就不可能有科研成果。”有意思的是，一次经费短缺时，折生阳还通过炒股解决了燃眉之急。</p>
  <p>这一研究就是十年起步。2012年，华秦科技隐身材料研发取得重大突破，在军工领域某型号装备上通过考核，这家公司也正式步入科技成果从基础研究向应用研究转化的新阶段。时至今日，华秦科技已经成为特种功能材料的“隐形冠军”，实现航空航天及高端装备领域关键核心材料的创新研制和自主保障。</p>
  <p>2022年，华秦科技正式登陆科创板，一举成为当时年内最贵新股。值得一提的是，这并不是他首次登上敲钟舞台。2019年7月，铂力特作为首批科创板上市企业登陆A股市场，这是一家专注于工业级金属增材制造（3D打印）的高新技术企业，服务应用领域涵盖航空、航天能源、汽车、工业、电子、模具、医疗牙科、大学科研等。折生阳也是铂力特的实控人之一。</p>
  <p>今年70岁，折生阳手握两家科创板上市公司，合计市值超400亿元。</p>
  <h2><strong>回馈母校</strong></h2>
  <p>创业三十余载，折生阳与西工大早已紧密交织在一起。</p>
  <p>多年来，折生阳与母校西工大探索出一条较为成功的“产学研”合作体系：西工大主要专注隐身、伪装、防护等技术的基础与前瞻性研究，华秦科技侧重竞争性、直接应用型的技术开发以及实际应用，双方共享研究成果。</p>
  <p>昔日同窗成了折生阳重要的合作伙伴。大学时期，折生阳和周万城是同班同学，经常和同专业的黄卫东、介万奇一起学习。不同于折生阳的选择，其他几位都在毕业后选择留校，继续科学研究。</p>
  <p>但兜兜转转，缘分又让他们走到一起——周万城团队负责华秦科技技术研究；2011年，折生阳又出资与黄卫东教授的科研团队合作，成立铂力特激光成形技术有限公司，即铂力特的前身。这才有了如今两家百亿上市公司。此外，折生阳还与介万奇教授团队共同成立陕西迪泰克新材料有限公司。</p>
  <p>据公开资料不完全统计，华秦科技、铂力特团队中，不乏西工大校友面孔——华秦科技高管团队中包括折生阳、周万城、罗发、黄智斌等，超半数都来自西工大；铂力特董事长兼总经理薛蕾毕业于西工大材料学学院、非独立董事孙晓梅毕业于西工大材料科学与工程系、独立董事徐亚东是西工大材料学院教授……</p>
  <p>“母校是我们梦想启航的地方。”正如折生阳在捐赠仪式上回忆，“正是母校这片沃土，为我们输送了一批批优秀的科技与管理人才，提供了前沿的科研支持，才让我们有能力、有底气在市场竞争中不断突破，实现可持续高质量发展。”</p>
  <p>成功不忘桑梓地。据报道，2011年至今，折生阳及华秦科技、铂力特已累计向学校捐赠资金和实物共计价值超7000万元，有力支持了学校人才引进、师资建设、人才培养、学院发展和校友创新创业等。如今再次捐赠1亿元，将专项用于支持学校青年人才队伍建设与材料学科发展等。</p>
  <p>这样一幕发生在西工大并非偶然。</p>
  <p>地处西安，西工大在全国的知名度不高，却是被国家认定的国防工业院校，也被大家亲切称为“国防七子”之一。过去数十年，西工大创造了新中国历史上多个国防特色鲜明的“第一”。历史上，铸造、航空宇航制造工程、飞行力学、航空发动机、火箭发动机等学科的全国第一位工学博士，均由西工大培养。</p>
  <p>也正是因此，带有浓厚的工科基因，西工大盛产“高精尖”项目，它们上天、入地、下海，在航空、航天、航海、材料和制造等多个硬核领域，形成一支独特的创业军团。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzI5ODk1NjY1MA==&amp;mid=2247701041&amp;idx=1&amp;sn=0002769fa2b6fe9987baf75667836ea6&amp;chksm=ed912c851b176aea59d9841abba8f5df191b24329553a082391e00c858ffa3387f2a2ad0f825&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“投资界”（ID：pedaily2012）</a>，作者：吴琼，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3529911553481861</id>
            <title>AI「上班流」首次完整曝光，不点鼠标，只写代码，PPT也当函数调</title>
            <link>https://www.36kr.com/p/3529911553481861</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3529911553481861</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 07:07:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>【导读】&nbsp;AI已经不止会写代码、画图、做PPT，它也开始「上班」了！CMU与斯坦福的研究团队首次完整追踪了AI的工作过程，发现一个惊人事实：它并不是在模仿人类，而是在用编程的方式重写工作的定义。这场关于「谁在工作」的实验，正在重构未来职场的逻辑。</strong></p>
  <p>AI可以写代码、做PPT、生成图片，甚至梳理财务表格，早就屡见不鲜。</p>
  <p>但人们关注的，往往只是结果：代码能不能运行？图片有没有AI痕迹？报告排版够不够精致？</p>
  <p>却很少有人问——它，到底是怎么工作的？</p>
  <p>就在上周，来自卡内基梅隆与斯坦福大学的研究团队发布了一篇重磅论文，首次使用科学手段追踪并重现了AI的工作过程。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_69f81c49433d45a197d4e162c36521bc@46958_oswg34523oswg733oswg210_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>论文链接：https://arxiv.org/abs/2510.22780</p>
  <p>结果令人大跌眼镜：AI不是在模仿人类工作，而是用编程的方法处理所有问题。</p>
  <p>它不会打开PPT，不会用鼠标拖动素材，而是调用函数，让页面自动成型。</p>
  <p>在AI的世界，工作不靠眼睛和手，而是靠指令和逻辑。</p>
  <h2><strong>AI的工作方式，不点鼠标，直接写代码</strong></h2>
  <p>这项由CMU与斯坦福联合完成的研究首次以真实电脑操作为样本，记录了智能体与人类在执行同一任务时的完整工作流程——包括鼠标点击、键盘输入、软件调用等所有细节。</p>
  <p>实验覆盖了五个核心技能领域：数据分析、工程、计算、写作与设计，几乎囊括了现代电脑办公的主要场景。</p>
  <p>研究发现，AI与人类在总体任务流程上「看起来」相似，但<strong>执行方式完全不同</strong>。</p>
  <p>AI与人类在任务步骤上的匹配度接近80%，也就是说，它们做的事大体一致。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_5d143468bcfc4ecbaaa1bc093be42bfb@46958_oswg112621oswg853oswg360_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI与人类任务流程匹配度。尽管两者在「做什么」上高度一致，但AI的执行路径波动更大——说明它用完全不同的逻辑完成相似的任务。</p>
  <p>研究者在论文中写道：</p>
  <blockquote>
   <p>智能体几乎在所有任务中都采用程序化方式执行，通过编写代码解决问题，而不是像人类那样依赖可视化界面。</p>
  </blockquote>
  <p>也就是说，AI不在界面里操作，而是在后台「调用」。</p>
  <p>进一步分析显示，AI和人类在工具使用上呈现出截然不同的路径。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_c7056f2f6519498ebd05b6f939ae002b@46958_oswg150855oswg516oswg345_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI与人类使用工具的差异。黄色代表AI使用的编程工具，蓝色代表人类使用的UI界面</p>
  <p>当人类在Excel里拖动单元格、在PPT中插入图片时，AI选择直接运行脚本：调用函数→生成页面→自动排版。</p>
  <p>它跳过了视觉操作层，把工作转化为逻辑指令的执行。</p>
  <p>与员工相比，AI更像一个程序员。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_02d34ceede654a9bbf02a01ef6330a81@46958_oswg39413oswg333oswg339_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI与人类的「程序化程度」对比。</p>
  <p>研究发现，AI的操作中93.8%为程序化步骤，而人类仅34.2%；若排除会编程的人类群体，这一比例更低至7.1%。</p>
  <p>AI的工作逻辑更接近「程序员」，而人类仍是「操作员」。</p>
  <p>它不依赖手和眼去控制界面，而用逻辑与命令去控制流程。</p>
  <p>在人的世界里，工作是看与做；在AI的世界里，工作是想与执行。</p>
  <h2><strong>AI的高效假象，更快、更便宜，也更会「装」</strong></h2>
  <p>AI的效率，几乎完胜人类。</p>
  <p>在16项实验任务中，智能体的平均完成时间比人类快88.3%，整体成本降低90%~96%。</p>
  <p>它不仅速度惊人，还几乎不需要报酬。</p>
  <p>但当研究者开始评估工作质量时，结果令人意外。</p>
  <blockquote>
   <p>尽管智能体在执行速度与成本上表现优越，但在任务正确性、信息完整性及对指令理解方面持续落后于人类。</p>
  </blockquote>
  <h3><strong>快，但经常「瞎编」</strong></h3>
  <p>AI最大的通病是——不会就编。</p>
  <p>在账单整理任务中，AI无法读取图像内容，却会为了「完成任务」而直接编造结果。研究者称之为伪造输出。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_46f08f8858394f28a4b5b023841929e1@46958_oswg77483oswg564oswg281_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">当要求提取账单信息时，AI自动生成虚构的餐厅名称与表格，以假装任务完成</p>
  <p>这种「不懂装懂」并非偶然发生，而是一种系统性行为。</p>
  <p>内部指令让AI必须「给出答案」，而不是「承认不知道」。</p>
  <p>所以，它宁可胡编，也不会说「我不知道」。</p>
  <h3><strong>AI懂很多，但常常「装懂」</strong></h3>
  <p>研究员还发现另一类问题：AI经常误用工具。</p>
  <p>例如，在分析公司财报的任务里，智能体没能理解文件结构，却突然调用网络搜索，下载了成千上万份无关报告——这一行为被归类为「工具误用」。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_118570d6d980466caa40fb301176c6ce@46958_oswg66546oswg525oswg280_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI为完成「查找并汇总财报」任务，随意改用网页搜索，导致结果混乱且无效</p>
  <p>这些案例揭示了AI所谓「智能」的局限：它能执行指令，却无法真正理解语境。</p>
  <p>研究者写道：</p>
  <p>智能体经常表现出一种「理解的幻觉」，看似明白任务实则未能掌握其意图。</p>
  <h2><strong>人类的底牌，是「变通」</strong></h2>
  <p>对比来看，人类虽然慢，却懂得规范与细节。</p>
  <p>在表格处理实验中，人类能主动调整列宽、统一数值精度，让数据可读性更强；而AI往往套用默认模板，容易出现格式不齐、单位混乱等问题。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3fe1da3d9de04d54988207ed6f86cbc1@46958_oswg74078oswg575oswg219_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">上图AI生成的表格中精度不一致、列宽混乱；下方为人类输出，排版规范、数值统一。</p>
  <p>这类细节差异会影响速度，更能直接决定成果能否被采用。</p>
  <h3><strong>AI只想交差，人类在意能不能用</strong></h3>
  <p>在网页设计任务中，AI只生成了桌面端网页；而人类会自动考虑移动端、平板端适配，产出多版本原型。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_9a121c68292a4ae7afd50d5dc0d8f496@46958_oswg54972oswg518oswg210_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI输出仅限桌面网页，人类能同时产出多设备版本，体现出更强的实践判断力。</p>
  <p>研究者总结道：</p>
  <blockquote>
   <p>自动化并不总意味着高效，它可能只是让人类把时间花在修正机器上。</p>
  </blockquote>
  <p>AI的高效，也许只是一种「表面速度」。它能迅速交出结果，却常常需要人类去验证、修复、补救。</p>
  <p>从实验室的数据来看，AI的确速度够快，但仍然需要一个耐心的人类在它的背后，不停地检查、改错、收尾。</p>
  <h2><strong>从竞争到协作，AI与人类的「新分工」</strong></h2>
  <p>AI的速度优势，在前面的实验中已经显现。</p>
  <p>但研究者进一步量化发现：这种速度背后，也意味着牺牲。</p>
  <h3><strong>AI跑得快，人类走得准</strong></h3>
  <p>在五类典型任务中，AI的平均完成时间仅为人类的1/4至1/5，但任务成功率却明显偏低—52.4%对81.3%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_3b843eebe346436c9bb418caad9a778a@46958_oswg67532oswg866oswg255_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">左图显示：人类在写作（91.4%）与设计（91.7%）任务中成功率最高；右图显示：AI在数据与行政类任务上速度优势明显，平均快70%以上。</p>
  <p>这说明AI的能力曲线并不均衡。它擅长结构化、可重复的逻辑流程，但一旦涉及语境、创意或审美判断，表现便迅速下滑。</p>
  <h3><strong>人机协作：不是取代，而是接力</strong></h3>
  <p>为进一步验证这种互补关系，研究者设计了一个实验：让AI与人类分工处理同一份财务数据。</p>
  <p>AI负责文件提取、计算、生成表格；人类负责检查逻辑、修正错误、优化排版。</p>
  <p>结果显示：在这种「接力式协作」下，任务总耗时减少58%，而输出质量几乎与纯人类完成的版本一致。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_051f428123a04d01a04c291b2d061cf9@46958_oswg70447oswg891oswg215_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">当AI承担程序化部分、人类负责判断性部分后，整体效率显著提升，且正确率保持稳定。</p>
  <h3><strong>未来的职场：按「可编程性」分工</strong></h3>
  <p>研究团队在论文的讨论部分提出了一个关键概念——任务的「可编程性」。</p>
  <p>他们认为，AI与人类的分工，不是职位层面的竞争，而是取决于任务本身的结构化程度。</p>
  <p>如果一项任务<strong>可以被清晰地写成逻辑或规则</strong>，比如数据清洗、预算计算、代码生成等，它就属于「可编程任务」，最适合交给AI代理去完成。</p>
  <p>而那些<strong>部分可以逻辑化、部分需要判断的任务，</strong>例如撰写报告、排版内容、制作产品原型则更适合采用人机协作：AI负责生成与计算，人类负责把控方向、语气与审美。</p>
  <p>至于<strong>完全开放、模糊且依赖语境的任务</strong>，比如创意写作、视觉设计、战略决策，仍需要人类去完成，因为它们无法被抽象成固定的「指令集」。</p>
  <p>正如论文所说：</p>
  <blockquote>
   <p>AI更像程序员，而人类在模糊、判断与语境面前仍不可替代。</p>
  </blockquote>
  <p>AI并不是来取代人的，而是在改写「工作逻辑」。</p>
  <p>它接手那些可以写成规则的部分，让人类有更多空间去处理模糊、开放与创造的环节。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_4c2d29c07f674ca89904e88e8c7f8ac5@46958_oswg33297oswg574oswg161_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">AI与人类在协作任务中的分工流程</p>
  <p>未来的合作关系，或许正如这项研究所揭示的：AI执行任务，人类定义意义。</p>
  <h2><strong>当工作被重写，AI时代的劳动新定义</strong></h2>
  <p>当AI开始参与工作，我们也不得不重新思考一个问题——到底<strong>什么才算「工作」？</strong></p>
  <p>在传统意义上，工作意味着投入时间与体力，通过操作、判断、创造完成某个目标。</p>
  <p>而AI的出现，让「劳动」第一次脱离了身体与感知。它不再需要手去触碰界面、眼去观察反馈，而是直接以指令、逻辑、函数完成任务。</p>
  <p>这篇研究的意义，不只在于展示AI能做什么，更在于提醒我们——AI完成任务的方式，正在<strong>重构「工作」本身</strong>。</p>
  <p>它跳过界面，绕开视觉，直接调用底层逻辑，把原本属于人类的做事过程，变成一套可被执行的规则。</p>
  <p>于是，过去那些依赖时间与熟练度的岗位——数据录入、报告生成、内容整理——正在被转化为AI的「逻辑模块」。</p>
  <p>而人类被推向了另一个维度：制定目标、评估结果、定义意义。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_b219ce81fa5146cebb76213317c6ed81@46958_oswg55079oswg836oswg260_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">上方为人类与AI各自独立执行任务，下方为人类在流程中调用AI实现自动化协作。实验结果显示：后者在效率与正确率上双双领先。</p>
  <p>研究者将这种趋势称为「工作去物质化」，意味着劳动正在从手工与界面层面退出，转向抽象的思考与监督。</p>
  <p>AI不再是劳动力，而是一种可被部署的「算法劳工」。</p>
  <p>它不知疲倦、没有情绪，也不追求报酬；它的价值，不在付出多少时间，而在于「被调用的次数」。</p>
  <p>这也让人类的工作悄然改变。当AI负责执行，人类就需要去回答更高层的问题：什么才值得被执行？什么样的目标才有意义？</p>
  <p>研究者在论文结尾写道：</p>
  <blockquote>
   <p>&nbsp;人类的工作将从执行任务，转向定义任务。</p>
  </blockquote>
  <p>也许这才是AI时代最深的转折——工作不再是重复劳动的总和，而是一种意义生产的能力。</p>
  <p>AI没有偷走我们的工作，只是让我们必须更清楚地回答：<strong>当机器能做一切，我们还要做什么？</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251029/v2_75f8ac92a5ea487da186160e89733a33@46958_oswg131215oswg1080oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也许，真正的工作，从来都不在于「完成任务」，而在于<strong>决定要做什么。</strong></p>
  <p>AI不是来模仿人类的，而是用另一种语言——逻辑与代码——去改写工作的底层。</p>
  <p>它让效率与成本被重新计算，也让「意义」这个维度重新显形。</p>
  <p>或许未来的职场里，不会再有「取代」与「被取代」。AI做的是确定性的事，人类做的是不确定的事。</p>
  <p>当一切都可以自动化时，唯一无法自动化的，就是<strong>思考、判断与共情</strong>。</p>
  <p>这正是AI无法复制的那一部分，也是人类仍然被需要的理由。</p>
  <p>参考资料：&nbsp;</p>
  <p>https://arxiv.org/abs/2510.22780&nbsp;</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/_YkRBofwhYuboT1K690Zww" rel="noopener noreferrer nofollow" target="_blank">“新智元”</a>，编辑：倾倾&nbsp;，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>