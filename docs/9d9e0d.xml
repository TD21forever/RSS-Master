<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 14:15:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    在此推出 FlowithOS，全球首个为 Agent 原生打造的操作系统，可能是你的最后一个浏览器。<br /><br />FlowithOS 让 AI 可以 100% 像人一样与整个数字世界交互。<br /><br />- browser-use 浏览器使用: 让它可以自主点击网页、上传/下载文件、甚至可以操纵第一视角游戏，与其它玩家对战。<br />- terminal-use 终端使用: 让它可以通过命令行、访问和操作你的整个计算机，帮你整理文件、或者直接批量创造。<br />- script-use 脚本使用: 让它可以自主根据你的需求和网页状态、实时生成脚本，以 100 倍效率批量获取信息。<br /><br />除了这些超能力外，FlowithOS Agent 还搭配了 online-RL 和自我进化和学习的能力，配合经验和记忆系统，你的 OS Agent 可以随着时间变得越来越聪明、越来越懂你。<br /><br />在 Online-Mind2Web 全球评测中，FlowithOS 以压倒性接近满分成绩超过 OpenAI Atlas、Gemini 2.5 Pro CU 等顶尖浏览器 Agent，成为现地表最强浏览器智能体。<br /><br />现在，FlowithOS 公测版已全量上线，支持 Windows、Mac 所有平台，在 flowith.com 即可开始
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 13:55:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    无意间发现 GPT 画这种信息图的还原度挺高啊<br /><br />搞成 SVG 以后还能扔进 Figma 里面改字体，改完就更像了<br /><br />让 GPT 总结了一套提示词👇<br /><br />用途：我发一张信息图或海报截图，你把它高保真还原为可编辑 SVG，整体排版尽量一致，但文字改成 {中文}（或保持原语言）。<br /> 提示词：<br />指令<br />请把我发送的图片转成可编辑 SVG：<br /><br />保持版式与层级结构（标题、分区、图标、箭头、图表等）尽量一致；<br />所有文字保留为  可编辑（不要转路径）；<br /><br />所有图形用向量元素（////），不要嵌入位图；<br /><br />颜色与风格尽量接近原图；<br /><br />分组与命名清晰：01_Header、02_Section_*、Icon_*、Chart_*；<br /><br />画布尺寸按原图推断；坐标/描边尽量用整数；<br /><br />生成文件到 /mnt/data/infographic.svg 并给出下载链接。<br />若图片中有不清晰的内容，请做合理假设并在结果底部列出“假设项”。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69003452e74e87a1be58b1f8</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/69003452e74e87a1be58b1f8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69003452e74e87a1be58b1f8</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 03:11:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Manus联创的“血泪”教训：为什么上下文工程，而非模型微调，才是护城河？<br /><br />一位拥有10年NLP（自然语言处理）经验的AI创业公司联创坦言：“对于创业公司，过早微调（Fine-tuning）模型是一个陷阱。”<br /><br />这不是危言耸听。<br /><br />Manus的联合创始人兼首席科学家Peak，在最近与LangChain创始人的对谈中，分享了他的“血泪教训”：他的上一个产品，迭代速度被长达1-2周的模型训练周期活活拖死。<br /><br />这一次，他选择把所有赌注压在“上下文工程”（Context Engineering）上，并为此，他的团队在短短几个月内，将产品重构了整整5次。<br /><br />为什么他如此笃定？<br /><br />1. “微调”的陷阱：被模型拖垮的“上一个”公司<br /><br />在创立Manus之前，Peak已经在NLP领域摸爬滚打了10年。他的上一个创业项目，和现在许多AI团队一样，选择了“训练自有模型”的重度路线。<br /><br />结果是灾难性的。<br /><br />“我们的产品创新速度，完全被模型的迭代速度给限制了。”Peak回忆道。<br /><br />在产品还没找到PMF（市场契合点）的阶段，他们却在花费大量时间“提升那些可能根本不重要的基准测试”。一个单一的“训练-评估”周期，就需要1到2周。<br /><br />当团队在焦急地等待模型时，市场窗口早已关闭。<br /><br />但最大的“陷阱”还不是时间，而是“僵化”。<br /><br />“当你微调一个模型时，”Peak解释道，“你通常会固定一个‘行动空间’（Action Space）。”<br /><br />这就像你花重金打造了一把精妙绝伦的“屠龙宝刀”。但如果第二天，巨头发布了（比如多模态MCP），市场不再需要“屠龙”，而是需要“飞天”，你这把刀就成了一堆废铁。<br /><br />“Manus的设计就曾被MCP的发布彻底改变。”Peak坦言，如果他们当时死磕微调，唯一的下场就是被市场活活抛弃。<br /><br />2. 划清界限：AI应用层的真正边界<br /><br />经历了上一次的“痛苦”领悟，Peak这次为Manus找到了一个清晰无比的战略边界。<br /><br />“你必须坚定地划清你的界限（Be firm about where you draw the line）。”<br /><br />对于AI应用层创业，这条界限就是“上下文工程”。<br /><br />Peak认为，这是目前应用和模型之间最清晰、最实用的边界。创业公司应该“尽可能久地”依赖通用大模型，而不是试图在模型层与巨头竞争。<br /><br />巨头的护城河是“模型”，而应用层的护城河，就是你“使用”模型的能力——即“上下文工程”。<br /><br />那么，这个听起来高深的“上下文工程”到底是什么？<br /><br />3. “上下文悖论”：Agent的阿喀琉斯之踵<br /><br />2022年，我们谈论的是“提示词工程”（Prompt Engineering），它解决的是单次交互。<br />而2024年，我们面临的是“上下文工程”（Context Engineering），它要解决的是Agent（智能体）的长序列、多轮工具调用。<br /><br />LangChain的创始人Lance指出了一个“上下文悖论”：<br /><br />Agent要完成复杂任务，必须大量调用工具（典型任务约50次）来获取上下文。<br /><br />但上下文越长，Agent的性能就越差，成本也呈指数级上升。<br /><br />更糟糕的是，Peak发现，即使是100万Token的上下文窗口，模型在处理到200K（约20万）时，性能就开始“腐烂”（Context Rot），出现重复、缓慢和质量下降。<br /><br />“上下文腐烂”的阈值，大约就在128K到200K之间。<br /><br />你的Agent又慢又笨，不是模型不行，是你的“上下文工程”没做好。<br /><br />4. 破局：上下文工程的4大支柱<br /><br />如何解决这个悖论？LangChain的Lance总结了业内顶尖团队（包括Manus）都在使用的4大工程支柱：<br /><br />上下文卸载 (Offloading)<br /><br />做法：不把所有信息都塞进上下文。比如，一个万字的网络搜索结果，只在上下文中返回一个文件路径（file.txt），Agent需要时自己去读。<br /><br />场景：处理大文件、大输出。<br /><br />上下文检索 (Retrieving)<br /><br />做法：把信息（如记忆）存储在外部（如向量数据库），在需要时通过RAG或简单的grep命令检索回来。<br /><br />场景：长时记忆、知识库。<br /><br />上下文隔离 (Isolation)<br /><br />做法：使用多智能体（Multi-Agent）架构，每个子Agent只处理自己的小上下文窗口，互不干扰。<br /><br />场景：复杂任务拆解。<br /><br />上下文缩减 (Reducing)<br /><br />做法：这是最核心也最精妙的一步，即在上下文“腐烂”之前，主动对其进行“瘦身”。<br /><br />而Manus团队，正是在“上下文缩减”上，做到了极致。<br /><br />5. Manus实战：“压缩”与“摘要”的精妙艺术<br /><br />Peak的团队将“缩减”分为了两种截然不同的操作：<br /><br />1. 压缩 (Compaction)：可逆的“瘦身”<br /><br />定义：删除那些可以从外部（如文件系统）重建的信息。<br /><br />例子：一个工具调用，完整信息是{path: "file.txt", content: "..."}。在“压缩”后，只保留{path: "file.txt"}。<br /><br />优势：信息“零”丢失，只是被“外置”了。<br /><br />2. 摘要 (Summarization)：不可逆的“遗忘”<br /><br />定义：对历史信息进行总结，彻底丢弃原文。<br /><br />优势：大幅度释放上下文空间。<br /><br />Manus的策略堪称精妙：<br /><br />设置“腐烂”闹钟：首先，团队会设置一个“腐烂阈值”，比如128K。<br /><br />先“压缩”，后“摘要”：当上下文达到128K时，系统首先触发“压缩”。只在“压缩”的收益也变小时，才万不得已触发“摘要”。<br /><br />“压缩”的艺术：执行“压缩”时，只压缩最老的50%历史，并保留最新的50%工具调用的完整信息。这能确保模型有足够的新鲜“样例”来模仿，防止其行为错乱。<br /><br />“摘要”的技巧：执行“摘要”时，会使用原始的、未经压缩的数据来总结，以保证信息保真度。并且，同样会保留最后几个工具调用的全量信息，防止模型“忘记自己刚刚在干什么”。<br /><br />6. 在流沙上构建：5次重构与“更贵”的开源<br /><br />这套复杂的“上下文工程”架构，就是Manus的护城河。它让Manus有能力在“流沙”（不断迭代的大模型）之上构建稳固的应用。<br /><br />“从3月到现在，我们已经重构了5次。”Peak说。<br /><br />这种“上下文工程”能力，也让他们在选择模型时有了更反直觉的洞察。<br /><br />Peak甚至认为，对于Agent应用，使用开源模型可能“更贵”。<br /><br />“这很有趣，关键在于成本。”他解释道，“Agent的输入（上下文）远大于输出，KV缓存至关重要。”而头部API厂商（如Anthropic）在分布式KV缓存上做了坚实的基建，使得在超长上下文中，API的成本甚至低于自托管的开源模型。<br /><br />7. 结语：构建更少，理解更多<br /><br />回顾Manus的历程，Peak给出了他最深刻的领悟：<br /><br />“我们最大的飞跃，不是来自添加了更花哨的上下文管理技巧，而是来自‘简化’和‘移除不必要的层’。”<br /><br />“我们最终的哲学是：构建更少，理解更多（Build less and understand more）。”<br /><br />这位10年NLP老兵最后总结道：<br /><br />“上下文工程的真正目标，不是让你的系统更复杂，而是让模型的工作，变得更简单。”<br /><br />from Langchain<br /><br />Context Engineering for AI Agents with LangChain and Manus
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68fde79e68d631f49d26ad30</id>
            <title>AI探索站 10月26日</title>
            <link>https://m.okjike.com/originalPosts/68fde79e68d631f49d26ad30</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68fde79e68d631f49d26ad30</guid>
            <pubDate></pubDate>
            <updated>Sun, 26 Oct 2025 09:19:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原来 Google 也有诚实签。🤣<br /><br />众所周知，灰度不到 Gemini in Chrome 是因为你 Google 账户的司法区在美国以外。<br /><br />而这个区域是不能自己设置的，是 Google 根据你过去一年的行为自动识别的，我之前一直被识别为“新加坡”。<br /><br />Google 提供了一个申请表允许你自己提交修改申请，但是否通过他们说了算。<br /><br />我之前以“我经常旅行”和“我经常使用 VPN”来试着改到美国，都失败了。<br /><br />昨天又申请了一次，勾选的其他原因， 然后直接写：<br /><br />My work requires me to use Gemini in Chrome. Therefore I would like to relocate my account to the United States.<br /><br />然后过了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68fc90641ed9b53c7834e4c3</id>
            <title>AI探索站 10月25日</title>
            <link>https://m.okjike.com/originalPosts/68fc90641ed9b53c7834e4c3</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68fc90641ed9b53c7834e4c3</guid>
            <pubDate></pubDate>
            <updated>Sat, 25 Oct 2025 08:55:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI 视频换脸，真的太离谱了😵‍💫
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68fad41012ce30c3dd448049</id>
            <title>AI探索站 10月24日</title>
            <link>https://m.okjike.com/originalPosts/68fad41012ce30c3dd448049</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68fad41012ce30c3dd448049</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Oct 2025 01:19:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    握草，巨牛逼，有个UP主叫AI研究室-帆哥，他给视障人士制作了一款AI眼镜，硬件成本只要一百多块钱，就能让盲人/视障人群自由出行。<br /><br />这个小哥戴上自家产品，模拟了盲人出行的一天，在盲道上走路，听AI提醒+纠错避开障碍物，过满是车流的红绿灯。到超市买水果，通过摄像头与耳机的指引拿到西瓜、黄瓜。让AI眼镜识别上海外滩的夜景，为他讲述眼前到底是怎样的造型与风韵，犹如聆听一首散文诗。<br /><br />一个3D打印眼镜架+摄像头+图传+扬声器+麦克风+陀螺仪+多模态大模型Qwen Omni=AI眼镜。<br /><br />核心硬件成本只要143.28块钱。 <br />这是我从未想到过的低价…<br /><br />市面上一些雷达避障的AI眼镜要3000块钱…<br />这省下的就不是一块两块了。<br /><br />关键帆哥把它的配件清单+agent代码开源了，放在了魔搭社区，任何厂家和个人都能用这套纯视觉避障方案做眼镜。<br />这是一种AI时代的伟大。<br /><br />我觉得啊，咱们中国的盲道之所以常常被占用，是盲人并没有真正的进入我们的生活，当帆哥蒙住双眼做道路测试时，很多路人主动提供了帮助，提醒他避障，为他挪动盲道上的车等等，体现出了人性上的伟大。<br /><br />#AI能帮视障群体做什么# 很多人在评论区建言献策，认为盲人不需要拍照录像功能，也不需要镜片，设计思维可以超出常理，像汽车设计方案那样弄更多的摄像头，用更好一点的图传，与高德等地图APP深度合作，让视障人群能够安全的抵达心目中的彼岸。<br /><br />原来盲人喜欢听的有声书是可以由自己谱写的。<br /><br />可能有一天，中国的盲人能去云南闻花香，去高山林莽听虫鸣鸟叫，去广袤的海岸线品尝各个海域海水的咸淡。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f8461a67913e3e94375a80</id>
            <title>AI探索站 10月22日</title>
            <link>https://m.okjike.com/originalPosts/68f8461a67913e3e94375a80</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f8461a67913e3e94375a80</guid>
            <pubDate></pubDate>
            <updated>Wed, 22 Oct 2025 02:48:58 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这绝对是我见过最清晰、最实用的 AI 工具列表了，用好他们能省下大把时间！<br /><br />日常助手<br />1. Perplexity：AI 搜索引擎和研究助手<br />2. Claude：通用聊天机器人，超适合做项目和分享成果<br />3. ChatGPT：记得开启高级语音模式，直接和 AI 对话<br /><br />效率工具<br />1. Granola：AI 会议笔记工具，自动生成摘要<br />2. Wispr Flow：语音转文字工具，在任何应用里把说的话变成文本<br />3. Gamma：用 AI 快速制作演示稿、文档和网站<br />4. Adobe：和 PDF 对话，还能自动总结内容<br />5. Cubby：协作研究专用的 AI 工作空间<br />6. Cora：AI 邮件助手，帮你智能整理收件箱<br />7. Lindy：搭建 AI 智能体，自动处理工作流程<br /><br />粉丝增长<br />1. Delphi：创建 AI 克隆分身（文字、语音、视频），和粉丝互动<br />2. HeyGen：用 AI 虚拟形象批量制作内容或给视频配音翻译<br />3. Argil：专为社交媒体视频打造的 AI 虚拟形象<br />4. Overlap、Opus：把长视频自动剪成爆款短视频<br />5. Persona：为创作者打造的 AI 智能体搭建工具<br />6. Captions：AI 视频剪辑，自动加字幕还能修正眼神接触<br /><br />产品开发<br />1. Cursor：懂你代码的 AI 编程编辑器<br />2. Replit：用自然语言描述，AI 智能体直接帮你建应用和网站<br />3. Anychat：一站式调用各种 AI 模型<br />4. Codeium：AI 驱动的代码自动补全工具<br /><br />创意设计<br />1. ElevenLabs：逼真的 AI 语音生成<br />2. Suno、Udio：用文字描述直接生成音乐<br />3. Midjourney、Ideogram、Playground：AI 图片生成<br />4. Runway、Kling、Viggle：AI 视频生成<br />5. Krea：创意画布，实时生成和增强图片/视频<br />6. Photoroom：AI 图片编辑器，产品图修图神器<br /><br />学习成长<br />1. Rosebud：交互式日记，用 AI 帮你分析内心想法<br />2. Good Inside：育儿助手，提供个性化支持<br />3. Ada Health：AI 驱动的症状健康评估<br />4. Ash：个性化 AI 心理咨询和教练<br />5. NotebookLM：把任意文档变成 AI 播客<br />6. Particle：AI 新闻应用，多篇文章整合成一篇摘要<br /><br />娱乐玩耍<br />1. Remix：AI 图片/视频创作与分享的社交应用<br />2. Meta Imagine：在 Meta 系应用里生成自己和朋友的 AI 形象<br />3. Grok：xAI 出品的聊天机器人<br />4. Curio：给孩子的 AI 互动对话玩具
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</id>
            <title>AI探索站 10月21日</title>
            <link>https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Oct 2025 00:30:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek的论文每篇都是精品，R1养活了一批研究强化学习的人，OCR这篇意味CV研究员的春天到来了。用图片替代文本输入，确实是很有开创性的想法。DeepSeek真是开源菩萨，换做CloseAI估计要藏一辈子。<br /><br />大模型在处理长文章时，消耗的计算量会爆炸性增长。<br /><br />但如果把文字“画成图片”，模型只需要很少的“视觉 token”就能理解同样内容。<br /><br />就像人看书一样，我们也是靠视觉来阅读文字，如果这个方向靠谱，那么我们就相当于用OCR技术给大模型装上了眼睛。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</id>
            <title>AI探索站 10月18日</title>
            <link>https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Oct 2025 10:00:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天读到了一个非常有趣的 idea。<br /><br />背景是 Dwarkesh Patel 和 Andrej Karpathy 的一个对谈，里面提到了一个智能领域的常见问题：不管是人还是 AI，如果局限于自己的经验，用经验指导自己的行为， 又在这个行为的基础上累计经验，如此循环下去，最终总会崩溃（这里的「崩溃」不是心理意义上的，是智能层面上的）。一个健康的心智需要不断通过从不在自己经验范围内的世界（比如同他人的交谈，和与自己行为模式不符的人合作，etc.）获得外部熵来阻止这种崩溃。小孩还没有对生活过拟合，所以不太容易崩溃，而成年人崩溃的风险则越来越大。<br /><br />以上是背景。下面是那个有趣的 idea，来自2021年的一篇 paper "The overfitted brain: Dreams evolved to assist generalization"。它的主旨是说：人类做梦是防止这种过度拟合和崩溃的一种方式。做梦之所以具有进化适应性，是因为它会让你置身于与你日常现实截然不同的奇特情境中，从而防止这种过度拟合。<br /><br />这里有个鸡生蛋蛋生鸡的问题：既然过拟合体现为大脑无法学到分布外的规律，大脑是如何构建出这些分布外的梦境的？Hoel 的解释是梦的构建有一个非智能的 noise injection 步骤，这些随机噪声在白天建立的神经连接中渗透，产生奇异的、扭曲的、不连贯的 corrupted sensory inputs，从而把大脑从过拟合的陷阱中拯救出来。<br /><br />虽然这只是一个假说（而且是一个非常新的理论），但我越想越觉得它非常精妙。按照这种视角，梦的价值不在于它的逼真，而恰恰在于它的不逼真——梦境与清醒时的经历（训练集）如此不同（但又不是纯粹意义上的噪声），所以才能迫使大脑学习到更具泛化性的表征而不是仅仅记忆真实经历本身。<br /><br />梦通过不可能存在的反事实体验迫使我们更好地理解世界的本质。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f10c1863dc501909135f14</id>
            <title>AI探索站 10月16日</title>
            <link>https://m.okjike.com/originalPosts/68f10c1863dc501909135f14</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f10c1863dc501909135f14</guid>
            <pubDate></pubDate>
            <updated>Thu, 16 Oct 2025 15:15:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Manus 1.5 来啦。全面升级的原生 AI web app 构建能力，让每个人都能用 AI 来实现自己的想法，打造自己人生中第一个 AI 应用。这个版本对我们来说也格外重要，除了在速度、性能上的全面提升外。它也再次证明了 Manus 核心架构的通用性，我们并没有刻意去做一个 AI website builder，而是持续进化 Manus 的核心框架，并为其提供合适的工具，最终在短短一个月的时间里就进化出了 sota 级别的 AI web app 构建能力。<br />与此同时，这个能力并不是单独存在的，它与 Manus 全套功能都是打通的，你可以创建一个自己的服务介绍网站，用户留资后你的 Manus 客户端会收到通知，你的邮件也会收到推送从而可以触发 Mail Manus 功能完成后续的任务（比如给每个留资客户准备一个个性化的幻灯片？）<br />这项增强功能今天面向所有 Manus 用户推出。支撑这项能力的基础设施是我们正在构建的更宏大愿景的一部分——一个任何人都能利用云计算和 AI 的全部力量的平台，只需通过对话。<br />敬请期待。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>