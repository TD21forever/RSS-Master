<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685524fd6e5ebb9142135d4e</id>
            <title>AI探索站 06月20日</title>
            <link>https://m.okjike.com/originalPosts/685524fd6e5ebb9142135d4e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685524fd6e5ebb9142135d4e</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Jun 2025 09:08:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    前几天我就说成熟的视频生成 Agent 应该马上就会出现<br /><br />没想到是 MiniMax 先做，推出 Hailuo Video Agent<br /><br />第一阶段是提供专业视频创意Agent模版，用户上传图片打几个字就能生完整高质量视频，然后是编辑和完全自动化<br /><br />上午试用了一下，门槛真的超级低，质量非常高<br /><br />下面是详细的介绍和案例👇<br /><br />他们将会分阶段打造 Hailuo Video Agent。<br /><br />第一个阶段是提供专业视频创意Agent模版，用户上传图片或者打几个字就能一键生成高质量视频<br />第二个阶段将会实现让用户在任意的进度自由的打断和编辑<br />第三个阶段就是端到端的完全自动化 Agent<br /><br />试用了一下发现，打磨的非常好，选择你喜欢的模板，点“做同款”就行，门槛超级低。<br />模板覆盖了你能想到的所有AI 视频出圈玩法，不管是外国山海经还是人像动态写真还是产品广告视频，你能想到的品类这里都能找到。<br /><br />你现在在社交媒体刷到的最多的应该是 AI 写真类的内容。<br /><br />Hailuo 直接把这个玩法变成了视频，而且 ID 保持非常好，跟原图也有很顺滑的过渡。<br />我上传的图片会有个水漫上来的效果，然后变成在水下的礼服，之后会更换多套不同的礼服，面部相似度依然可以保持。<br /><br />有了人物的动态写真怎么能没有宠物呢。<br /><br />只需要上传你宠物的照片就行，不需要任何提示词。我整了一个狗狗麦当劳送货的视频，非常可爱，得益于 Hailuo 视频模型的强大示例，基本稳定生成。<br /><br />然后再来个电商场景把。<br /><br />你只需要上传你的产品照片， Hailuo Video Agent 就可以直接一键搞定，只需要简单描述一下产品的样子就行。<br /><br />短视频平台火爆的 AI 视频另一个品类就行科普类视频。<br /><br />我这里就让 Hailuo 做了一个抹茶的历史科普视频，这个科普视频有 80 秒，结果他除了音乐动画以外还有口播，选的声音也非常合适，终于摆脱短视频平台的劣质 AI 配音了。<br /><br />最近流行的还有像素风格的视频，咱也可以一键生成了，只需要上传一张情侣照片，然后给 Agent 描述一下你们日常的几个场景就行，不需要详细只需要词语。<br /><br />最后来个小牛马自嘲吧，这个 Workflow 非常复杂，涉及到了两个不同语音风格的对话，还有视频上的图片文字包装，其中还有字幕的变化。<br /><br />从这么多模板来看 Hailuo 肯定是有一个 Agent 编辑工具的，不然不可能积累这么多，希望他们早日能把这个编辑工具的界面放出来，我都不敢想到时候能有多少流行玩法从这里出现。<br />我昨天看了 Karpathy 的分享之后发了个朋友圈，不可编辑和暂停修改的 Agent 不可进化，从 Minimax 发布的三个阶段来看他们是真的懂，希望尽快看到第二个阶段的 Hailuo Video Agent。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6854e3cff4324211644808b0</id>
            <title>AI探索站 06月20日</title>
            <link>https://m.okjike.com/originalPosts/6854e3cff4324211644808b0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6854e3cff4324211644808b0</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Jun 2025 04:30:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Gemini 现在支持上传视频分析了<br /><br />终于不用一直用 AI studio 了，这估计也是第一家直接能分析长视频的 AI<br /><br />可以参考我前几天交的这个提示词和方法分析爆款视频提取创作逻辑
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6854c2a6f0d718ce7aecf7ab</id>
            <title>AI探索站 06月20日</title>
            <link>https://m.okjike.com/originalPosts/6854c2a6f0d718ce7aecf7ab</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6854c2a6f0d718ce7aecf7ab</guid>
            <pubDate></pubDate>
            <updated>Fri, 20 Jun 2025 02:08:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Dia 要有类似 Arc 的侧边栏了，你要真这样改，那我就真换默认浏览器了啊
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68540a04058533d925c154f7</id>
            <title>AI探索站 06月19日</title>
            <link>https://m.okjike.com/originalPosts/68540a04058533d925c154f7</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68540a04058533d925c154f7</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Jun 2025 13:00:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    豆包新上线了AI播客，瑞士军刀功能再+1，目前支持PDF和网页链接的上传，总体来说，通过大模型的智能识别，豆包现在可以把任何内容转化成一条高度口语化的双人对话播客，属于趣味性和实用价值都很高的一次尝试。<br /><br />熟悉大模型播客产品的人都知道，豆包这次对标的是谷歌NotebookLM——或者说是它最出圈的Audio Overviews功能——后者通过识别用户上传的文本、网页、视频，就可以转化成一条口语化且带有情绪表达的AI播客，深得用户喜爱。<br /><br />Audio Overviews大约是在上个月开始支持中文的，但在中文播客市场砸出来的水花并没有想象中的大，一方面是众所周知的产品迁移成本，另一方面，中文播客市场体系化进度实在迟缓，用户习惯是高度分散的，这就导致了播客本身的适配场景很多，深究起来的播客用户以及潜在播客用户也不少，但商业化空间始终有限。<br /><br />说回正题，我第一时间试了下豆包的AI播客，并分别投喂了两个不同的网站，一个是我写的刘强东前两天内部讲话的文章「刘强东的机巧」，另一个是B站UP主对Prompt, Agent, MCP等AI技术的科普文。<br /><br />先说结论，在真正听完豆包生成的这两条AI播客之前，我对这项功能的完整程度预期并不高，原因在于，在这种复杂的任务上，目前很多主流大模型的做法还是「边吞边吐」，由此就会破坏内容输出的结构性。<br /><br />但豆包已经可以做到在10分钟左右的播客篇幅里基于框架生成内容了，在「刘强东的机巧」生成AI播客的任务里，所有对话的前后呼应都很强，能听得出它是按照同一条逻辑线不断往下捋的，有点意外。<br /><br />另外就是，豆包AI播客的拟人程度已经可以做到以假乱真了，这真的不是夸张，对话的流畅度、松弛感以及合时宜的抑扬顿挫，像我这种文字工作者，文章简单拿来改一改就能直接原地起个播客账号的程度。<br /><br />那条硬核技术帖转播客的任务表现也相当亮眼，首次提及专业名词的时候，会贴心附上一段对这个概念的解释。整体的输出脉络，也都是建立在「我要深入浅出讲明白这条科普」这个最终目的上。<br /><br />说人话，就是AI播客让内容的「可听性」变强了，哪怕注意力没有完全集中在耳朵上，这种通俗易懂的内容也变得更容易被消化。<br /><br />播客——以及整个音频产业——一直以来的优势，是它不会完全参与到竞争用户注意力的零和博弈里去，大部分情况下，刷视频、聊微信、逛淘宝都是非此即彼的单一选项，但播客只占用一个耳朵，由此它能与很多不同的场景做适配。<br /><br />豆包不是第一个推出这种功能的大模型，但它在应用场景上的成熟度是完全可以进到第一梯队的，不仅能把拗口的文字进行口语化改造再丝滑地表达出来，同时所有内容输出也都是基于原稿，不存在自己加戏的幻觉问题。<br /><br />当然，作为新上线的功能，豆包AI播客还会经历一个漫长的迭代过程，比如目前它做不到像NotebookLM一样吃下视频内容，对话的声音、关键信息的提炼浓度，以及生成后的整体风格也都不是客制化的可选项，离用户可以随心所欲地深度使用它，尚且还有一段路要走。<br /><br />但这并不妨碍我们从这个简单的小功能身上窥见AI在未来的使用场景，一切都是假以时日的问题。<br /><br />虽然知道AI的技术一日千里，但每次实际体验的时候，那种奇妙感还是会忍不住涌上来。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68526147b4800e190d59ec51</id>
            <title>AI探索站 06月18日</title>
            <link>https://m.okjike.com/originalPosts/68526147b4800e190d59ec51</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68526147b4800e190d59ec51</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Jun 2025 06:48:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    学习@哥飞 的小树林理论：种下一颗树苗，成长速度可能会很快！<br /><br />去年年底上的一个站 ，历经半年，排名突然就起来了，流量也起来了！<br /><br />给出一些基本数据，供大家参考：<br />KD:44<br />每月搜索量：约20万<br />这个词不是新词，是刚开始ai出来的时候产生的，大概时间有2年左右。<br /><br />做完站后做了如下工作：<br />第一个月上DR低的外链，约20条<br />第2-3月上DR中等的外链，约100条<br />半年左右，上高DR的外链，约200条。<br /><br />后面就没怎么管了，静等花开！<br /><br />ps.这段时间尝试了各种外链的DR对排名的影响，感觉加外链也需要循序渐进，外链与你网站要对等的DR来加，小树苗期间去做做论坛blog小型导航站没问题，中期可尝试付费提交高DR的，后期可买guest posts提升DR。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6852513a2b50c6891806fad4</id>
            <title>AI探索站 06月18日</title>
            <link>https://m.okjike.com/originalPosts/6852513a2b50c6891806fad4</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6852513a2b50c6891806fad4</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Jun 2025 05:40:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    藏师傅又把压箱底的家伙事掏出来了，今天下午发
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685228962d05f8d12ae502df</id>
            <title>AI探索站 06月18日</title>
            <link>https://m.okjike.com/originalPosts/685228962d05f8d12ae502df</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685228962d05f8d12ae502df</guid>
            <pubDate></pubDate>
            <updated>Wed, 18 Jun 2025 02:46:46 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一个新的即将爆火的 Veo3 ASMR 视频品类<br /><br />直接模仿 ASMR 主播带上人物口播和物品操作一起，这下 ASMR 女主播也有点难了<br /><br />提示词模板在下面👇<br /><br />【画面描述】<br /><br />ASMR视频，[景别，如：特写镜头/中景/微距镜头/俯拍视角]。一位 [主播的外貌和神态描述，如：长发飘飘的漂亮年轻女性/表情优雅的女士] 身穿 [服装描述，如：丝绸质感的吊带裙/黑色蕾丝上衣]，身处于一个 [场景环境和氛围，如：灯光柔和的卧室/舒适的书房/黑暗极简风格的房间] 中。<br />一支 [麦克风的描述，如：专业的录音室麦克风/复古的电容麦克风] 被放置在 [麦克风的位置，如：她的面前/离动作非常近的地方]。<br />她正在与 [核心ASMR道具的描述，如：一大张气泡膜/一块白色的固体香皂/一本皮质封面的日记本] 互动。她 [主播与道具互动的具体动作，如：用手指缓慢地按破每一个气泡/小心翼翼地削下薄薄的皂片/用钢笔在纸上缓缓书写]。镜头的视觉焦点集中在 [画面的主要焦点，如：她的手和道具/香皂的纹理/钢笔尖与纸张的接触点]。<br /><br />【音频描述】<br /><br />一个 [主播的音色和语气，如：温柔甜美的女声耳语/低沉平静的耳语/充满亲密感的呼吸声] 说道：“[具体的口播内容，如：‘我们一起来捏破它们吧’/‘听这轻柔的刮擦声’]。”<br />随后是 [核心ASMR音效的详细描述，使用拟声词和形容词，如：气泡被捏破时清脆响亮的“啪！”声/刀片刮过香皂时发出的酥脆、带有颗粒感的声音/钢笔在纸上书写时独特的、略带刮擦感的“沙沙”声]。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/684f02a9e441f085b7ce67c6</id>
            <title>AI探索站 06月15日</title>
            <link>https://m.okjike.com/originalPosts/684f02a9e441f085b7ce67c6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/684f02a9e441f085b7ce67c6</guid>
            <pubDate></pubDate>
            <updated>Sun, 15 Jun 2025 17:28:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我为什么要创建 Fellou AI 浏览器<br />这其实是一个关于生产力的故事
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</id>
            <title>AI探索站 06月06日</title>
            <link>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Jun 2025 05:08:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近大家都在聊 AI 加持下的 vibe coding，我来聊聊作为资深开发者最近高强度使用 AI 的一些感受：<br /><br />一句话总结，AI 让不会写代码的人具备了“直接造辆车”的能力，而让资深开发者一个人就有了“独立建造航母”的可能。<br /><br />### 项目重构<br /><br />最近使用 claude-4 对我之前的一些代码进行了重构。原因是原来的实现中，为了降低编写时的心智负担，会使用一些性能偏低但是易于书写的代码。比方说自动锁管理、ARC、使用 array 数据结构代替 queue。<br /><br />然而用 AI 实现就没了这些负担，我先让 AI 为原始实现编写完整测试用例，确保原代码行为明确，然后让 AI 对整个 class 进行重构，追求极致性能，写完新代码后再重新运行测试保证行为一致。<br /><br />就这样，我轻松完成了部分核心数据结构的重构。尽管重构后的代码量几乎翻倍，但逻辑清晰、复杂度可控，换来的则是约 20% 的性能提升。<br /><br />核心是，AI 编写代码不怕苦不怕累，没有必要为了简化代码而牺牲性能。人类工程师目前主流习惯是牺牲部分运行性能以换取开发效率。<br /><br />### AI 编程语言<br /><br />这牵扯出的另一个观察是，什么编程语言对 AI 更友好，我的观察是可读性越高、行为越明确的语言效果越好。语法糖等简化编码技术，反而不利于 AI 使用。（AI 在发现一些奇怪的行为是运算符重载导致的不知道会不会跟我一样跳脚骂街）<br /><br />而像 SwiftUI 那些优势仅在开发效率上的技术，在 AI 时代更显得有些生不逢时。反正都是 AI 写，AI 用 UIKit/AppKit 实现不过是代码长一点而已，在可控性和行为明确性方面更适合 AI 自动化维护，性能也高的多。<br /><br />### AI 的资深<br /><br />虽然 AI 的编码技能，比起资深的工程师其实可能还是会有差距，但是要论知识丰富程度，则远非任何个体可比。<br /><br />这个优势体现在当我要去实现一些技术盲区时，原本的流程大概是：先读几本书，再对照比较一系列 RFC，再请教下相关领域的朋友确认自己已经理解。或者先按照自己的想象做个最小工程实践，然后再根据各种问题一点点填坑。<br /><br />比方说最近在实现 IPv6 ND 协议栈，一些特定的 RA 消息构造在某些操作系统上就是无法生效，原本这可能要耗费我几天的时间去研究，阅读各种文献甚至 kernel 源码实现，而现在只需请教 AI，就能非常准确地找到答案。<br /><br />AI 的这种资深，在你对某个技术的表层足够了解，但是缺乏经验和细节信息时，能够极快的帮你补全。<br /><br />### 极强的 debug 能力<br /><br />我的项目里有一个藏了很久的问题，在特定情况下会出现 TCP 性能下降，由于并没有产生任何明确的报错，这让修正这个问题变得异常麻烦。<br /><br />我原本是单纯向 AI 描述了我的使用场景和问题表现，AI 提出了几种猜想，大部分我看一眼就知道不靠谱，剩下几个试了下也并无效果。索性，我直接把 100MB 的抓包结果丢给了 o3 让他分析。它在几分钟内就精准指出了问题所在，甚至给出了改进建议。这种调试能力在人类团队中几乎无法复现。<br /><br />如此庞大的数据量，人工分析非常困难。即使借助各种工具，仅学习用法、配置环境就已令人头大。（因为 TCP 流控分析的各种工具链基本都是上个世纪的项目）<br /><br />现在我已经习惯了这种 vibe debug，遇到什么问题，直接把 verbose 日志和问题描述丢给 AI，大概率就能直接找到问题，这其实也是得益于 AI 的不怕苦不怕累的精神。<br /><br />### Peer review<br /><br />作为独立开发者，我的 code review 一直以来只能靠自己，但是自己写的 bug，很多时候自己是看不出来的🙈，现在我只需将 git diff 的结果交给 AI，就能请它帮我 review。<br /><br />同样的，我也会 review AI 给出的结果，AI 当然也会犯错，高级低级的都有。但是比起人类同事来说，AI 没有 ego，能很好地接受反馈并立即调整；很多人类做不到，或至少过程很曲折。<br /><br />### 职业影响<br /><br />就目前 AI 的能力来看，无疑是对初级开发者就业市场产生了巨大的压力，对于资深工程师来说，反而是一种赋能。（我目前还是能为找到 AI 的错误并指导它而沾沾自喜，但也不知道还能持续多久。）<br /><br />这比较让人担忧的是，这可能导致职业断层，因为初级开发者根本没有机会得到训练机会而成长。<br /><br />不过这已经早已不仅仅是软件工程师所面临的问题，本质上来说，所有脑力工作者的职业都受到了巨大威胁。像咨询、律师等职业，还可以依靠私域信息门槛维持。而像医生这样完全依赖公域信息的职业，初级职位也同样完全可以被 AI 替代了，当然最终取决于患者的接受程度。<br /><br />我最近一次体检后的报告喂给 o3 进行解读，他给出的信息量、准确性、建议，均远超全科医生给出的解读。不仅仅是因为 AI 的信息更全面，AI 可以为报告中每一项异常数据，检索最新研究与各国医疗指南，并整合后给出建议，甚至由于 GPT 已经了解我的生活习惯，能更优针对性的给出意见。而这种工作量对于人类医生来说是不可接受的（当然大多数情况下也确实没有必要）。<br /><br />很多人对 AI 医疗的顾虑是：AI 犯错了怎么办？然而其实人类医生也会犯错，而且就现在的 AI 水平来看，AI 犯错的概率应该已经比一般人类医生低了。当然最优解还是兼听则明，把 AI 的意见告知医生，也把医生的反馈告知 AI，基本最后都会达成一致。对于一些不重要的小问题，仅 AI 意见完全足够。<br /><br />### AI 的限制<br /><br />当然 AI 也不是万能的，甚至可以说局限性相当明显。claude-4 虽然非常强，但是随着 context 的增长，注意力溃散的非常严重，后面基本就像喝多了一样。<br /><br />当前的最佳实践是：尽量保持 context 精简，聚焦具体任务，依靠人力来拆解复杂目标。<br /><br />比方说先用一个 context 确定具体需求，再开一个 context 将明确好了的需求转换为具体任务列表，再把任务单独交给一个个 context 去具体实现。这样效果会好很多。<br /><br />仔细一看，这不就是人类的团队协作模式嘛 😂<br /><br />这让我想起不久前由 GPT o1 和 DeepSeek R1 的思维链引发的 AI 能力巨幅提升。其实在思维链能力出来之前，就可以靠 prompt 指引 AI 一步步思考，取得类似的效果，甚至催生了 prompt 工程师职业。然而直接在模型层面将这种能力整合后，prompt 引导就非常多余了。<br /><br />那么目前编程实践中，如今常用的 context 切分技巧，我认为在不久的将来也可能被模型层原生支持，即 AI 自主可以通过切换 context 的方式维持注意力，保持高效。这可能带来 AI 能力的又一次飞跃式进步。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</id>
            <title>AI探索站 05月30日</title>
            <link>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</guid>
            <pubDate></pubDate>
            <updated>Fri, 30 May 2025 05:01:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    感谢@硬地骇客 的支持，把三五环和半拿铁的多数文稿整理了一下，投入到 ima.copilot 里面，可以对话了。<br /><br />之前跟 ima 的朋友交流，就聊到未来知识库的「整理」变得没那么重要，而「采集」变得更重要，独特的筛选标准，以及采集逻辑，是决定知识库的价值的。ima 里也有很多筛选自己喜欢的内容而形成的公开知识库。<br /><br />对内容创作者自己来说，沉淀好自己的内容也特别有意义，有的不存不用确实就容易丢了。哪怕对别人没用，自己时常反刍也很有帮助。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>