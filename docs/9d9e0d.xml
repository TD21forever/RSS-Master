<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6846f7ad00f40eaa41875097</id>
            <title>AI探索站 06月09日</title>
            <link>https://m.okjike.com/originalPosts/6846f7ad00f40eaa41875097</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6846f7ad00f40eaa41875097</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Jun 2025 15:03:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天脑子里突然闪过 @hidecloud 的分享<br />“Less control, More intelligent”<br /><br />趁着 DS 更新了 0528 版本，把 flomo AI 洞察的提示词改到极短，效果意外的好，多样性和细节都比之前超长的要精彩。<br /><br />接下来就是上线 AB 测试看看用户选哪个了👀
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68468cf4747af0f12129117c</id>
            <title>AI探索站 06月09日</title>
            <link>https://m.okjike.com/originalPosts/68468cf4747af0f12129117c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68468cf4747af0f12129117c</guid>
            <pubDate></pubDate>
            <updated>Mon, 09 Jun 2025 07:27:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    前几天发了 FLUX Kontext 的很多案例<br /><br />虽然大概教了一下怎么用，但还是有很多人不会<br /><br />这次刚好发现 Liblib 上线了 Kontext，不需要本地跑 Comfyui ，可以在线处理<br /><br />索性手把手一步一步教大家用，顺便分享一下常见用法的 Comfyui 工作流：https://mp.weixin.qq.com/s/5M35Fr7pU1nzIc3Cm3_2Kg<br /><br />链接不太方便，我把 Kontext 工作流上架到 Liblib 了，搜索「藏师傅」就行，双图和三图超分的都有。<br /><br />在 Web UI 上简单体验 Kontext<br /><br />这里先教一下如何用最基本的 WebUI 里的 Kontext 对图片进行修改，需要注意的是 Web UI 只支持单图。<br />首先我们需要在 liblib 首页找到 F.1 Kontext，然后进到详情页里面点加模型库。<br />然后我们在侧边栏找到“在线生成”就可以进入到 web UI 的界面了，下面跟着我的操作设置就行：<br />1️⃣在页面最上面 CHECKPOINT 部分选择你刚刚加入到模型库的 F.1 Kontext 模型<br />2️⃣然后选择图生图模式<br />3️⃣之后输入提示词，Liblib 这里的提示词输入框可以一键帮你把中文提示词翻译为英文，非常省心<br />4️⃣我们可以在页面下方这里调整你期望生成的图像比例<br />5️⃣最后点击开始生图就好，我们的厨神 Labubu 就诞生了<br />另外，Web UI 近几天也会上线 Kontext 的多图参考能力。<br /><br />Comfyui 上解锁 Kontext 高级技巧<br /><br />可能很多人听到 Comfyui 又头疼了。<br />没事，在 Liblib 不需要你处理复杂的插件安装和模型下载问题。<br />即使是最复杂工作流搭建我也帮你搞好了你直接用就行。<br /><br />单图 Kontext 工作流使用<br /><br />首先我们需要在 Liblib 左侧导航找到“在线工作流”，然后打开页面之后将你获取到的「FLUX Kontext 单图工作流」拖入到界面中就可以了。<br />我们其实需要关注的就是三个地方，首先在「加载图像」节点上传你需要修改的图片。<br />然后在 Liblib Translate 节点输入中文的提示词，这个节点会自动帮你将提示词翻译为英文传输到 Kontext 节点里。<br />之后我们需要关注的就是 Kontext 节点中的 aspect_ratio 参数，这里的意思是输出图片的比例，按你需求的来就行。<br />最后点击右上角的运行按钮，等待就行。<br /><br />双图和三图 Kontext 工作流的使用<br /><br />接下来我们就真正到 Kontext 最独特的功能了，他支持将多张图片的元素融合在一张图片中，比如将产品放在指定环境的图片里面，让模特穿上指定的服饰等。<br />而且 Kontext 不止支持双图的融合还支持三图进行融合非常强大。<br />我们还是先将双图工作流拖放到 Liblib 的 Comfyui 界面中。<br />跟单图的时候区别不大，只是这次需要我们上传两张图片。<br />之后会自动拼合为一张传给模型，然后输入提示词选择生成图片的比例就行。<br /><br />这里我们输入的提示词就是“将化妆品瓶子放在周围有橘子和花的白色石块上，保留海报文字”。<br />一般在多图融合的时候 Kontext 会尽量还原产品的细节，但是环境图片的细节会跟原图有出入。<br />她会优先保证自然度，比如上面这里石头的位置和画面角度都不适合将瓶子放在小石头上，它机会自己提取石头元素和橘子元素重新布局画面。<br /><br />接下来三图也是一样的操作，我们现在可以混合更加复杂的场景，比如让模特拿着指定的化妆品站在指定的场景中。<br />你还是只需要设置你的三张图片、提示词和生成图像的比例，其他不需要管。<br /><br />最后其实 Kontext 生成的图片分辨率不太高，所以可能很多时候大家有放大图片的需求。<br />索性在 liblib 的 Comfyui 有很多其他的基建，所以藏师傅就找了一个图像放大流程然后整合到了里面。<br />而且我还加上了一个我训练的 FLUX Lora，可以非常好的去掉 FLUX 的有你感觉，可以看到人物的肤质、服装材质和画面颜色都好了很多。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6845a08faceddcdd1485340a</id>
            <title>AI探索站 06月08日</title>
            <link>https://m.okjike.com/originalPosts/6845a08faceddcdd1485340a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6845a08faceddcdd1485340a</guid>
            <pubDate></pubDate>
            <updated>Sun, 08 Jun 2025 14:39:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    白嫖一年 Perplexity 会员！<br /><br />在下面链接输入 PPLXLIUMBLHOTVAJ2QI 优惠码就行<br /><br />建议先将 IP 更换为美国或者新加坡，然后开无痕窗口打开链接
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68439e41dfa0f1ef3ad1cbb8</id>
            <title>AI探索站 06月07日</title>
            <link>https://m.okjike.com/originalPosts/68439e41dfa0f1ef3ad1cbb8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68439e41dfa0f1ef3ad1cbb8</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Jun 2025 02:04:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    分享一个自用的数据打标小工具<br /><br />前段时间女朋友在加班加点给数据打标<br />我一看，这不就是我天天用API干的事情（狗头<br />直接用Claude4搓了一个小前端，唯一的用户反馈还不错，就整理了一下开源出来，希望能够让大家轻松体验下指挥AI牛马的感觉<br /><br />设计的核心思路是用户只需要用自然语言描述任务（如p2），Prompt设计和实际打标任务都由模型完成，尽量简化操作<br />另外加了一些保存API和当前任务的配置，方便复现之前的结果<br />最后考虑到并不是所有人都会在电脑上安装Python和配环境，所以还打包成了exe，保证下载即用<br />欢迎大家体验，希望大家多多提意见！<br /><br />👉 在线玩（注意不要保存API Key和敏感数据）：https://tablelabelingtool-bingxuan.streamlit.app<br />🔧 Win免安装版：https://pan.quark.cn/s/d0360a24b2af<br />🐙 GitHub源码和使用指南：https://github.com/DOGEwbx/table_labeling_tool
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68439bc5d82bae994abd354d</id>
            <title>AI探索站 06月07日</title>
            <link>https://m.okjike.com/originalPosts/68439bc5d82bae994abd354d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68439bc5d82bae994abd354d</guid>
            <pubDate></pubDate>
            <updated>Sat, 07 Jun 2025 01:54:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我个人目前觉得垂直领域做得最好的AI产品<br />OpenEvidence （医疗）<br />Harvey （法律）<br />Lovart（设计）<br />Gamma（PPT）<br />FateTell（命理）<br />欢迎补充
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</id>
            <title>AI探索站 06月06日</title>
            <link>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Jun 2025 05:08:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近大家都在聊 AI 加持下的 vibe coding，我来聊聊作为资深开发者最近高强度使用 AI 的一些感受：<br /><br />一句话总结，AI 让不会写代码的人具备了“直接造辆车”的能力，而让资深开发者一个人就有了“独立建造航母”的可能。<br /><br />### 项目重构<br /><br />最近使用 claude-4 对我之前的一些代码进行了重构。原因是原来的实现中，为了降低编写时的心智负担，会使用一些性能偏低但是易于书写的代码。比方说自动锁管理、ARC、使用 array 数据结构代替 queue。<br /><br />然而用 AI 实现就没了这些负担，我先让 AI 为原始实现编写完整测试用例，确保原代码行为明确，然后让 AI 对整个 class 进行重构，追求极致性能，写完新代码后再重新运行测试保证行为一致。<br /><br />就这样，我轻松完成了部分核心数据结构的重构。尽管重构后的代码量几乎翻倍，但逻辑清晰、复杂度可控，换来的则是约 20% 的性能提升。<br /><br />核心是，AI 编写代码不怕苦不怕累，没有必要为了简化代码而牺牲性能。人类工程师目前主流习惯是牺牲部分运行性能以换取开发效率。<br /><br />### AI 编程语言<br /><br />这牵扯出的另一个观察是，什么编程语言对 AI 更友好，我的观察是可读性越高、行为越明确的语言效果越好。语法糖等简化编码技术，反而不利于 AI 使用。（AI 在发现一些奇怪的行为是运算符重载导致的不知道会不会跟我一样跳脚骂街）<br /><br />而像 SwiftUI 那些优势仅在开发效率上的技术，在 AI 时代更显得有些生不逢时。反正都是 AI 写，AI 用 UIKit/AppKit 实现不过是代码长一点而已，在可控性和行为明确性方面更适合 AI 自动化维护，性能也高的多。<br /><br />### AI 的资深<br /><br />虽然 AI 的编码技能，比起资深的工程师其实可能还是会有差距，但是要论知识丰富程度，则远非任何个体可比。<br /><br />这个优势体现在当我要去实现一些技术盲区时，原本的流程大概是：先读几本书，再对照比较一系列 RFC，再请教下相关领域的朋友确认自己已经理解。或者先按照自己的想象做个最小工程实践，然后再根据各种问题一点点填坑。<br /><br />比方说最近在实现 IPv6 ND 协议栈，一些特定的 RA 消息构造在某些操作系统上就是无法生效，原本这可能要耗费我几天的时间去研究，阅读各种文献甚至 kernel 源码实现，而现在只需请教 AI，就能非常准确地找到答案。<br /><br />AI 的这种资深，在你对某个技术的表层足够了解，但是缺乏经验和细节信息时，能够极快的帮你补全。<br /><br />### 极强的 debug 能力<br /><br />我的项目里有一个藏了很久的问题，在特定情况下会出现 TCP 性能下降，由于并没有产生任何明确的报错，这让修正这个问题变得异常麻烦。<br /><br />我原本是单纯向 AI 描述了我的使用场景和问题表现，AI 提出了几种猜想，大部分我看一眼就知道不靠谱，剩下几个试了下也并无效果。索性，我直接把 100MB 的抓包结果丢给了 o3 让他分析。它在几分钟内就精准指出了问题所在，甚至给出了改进建议。这种调试能力在人类团队中几乎无法复现。<br /><br />如此庞大的数据量，人工分析非常困难。即使借助各种工具，仅学习用法、配置环境就已令人头大。（因为 TCP 流控分析的各种工具链基本都是上个世纪的项目）<br /><br />现在我已经习惯了这种 vibe debug，遇到什么问题，直接把 verbose 日志和问题描述丢给 AI，大概率就能直接找到问题，这其实也是得益于 AI 的不怕苦不怕累的精神。<br /><br />### Peer review<br /><br />作为独立开发者，我的 code review 一直以来只能靠自己，但是自己写的 bug，很多时候自己是看不出来的🙈，现在我只需将 git diff 的结果交给 AI，就能请它帮我 review。<br /><br />同样的，我也会 review AI 给出的结果，AI 当然也会犯错，高级低级的都有。但是比起人类同事来说，AI 没有 ego，能很好地接受反馈并立即调整；很多人类做不到，或至少过程很曲折。<br /><br />### 职业影响<br /><br />就目前 AI 的能力来看，无疑是对初级开发者就业市场产生了巨大的压力，对于资深工程师来说，反而是一种赋能。（我目前还是能为找到 AI 的错误并指导它而沾沾自喜，但也不知道还能持续多久。）<br /><br />这比较让人担忧的是，这可能导致职业断层，因为初级开发者根本没有机会得到训练机会而成长。<br /><br />不过这已经早已不仅仅是软件工程师所面临的问题，本质上来说，所有脑力工作者的职业都受到了巨大威胁。像咨询、律师等职业，还可以依靠私域信息门槛维持。而像医生这样完全依赖公域信息的职业，初级职位也同样完全可以被 AI 替代了，当然最终取决于患者的接受程度。<br /><br />我最近一次体检后的报告喂给 o3 进行解读，他给出的信息量、准确性、建议，均远超全科医生给出的解读。不仅仅是因为 AI 的信息更全面，AI 可以为报告中每一项异常数据，检索最新研究与各国医疗指南，并整合后给出建议，甚至由于 GPT 已经了解我的生活习惯，能更优针对性的给出意见。而这种工作量对于人类医生来说是不可接受的（当然大多数情况下也确实没有必要）。<br /><br />很多人对 AI 医疗的顾虑是：AI 犯错了怎么办？然而其实人类医生也会犯错，而且就现在的 AI 水平来看，AI 犯错的概率应该已经比一般人类医生低了。当然最优解还是兼听则明，把 AI 的意见告知医生，也把医生的反馈告知 AI，基本最后都会达成一致。对于一些不重要的小问题，仅 AI 意见完全足够。<br /><br />### AI 的限制<br /><br />当然 AI 也不是万能的，甚至可以说局限性相当明显。claude-4 虽然非常强，但是随着 context 的增长，注意力溃散的非常严重，后面基本就像喝多了一样。<br /><br />当前的最佳实践是：尽量保持 context 精简，聚焦具体任务，依靠人力来拆解复杂目标。<br /><br />比方说先用一个 context 确定具体需求，再开一个 context 将明确好了的需求转换为具体任务列表，再把任务单独交给一个个 context 去具体实现。这样效果会好很多。<br /><br />仔细一看，这不就是人类的团队协作模式嘛 😂<br /><br />这让我想起不久前由 GPT o1 和 DeepSeek R1 的思维链引发的 AI 能力巨幅提升。其实在思维链能力出来之前，就可以靠 prompt 指引 AI 一步步思考，取得类似的效果，甚至催生了 prompt 工程师职业。然而直接在模型层面将这种能力整合后，prompt 引导就非常多余了。<br /><br />那么目前编程实践中，如今常用的 context 切分技巧，我认为在不久的将来也可能被模型层原生支持，即 AI 自主可以通过切换 context 的方式维持注意力，保持高效。这可能带来 AI 能力的又一次飞跃式进步。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6840e611f432421164ef17fa</id>
            <title>AI探索站 06月05日</title>
            <link>https://m.okjike.com/originalPosts/6840e611f432421164ef17fa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6840e611f432421164ef17fa</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Jun 2025 00:34:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    目前最好的讲MCP的课程<br /><br />Anthropic 和 Deeplearning 合作推出了MCP系列课程，希望系统了解mcp推荐看这个课程。<br /><br />一样是一个小时左右，从概念讲到host，讲到 client 和 server，再讲到mcp内的各个组件 tools，prompts，resources，同时还分享了目前在逐渐支持的 stream http和正在发展的 roots sampling，mcp registry 等情况。<br /><br />看完对整个mcp的当下、现在和未来的路线图一下就清晰了。<br /><br />还有一个比较触动我的点是: 好的应用是实践"生长"出来的。<br /><br />anthropic 说mcp，artifacts 都是由内部实践诞生出来的项目，自己用了好用，发现是刚需就打磨发布出来了，都成了口碑和价值俱佳的产品。<br /><br />https://www.deeplearning.ai/short-courses/mcp-build-rich-context-ai-apps-with-anthropic/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</id>
            <title>AI探索站 05月30日</title>
            <link>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</guid>
            <pubDate></pubDate>
            <updated>Fri, 30 May 2025 05:01:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    感谢@硬地骇客 的支持，把三五环和半拿铁的多数文稿整理了一下，投入到 ima.copilot 里面，可以对话了。<br /><br />之前跟 ima 的朋友交流，就聊到未来知识库的「整理」变得没那么重要，而「采集」变得更重要，独特的筛选标准，以及采集逻辑，是决定知识库的价值的。ima 里也有很多筛选自己喜欢的内容而形成的公开知识库。<br /><br />对内容创作者自己来说，沉淀好自己的内容也特别有意义，有的不存不用确实就容易丢了。哪怕对别人没用，自己时常反刍也很有帮助。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/682d6a21ca977f7fc7e6e8e6</id>
            <title>AI探索站 05月21日</title>
            <link>https://m.okjike.com/originalPosts/682d6a21ca977f7fc7e6e8e6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/682d6a21ca977f7fc7e6e8e6</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 May 2025 05:52:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    但我觉得 Sergey Brin 和 Demis Hassabis 那个对谈里最有趣的问题其实是这个。<br />主持人：你会雇佣一个在面试里用 AI 的面试者吗？<br />两个人显然都愣住了，哼哼唧唧半天，最后基本上都是说自己也说不好。<br /><br />这看起来是个实操细节，事实上是个本质议题。就是如果 AGI 真的如他们预言的那样在五年左右（见上一条 https://web.okjike.com/u/0E8AFC24-2DB7-4C8D-8D27-794903C79641/post/682d48f8e0619112afecf6e8 ）到来，那今天你就要开始想你到底怎么量度工作的价值，包括面试的时候你要考察什么东西。换句话说就是：人这个世界上最重要的商品和资源到底怎么定价。<br /><br />很显然即使聪明如 Sergey Brin 和 Demis Hassabis 也没想好。我不认为世界上真的有人想清楚了这个问题，但五年后社会经济怎么运转是基于这个问题的答案的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822c473e03d82181c847000</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 04:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    真正的领导者探索未知，而非发号施令<br /><br />在AI first团队中，真正的leader不会满足于开通付费工具、督促他人适应，而是亲自穿越未知的崎岖小径、发现独特风景，并将这些宝贵的发现和感悟无保留地分享给团队。<br /><br />在剧变的时代，领导力的精髓不只是指挥，而在于示范；不在于命令，而在于树立榜样。<br /><br />好的Leader以好奇心和同理心绘制「探索路书」，团队才会真正激发出10X的创造力。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>