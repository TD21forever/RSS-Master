<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6842cd91a26304532600fa4d</id>
            <title>AI探索站 06月06日</title>
            <link>https://m.okjike.com/originalPosts/6842cd91a26304532600fa4d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6842cd91a26304532600fa4d</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Jun 2025 11:14:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    即梦AI的图片3.0上线了智能参考<br /><br />可以基于上传的图像，生成任何你想要生成的内容，这太爽了！<br /><br />不管是海报、电商封面、小红书封面还是视频封面，甚至只是想给你的照片添加一些装饰，都能搞定<br /><br />我还写了套提示词帮你复刻任何你喜欢的电商或者小红书封面的排版样式<br /><br />这里是详细的提示词和介绍：https://mp.weixin.qq.com/s/_kt9OLylR95sG7U37wseSw<br /><br />基本能力测试<br /><br />首先是照片和人像的测试，我们分别从大面积到小细节分别对一个人像照片进行修改。<br />从更换背景到增加配饰再到更改姿势，都没啥问题，只改了需要改的地方，更改的位置跟原有的融合度不错，人眼看不出来更改过。<br />然后我还让他给照片加了滤镜，测试了在上面覆盖内容的这种修改，也很好。<br /><br />再然后就是即梦的看家本事了，中文生成，这次还要加上修改。<br />我们先来看一下生成，这里我那一张原有的图片让即梦帮我给这个武器设计加上文字。<br />可以看到即梦对于文字样式和位置的响应非常精准。<br /><br />然后是改字，我在社区找了一个非常复杂的文字效果，除了字体不是常规字体外，还有 3D Q 版挤压效果。<br />然后让他修改的时候也增加了难度，没有单独改某个字而是让他把原来上面的三个字变成五个字，没想到搞得还挺好，新增的文字基本上都有类似的立体效果和挤压效果。<br /><br />日常应用场景<br /><br />我们日常分享照片的时候一般就是几类需求：<br />- 给照片加滤镜<br />- 修改照片内容，改变照片比例<br />- 给照片增加装饰帮助表达<br />- 用 AI 给照片转换风格<br /><br />前三种基本上都是之前美图、醒图这类图片软件最常见的需求，现在即梦全都可以搞定了。<br />比如最近很火的撕拉片风格照片，我们只需要上传你拍的照片加一点提示词就可以用即梦图片3.0直接生成。<br /><br />即梦图片3.0 还可以自己分析图片内容给图片生成海报和装饰，你只需要在提示词输入海报两个字就行，这门槛够低了吧。<br />这里就是模型自己搞的，生成的字体和装饰都非常契合原来照片的风格和感觉。<br /><br />如果你不喜欢他自己加的文字的话也可以自己在提示词里面写一下，这种方式可以极大的增加日常分享照片的表现力。<br />比如对于每天喝咖啡的人完全可以给自己每天喝的咖啡加上日期和咖啡种类的标记，当做打卡方式，当时我记得就单纯给照片加水印这个功能有些软件就活得很不错了，现在要啥水印你自己定义。<br /><br />营销物料生成<br />之前在图片3.0 发布的时候即梦生成的封面就已经很强了，主要就剩下跟现实照片相关的内容没办法做。<br /><br />主要就是两类：<br />一类是电商商品，商品的还原度非常重要，所以原来直接生成不行。<br />另一类是小红书或者视频封面，一些主打 IP 的非常需要将 up 自己的人像放在封面上。<br /><br />现在这两类直接全部都解决了，而且我还整理了一套生成提示词的提示词，你可以用来复刻你喜欢的博主的封面或者店铺的宣传图。<br />你只需要找一个支持多模态的 LLM，将你想要参考的排版和下面这段提示词放进去，就能直接生成对应的即梦智能参考提示词。<br /><br />首先是电商的商品展示或者营销内容<br /><br />可以看到人物和商品的 ID 都没有变化，甚至他还帮你把照片背景和封面的粉色背景做了渐变让两者更加融合。<br /><br />当然你要是懒得输入提示词，其实即梦的智能参考也没问题。<br />比如这里我就写了一个“29.9 元蛋糕新品海报”，他就帮我生成了一个非常可爱和漂亮的蛋糕营销海报。<br />甚至连文案都帮我补充好了，萌趣造型，甜蜜诱惑这种词你让我想我想不出来反正，太强了。<br /><br />然后是常见的小红书封面或者说视频封面。比如这种宣传旅游景点或者露营景点的，完全可以在保证照片是对应位置的情况下加上文字排版。<br /><br />如果说这种风景图简单的话我们来个人像的。类似很多探店视频都是这种将人物抠出来加上其他店里的内容展示在加标题的方式，以往这一套还是挺麻烦的，现在一句话搞定。<br /><br />模型信息&amp;如何使用<br /><br />刚好今天他们发了这个模型的公众号文章，原来这一个功能是有两个模型驱动的，分别是SeedEdit3.0和DreamPoster模型。<br />改文字、做海报功能调用的模型是字节的 DreamPoster模型。<br />智能参考的使用方式也很简单，选择图片图片3.0 模型，然后上传图片，默认就是智能参考，输入提示词直接生成就行。<br /><br />目前这个功能在内测阶段，下周就会全量上线，到时候就可以拿着藏师傅的宝典操练起来了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</id>
            <title>AI探索站 06月06日</title>
            <link>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Jun 2025 05:08:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近大家都在聊 AI 加持下的 vibe coding，我来聊聊作为资深开发者最近高强度使用 AI 的一些感受：<br /><br />一句话总结，AI 让不会写代码的人具备了“直接造辆车”的能力，而让资深开发者一个人就有了“独立建造航母”的可能。<br /><br />### 项目重构<br /><br />最近使用 claude-4 对我之前的一些代码进行了重构。原因是原来的实现中，为了降低编写时的心智负担，会使用一些性能偏低但是易于书写的代码。比方说自动锁管理、ARC、使用 array 数据结构代替 queue。<br /><br />然而用 AI 实现就没了这些负担，我先让 AI 为原始实现编写完整测试用例，确保原代码行为明确，然后让 AI 对整个 class 进行重构，追求极致性能，写完新代码后再重新运行测试保证行为一致。<br /><br />就这样，我轻松完成了部分核心数据结构的重构。尽管重构后的代码量几乎翻倍，但逻辑清晰、复杂度可控，换来的则是约 20% 的性能提升。<br /><br />核心是，AI 编写代码不怕苦不怕累，没有必要为了简化代码而牺牲性能。人类工程师目前主流习惯是牺牲部分运行性能以换取开发效率。<br /><br />### AI 编程语言<br /><br />这牵扯出的另一个观察是，什么编程语言对 AI 更友好，我的观察是可读性越高、行为越明确的语言效果越好。语法糖等简化编码技术，反而不利于 AI 使用。（AI 在发现一些奇怪的行为是运算符重载导致的不知道会不会跟我一样跳脚骂街）<br /><br />而像 SwiftUI 那些优势仅在开发效率上的技术，在 AI 时代更显得有些生不逢时。反正都是 AI 写，AI 用 UIKit/AppKit 实现不过是代码长一点而已，在可控性和行为明确性方面更适合 AI 自动化维护，性能也高的多。<br /><br />### AI 的资深<br /><br />虽然 AI 的编码技能，比起资深的工程师其实可能还是会有差距，但是要论知识丰富程度，则远非任何个体可比。<br /><br />这个优势体现在当我要去实现一些技术盲区时，原本的流程大概是：先读几本书，再对照比较一系列 RFC，再请教下相关领域的朋友确认自己已经理解。或者先按照自己的想象做个最小工程实践，然后再根据各种问题一点点填坑。<br /><br />比方说最近在实现 IPv6 ND 协议栈，一些特定的 RA 消息构造在某些操作系统上就是无法生效，原本这可能要耗费我几天的时间去研究，阅读各种文献甚至 kernel 源码实现，而现在只需请教 AI，就能非常准确地找到答案。<br /><br />AI 的这种资深，在你对某个技术的表层足够了解，但是缺乏经验和细节信息时，能够极快的帮你补全。<br /><br />### 极强的 debug 能力<br /><br />我的项目里有一个藏了很久的问题，在特定情况下会出现 TCP 性能下降，由于并没有产生任何明确的报错，这让修正这个问题变得异常麻烦。<br /><br />我原本是单纯向 AI 描述了我的使用场景和问题表现，AI 提出了几种猜想，大部分我看一眼就知道不靠谱，剩下几个试了下也并无效果。索性，我直接把 100MB 的抓包结果丢给了 o3 让他分析。它在几分钟内就精准指出了问题所在，甚至给出了改进建议。这种调试能力在人类团队中几乎无法复现。<br /><br />如此庞大的数据量，人工分析非常困难。即使借助各种工具，仅学习用法、配置环境就已令人头大。（因为 TCP 流控分析的各种工具链基本都是上个世纪的项目）<br /><br />现在我已经习惯了这种 vibe debug，遇到什么问题，直接把 verbose 日志和问题描述丢给 AI，大概率就能直接找到问题，这其实也是得益于 AI 的不怕苦不怕累的精神。<br /><br />### Peer review<br /><br />作为独立开发者，我的 code review 一直以来只能靠自己，但是自己写的 bug，很多时候自己是看不出来的🙈，现在我只需将 git diff 的结果交给 AI，就能请它帮我 review。<br /><br />同样的，我也会 review AI 给出的结果，AI 当然也会犯错，高级低级的都有。但是比起人类同事来说，AI 没有 ego，能很好地接受反馈并立即调整；很多人类做不到，或至少过程很曲折。<br /><br />### 职业影响<br /><br />就目前 AI 的能力来看，无疑是对初级开发者就业市场产生了巨大的压力，对于资深工程师来说，反而是一种赋能。（我目前还是能为找到 AI 的错误并指导它而沾沾自喜，但也不知道还能持续多久。）<br /><br />这比较让人担忧的是，这可能导致职业断层，因为初级开发者根本没有机会得到训练机会而成长。<br /><br />不过这已经早已不仅仅是软件工程师所面临的问题，本质上来说，所有脑力工作者的职业都受到了巨大威胁。像咨询、律师等职业，还可以依靠私域信息门槛维持。而像医生这样完全依赖公域信息的职业，初级职位也同样完全可以被 AI 替代了，当然最终取决于患者的接受程度。<br /><br />我最近一次体检后的报告喂给 o3 进行解读，他给出的信息量、准确性、建议，均远超全科医生给出的解读。不仅仅是因为 AI 的信息更全面，AI 可以为报告中每一项异常数据，检索最新研究与各国医疗指南，并整合后给出建议，甚至由于 GPT 已经了解我的生活习惯，能更优针对性的给出意见。而这种工作量对于人类医生来说是不可接受的（当然大多数情况下也确实没有必要）。<br /><br />很多人对 AI 医疗的顾虑是：AI 犯错了怎么办？然而其实人类医生也会犯错，而且就现在的 AI 水平来看，AI 犯错的概率应该已经比一般人类医生低了。当然最优解还是兼听则明，把 AI 的意见告知医生，也把医生的反馈告知 AI，基本最后都会达成一致。对于一些不重要的小问题，仅 AI 意见完全足够。<br /><br />### AI 的限制<br /><br />当然 AI 也不是万能的，甚至可以说局限性相当明显。claude-4 虽然非常强，但是随着 context 的增长，注意力溃散的非常严重，后面基本就像喝多了一样。<br /><br />当前的最佳实践是：尽量保持 context 精简，聚焦具体任务，依靠人力来拆解复杂目标。<br /><br />比方说先用一个 context 确定具体需求，再开一个 context 将明确好了的需求转换为具体任务列表，再把任务单独交给一个个 context 去具体实现。这样效果会好很多。<br /><br />仔细一看，这不就是人类的团队协作模式嘛 😂<br /><br />这让我想起不久前由 GPT o1 和 DeepSeek R1 的思维链引发的 AI 能力巨幅提升。其实在思维链能力出来之前，就可以靠 prompt 指引 AI 一步步思考，取得类似的效果，甚至催生了 prompt 工程师职业。然而直接在模型层面将这种能力整合后，prompt 引导就非常多余了。<br /><br />那么目前编程实践中，如今常用的 context 切分技巧，我认为在不久的将来也可能被模型层原生支持，即 AI 自主可以通过切换 context 的方式维持注意力，保持高效。这可能带来 AI 能力的又一次飞跃式进步。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68414551d82bae994a9519b9</id>
            <title>AI探索站 06月05日</title>
            <link>https://m.okjike.com/originalPosts/68414551d82bae994a9519b9</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68414551d82bae994a9519b9</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Jun 2025 07:20:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    众所周知，医疗和教育是压在普通人头顶的两座大山，决策成本之高，催生了为那些迫不得已需要翻山越岭的人贩卖手杖的行当，搜索就是一个重灾区，搜索疾病症状，出来的必然是各种医药服务的小广告，搜索填报志愿，充斥眼前的也全都是教育机构的留资引导。<br /><br />不是说广告不好，而是一个需求入口被贴满了牛皮癣，以致于用户要从无孔不入的商业推广里学会分辨客观信息，这实在不合理，至于「天下苦xx久矣」的说法用得多了，也就不剩下多少批判性了，反而更有「日哭夜哭能哭死董卓否」的抽象感。<br /><br />套用俞军老师的著名公式——产品价值=（新体验-旧体验）-迁移成本——只有在体验差距足够大的时候，才会撼动传统搜索的商业模式，这也是AI被寄予厚望的经济预期，至少在针对那两座大山的「移山工程」里，夸克塞到用户手里的铲子，是真的有用。<br /><br />几乎是在同一时间，夸克的健康大模型通过了副主任医师的职称考试，在12个主流门诊学科里都超过了合格线，另外还推出了面向高考场景的深度搜索服务，可以成为一个高度定制化的志愿规划师。<br /><br />从原理上，这是夸克走上「工具箱化」这条道路的必然结果，基于通义千问基座模型的底层能力，为特定的痛点需求进行额外的数据采集和后训练，最后集成到框里去。<br /><br />考虑到本来用户的使用习惯都已经在转移过程中了——每次评论区都有很多现身说法的，表示自己越来越依赖遇事不决问AI、不再选择在搜索结果里翻拣网页——趁势完善端到端的体验，是百利而无一害的。<br /><br />我测试下来的感受是，要说取代医生和老师，可能为时尚早，但是取代搜索，已经完全可行了，而且不是平替，是更优解。<br /><br />比如查完血常规后，拍照发给夸克，在排除疑难杂症的前提下，它所给出的答案和医生问诊的结果是没什么差别的，各种用药禁忌和症状分析，也都能给出纯粹干货的说明，不再需要担心夹带私货。<br /><br />我看到前几天也有医生出来表态了，他个人并不介意患者拿着AI的答案和他掰扯，在医疗资源长期紧张的环境下，患者这么做的心理实际上是怕医生在百忙之中有所遗漏，希望受到重视。而在医生看来，不管怎么样，懂得使用AI总比轻信不明网站里的野鸡专家要好，AI至少不会胡说八道，它能让医患之间产生更加顺畅的交流。<br /><br />填报志愿也是类似，张雪峰的火爆和定价足以说明，在东亚这个「年年都是人生最重要的一年」的做题氛围里，错一步误一生的焦虑始终困扰着学生和家长们，现在有了AI搭把手弥补信息差，总归是件好事。<br /><br />另一方面，「深耕垂直模型突破」的行业判断可能也确实成立了。首先，通用模型的能力是最关键的，若是基础智能不能保持领先，就很难适应千人千面的大众需求，反过来说，通用模型却很容易把垂直模型整合到一个入口里，让不同领域的专家时刻待命，分给不同的场景上岗。<br /><br />夸克也证明了只要通用模型足够领先——通义千问俨然已成全球开源旗舰——细分出的垂直模型会有更大的进步跨度，兼具通用模型里最专业的、垂直模型里最聪明的两大优势。<br /><br />夸克这次的升级就是如此，框还是那个框，后面的模型又过了不知道多少遍的万重山，用户也不需要特意去选择模型版本，只需要输入意图，模型自己就能做出判断，然后调用对应的垂直模型出来「接客」。<br /><br />根据Sam Altman的说法，他对用户抱怨ChatGPT的模型版本过于复杂深有同感，让用户每次输入前都要考虑是不是选对了模型也很多余，所以GPT-5将回归「All In One」的模式，一个模型解万事。<br /><br />这么来看，夸克的含金量还在上升。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6840e611f432421164ef17fa</id>
            <title>AI探索站 06月05日</title>
            <link>https://m.okjike.com/originalPosts/6840e611f432421164ef17fa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6840e611f432421164ef17fa</guid>
            <pubDate></pubDate>
            <updated>Thu, 05 Jun 2025 00:34:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    目前最好的讲MCP的课程<br /><br />Anthropic 和 Deeplearning 合作推出了MCP系列课程，希望系统了解mcp推荐看这个课程。<br /><br />一样是一个小时左右，从概念讲到host，讲到 client 和 server，再讲到mcp内的各个组件 tools，prompts，resources，同时还分享了目前在逐渐支持的 stream http和正在发展的 roots sampling，mcp registry 等情况。<br /><br />看完对整个mcp的当下、现在和未来的路线图一下就清晰了。<br /><br />还有一个比较触动我的点是: 好的应用是实践"生长"出来的。<br /><br />anthropic 说mcp，artifacts 都是由内部实践诞生出来的项目，自己用了好用，发现是刚需就打磨发布出来了，都成了口碑和价值俱佳的产品。<br /><br />https://www.deeplearning.ai/short-courses/mcp-build-rich-context-ai-apps-with-anthropic/
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68402141b7f4ddcfdf80acc2</id>
            <title>AI探索站 06月04日</title>
            <link>https://m.okjike.com/originalPosts/68402141b7f4ddcfdf80acc2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68402141b7f4ddcfdf80acc2</guid>
            <pubDate></pubDate>
            <updated>Wed, 04 Jun 2025 10:34:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这是我的 AI 产品的使用习惯，看起来跟大家也没有太大区别。<br /><br />资料整理，海外，搭配搜索：Gemini &gt; ChatGPT &gt; 腾讯元宝（DeepSeek） &gt; 秘塔 &gt; DeepSeek &gt; 豆包<br /><br />资料整理，国内，搭配搜索： 腾讯元宝（DeepSeek）&gt; 秘塔 &gt; 夸克 &gt; Gemini &gt; ChatGPT &gt; DeepSeek&gt; 豆包 <br /><br />深度整理，搭配文档：ChatGPT<br /><br />文章查漏补缺：Gemini、ChatGPT、腾讯元宝（DeepSeek）、DeepSeek 、豆包<br /><br />学习常识：腾讯元宝（DeepSeek）、豆包<br /><br />知识库问答：ima.coplit<br /><br />美工：Midjourney、ChatGPT o3<br /><br />翻译转写：Claude 4 、豆包<br /><br />代码编程：Trae<br /><br />边拍边学：ChatGPT o3、豆包<br /><br />旅行中搭配的深度阅读：Gemini 、ChatGPT、夸克 <br /><br />办事文档撰写：ChatGPT、腾讯元宝（DeepSeek）、Gemini、百度文库<br /><br />记录梦境/照片处理：ChatGPT o3<br /><br />视频：Veo 3、即梦、可灵<br /><br />音频：MiniMax、NotebookLM、扣子空间
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/683f188e3199f48905d7520d</id>
            <title>AI探索站 06月03日</title>
            <link>https://m.okjike.com/originalPosts/683f188e3199f48905d7520d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/683f188e3199f48905d7520d</guid>
            <pubDate></pubDate>
            <updated>Tue, 03 Jun 2025 15:45:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    试了一组高饱和度的Coser剪影硬照，很适合批量生成手机壁纸。<br /><br />提示词：<br /><br />这张照片视觉语言极强，兼具复古感、未来感与强烈的视觉隐喻，同时具有很高的真实性，画面主体为一位全身黑色剪影的人物[名字]，穿着标志性的服装，背后是强烈的纯[颜色]背景，色彩张力极高。人物和一台老式CRT电视机有着互动动作，电视中正显示一张高度还原的[名字]镜头。<br />构图方式<br />中心对称，人物垂直站立于画面正中动作符合人设，电视画面居于人物侧面右下角桌上位置，视觉焦点精准；<br />颜色语言<br />背景为高饱和[颜色]，人物为黑影轮廓，形成极端对比；电视画面带来局部色彩，灯光技术含噪点并且带有闪烁；<br />使用背打强光制造剪影；前景无补光，完全靠电视自发光制造对比；<br />道具象征<br />电视作为自我投射媒介或外在呈现的内在图像，极具隐喻；<br />相机与镜头<br />全画幅数码相机 + 中焦镜头（如 50mm 或 85mm），以保证剪影不变形；<br />背景光源<br />[颜色]无阴影背景布 + 均匀背光LED/色片灯，打出饱和[颜色]背景；<br />主体灯光<br />无主光，仅靠背景产生人物黑影轮廓和经典动作；电视自带画面亮度为唯一前景光源<br />后期处理；<br />色彩增强（提升[颜色]饱和）、清晰度拉高、局部锐化电视图像区域。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/683e9ddc6ac4ada7b47fdffa</id>
            <title>AI探索站 06月03日</title>
            <link>https://m.okjike.com/originalPosts/683e9ddc6ac4ada7b47fdffa</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/683e9ddc6ac4ada7b47fdffa</guid>
            <pubDate></pubDate>
            <updated>Tue, 03 Jun 2025 07:01:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我操，用户彻底怒了
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</id>
            <title>AI探索站 05月30日</title>
            <link>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</guid>
            <pubDate></pubDate>
            <updated>Fri, 30 May 2025 05:01:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    感谢@硬地骇客 的支持，把三五环和半拿铁的多数文稿整理了一下，投入到 ima.copilot 里面，可以对话了。<br /><br />之前跟 ima 的朋友交流，就聊到未来知识库的「整理」变得没那么重要，而「采集」变得更重要，独特的筛选标准，以及采集逻辑，是决定知识库的价值的。ima 里也有很多筛选自己喜欢的内容而形成的公开知识库。<br /><br />对内容创作者自己来说，沉淀好自己的内容也特别有意义，有的不存不用确实就容易丢了。哪怕对别人没用，自己时常反刍也很有帮助。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/682d6a21ca977f7fc7e6e8e6</id>
            <title>AI探索站 05月21日</title>
            <link>https://m.okjike.com/originalPosts/682d6a21ca977f7fc7e6e8e6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/682d6a21ca977f7fc7e6e8e6</guid>
            <pubDate></pubDate>
            <updated>Wed, 21 May 2025 05:52:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    但我觉得 Sergey Brin 和 Demis Hassabis 那个对谈里最有趣的问题其实是这个。<br />主持人：你会雇佣一个在面试里用 AI 的面试者吗？<br />两个人显然都愣住了，哼哼唧唧半天，最后基本上都是说自己也说不好。<br /><br />这看起来是个实操细节，事实上是个本质议题。就是如果 AGI 真的如他们预言的那样在五年左右（见上一条 https://web.okjike.com/u/0E8AFC24-2DB7-4C8D-8D27-794903C79641/post/682d48f8e0619112afecf6e8 ）到来，那今天你就要开始想你到底怎么量度工作的价值，包括面试的时候你要考察什么东西。换句话说就是：人这个世界上最重要的商品和资源到底怎么定价。<br /><br />很显然即使聪明如 Sergey Brin 和 Demis Hassabis 也没想好。我不认为世界上真的有人想清楚了这个问题，但五年后社会经济怎么运转是基于这个问题的答案的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822c473e03d82181c847000</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 04:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    真正的领导者探索未知，而非发号施令<br /><br />在AI first团队中，真正的leader不会满足于开通付费工具、督促他人适应，而是亲自穿越未知的崎岖小径、发现独特风景，并将这些宝贵的发现和感悟无保留地分享给团队。<br /><br />在剧变的时代，领导力的精髓不只是指挥，而在于示范；不在于命令，而在于树立榜样。<br /><br />好的Leader以好奇心和同理心绘制「探索路书」，团队才会真正激发出10X的创造力。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>