<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68b72979363f45c0737c49ef</id>
            <title>AI探索站 09月02日</title>
            <link>https://m.okjike.com/originalPosts/68b72979363f45c0737c49ef</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68b72979363f45c0737c49ef</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Sep 2025 17:29:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Nano Banana🍌生成艺术肖像照，直接省下几万块！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68b6a3569266e3b27128bae0</id>
            <title>AI探索站 09月02日</title>
            <link>https://m.okjike.com/originalPosts/68b6a3569266e3b27128bae0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68b6a3569266e3b27128bae0</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Sep 2025 07:57:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    nanobanana真TM牛逼！图二是我的原图。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68b67d4c1e5664293df30c33</id>
            <title>AI探索站 09月02日</title>
            <link>https://m.okjike.com/originalPosts/68b67d4c1e5664293df30c33</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68b67d4c1e5664293df30c33</guid>
            <pubDate></pubDate>
            <updated>Tue, 02 Sep 2025 05:14:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    卧槽，今天就一顿捣鼓解决了 Nano Banana 最恶心的一个问题。<br /><br />你现在可以自定义他生成和修改后的图片比例了。<br /><br />我们需要两张图片来完成这个任务：<br /><br />首先肯定是你之前生成的结果图，或者是你从其他地方获取的图片只是想更改比例也可以的。<br /><br />比如我前几天做的这个 AI 书法舞女，由于书法字体每张截图都不一样大，导致生成的图片大小也不一样，很烦，为了生成视频我还得自己裁切，这样就容易丢失信息。<br /><br />然后我们需要一张比例参考图，让 Nano Banana 将我们原来的内容替换到这张参考图上。<br /><br />他们长这样，这个图像内容我参考了 glif 的。<br /><br />但是他们的比例不全，我索性全部重做一遍，基本覆盖了所有常见比例，你也可以按这个样子自定义自己的比例，用Figma 就可以很简单。<br /><br />你要懒得做的话，文章最后有成品下载：https://mp.weixin.qq.com/s/RmM2sfcGlfMdmgH2DFqRug<br /><br />两张图片素材都有了以后，就可以探索提示词该怎么写了，我先是让 Nano Banana 将图片替换到比例模版图上，结果发现，会有类似的蓝色边，他没有帮我们扩图，只是简单的拼贴。<br /><br />于是在藏师傅疯狂迭代和尝试下，新生成的图片会基于原有图片的内容填充新的内容适应更改后的比例。<br /><br />提示词为：Redraw the content of Figure 1 onto Figure 2, add content to Figure 1 to fit the aspect ratio of Figure 2, completely clear the content of Figure 2, and only retain the aspect ratio of Figure 2.<br /><br />这里需要注意图片的顺序，想要修改的图放第一张，比例图放第二张。<br /><br />这就是教程的全部内容了，我们再来复习一下过程：<br /><br />1. 准备好你想要更改比例的图片以及对应的比例模版图<br /><br />2. 将想要更改比例的图片放第一张，将比例模版图放第二张，不建议更改顺序<br /><br />3. 输入提示词：“Redraw the content of Figure 1 onto Figure 2, add content to Figure 1 to fit the aspect ratio of Figure 2, completely clear the content of Figure 2, and only retain the aspect ratio of Figure 2. ”
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68b52b1c350688a1348d7663</id>
            <title>AI探索站 09月01日</title>
            <link>https://m.okjike.com/originalPosts/68b52b1c350688a1348d7663</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68b52b1c350688a1348d7663</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Sep 2025 05:11:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    大家玩得高興，我也湊湊熱鬧。看來圖一比較擬真，然而也仍都是假。活在AI模型裡，我們可以找到渴求的永生。<br />有冇好玩的指令也可以分享我🙏
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68b504af578795b229053d59</id>
            <title>AI探索站 09月01日</title>
            <link>https://m.okjike.com/originalPosts/68b504af578795b229053d59</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68b504af578795b229053d59</guid>
            <pubDate></pubDate>
            <updated>Mon, 01 Sep 2025 02:27:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这几天「二次元年轻人的第一次NTR」的AI图片传得到处都是，我也跑了一组，效果确实很能唤起难受的感觉……[doge]<br /><br />主要还是归功于Google的nano banana模型在保持一致性上的优秀表现，出图原理就是把原画喂给nano banana——也就是图里手机屏幕上的那张——然后再以其为基准生成经典的餐厅构图。<br /><br />我把推友Tz大神的提示词稍微改良了一下，也分享在这里：<br /><br />```<br />A cinematic scene inside a fast food restaurant at night.  <br />Foreground: a lonely table with burgers and fries, and a smartphone shown large and sharp on the table, clearly displaying the uploaded anime/game character image.  <br />A hand is reaching for food, symbolizing solitude.  <br /><br />Midground: in the blurred background, a couple is sitting together and kiss.  <br />One of them is represented as a cosplayer version of the uploaded character:  <br />- If the uploaded character is humanoid, show accurate cosplay with hairstyle, costume, and signature props.  <br />- If the uploaded character is non-humanoid (mecha, creature, mascot, etc.), show a gijinka (humanized cosplay interpretation) that carries clear visual cues, costume colors, and props from the reference image (armor pieces, wings, ears, weapon, or iconic accessories).  <br />The other person is an ordinary japan human, and they are showing intimate affection (kissing, holding hands, or sharing food).  <br /><br />Background: large glass windows, blurred neon city lights outside.  <br />Mood: melancholic, bittersweet, ironic, cinematic shallow depth of field.<br /><br />[reference: the uploaded image defines both the smartphone display and the cosplay design, with visible props emphasized]<br /><br />Image size is 585px 1024px<br /><br />```<br /><br />* 推荐在AI Studio里生成，体感上比Gemini质量要高。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68b32053f6ed4bc2864ea788</id>
            <title>AI探索站 08月30日</title>
            <link>https://m.okjike.com/originalPosts/68b32053f6ed4bc2864ea788</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68b32053f6ed4bc2864ea788</guid>
            <pubDate></pubDate>
            <updated>Sat, 30 Aug 2025 16:01:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    大聪明（赛博禅心）刚才发了个 Nano Banana 一图读懂XXX的提示词。<br />非常适合用来学习和解释一些概念，浅显易懂。<br />但他那个是针对 Lovart 搞的，我优化了一下，现在单独用Nano Banana也可以稳定生成，而且排版更加一致。<br /><br />这么好的点子怎么能不做个产品呢？ 来了朋友们，Nano Banana 解答世间万物 只要你输入概念，他就会给你生成三张图文并茂的解答卡片：yw.app/hZtZkst<br /><br />提示词：Help me generate multiple 16:9 doodle-style images to explain the concept of "futures" to middle school students. The images should have a consistent colorful, thick-pencil hand-drawn style, be rich in information, feature English text, use solid color backgrounds, have outlines around the cards, and include uniform titles, similar to a PowerPoint presentation.
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68afdc69704e30c9e4ab5a1c</id>
            <title>AI探索站 08月28日</title>
            <link>https://m.okjike.com/originalPosts/68afdc69704e30c9e4ab5a1c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68afdc69704e30c9e4ab5a1c</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Aug 2025 04:34:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很荣幸作为 Google AI Asia 的开场嘉宾来介绍下 Manus 近期的进展。除了上午的 panel 和 keynote 外，下午三点我还会分享 Manus 背后的几点产品设计与技术思考，如果在现场欢迎来听听。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ae821114af706d82dbd41b</id>
            <title>AI探索站 08月27日</title>
            <link>https://m.okjike.com/originalPosts/68ae821114af706d82dbd41b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ae821114af706d82dbd41b</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Aug 2025 03:57:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🧙‍♀️我无数次表达过 GPT image 是真正的魔法。但难以置信的是，仅仅半年时间Gemini 2.5 flash image 就将这种魔法上升到了全新的层次：<br /><br />- 10倍的生成速度<br />- 惊人的品质和一致性<br />- 几乎完全免费<br /><br />值得再次强调是，获取这种魔法的关键就是亲自尝试——「对话」的能动性成为了唯一的门槛。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</id>
            <title>AI探索站 08月12日</title>
            <link>https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Aug 2025 09:23:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    遇到了一个有趣的问题，正好落在 AI 模型的能力边界处：试证明不可能把平面分成无穷个圆的无交并。<br /><br />在我尝试的所有模型里，只有 GPT 5 thinking model 成功做了出来（虽然花了点时间）。<br /><br />有趣的不是这个结论，而是观察它们的思路。所有失败的模型都有个共同点：它们的思考基本上是从文字到文字的。它们会调用自己脑海中各种已有的定理和知识，然后漫无目的地试图拼凑出一个证明，但所有这些定理，不管是拓扑的还是几何的还是测度的，对它们来说都是纯粹字面意义上的陈述。Qwen 的思考过程最典型：它滔滔不绝想了很久，但很显然从头到尾它都并不真的理解它在说什么。圆也罢，开集闭集也罢，Baire 纲定理也罢，对它来说都是纯粹的概念，给人的感觉是它甚至并不真的知道「圆是圆的」。<br /><br />微妙之处在于，这种「没有几何直觉的几何思考」在某些时候其实未必是一种劣势。现代数学早已挣脱了对三维现实想象的依赖，大部份数学思考本来也确实是在纯粹的概念思辨空间中进行（特别是当问题进入代数乃至范畴论的领域的时候，这时从概念到概念的思考就变成了一种必然）。有的时候，几何直觉甚至反而会成为一种束缚，特别是当思考高维空间的时候，基于低维现实的直观常常是有误导性的。在这些问题上，AI 的「盲目」反而带来了自由，使得它不必受困于视觉直觉。——当然，人类的视觉直觉可能会渗透进人类的文本语料里，在某种程度上「污染」AI，但这是另一个问题。<br /><br />然而对原问题来说，因为这是一个低维问题，直觉在这里不但有用，而且能大大缩短思考搜索的难度。在这一点上，一个把圆只作为抽象概念来理解的 AI 就会有巨大的劣势，因为它无法享受到几何直觉带来的跳步。这种直觉使得人可以一眼「看出」关键的构造，而这种构造在文本层面被搜索出来是困难的。<br /><br />考虑到 AI 的应用毕竟大多数情况下还是为了解决世界现实问题而不是思考高维几何，有几何直觉的 AI 会在大多数问题上显得聪明得多。于是一个现实问题是，这种直觉是只有依赖多模态的训练才能获取，还是可以通过精巧的文本训练就能实现？这有点像是 AI 领域的玛丽房间问题。这是一个经典的知识论思想实验：一个从出生就生活在黑白房间里、精通颜色物理与神经机制的科学家玛丽，当她第一次走出房间看到红色时，她是否获得了新的知识？<br /><br />今天大多数 AI 领域的困难都可以归结于此。人类是自己感官的奴隶，我们听到、看到、闻到，我们体会身体激素的涨落，我们想象、困惑、愤怒，然后试图把这一切投射在文字空间里。AI 则正好相反，它们在文字里理解这一切，但最终需要努力地——有时候是徒劳地——明白，一个圆在什么意义上是圆的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68956c79369da0a84be8c3a2</id>
            <title>AI探索站 08月08日</title>
            <link>https://m.okjike.com/originalPosts/68956c79369da0a84be8c3a2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68956c79369da0a84be8c3a2</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Aug 2025 03:18:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ✨ GPT-5 初体验<br /><br />作为ChatGPT 的深度同行者，我在GPT-5 发布这个重要节点，选择了最朴素的交流方式—— 模拟大学生询问它有什么特别之处？ GPT-5  以极快的速度输出了一张场景匹配表，隐约揭示出我们正站在新的分水岭。<br /><br />随后，想到了ChatGPT最新Study模式正风靡全球，想看看它会怎么介绍给新时代的中学生们；让GPT-5 写了欢迎信进行自我介绍；GPT-5 非常快、而5 Pro的缜密和深度令人印象相当深刻。<br /><br />回想起任天堂刚刚发布了一个独立游戏的直面会还没看，要不先让Agent 帮我梳理一下？  GPT-5 在 Agent 模式花了18分钟，列出了一份详实的清单：好家伙，21个新游、熟悉面孔不多；不过铲子骑士家出的新作《挖掘者米娜》很期待呢<br /><br />打开Open AI 的GPT-5直播发布会，气氛依旧温暖、平等并充满人文气， 其中关于 GPT-5 语音模式的对话意外相当亲切；于是拿起手机端也聊了几句，更智能、也更个人化（调皮），我知道以后的日子里更离不开它了。<br /><br /> GPT-5的发布会如老朋友般松弛，这与当年的苹果式发布会炫酷创新形成鲜明反差。任何一个保持开放、拥抱变化的AI 创造者来说，无论过去三年多么的波澜壮阔，也会在这个时刻有那么点怀旧；Open AI 也找来了早期员工分享2022年底正式发布前，内部还称呼这个产品还叫Chat with GPT的往事，不疾不徐、简约克制。<br /><br />然而，新时代的改变又是极为剧烈的：过去我们与AI对话，现在我们委托AI执行；每天数十个任务ChatGPT Agents ——做研究、写创意文案、完成海量设计和编码。这个全能助手已经彻底融入工作和生活，比移动设备更加亲密和自然。 <br /><br />我知道无法在短短几十分钟揭示GPT-5的全貌， 便让它以自己最擅长的方式—— Deep Research ——进行一次深度回顾。<br /><br />三年巨浪，我们从旁观者成为创造者。这不只是技术进步的见证，更是每个深度用户内心变迁的缩影。 相信你也能在这个回顾中找到自己的心路历程。Enjoy～<br /><br />《从ChatGPT到GPT-5：三年AI革命的全景回顾》<br />https://chatgpt.com/s/dr_6895633264248191913fdb1138eaf853
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>