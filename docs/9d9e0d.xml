<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6901ce18d9abb9785d02257d</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/6901ce18d9abb9785d02257d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6901ce18d9abb9785d02257d</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:19:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    谷歌昨晚发布了新的 AI 设计产品，想法挺屌的<br /><br />只需要只需要把你的官网链接给他，他就会提取品牌设计相关的所有元素，帮你生成营销海报<br /><br />下面是使用教程和具体的产品分析👇<br /><br />目前这个产品在美国、加拿大、澳大利亚和新西兰推出，需要尝试的注意 IP。<br /><br />长文链接在这里：https://mp.weixin.qq.com/s/TQRl_TX7iXUIzcYCBr5LYg<br /><br />我试了一下之后发现，如果优化一下这个思路未必不能再造一个 AI 版 Canvas，操作成本低，自定义程度高。<br /><br />在你进到产品里之后只有一个非常简洁的网址输入框，直接输入你的官网地址点击 Continue 就行。<br /><br />我们先输入我们的老朋友 Lovart 的官网，因为他们的设计比较一致，同时官网信息给的也比较丰富。<br /><br />Pomelli 会开始分析官网中涉及品牌的各种信息比如配色、字体、产品能力等。<br /><br />稍微等待一会之后，他就会根据从网站爬取的信息，帮你创建一个关于这个产品的品牌 DNA 卡片。<br /><br />如果你做品牌设计的话肯定很熟悉，包括产品 Logo、品牌字体、主要配色、各种主页上的图片素材，还有产品能力以及商业上的定位关键词等，非常详细。<br /><br />当你觉得上面的信息没问题的时候你就可以点那个「looks good」然后进入到生成页面了，他会在下方根据你的品牌 DNA 生成几个用于预览的设计稿。<br /><br />你也可以在输入框输入你需要的营销活动内容，他就会自动优化文案，帮你规划排版生成营销图片了。<br /><br />可以看到点击 「Generate ideas」 之后就会开始生成他会给你三个广告内容的创意，你需要先选择这部分。<br /><br />可以看到第三个的文案内容是比较符合这次营销的主题的，我们选择这个。<br /><br />在你选择文案主题之后，他就会开始生成对应的图片了，会给你四个选项。<br /><br />可以看到他给了四种完全不同的排版风格，比如第一种是比较专业的背景，第二种有点科技感，第三张偏人文，最后一张就是纯文字排版，比较醒目。<br /><br />如果你喜欢某一张图片的话，就可以点进去进行微调，这里我觉得第三张还行。<br /><br />微调的主要有四部分：背景图片、标题、内容、号召按钮。<br /><br />图片都是他从网站上爬取的图片素材，如果实在没有素材他也会调用 Nano Banana 生成背景图片。<br /><br />标题和内容这里主要调整的就是文案的内容以及文案样式，可以帮你生成新的文案。<br /><br />字体这里内置了一些，如果你改了之后就会重新生成。<br /><br />号召按钮 这里默认他是不生成的，如果你这张图是投放内容，需要有号召按钮需要点击的话，可以点击右边的生成按钮让他帮你生成。<br /><br />可以看到他生成的按钮颜色就是 Lovart 网站按钮的颜色，整个的一致性就会很高。<br /><br />可能你会看到海报下面有个「Fix Layout」的按钮，这个主要是为了修复在修改文案后，由于文字宽度和长度的不同导致的没有对齐的问题，如果他生成的海报有这个问题，可以点这个按钮。<br /><br />最后如果没问题的话点击下载按钮下载生成的海报和营销物料就行，下面这三张就是我在测试中生成还行的。<br /><br />好了这就是谷歌新的 AI 设计工具 Pomelli 的体验了。<br /><br />总得来说整个交互和产品点子是非常好的，如果是临时救急和批量生产广告内容也不错，总比代理商瞎搞强。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6901c89e4268c406fc41a671</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/6901c89e4268c406fc41a671</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6901c89e4268c406fc41a671</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 07:56:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    苹果美区账号注册最稳方法<br />无需信用卡，无需美国手机号，100%成功率。<br /><br />1、访问美区 Apple ID 注册页面<br />浏览器打开 appleid.apple.com，点击右上角「创建您的 Apple ID」。使用未注册过的邮箱（Gmail、 Outlook 等国际邮箱最佳）。<br /><br />2、填写注册信息<br />国家/地区务必选择「美国」。生日选择满18 岁以上日期。其他信息如实填写，手机号填写国内号码即（+86）。<br /><br />3、验证邮箱和手机号<br />查收邮箱和短信中的验证码，依次输入完成验证。通常1分钟内即可收到，若未收到检查垃圾邮件文件夹。<br /><br />4、登录并前往 App Store（重点）<br />在iPhone/iPad 的 App Store 中登录新账号（不要在iCloud 登录）。首次登录会弹出「检查账户信息」提示，点击「检查」。<br /><br />5、同意条款并填写付款信息<br />勾选同意条款，付款方式选择「无」。账单地址填写免税州地址（推荐俄勒冈州、特拉华州）。<br /><br />6、生成美国地址<br />访问meiguodizhi.com，点击「俄勒冈州地址」或「特拉华州地址」生成免税州地址，复制以下信息：<br />姓名、街道、城市、州、邮编、电话<br /><br />7、填写地址信息并完成<br />将生成的美国地址信息粘贴到对应字段，点击「下一页」完成设置。现在可以自由下载美区应用啦。<br /><br />🌟温馨小Tip<br />建议保持美区账号仅用于 App Store，日常iCloud 使用国区账号。需要付费购买 App时，可使用礼品卡充值（淘宝、美亚购买）。避免频繁切换地区，可能导致订阅服务中断。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69018d5b477e33c6e006d2c7</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/69018d5b477e33c6e006d2c7</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69018d5b477e33c6e006d2c7</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 03:43:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    让我们直接一点。<br /><br />如果你不是投资人和研究员，这些媒体热议的话题，跟你关系不大：<br /><br />- AGI 到底是什么，何时实现？ 会不会抢掉大家的饭碗？<br />- AI 硬件投资是否过剩？ 寒冬还是泡沫？<br />- Agent 到底有没有通用性，是新的基础设施还是过度炒作？<br />- Reinforcement Learning  走到了死胡同？ Scaling Law 还在扩展吗？<br />- 某某公司又融了多少钱， ARR突破了多少？<br /><br />真正决定你的未来，是这些问题：<br /><br />- 你日常使用哪几个模型？ 它们是最好的吗？你如何更新认知？<br />- GPT-5 到底有多少种模式？ Thinking 模式为什么重要？<br />- 推理模型在哪些应用场景，实实在在改变了我的工作和生活？ <br />- 重大突破的新产品（例如 Deep Research、Notebook LM、Sora、Claude Code等），你持续探索其边界吗？<br />- 除了日常Copliot， 每周这个尺度上，AI 工作流有哪些新进展？<br />- 原型驱动为什么重要？为什么软件和创作领域专业人士认为，它在重塑创造范式？<br />- 对任何一个模型或一个新产品，下定论之前，我们深度探索过 10 次以上吗？那些使用 1000小时以上的人是如何看待的？<br /><br />好奇心与充满野心应用 AI 并不冲突；难的是突破认知偏见、对抗噪声。<br /><br />如费曼先生所言，「凡是我不能创造的，就意味着我还不理解」 。少围观， 多创造。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/690174d92c7c9e2ff1ef07f0</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/690174d92c7c9e2ff1ef07f0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/690174d92c7c9e2ff1ef07f0</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 01:58:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🚀 YouMind 0.5 正式发布<br /><br />YouMind 是一个专门为内容创作者、内容学习者打造的一站式 AI 工作室。<br /><br />你是否记得，收集的一堆资料，再也没去看了。你是否记得，很想开始创作，但始终卡在第一篇。<br /><br />有了 YouMind，这一切挑战，依旧还是挑战。然而一个好的工具，可以塑造一个良好的环境。拥有 YouMind，你想创作的任何起心动念，就拥有了开始行动的翅膀。<br /><br />欢迎使用：https://youmind.com<br />大胆创作，不止于学
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 14:15:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    在此推出 FlowithOS，全球首个为 Agent 原生打造的操作系统，可能是你的最后一个浏览器。<br /><br />FlowithOS 让 AI 可以 100% 像人一样与整个数字世界交互。<br /><br />- browser-use 浏览器使用: 让它可以自主点击网页、上传/下载文件、甚至可以操纵第一视角游戏，与其它玩家对战。<br />- terminal-use 终端使用: 让它可以通过命令行、访问和操作你的整个计算机，帮你整理文件、或者直接批量创造。<br />- script-use 脚本使用: 让它可以自主根据你的需求和网页状态、实时生成脚本，以 100 倍效率批量获取信息。<br /><br />除了这些超能力外，FlowithOS Agent 还搭配了 online-RL 和自我进化和学习的能力，配合经验和记忆系统，你的 OS Agent 可以随着时间变得越来越聪明、越来越懂你。<br /><br />在 Online-Mind2Web 全球评测中，FlowithOS 以压倒性接近满分成绩超过 OpenAI Atlas、Gemini 2.5 Pro CU 等顶尖浏览器 Agent，成为现地表最强浏览器智能体。<br /><br />现在，FlowithOS 公测版已全量上线，支持 Windows、Mac 所有平台，在 flowith.com 即可开始
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 13:55:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    无意间发现 GPT 画这种信息图的还原度挺高啊<br /><br />搞成 SVG 以后还能扔进 Figma 里面改字体，改完就更像了<br /><br />让 GPT 总结了一套提示词👇<br /><br />用途：我发一张信息图或海报截图，你把它高保真还原为可编辑 SVG，整体排版尽量一致，但文字改成 {中文}（或保持原语言）。<br /> 提示词：<br />指令<br />请把我发送的图片转成可编辑 SVG：<br /><br />保持版式与层级结构（标题、分区、图标、箭头、图表等）尽量一致；<br />所有文字保留为  可编辑（不要转路径）；<br /><br />所有图形用向量元素（////），不要嵌入位图；<br /><br />颜色与风格尽量接近原图；<br /><br />分组与命名清晰：01_Header、02_Section_*、Icon_*、Chart_*；<br /><br />画布尺寸按原图推断；坐标/描边尽量用整数；<br /><br />生成文件到 /mnt/data/infographic.svg 并给出下载链接。<br />若图片中有不清晰的内容，请做合理假设并在结果底部列出“假设项”。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69003452e74e87a1be58b1f8</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/69003452e74e87a1be58b1f8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69003452e74e87a1be58b1f8</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 03:11:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Manus联创的“血泪”教训：为什么上下文工程，而非模型微调，才是护城河？<br /><br />一位拥有10年NLP（自然语言处理）经验的AI创业公司联创坦言：“对于创业公司，过早微调（Fine-tuning）模型是一个陷阱。”<br /><br />这不是危言耸听。<br /><br />Manus的联合创始人兼首席科学家Peak，在最近与LangChain创始人的对谈中，分享了他的“血泪教训”：他的上一个产品，迭代速度被长达1-2周的模型训练周期活活拖死。<br /><br />这一次，他选择把所有赌注压在“上下文工程”（Context Engineering）上，并为此，他的团队在短短几个月内，将产品重构了整整5次。<br /><br />为什么他如此笃定？<br /><br />1. “微调”的陷阱：被模型拖垮的“上一个”公司<br /><br />在创立Manus之前，Peak已经在NLP领域摸爬滚打了10年。他的上一个创业项目，和现在许多AI团队一样，选择了“训练自有模型”的重度路线。<br /><br />结果是灾难性的。<br /><br />“我们的产品创新速度，完全被模型的迭代速度给限制了。”Peak回忆道。<br /><br />在产品还没找到PMF（市场契合点）的阶段，他们却在花费大量时间“提升那些可能根本不重要的基准测试”。一个单一的“训练-评估”周期，就需要1到2周。<br /><br />当团队在焦急地等待模型时，市场窗口早已关闭。<br /><br />但最大的“陷阱”还不是时间，而是“僵化”。<br /><br />“当你微调一个模型时，”Peak解释道，“你通常会固定一个‘行动空间’（Action Space）。”<br /><br />这就像你花重金打造了一把精妙绝伦的“屠龙宝刀”。但如果第二天，巨头发布了（比如多模态MCP），市场不再需要“屠龙”，而是需要“飞天”，你这把刀就成了一堆废铁。<br /><br />“Manus的设计就曾被MCP的发布彻底改变。”Peak坦言，如果他们当时死磕微调，唯一的下场就是被市场活活抛弃。<br /><br />2. 划清界限：AI应用层的真正边界<br /><br />经历了上一次的“痛苦”领悟，Peak这次为Manus找到了一个清晰无比的战略边界。<br /><br />“你必须坚定地划清你的界限（Be firm about where you draw the line）。”<br /><br />对于AI应用层创业，这条界限就是“上下文工程”。<br /><br />Peak认为，这是目前应用和模型之间最清晰、最实用的边界。创业公司应该“尽可能久地”依赖通用大模型，而不是试图在模型层与巨头竞争。<br /><br />巨头的护城河是“模型”，而应用层的护城河，就是你“使用”模型的能力——即“上下文工程”。<br /><br />那么，这个听起来高深的“上下文工程”到底是什么？<br /><br />3. “上下文悖论”：Agent的阿喀琉斯之踵<br /><br />2022年，我们谈论的是“提示词工程”（Prompt Engineering），它解决的是单次交互。<br />而2024年，我们面临的是“上下文工程”（Context Engineering），它要解决的是Agent（智能体）的长序列、多轮工具调用。<br /><br />LangChain的创始人Lance指出了一个“上下文悖论”：<br /><br />Agent要完成复杂任务，必须大量调用工具（典型任务约50次）来获取上下文。<br /><br />但上下文越长，Agent的性能就越差，成本也呈指数级上升。<br /><br />更糟糕的是，Peak发现，即使是100万Token的上下文窗口，模型在处理到200K（约20万）时，性能就开始“腐烂”（Context Rot），出现重复、缓慢和质量下降。<br /><br />“上下文腐烂”的阈值，大约就在128K到200K之间。<br /><br />你的Agent又慢又笨，不是模型不行，是你的“上下文工程”没做好。<br /><br />4. 破局：上下文工程的4大支柱<br /><br />如何解决这个悖论？LangChain的Lance总结了业内顶尖团队（包括Manus）都在使用的4大工程支柱：<br /><br />上下文卸载 (Offloading)<br /><br />做法：不把所有信息都塞进上下文。比如，一个万字的网络搜索结果，只在上下文中返回一个文件路径（file.txt），Agent需要时自己去读。<br /><br />场景：处理大文件、大输出。<br /><br />上下文检索 (Retrieving)<br /><br />做法：把信息（如记忆）存储在外部（如向量数据库），在需要时通过RAG或简单的grep命令检索回来。<br /><br />场景：长时记忆、知识库。<br /><br />上下文隔离 (Isolation)<br /><br />做法：使用多智能体（Multi-Agent）架构，每个子Agent只处理自己的小上下文窗口，互不干扰。<br /><br />场景：复杂任务拆解。<br /><br />上下文缩减 (Reducing)<br /><br />做法：这是最核心也最精妙的一步，即在上下文“腐烂”之前，主动对其进行“瘦身”。<br /><br />而Manus团队，正是在“上下文缩减”上，做到了极致。<br /><br />5. Manus实战：“压缩”与“摘要”的精妙艺术<br /><br />Peak的团队将“缩减”分为了两种截然不同的操作：<br /><br />1. 压缩 (Compaction)：可逆的“瘦身”<br /><br />定义：删除那些可以从外部（如文件系统）重建的信息。<br /><br />例子：一个工具调用，完整信息是{path: "file.txt", content: "..."}。在“压缩”后，只保留{path: "file.txt"}。<br /><br />优势：信息“零”丢失，只是被“外置”了。<br /><br />2. 摘要 (Summarization)：不可逆的“遗忘”<br /><br />定义：对历史信息进行总结，彻底丢弃原文。<br /><br />优势：大幅度释放上下文空间。<br /><br />Manus的策略堪称精妙：<br /><br />设置“腐烂”闹钟：首先，团队会设置一个“腐烂阈值”，比如128K。<br /><br />先“压缩”，后“摘要”：当上下文达到128K时，系统首先触发“压缩”。只在“压缩”的收益也变小时，才万不得已触发“摘要”。<br /><br />“压缩”的艺术：执行“压缩”时，只压缩最老的50%历史，并保留最新的50%工具调用的完整信息。这能确保模型有足够的新鲜“样例”来模仿，防止其行为错乱。<br /><br />“摘要”的技巧：执行“摘要”时，会使用原始的、未经压缩的数据来总结，以保证信息保真度。并且，同样会保留最后几个工具调用的全量信息，防止模型“忘记自己刚刚在干什么”。<br /><br />6. 在流沙上构建：5次重构与“更贵”的开源<br /><br />这套复杂的“上下文工程”架构，就是Manus的护城河。它让Manus有能力在“流沙”（不断迭代的大模型）之上构建稳固的应用。<br /><br />“从3月到现在，我们已经重构了5次。”Peak说。<br /><br />这种“上下文工程”能力，也让他们在选择模型时有了更反直觉的洞察。<br /><br />Peak甚至认为，对于Agent应用，使用开源模型可能“更贵”。<br /><br />“这很有趣，关键在于成本。”他解释道，“Agent的输入（上下文）远大于输出，KV缓存至关重要。”而头部API厂商（如Anthropic）在分布式KV缓存上做了坚实的基建，使得在超长上下文中，API的成本甚至低于自托管的开源模型。<br /><br />7. 结语：构建更少，理解更多<br /><br />回顾Manus的历程，Peak给出了他最深刻的领悟：<br /><br />“我们最大的飞跃，不是来自添加了更花哨的上下文管理技巧，而是来自‘简化’和‘移除不必要的层’。”<br /><br />“我们最终的哲学是：构建更少，理解更多（Build less and understand more）。”<br /><br />这位10年NLP老兵最后总结道：<br /><br />“上下文工程的真正目标，不是让你的系统更复杂，而是让模型的工作，变得更简单。”<br /><br />from Langchain<br /><br />Context Engineering for AI Agents with LangChain and Manus
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68fad41012ce30c3dd448049</id>
            <title>AI探索站 10月24日</title>
            <link>https://m.okjike.com/originalPosts/68fad41012ce30c3dd448049</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68fad41012ce30c3dd448049</guid>
            <pubDate></pubDate>
            <updated>Fri, 24 Oct 2025 01:19:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    握草，巨牛逼，有个UP主叫AI研究室-帆哥，他给视障人士制作了一款AI眼镜，硬件成本只要一百多块钱，就能让盲人/视障人群自由出行。<br /><br />这个小哥戴上自家产品，模拟了盲人出行的一天，在盲道上走路，听AI提醒+纠错避开障碍物，过满是车流的红绿灯。到超市买水果，通过摄像头与耳机的指引拿到西瓜、黄瓜。让AI眼镜识别上海外滩的夜景，为他讲述眼前到底是怎样的造型与风韵，犹如聆听一首散文诗。<br /><br />一个3D打印眼镜架+摄像头+图传+扬声器+麦克风+陀螺仪+多模态大模型Qwen Omni=AI眼镜。<br /><br />核心硬件成本只要143.28块钱。 <br />这是我从未想到过的低价…<br /><br />市面上一些雷达避障的AI眼镜要3000块钱…<br />这省下的就不是一块两块了。<br /><br />关键帆哥把它的配件清单+agent代码开源了，放在了魔搭社区，任何厂家和个人都能用这套纯视觉避障方案做眼镜。<br />这是一种AI时代的伟大。<br /><br />我觉得啊，咱们中国的盲道之所以常常被占用，是盲人并没有真正的进入我们的生活，当帆哥蒙住双眼做道路测试时，很多路人主动提供了帮助，提醒他避障，为他挪动盲道上的车等等，体现出了人性上的伟大。<br /><br />#AI能帮视障群体做什么# 很多人在评论区建言献策，认为盲人不需要拍照录像功能，也不需要镜片，设计思维可以超出常理，像汽车设计方案那样弄更多的摄像头，用更好一点的图传，与高德等地图APP深度合作，让视障人群能够安全的抵达心目中的彼岸。<br /><br />原来盲人喜欢听的有声书是可以由自己谱写的。<br /><br />可能有一天，中国的盲人能去云南闻花香，去高山林莽听虫鸣鸟叫，去广袤的海岸线品尝各个海域海水的咸淡。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</id>
            <title>AI探索站 10月21日</title>
            <link>https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Oct 2025 00:30:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek的论文每篇都是精品，R1养活了一批研究强化学习的人，OCR这篇意味CV研究员的春天到来了。用图片替代文本输入，确实是很有开创性的想法。DeepSeek真是开源菩萨，换做CloseAI估计要藏一辈子。<br /><br />大模型在处理长文章时，消耗的计算量会爆炸性增长。<br /><br />但如果把文字“画成图片”，模型只需要很少的“视觉 token”就能理解同样内容。<br /><br />就像人看书一样，我们也是靠视觉来阅读文字，如果这个方向靠谱，那么我们就相当于用OCR技术给大模型装上了眼睛。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</id>
            <title>AI探索站 10月18日</title>
            <link>https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Oct 2025 10:00:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天读到了一个非常有趣的 idea。<br /><br />背景是 Dwarkesh Patel 和 Andrej Karpathy 的一个对谈，里面提到了一个智能领域的常见问题：不管是人还是 AI，如果局限于自己的经验，用经验指导自己的行为， 又在这个行为的基础上累计经验，如此循环下去，最终总会崩溃（这里的「崩溃」不是心理意义上的，是智能层面上的）。一个健康的心智需要不断通过从不在自己经验范围内的世界（比如同他人的交谈，和与自己行为模式不符的人合作，etc.）获得外部熵来阻止这种崩溃。小孩还没有对生活过拟合，所以不太容易崩溃，而成年人崩溃的风险则越来越大。<br /><br />以上是背景。下面是那个有趣的 idea，来自2021年的一篇 paper "The overfitted brain: Dreams evolved to assist generalization"。它的主旨是说：人类做梦是防止这种过度拟合和崩溃的一种方式。做梦之所以具有进化适应性，是因为它会让你置身于与你日常现实截然不同的奇特情境中，从而防止这种过度拟合。<br /><br />这里有个鸡生蛋蛋生鸡的问题：既然过拟合体现为大脑无法学到分布外的规律，大脑是如何构建出这些分布外的梦境的？Hoel 的解释是梦的构建有一个非智能的 noise injection 步骤，这些随机噪声在白天建立的神经连接中渗透，产生奇异的、扭曲的、不连贯的 corrupted sensory inputs，从而把大脑从过拟合的陷阱中拯救出来。<br /><br />虽然这只是一个假说（而且是一个非常新的理论），但我越想越觉得它非常精妙。按照这种视角，梦的价值不在于它的逼真，而恰恰在于它的不逼真——梦境与清醒时的经历（训练集）如此不同（但又不是纯粹意义上的噪声），所以才能迫使大脑学习到更具泛化性的表征而不是仅仅记忆真实经历本身。<br /><br />梦通过不可能存在的反事实体验迫使我们更好地理解世界的本质。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>