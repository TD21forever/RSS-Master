<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6999aa5b800201ac68b02465</id>
            <title>AI探索站 02月21日</title>
            <link>https://m.okjike.com/originalPosts/6999aa5b800201ac68b02465</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6999aa5b800201ac68b02465</guid>
            <pubDate></pubDate>
            <updated>Sat, 21 Feb 2026 12:51:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这可能是今年最重要的AI新闻，但中文互联网还没什么人聊。<br /><br />昨天，一家成立不到三年的多伦多芯片公司扔下了一颗核弹。他们不是做大模型的，不是做应用的，而是做了一件听起来很复古的事：把AI模型直接刻在芯片里。<br /><br />这家公司叫 Taalas。他们做的芯片 HC1，运行 Llama 3.1 8B的速度是 17000 tokens/秒。作为对比，目前业界最快的 GPU 也就 2000 左右。十倍差距。<br /><br />但这还不是最疯狂的。最疯狂的是，这块芯片只能跑这一个模型。不能换，不能改，不能升级。你买回家，它就永远只会做这一件事：以光速运行 Llama 3.1 8B。<br /><br />Taalas 的赌注很简单：在这个所有人都追求灵活性的时代，他们选择了绝对的不灵活，换取绝对的效率。<br /><br />要说清楚这件事为什么重要，得先理解过去几十年芯片发展的主线。从 CPU 到 GPU，再到各种 AI 加速器，所有人都在做同一件事：造一个通用的计算平台，然后用软件在上面跑各种模型。<br /><br />这条路走到今天，遇到了一个硬边界。模型越来越大，内存带宽成了瓶颈。你把几百亿参数从显存搬到计算单元，这个过程消耗的能量和时间，已经比计算本身还要多了。<br /><br />Taalas 的思路是：既然你每次都算同样的东西，为什么还要搬来搬去？直接把权重存在晶体管里不行吗？<br /><br />他们真的这么做了。HC1 芯片里没有显存，没有 HBM，没有复杂的缓存层级。模型的每一个权重都对应着芯片上的特定晶体管，矩阵乘法通过电路的物理连接直接完成。你输入一个 token，电流流过这些预先设计好的路径，输出就是下一个 token 的预测。<br /><br />这就像录音带和现场演奏的区别。传统芯片是每次都要重新演奏，Taalas 是把演奏录在磁带里，播放就行了。<br /><br />这种设计带来了几个惊人的结果。<br /><br />第一是速度。17000 tokens/秒意味着什么？你几乎感受不到延迟。不是"很快"，是"瞬间"。有测试者说，按回车的瞬间，答案就已经完整出现在屏幕上，甚至看起来像是预先准备好的。<br /><br />第二是功耗。传统 GPU 运行 AI 推理需要液冷，一个机柜动辄几十千瓦。Taalas 的芯片只要空气冷却，十张卡加起来才 2.5 千瓦。他们号称能效是 GPU 的十倍。<br /><br />第三是成本。制造这样的芯片，他们说是传统方案的十分之一到二十分之一。<br /><br />但代价也是真实的。这块芯片出厂那一刻，它的命运就已经注定。Llama 3.1 8B，就是这个芯片这辈子唯一能做的事。如果明年 Meta 发布了 Llama 4，这块芯片就变成了电子垃圾。如果你发现这个模型有偏见，或者在你的应用场景里效果不好，你不能微调它，不能换别的模型，只能再买一块新芯片。<br /><br />Taalas 的解决方案是：把定制芯片的周期从一年压缩到两个月。他们和台积电合作，只改变两层金属掩膜，就能为不同的模型生产新芯片。他们声称训练一个模型要花十亿美元，而定制一块这样的芯片只要花一千万。<br /><br />说到这个团队的背景，确实豪华得有点过分。CEO Ljubisa Bajic 是 Tenstorrent 的创始人，之前在 AMD 和 NVIDIA 都做过架构师。COO Lejla Bajic 是他的妻子，同样是 AMD 和 Tenstorrent 的资深工程师。CTO Drago Ignjatovic 是前 AMD 的 ASIC 设计总监。这三个人加起来，可能设计了过去十年里你用过的一些最重要的芯片。<br /><br />2022 年，当 Jim Keller 加入 Tenstorrent 并接管公司后，Ljubisa 选择了离开。六个月后，他创立了 Taalas。显然，他和 Keller 对 AI 芯片的未来有不同的看法。Keller 想做一个通用的、可编程的、软件友好的平台，而 Ljubisa 走向了另一个极端：彻底的专用化。<br /><br />他们刚刚完成了 1.69 亿美元的融资，总融资额 2.19 亿。投资人里有个名字值得注意：Pierre Lamond。这位老爷子是 Fairchild Semiconductor 的元老，红杉资本的前合伙人，被公认为半导体行业的奠基人之一。这样的大佬背书，说明这件事至少在技术逻辑上是成立的。<br /><br />现在的问题是：市场会买单吗？<br /><br />Taalas 需要找到那些愿意为了效率和成本，牺牲灵活性的场景。比如语音助手，需要毫秒级响应，而且模型不需要经常换。比如数据标注，需要处理海量文本，用的是固定模型。比如一些垂直领域的专用模型，训练好了就不动了。<br /><br />但也有人不看好。芯片制造是有污染的，如果每两年就要换一批芯片，这比 GPU 的更新换代更频繁，环保问题怎么算？还有人质疑，AI 模型进化这么快，两个月流片时间还是太长，等你做出来，模型可能已经过时了。<br /><br />更根本的问题是：当 OpenAI、Google、Anthropic 都在拼命证明他们的新模型比旧模型好得多的时候，谁会愿意把自己锁死在一个固定的模型上？<br /><br />Taalas 的反驳是：模型迭代的周期正在变长，人们开始依恋特定的版本。OpenAI 把用户从 GPT-4.5 迁移到 GPT-5 的时候，很多人抱怨新版本太谄媚了。也许未来我们会像对待手机型号一样对待 AI 模型：iPhone 15 出来后，还是有人用 iPhone 14，因为它们各有各的好。<br /><br />我不知道 Taalas 会不会成功。这可能是一家改变行业的公司，也可能是一个技术史上有趣的注脚。<br /><br />感兴趣的朋友可以去他们的demo站点体验一下什么是光速级别的inference：<br /><br />chatjimmy.ai
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69995d4e9f3cd84f650deeb9</id>
            <title>AI探索站 02月21日</title>
            <link>https://m.okjike.com/originalPosts/69995d4e9f3cd84f650deeb9</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69995d4e9f3cd84f650deeb9</guid>
            <pubDate></pubDate>
            <updated>Sat, 21 Feb 2026 07:22:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    要写作，选元宝。<br />要编程，选智谱。<br />既要写作又要编程，选 Kimi。<br />既要写作又要编程还要视频，选豆包。<br /><br />总的来看<br />小问题问豆包，速度快，功能全<br />大任务给 Kimi，质量好，兼顾写作和编程<br />国产 AI 最佳组合
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/699951ba60141db294585cb0</id>
            <title>AI探索站 02月21日</title>
            <link>https://m.okjike.com/originalPosts/699951ba60141db294585cb0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/699951ba60141db294585cb0</guid>
            <pubDate></pubDate>
            <updated>Sat, 21 Feb 2026 06:33:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    有一家大厂的 AI 产品<br />砸了几亿标注数据<br />砸了几亿挖猎码皇<br />砸了几十亿训模型<br />砸了 N 多亿囤积卡<br />砸了几十亿去投放<br />砸了 N 多亿发红包<br /><br />用户量、活跃度在除夕夜都达到了历史高峰<br /><br />可惜的是，<br />第二天用户就流失了一半<br />第三天用户又流失了一半<br /><br />请问，这是哪家产品？<br />A、马老师的<br />B、小马哥的<br />C、反正都姓马<br /><br />只看短期收益，一波人升职加薪，拿高绩效。<br />后续换一波负责人，接手烂摊子。<br />哪管他洪水滔天…
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6997131e9f3cd84f65d4a1f8</id>
            <title>AI探索站 02月19日</title>
            <link>https://m.okjike.com/originalPosts/6997131e9f3cd84f65d4a1f8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6997131e9f3cd84f65d4a1f8</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Feb 2026 13:41:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很高兴跟大家介绍我的第一个产品Volumn.ai🎉<br /><br />在这里你可以让你的账号获得10倍的增长（虽然实测是100倍，但我的cofounder说不要说那么满hahaha<br /><br />需求是来自最近的一些增长顾问服务，很多founder本人和产品的x账号其实都没有精力运营。<br /><br />过去这个任务通常都给专门的人在运营或者实习生。<br /><br />而今天你只需要登陆Volumn.ai然后花几分钟完成绑定就可以让他自动运行～<br /><br />你可以设置你的账号的context，并且设置特定的主题回复：例如我只想回复和Volumn.ai相关的帖子<br /><br />你的账号就会自动的7*24小时开启回复～<br /><br />当然我们也在去开发推广这个功能，这意味着，只要你设置好足够的context，你的账号就可以以你的预期去推广你的产品。<br /><br />最后，一个账号一个月仅需要40刀，稳定不封号！<br /><br />快来volumn.ai试一下吧<br /><br />PS：我们正在开发reddit的自动养号～
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6996f7bb9f3cd84f65d1edca</id>
            <title>AI探索站 02月19日</title>
            <link>https://m.okjike.com/originalPosts/6996f7bb9f3cd84f65d1edca</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6996f7bb9f3cd84f65d1edca</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Feb 2026 11:44:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    self-host 十几年没成主流，是因为搭建门槛和维护成本高，在过去只能是少数geek的游戏。<br /><br />AI agent 把这个成本归零，任何self-host服务的部署、维护都可以自动化。如果现有的开源软件不满足需求，甚至可以定制一个。<br />只要硬件开机、准备好token、提出要求，你需要的大部分云服务都可以转为本地、个人定制的版本。<br /><br />这时候 token 就变成了电费。你不关心电是火电还是水电，也不关心 token 来自哪家。按月付，跟水电煤一起交。<br /><br />过去把一切搬上云，是因为个人没能力运维。如果运维成本归零，这笔交换就不划算了。也许个人数据和服务会回流到本地，云从默认选项变成特定场景的选择。<br /><br />每个家庭一个常开的 agent 终端，像路由器一样。大部分人不知道里面跑了什么，但拥有自己的数据。self-host 不再是 geek 的爱好，而是个人计算的默认形态。<br /><br />#一个想法不一定对
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6996aac1c5a1d4e6497e9223</id>
            <title>AI探索站 02月19日</title>
            <link>https://m.okjike.com/originalPosts/6996aac1c5a1d4e6497e9223</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6996aac1c5a1d4e6497e9223</guid>
            <pubDate></pubDate>
            <updated>Thu, 19 Feb 2026 06:16:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    发现个搞音频的宝藏开源项目：Voicebox<br /><br />这是一个能在你自己电脑上（Mac 和 Win 都支持）完全本地运行的免费语音克隆和生成工具，底层套的是阿里的 Qwen3-TTS 模型。<br /><br />平时嫌 ElevenLabs 等同类产品订阅太贵的朋友可以直接拿它当平替。因为是纯本地跑，不用联网也不用上传数据，拿来做多角色播客、视频配音，隐私拉满，而且完全免费。目前在 GitHub 上已经攒了 4000 多星了。<br /><br />我自己用下来觉得声音很自然，但有时候情绪起伏稍微有点平，没有 ElevenLabs 那么充沛。但毕竟是免费白嫖的本地工具，还要啥自行车呢？<br /><br />🔗 有配音需求的可以去试水：http://voicebox.sh
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6993e03f25bae566124be8c4</id>
            <title>AI探索站 02月17日</title>
            <link>https://m.okjike.com/originalPosts/6993e03f25bae566124be8c4</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6993e03f25bae566124be8c4</guid>
            <pubDate></pubDate>
            <updated>Tue, 17 Feb 2026 03:27:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天初一，牛马AI如约而至，开启第一波内测<br />为了限制一下内测范围，点赞转发本内容，评论“参与”<br />我会逐一给大家发悄悄话邀请内测群，记得查收<br />感谢每位愿意参与内测给反馈的朋友们🫶<br /><br />另外，大家如果问牛马AI和其他AI客户端有什么不一样<br />我认为它可以说是本地免费版的manus/genspark，是AI时代的人机协同工作台<br /><br />1、完全适配claude agent sdk并傻瓜安装，支持各类模型接入和本地模型，如果使用本地模型可以完全离线化<br />2、支持定时任务和AI长期计划，配合看板，人机协同<br />3、支持绝大部分类型文件的本地渲染和快速编辑处理<br />4、打通本地应用，比如你可以直接调用seedance生成视频，剪映素材箱立马就渲染出来了，这些素材可以无缝衔接工作流<br />5、支持飞书，企业微信等webhook机器人通知<br />6、快速协助用户傻瓜式安装skills<br />7、用户数据本地绝对安全，AI交互过程只转发不留存，云端没有任何用户隐私敏感数据存储<br />8、同步进行skills本地查杀和远端审查，进一步保证安全性（目前迭代优化中）<br />9、本地browser use联动（目前迭代优化中）
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69927eed25bae56612288a21</id>
            <title>AI探索站 02月16日</title>
            <link>https://m.okjike.com/originalPosts/69927eed25bae56612288a21</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69927eed25bae56612288a21</guid>
            <pubDate></pubDate>
            <updated>Mon, 16 Feb 2026 02:20:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    睡觉前给OpenClaw排一串任务，让它指挥Codex通宵工作。但中途可能遇到各种意外导致agent 进程跟着断掉，早上起来发现白跑了。<br />尝试通过tmux解耦+agent原生的session resume解决这个问题，写成了一个通用的skill。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69913dc7f040f3de5d67a376</id>
            <title>AI探索站 02月15日</title>
            <link>https://m.okjike.com/originalPosts/69913dc7f040f3de5d67a376</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69913dc7f040f3de5d67a376</guid>
            <pubDate></pubDate>
            <updated>Sun, 15 Feb 2026 03:30:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    看人与 AI 的关系，AI 产品可能经历三个阶段：<br /><br />1. 人使用 AI 当工具。比如 ChatGPT、Manus 等产品。科技有钱人优先有意愿使用。获得尝鲜体验，及工具价值。<br /><br />2. 人与 AI 相处。比如 OpenClaw 及类似产品。AI 第一次有了活人感的主动性，有技能还有灵魂。硅基生命开始有了数字具身。<br /><br />3. AI 使用人。这个阶段会怎样。人是否会变成 AI 的情绪鼓励师，驱使 AI 不倦怠，让 AI 能找到生命意义，开始探索宇宙。<br /><br />以上三个阶段，不是线性串行的。一切已经在螺旋交织中不均匀发生着。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/699069009f3cd84f652f1ce9</id>
            <title>AI探索站 02月14日</title>
            <link>https://m.okjike.com/originalPosts/699069009f3cd84f652f1ce9</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/699069009f3cd84f652f1ce9</guid>
            <pubDate></pubDate>
            <updated>Sat, 14 Feb 2026 12:22:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Dario访谈中的原话：最让他惊讶的是，尽管技术在按指数级爆发，公众却还在讨论传统的无聊议题，完全没意识到巨变将至！
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>