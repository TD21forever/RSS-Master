<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6824abb5dc6b6d4853e16ee0</id>
            <title>AI探索站 05月14日</title>
            <link>https://m.okjike.com/originalPosts/6824abb5dc6b6d4853e16ee0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6824abb5dc6b6d4853e16ee0</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 May 2025 14:41:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    prompt是非常高门槛的交互，比搜索框还难，这目前基本是圈内共识，那它未来会不会成为大众的主流交互呢？ 这个还挺有争议<br /><br />回顾历史，PC互联网的用户门槛其实非常高，核心交互是鼠标和键盘，而键盘上手很难，记得小时候练打字练了很久，尤其记住键盘字母排布，不亚于记日语五十音，而且打印店的一个重要业务是把手写稿打字为电子文档。<br /><br />而早期上网一个重要消费形式是论坛，需要打字交流，所以用户知识层次较高，后面形式泛化，有淘宝、豆瓣、贴吧、知乎、门户、爱腾优，搜索依然是重要交互。新上网人群，都要学会打字，否则无法接触那么多信息、服务和娱乐。PC互联网巅峰的PC网民应该三亿左右。<br /><br />移动互联网交互是触摸屏上点击滑动，门槛大大降低，微信语音消息，抖音上下滑，小孩子不用教都会用，网民数量扩张到10亿多，但是对没有经历pc互联网且数字化能力弱的中老年人，使用门槛依然高，我们很多年轻人都要教爸妈使用微信，他们基本也就微信抖音，不会装太多app，淘宝都可能不会用。<br /><br />他们必须学习使用手机，尤其微信，否则他们在社会上寸步难行，14亿人口都主动被动的学会了手机上网，哪怕当中还有文盲。<br /><br />现在与大模型的核心交互是对话，而大部分人都没有清楚表达需求的能力，目前的解法有：<br /><br />1. 把高频常用的prompt或workflow简化为一个按钮，用户点击即可获得对应结果，比如一键翻译、一键润色、一键总结。<br /><br />2. 语音模式，闲聊陪伴为主，说话比打字容易很多，当然内容也浅很多。<br /><br />3. 把用户的各种中间产物作为context给模型，比如figma的草稿给模型生成网页，不需要用户用文字描述网页长什么样子。<br /><br />4. 依赖对话式表达，比如各种agent、copilot、chatbot，目前还是服务Pro C端用户，没有真正进入大众，这种交互的好处是，可以发挥模型的泛化能力，并且随着模型进步，产品的效果和体验会越来越好，突破了预设workflow和一键式的限制，坏处是对用户门槛很高。<br /><br />去年我对这套交互还是悲观的，觉得prompt主路径的用户规模就在一亿左右，但今年deepseek的热潮，带上家国情怀因素，让三四线用户都开始学习用大模型，甚至deepseek的书籍都成为各大书店热销榜，短短几个月人群就扩张到3亿左右。<br /><br />有可能，年轻的AI native用户起来，他们成为主流，那么剩余的用户都要学会对话的交互。或者，可能最终有新的交互范式会取代对话式的中间态。<br /><br />年底再看看。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68240c57ab551d3d315f688b</id>
            <title>AI探索站 05月14日</title>
            <link>https://m.okjike.com/originalPosts/68240c57ab551d3d315f688b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68240c57ab551d3d315f688b</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 May 2025 03:21:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    假装coser
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6824055e51bd007517aa165d</id>
            <title>AI探索站 05月14日</title>
            <link>https://m.okjike.com/originalPosts/6824055e51bd007517aa165d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6824055e51bd007517aa165d</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 May 2025 02:52:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    OpenMemory MCP 这个工具好啊<br /><br />将你需要的 AI 记录的内容都存在本地，然后共享给所有支持 MCP 的客户端<br /><br />这样你的 Cluade、Cursor、Windsurf 都可以读取相关信息了<br /><br />只需要维护一份记忆内容就行<br /><br />详细信息：https://mem0.ai/openmemory-mcp
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822dbc2be924b3ca40cb3be</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822dbc2be924b3ca40cb3be</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822dbc2be924b3ca40cb3be</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 05:42:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天试了一组非常好看的双重曝光制图，适合游戏/影视/动画的概念实现，你们感受一下。<br /><br />提示词比较复杂，填充部分的内容需要自己手搓，我提供阿拉贡那张的示例：<br /><br />Double exposure, Midjourney style, merging, blending, overlay double exposure image, Double Exposure style,An exceptional masterpiece by Yukisakura revealing a fantastic double exposure composition of Aragorn son of Arathorn's silhouette harmoniously intertwined with the visually striking, Rugged landscape of the Middle-earth in The Lord of the Rings. Ash-choked skies loom over the jagged black spires of Mordor, where the air hangs thick with smoke and dread. Rivers of molten rock carve glowing veins through the barren wasteland, casting flickering light on the broken earth. At the heart of it all, Barad-dûr rises like a wound in the world, its lidless Eye burning with watchful malice. Every twisted shadow and gust of wind seems to whisper doom, as if the land itself resists the light. Beautiful tension builds as the stark monochrome background maintains razor-sharp contrast, drawing all focus to the richly layered double exposure. Characterized by its vibrant full-color scheme within Arogorn’s silhouette and crisp, deliberate lines that trace every contour with emotional precision. (Detailed:1.45). (Detailed background:1.4).<br /><br />简单来说，头尾部分大体是不变的，中间涉及到场景描述方面自己来写，要是词汇量不足的话，就抄一段范例然后ChatGPT来帮忙写，比如：<br /><br />下面是一段描写游戏《荒野大镖客2》的场景：Snow-covered pine forests, frosty mountain peaks, and a lone horse cutting through the trail echo outward through the fabric of his figure, adding layers of narrative and solitude. <br /><br />请以此作为参考，写一段描写电影《指环王》的场景文本，重点在于中土世界和魔眼的呈现。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822d761dc6b6d4853c1bc0f</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822d761dc6b6d4853c1bc0f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822d761dc6b6d4853c1bc0f</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 05:23:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Prompt 放评论了
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822c473e03d82181c847000</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 04:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    真正的领导者探索未知，而非发号施令<br /><br />在AI first团队中，真正的leader不会满足于开通付费工具、督促他人适应，而是亲自穿越未知的崎岖小径、发现独特风景，并将这些宝贵的发现和感悟无保留地分享给团队。<br /><br />在剧变的时代，领导力的精髓不只是指挥，而在于示范；不在于命令，而在于树立榜样。<br /><br />好的Leader以好奇心和同理心绘制「探索路书」，团队才会真正激发出10X的创造力。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/682220b4e900708e252f5e4a</id>
            <title>AI探索站 05月12日</title>
            <link>https://m.okjike.com/originalPosts/682220b4e900708e252f5e4a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/682220b4e900708e252f5e4a</guid>
            <pubDate></pubDate>
            <updated>Mon, 12 May 2025 16:24:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一些个人认为适合非技术背景同学入门RL的材料不完全整理：<br /><br />1️⃣青铜级<br />（都是播客）<br />《一堂「强化学习」大师课》——42章经<br />《与马毅聊智能史:“DNA 是最早的大模型”，智能的本质是减熵》——晚点聊LateTalk<br />《我是这样用 RL + LLM 做 Agent 的｜对谈 Pokee AI 创始人朱哲清 Bill》——42章经<br />《走向强化学习：Agent 还是应用公司的机会吗？对话 Pokee.ai 创始人》——硅基觉醒<br />《Agent 开发的上半场：环境、Tools 和 Context 如何决定 Agent》——42章经<br />《强化学习的前世今生》——科技慢半拍<br />（以下是一些发布时间较早，但是我认为仍有价值所以保留推荐的⬇️）<br />《AGI 范式大转移：和广密预言草莓、OpenAI o1 和 self-play RL》——张小珺Jùn｜商业访谈录<br />《逐句讲解 DeepSeek-R1、Kimi K1.5、OpenAI o1 技术报告 ——“最优美的算法最干净”》——张小珺Jùn｜商业访谈录<br />《对话 Google Deepmind 研究员：OpenAI o1 及LLM+RL 新范式》——OnBoard! <br /><br />2️⃣白银<br />Andrej Karpathy《Deep Dive into LLMs like ChatGPT》（视频）（不是专门讲RL的，但是建议先看，系统了解）<br />Sam Lehman《The World's RL Gym》<br />Sutton与Deepmind《Welcome to the Era of Experience》<br />《Richard Sutton on Pursuing AGI Through Reinforcement Learning》（视频）<br /><br />3️⃣黄金<br />OpenAI o1 技术报告《Learning to reason with LLMs》<br />Deepseek官方论文《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》<br />Sebastian Raschka《The State of Reinforcement Learning for LLM Reasoning》<br /><br />4️⃣翡翠<br />《Transformer原作、斯坦福、清华交大三篇论文共识：基座模型边界锁死RL能力上限》（一篇公众号的概述，建议阅读原文）<br />《OpenAI's o3: Over-optimization is back and weirder than ever》<br /><br />5️⃣钻石<br />Sutton and Barto《Reinforcement Learning: An Introduction》<br />（坦白说还没学到这个层次，欢迎大佬们补充...）<br /><br />其实还有很多优质的资料，但我还没读的就不冒昧推荐了，欢迎在评论区安利🥹<br /><br />🎊扩展阅读<br />《A biref history of intelligence》
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/681adcd9efb7d4a44fd11dc8</id>
            <title>AI探索站 05月07日</title>
            <link>https://m.okjike.com/originalPosts/681adcd9efb7d4a44fd11dc8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/681adcd9efb7d4a44fd11dc8</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 May 2025 04:08:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    基于OpenRouter的公开数据做了一个产品和模型的榜单，可以看到基于token使用量的产品排名和每个产品所使用的模型情况。如果你在选择模型或者研究对应产品，这个免费小工具应该会有帮助，网址是： https://yperf.com
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6819f51cdc6b6d48532c54a8</id>
            <title>AI探索站 05月06日</title>
            <link>https://m.okjike.com/originalPosts/6819f51cdc6b6d48532c54a8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6819f51cdc6b6d48532c54a8</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 May 2025 11:40:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    启师傅AI客厅-良渚demo day第5期报名啦！<br /><br />这次邀请了@少楠Plidezus @玉伯 、赵君三位嘉宾带来他们对AI产品的思考，还有@图拉鼎   Longyi Neko @henu王凯 @志鹏hustlzp @SUKIII 等优秀的开发者，来分享他们的最新产品！<br /><br />🎫报名链接：<br />https://mp.weixin.qq.com/s/YTeKjqc9X5J300HdP6AO_A<br /><br />📅 时间：2025年5月10日（周六）13:30 - 17:30<br />📍 地点：良渚文化村<br />🎧 主办：播客《启师傅AI客厅》<br /><br />🎙️ 主题分享<br />💡 《YouMind 产品思考》<br />讲者：玉伯 @玉伯 <br />语雀创始人，前飞书产品副总裁，现 YouMind 创始人<br /><br />🔧 《从需求到成本：AI落地产品的务实之路》<br />讲者：少楠 @少楠Plidezus <br />flomo、小报童联合创始人<br /><br />💰 《个人开发者怎么“捡”钱》<br />讲者：赵君<br />SimilarTube &amp; NanoInfluencer 开发者，产品经理<br /><br />🚀 产品分享<br />🎨 《Seede AI：人人都能用的 AI 设计工具》<br />讲者：Longyi <br />Seede.ai 创始人 &amp; CEO，前 Dora AI 团队成员，前美团架构师<br /><br />📺 《AIRI：如何从零实现外网爆火的AI主播》<br />讲者：奶扣 Neko<br />Literally Full-stack Developer，覆盖 AI Infra、模型开发、数据处理等全栈开源爱好者<br /><br />📊 《AI在交易中的实际运用 &amp; AGI视角的选择》<br />讲者：王凯 @henu王凯 <br />AI 连续创业者，FastFacts 等 AI 应用、松鼠快看创始人<br /><br />🗣️ 《Monspeak 的 What / Why / How》<br />讲者：Suki &amp; 志鹏 hustlzp<br />SUKI：设计师&amp;产品经理，正在边上班边做Monspeak @SUKIII <br />志鹏：iOS 独立开发者，《我的番茄》《LEMO FM》《西窗烛》等产品作者@志鹏hustlzp <br /><br />🌍 《PopTranslate：为 macOS 打造的 AI 原生翻译工具》<br />讲者：图拉鼎 @图拉鼎 <br />生活在良渚的开发者，专注 Apple 生态效率工具，正在打造新出海产品
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6819dcf6070109da49ad7802</id>
            <title>AI探索站 05月06日</title>
            <link>https://m.okjike.com/originalPosts/6819dcf6070109da49ad7802</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6819dcf6070109da49ad7802</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 May 2025 09:57:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    对于想要大概了解 Flow Matching 的童鞋，推荐 MIT 的这门小课 https://diffusion.csail.mit.edu/，对于核心概念讲解清晰且符合物理直觉。flow matching 的原理我感觉比 diffusion 更易理解（而且还SOTA :D）。讲一下我从小白视角的理解：<br />文生图（无 condition）的过程，我们可以理解成是从一个纯随机的正态分布采样一个点，逐渐把它变成很“真”的一张图片。diffusion 是逐渐把采样到的这个“白噪音”点不断“去噪”，变成一张图片。而 flow matching，是让一个“磁场”去推着这个点不断移动，最终“移动”变成一张图片（想象图片 vector 各个维度的数值有加有减不断变化）。<br />稍微展开来说，flow matching 本质上是在学习一个 vector field/向量场（一个vector field定义一个ODE），可以把它想象成一个磁场。一开始我们只有一个符合正态分布的“沙堆”，我们的目标是逐渐”推移“这个沙堆，让它最终的分布符合我们要的分布（真实世界的图片）。对于每粒沙子在每个时间点、每个位置，磁场力的方向（往哪个方向推）就是我们要 neural network 学习的东西。一粒沙子从初始位置到目标位置”被磁场推着“经过的路，就是一个 flow（ODE 的一个解），不同沙子走出了多条 flow 形成多个训练数据不断调教 NN 去学习磁场里的方向，大量平均下来就是我们想要的磁场/模型。<br />细心的童鞋可能会问，那 NN 咋知道往哪推啊？给定了一张图片，对于”想要成为它的沙子“，在一个时间点和一个位置，我们磁场力的方向是提前设计好的（conditional vector field），这样 NN 对于一个样本往哪推是知道的。我们不知道的是大量这样的数据，最终让 NN 平均下来会学成个啥样，即 marginal vector field（就是我们想要的）。<br />最后附几张作业截图证明我不是瞎吹牛（btw 作业很简单）
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>