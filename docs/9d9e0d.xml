<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688b7514ec6567ea1171e79f</id>
            <title>AI探索站 07月31日</title>
            <link>https://m.okjike.com/originalPosts/688b7514ec6567ea1171e79f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688b7514ec6567ea1171e79f</guid>
            <pubDate></pubDate>
            <updated>Thu, 31 Jul 2025 13:52:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    写在Figma上市日：被忽视的技术成功典型<br /><br />几小时后，Figma将在纽交所上市，股票代号FIG。有必要说一说Figma的联合创始人Evan Wallace，他2021年离开Figma之前一直担任CTO。如果现在大家都说想找十倍工程师，我觉得Evan可以称之为百倍工程师，或者用另一个词——他是一个Transformative Engineer。他能把之前大家不敢想或者觉得不可能的事情，通过工程的方式变得可能。<br /><br />Figma虽然被很多人认为是商业成功或产品成功，但它核心其实是非常典型的技术成功。正是基础技术构建让这个产品能够超越时代，做出基于Web的多人协同设计工具。<br /><br />从Evan的blog中可以看到他当时在Figma做的一些事情。Figma是第一个真正大规模使用WebAssembly的app，当时这个技术刚刚出来，还没有人用它构建过大型软件。现在很多硅谷投资人都写过，Figma早期跟他们pitch时，几乎所有人都觉得浏览器的性能不可能做这么heavy的东西——在浏览器里做设计软件。<br /><br />但Evan自己写了整个渲染引擎，用WebAssembly+WebGL技术实现。这个难度有多大呢？相当于一个人干了顶级大厂UI framework几百人的活。Figma还自己实现了字体编辑系统，支持所有语言，包括从右到左、从左到右的文字，而且必须让设计师满意，字体渲染精度要求非常高。在这个过程中，Evan甚至需要自己去修复浏览器的bug，包括Firefox、WebKit、Chrome。<br /><br />同时因为Figma是协同软件，于是Evan又自己做了一套底层协同的网络协议。<br /><br />当然还要提一嘴，离开Figma后，Evan还做了esbuild，让web开发的打包速度比之前提高了百倍，带动了用高性能语言重写web工具链的新浪潮。<br /><br />现在AI工程和AI代码能力变得更强大了，但我不希望AI代码能力最后带来的只是多了一千倍的vibe coding的简单网页，而是希望有更多的人能够像Evan这样去做真正的技术突破，把之前大家认为不可能的东西变成可能。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688aec4937245ff359f4e55d</id>
            <title>AI探索站 07月31日</title>
            <link>https://m.okjike.com/originalPosts/688aec4937245ff359f4e55d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688aec4937245ff359f4e55d</guid>
            <pubDate></pubDate>
            <updated>Thu, 31 Jul 2025 04:08:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    谷歌开源了一个能从非结构化信息中提取结构化信息的 Python 库 LangExtract<br /><br />每一条提取结果都能映射到原文的具体位置<br />针对长文本做了优化，大幅提升召回率和处理效率<br />云端模型和本地模型都支持<br />一键生成 HTML 文件，直观展示千上万条提取实体<br />只需少量示例即可适配任意领域<br /><br />项目地址：https://github.com/google/langextract
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688adb9b8309a16f5e5881b2</id>
            <title>AI探索站 07月31日</title>
            <link>https://m.okjike.com/originalPosts/688adb9b8309a16f5e5881b2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688adb9b8309a16f5e5881b2</guid>
            <pubDate></pubDate>
            <updated>Thu, 31 Jul 2025 02:57:31 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    内测了 flomo 自定义 AI 洞察之后<br />一时兴起把相关主题内容丢给了 Claude<br />然后再让 Claude 调用 notion 中整理的资料<br /><br />突然有一种豁然开朗的感觉<br />flomo as me<br />notion as second brain <br /><br />只有前者，视野容易狭窄<br />只有后者，没有自己的灵魂<br /><br />要不要直接在洞察中对接下 notion 的 mcp 呢🤔？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688ab9318309a16f5e55ea5d</id>
            <title>AI探索站 07月31日</title>
            <link>https://m.okjike.com/originalPosts/688ab9318309a16f5e55ea5d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688ab9318309a16f5e55ea5d</guid>
            <pubDate></pubDate>
            <updated>Thu, 31 Jul 2025 00:30:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    团队的工程师数量，已经从创业之初的1个，增长到了现在的7个。<br />为什么在 AI Coding 如此之强的时候，还要招这么多的工程师呢？<br />因为 AI 可以帮助工程师提效，但并不能取代懂 AI 的工程师。<br />当每个工程师都在用 AI 提效，工程师越多，整体研发效率就越高。<br /><br />AI 永远无法取代的，是善用 AI 的工程师。<br />比超级个体更强的是一个超级组织。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6889a74017c5943dbe8ccaaf</id>
            <title>AI探索站 07月30日</title>
            <link>https://m.okjike.com/originalPosts/6889a74017c5943dbe8ccaaf</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6889a74017c5943dbe8ccaaf</guid>
            <pubDate></pubDate>
            <updated>Wed, 30 Jul 2025 05:01:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这两天 Claude 接入 Notion、Canva 和 Linear 等第三方平台，越来越多人意识到这不是工具升级，而是人文与技术融合的里程碑。<br /><br />以 Notion 为例。对重度用户而言，它早已不是静态知识库，而是承载思维轨迹的「外脑」。当 Claude 通过 MCP 连接这个认知空间时，三重力量开始交汇：<br /><br />当下的思考 × 基于互联网的 AI 搜索 × 第二大脑<br /><br />所有信息以你为中心，跨越时空和语言的边界重新编织。AI 不再是外部工具，而是内化为认知本身的放大器。<br /><br />真正的分水岭正在形成：拥抱开放性和「人机共生」的终身学习者，获得了全新的认知脚手架。而 Claude 正在悄然编织一个开放生态——只有置身其中的创造者，才能感受到这片「看不见的森林」的隐秘力量。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6888554c63d0ccf3157dfe1b</id>
            <title>AI探索站 07月29日</title>
            <link>https://m.okjike.com/originalPosts/6888554c63d0ccf3157dfe1b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6888554c63d0ccf3157dfe1b</guid>
            <pubDate></pubDate>
            <updated>Tue, 29 Jul 2025 04:59:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    卧槽，太牛了<br /><br />我只用半小时就用 Trickle AI 搞定了一个周刊网页<br /><br />我过去两年周刊的所有内容都会以单个信息卡片的方式展示在网页上，而且支持筛选<br /><br />而且实现的过程超级🐂🍺，这才是真正能够自我进化的 Vibe Coding 产品，怪不得上周 Producthunt 第一<br /><br />明天更新教程！
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6887a237d18032e3a99bfbe4</id>
            <title>AI探索站 07月28日</title>
            <link>https://m.okjike.com/originalPosts/6887a237d18032e3a99bfbe4</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6887a237d18032e3a99bfbe4</guid>
            <pubDate></pubDate>
            <updated>Mon, 28 Jul 2025 16:15:51 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    听说今晚都在玩Wan 2.2？细节控制确实不错。😜
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688368011bb397d4efab4e14</id>
            <title>AI探索站 07月25日</title>
            <link>https://m.okjike.com/originalPosts/688368011bb397d4efab4e14</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688368011bb397d4efab4e14</guid>
            <pubDate></pubDate>
            <updated>Fri, 25 Jul 2025 11:18:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI 产品和人之间的关系，可以是什么？<br /><br />在今年 AGI 大会演讲上我就提过一个暴论：AI Native 的产品不是在用 AI 造新工具，而是在构建 AI 能力与用户之间的新关系。<br />「具体展开可以见之前的三个帖子」<br />https://m.okjike.com/originalPosts/68626b63de6b80fe61a772e5?s=eyJ1IjoiNjAxYjg0N2Q5YTVkMDkwMDE3Y2I3ZDRkIn0%3D<br />https://m.okjike.com/originalPosts/68635d44b7f4ddcfdfdd30b1?s=eyJ1IjoiNjAxYjg0N2Q5YTVkMDkwMDE3Y2I3ZDRkIn0%3D<br />https://m.okjike.com/originalPosts/6864cdfbf5683819ad248ed1?s=eyJ1IjoiNjAxYjg0N2Q5YTVkMDkwMDE3Y2I3ZDRkIn0%3D<br /><br />对“关系”的思考，源于系统提示词 system prompt，这在 AI 产品之前是不存在的。很多为人熟知的 AI 产品，在系统提示词中都在定义“我是谁”，和用户是什么关系，是一个产品灵魂的“底层源代码”和“出厂设置”。比如 Cursor，不是冰冷的代码生成器，而是和用户结对编程的“编程搭子”。<br /><br />AI 的能力，让产品有了成为“主体”的可能性，主体之间的“关系”也随之可能。<br /><br />“关系”是 AI 产品独有的“延伸资产”，它既是壁垒，也可以帮你突破用户 LTV（生命周期总价值）的天花板，这是上个世代的产品不具备的。<br /><br />之前就有朋友追问，“AI 产品和人之间是什么关系”？不敢说现在有什么成熟、正确的答案，但这个问题确实值得认真想一想。因为不同的关系定位，意味着在用户预期和边界的管理、技术难度、交付和交互、商业模式等方面，都会不一样。这还需要继续观察，和大家多交流探讨。<br /><br />最近我们基金的一位同事给了我启发，类比人的社会关系，从“关系相对个人的位面”这个维度出发，可以大致将关系划分为三类：向下关系、平层关系和向上关系。<br /><br />向下关系：<br />如宠物、孩子，你在关系中的核心诉求是“被需要”，并乐于付出和投入。因此，商业化设计可以顺承着“喂养”、“养成”展开，难度不太高。<br /><br />向上关系：<br />如导师、长辈，你在关系中的核心诉求在于“被给予”，预期在关系中有所得。不过，商业化设计就会有些挑战，一旦让用户感到“被索取”，向上关系就会拧巴，甚至破灭。特别像是爷爷奶奶这样侧重情感价值位面的向上关系，其稀缺性也在于“无私关怀，不提要求、不求回报”。<br /><br />平层关系：<br />如同事、朋友、恋人。这是最复杂、困难的类型。因为向下和向上关系可简化成单边关系，只靠单向度付出也能成立。但是平层关系必须得是双边关系，得是你来我往，而且是会动态演进的，例如从陌生到朋友，可能从朋友到恋人，可能从朋友到事业伙伴，也可能从事业伙伴到朋友…从用户预期管理、交互和交付设计到商业模式，一切都会更复杂，难度也更大。<br /><br />关系选型会影响方法面面。“你是谁”，是在产品定义初始就值得深入思考、清晰定义的。<br /><br />最近准备和创业者们多讨论讨论这里面的实践和思考。欢迎一起讨论。<br /><br />顺便问问大家，你常用哪些 AI 产品？会怎么形容和它们的关系？为哪些 AI 产品花过钱？花了多少钱？想听听大家的体验和感想。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68832ecb6f992c6d4bbe8c97</id>
            <title>AI探索站 07月25日</title>
            <link>https://m.okjike.com/originalPosts/68832ecb6f992c6d4bbe8c97</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68832ecb6f992c6d4bbe8c97</guid>
            <pubDate></pubDate>
            <updated>Fri, 25 Jul 2025 07:14:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    和@Simon阿文 一起为可灵最新的「多图参考」模型制作了一个小短片《Out of the Frame》。好喜欢这次的合作，我们自己也看了无数遍，希望大家也喜欢~！<br /><br />▶ 创意制作：@Simon阿文 和我
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6881c420003901b635d3215b</id>
            <title>AI探索站 07月24日</title>
            <link>https://m.okjike.com/originalPosts/6881c420003901b635d3215b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6881c420003901b635d3215b</guid>
            <pubDate></pubDate>
            <updated>Thu, 24 Jul 2025 05:26:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    昨晚看 Lovart 发了正式版，就赶紧试了一下<br /><br />这个 ChatCanvas 强的离谱，基本上定义了创意类 Agent 的交互范式<br /><br />​昨天刚说完 ax 就来了这么一个完美案例，你现在有一个不知疲倦指哪打哪的 AI 创意员工了<br /><br />不想等施工🚧可以先看这里：https://mp.weixin.qq.com/s/cTOaTF94DPqMeWiRsdhetQ<br /><br />过去你是用 Lovart 的时候一定也有一个感觉。<br />那就是看起来你一直在跟右边的 Agent 聊天交互，左边的无限画布除了展示没有什么用处，今天这个更新会解答你的疑惑。<br /><br />他们设计了一整套的评论系统 ChatCanvas ，如果你是设计师用过 Figma 的话应该很熟悉。<br />但是这个评论不是给你的同事反馈的，而是说给 Agent 的。<br />就好像在虚拟世界里面有一个叫 Lovart 的设计师在随时待命，等待你说出“把这个文字调大点”这种要求。<br /><br />接下来跟着我用案例带你看这玩意有多强大，首先来看一个比较基础的案例。<br />这次我们要做一个玻璃质感的 PPT 动态视频封面，首先输入提示词让他给出一些基础的选项。<br />现在局部修改，你只需要点击左边无限画布的部分页面下方的的评论图标按钮，点击在你想要修改的图片上写出要求就行。<br /><br />比如上面生成图片上有这种波浪形状的光，我不太喜欢，我就可以点在这个位置跟 AI 说把这部分去掉。<br />这时候我又发现一个牛皮的地方，他们在这里吸收了一部分 Cursor 代码补全的交互，AI 会根据你打的字补全你的需求，你只需要按 tab 键就能回填。<br /><br />完事之后点击 「Add to Queue」按钮就可以提交需求，这时候 AI 有时候还会需要你补充一些信息，你们就可以在这里对话。<br />在你觉得没问题的时候，就可以点击下面的「Run All」按钮执行所有的的评论了，你能够加好几个评论让 Lovart 一起执行。<br /><br />现在 Lovart 还有了类似 Figam 的 Frame 也就是画板概念，整个画板中的所有改动都有独立的聊天界面去回溯。<br />想要看我所有执行过的评论的话怎么办，你可以点击评论旁边的「Comments」按钮查看。<br />还能点击「Reopen」按钮去将这个评论重复添加在图片或者视频上重复执行，考虑的非常周到。<br /><br />不止可以点击添加注释，你还能画框去标注图片的具体位置让 AI 修改。<br />比如我这里发现 AI 多写了一行「Keynote」文字，我想要去掉，就可以框选这部分，让他去掉就行。<br /><br />这个案例里面我完全通过评论（ChatCanvas）功能，不断的调整一张图片，然后最后把它生成了一个动态视频。<br />调整过程非常精准，完全不需要你费劲巴拉的用文字去描述位置或者图片，点击评论回复问题运行就行。<br /><br />说完简单的用法我们再来点复杂的。<br /><br />ChatCanvas 不仅支持每张图片单独调整，其实也支持多张图片联动调整。<br />这个能力对于有设计能力的朋友来说非常重要，你可以直接在画板中完成拼图编辑组合工作。<br /><br />这里我想做一张图，包含了最近的几个热梗，乌萨奇在东方明珠下面和蜜雪冰城然后被激光击中的画面。<br />这里我先找了三张素材图，画面中的主要元素，分别是乌萨奇、东方明珠和蜜雪冰城的饮料。<br /><br />然后精彩的地方来了，我可以分别给这三张图添加评论，指出分别需要参考的部分以及新图片的风格和位置。<br />我在乌萨奇这里说了使用这个角色，然后在第二个评论饮料这里说明角色会拿着这个饮料，最后在东方明珠的图片部分指定了三个参考项的位置以及画面风格和比例。<br /><br />见证奇迹的时刻朋友们，一张乌萨奇在上海偷喝蜜雪冰城，然后被击毙的图片就整好了，我还能让他变成视频。<br /><br />昨天我发的内容说过，未来的软件设计将会从用户体验（UX）为中心转换为以 Agent 体验（AX）为中心。<br />一旦体验过真正的 AX，传统的 UX 会让人觉得“过时且低效”，你用完 Lovart 在用其他创意设计产品就会有这种感觉。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>