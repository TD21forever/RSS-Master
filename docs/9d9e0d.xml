<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68c113b71e5664293dc65492</id>
            <title>AI探索站 09月10日</title>
            <link>https://m.okjike.com/originalPosts/68c113b71e5664293dc65492</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68c113b71e5664293dc65492</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Sep 2025 05:59:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    测试了下，豆包最新上线的 Seedream 4.0 可以一键生成定制化婚礼物料。<br /><br />你可以先用豆包的婚庆设计智能体，根据指定主题，获得婚礼全套物料的设计 prompt<br /><br />再用豆包 Seedream 4.0, 根据你的照片，设计所有的婚礼物料~<br /><br />以下为用“莫奈花园”为主题，给图一的 AI 新婚夫妇，设计的全套婚礼物料，分别是：迎宾区、合影区、邀请函、红包、誓言卡、胸花、伴手礼~ <br /><br />如果你有其他想设计的物料也可以和豆包说，让 TA 追加！<br /><br />▶ 豆包婚庆智能体：doubao.com/bot/rtTnVqgd
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68c10200236de2e48fb16e32</id>
            <title>AI探索站 09月10日</title>
            <link>https://m.okjike.com/originalPosts/68c10200236de2e48fb16e32</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68c10200236de2e48fb16e32</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Sep 2025 04:43:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我去，太吊了<br /><br />试了一下豆包 Seedream 4.0 的 4K 直出模式，文字和合成进去的图片极其清晰，一点劣化没有<br /><br />最后一张这个日记除了最后俩字，看起来就像我自己拿设计软件做的也一样<br /><br />自媒体知识卡片更是根本看不出是 AI 生成，文字非常细腻清晰，这下真神器了<br /><br />目前只有火山的 API 可以直出 4K
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68c0e69e14af706d824eec76</id>
            <title>AI探索站 09月10日</title>
            <link>https://m.okjike.com/originalPosts/68c0e69e14af706d824eec76</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68c0e69e14af706d824eec76</guid>
            <pubDate></pubDate>
            <updated>Wed, 10 Sep 2025 02:46:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    原本只服务于中小客户的Nebius，宣布拿下微软174-194亿美元GPU大单，一天暴涨50%。Nebius的背景很有意思，Nebius源自俄罗斯版的“谷歌”Yandex，在俄乌战争后，由于俄被国际制裁，毅然决然的放弃公司，逃出俄罗斯，创始人Arkady Volozh带着几百名工程师及他们的家眷，一共1000多人，辗转亚美尼亚、格鲁吉亚、哈萨克斯坦，最终重新汇聚在荷兰阿姆斯特丹，开启了Nebius的新生活。<br /><br />想想创始人Arkady Volozh当时的压力，组织1000多人技术精英的撤离行动，然后还要彻底剥离俄相关业务，让在纳斯达克停牌的公司复牌，如今在美国重新斩获微软大单，市值创下新高。当年带出来的俄罗斯技术精英们，携家带口离开家乡，背水一战，是近年来地缘政治冲突下，最著名的企业出走事件了，一段传奇
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68c0292be5597c28d3dc5c21</id>
            <title>AI探索站 09月09日</title>
            <link>https://m.okjike.com/originalPosts/68c0292be5597c28d3dc5c21</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68c0292be5597c28d3dc5c21</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Sep 2025 13:18:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🌲YouMind 0.4 发布<br />同时今天在 Product Hunt 上线啦！🚀<br /><br />YouMind 是一个专门为知识学习者、内容创作者打造的 AI Creation Studio，助力你把每一个灵感想法转变成“让自己满意的作品”。<br /><br />现在非常需要你和团队宝贵的 up/comment！🙏<br />感谢万能的即友。<br />你们的支持，总是让人内心暖暖。<br /><br />PH launch 链接 👇<br />（点击链接后，再点击顶部横条）
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68bf9fbc1e5664293da91746</id>
            <title>AI探索站 09月09日</title>
            <link>https://m.okjike.com/originalPosts/68bf9fbc1e5664293da91746</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68bf9fbc1e5664293da91746</guid>
            <pubDate></pubDate>
            <updated>Tue, 09 Sep 2025 03:32:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    NotebookLM 又有大更新，现在更适合用来学习了<br /><br />闪卡：基于文档内容生成闪卡，正面是问题，点击反面会有答案，适合用来记概念<br /><br />测验：AI 会基于文档信息生成一些选择题，而且选错的话会有对应的解释
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68bd221f5b2a82bc20097483</id>
            <title>AI探索站 09月07日</title>
            <link>https://m.okjike.com/originalPosts/68bd221f5b2a82bc20097483</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68bd221f5b2a82bc20097483</guid>
            <pubDate></pubDate>
            <updated>Sun, 07 Sep 2025 06:11:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用即梦 (Seedream) 4 图像模型给自己做一个非常有质感的头像。<br /><br />这还原的也太好了，关键的 ID 要素都还原了，而且有那种非常有质感的笔触效果。<br /><br />也可以给你喜欢的游戏或者动漫角色画，当然也可以搞抽象，给味真族族长大胃袋画一个。<br /><br />提示词：参考图1的风格和样式为图2的角色生成一个图标，同时只要参考图2的头部位置，像一个头像图标，图标下方的文字应该为“Jinx”<br />垫上最后的图就行，垫图的图片作者是“Darius Dan”注意自己玩可以不要盈利哈，尤其是垫图这种方式
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68bab054c98bad39de3e3702</id>
            <title>AI探索站 09月05日</title>
            <link>https://m.okjike.com/originalPosts/68bab054c98bad39de3e3702</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68bab054c98bad39de3e3702</guid>
            <pubDate></pubDate>
            <updated>Fri, 05 Sep 2025 09:41:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    【Zho】终于把我的 Nano-Banana 创意玩法大全 Github 库 写好了！！！<br /><br />目前一共 46 种！持续更新/开源中！！！<br /><br />这下方便大家查看和使用提示词了，但注意标明出处哦！！！<br /><br />一键直达：https://github.com/ZHO-ZHO-ZHO/ZHO-nano-banana-Creation
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68afdc69704e30c9e4ab5a1c</id>
            <title>AI探索站 08月28日</title>
            <link>https://m.okjike.com/originalPosts/68afdc69704e30c9e4ab5a1c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68afdc69704e30c9e4ab5a1c</guid>
            <pubDate></pubDate>
            <updated>Thu, 28 Aug 2025 04:34:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很荣幸作为 Google AI Asia 的开场嘉宾来介绍下 Manus 近期的进展。除了上午的 panel 和 keynote 外，下午三点我还会分享 Manus 背后的几点产品设计与技术思考，如果在现场欢迎来听听。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ae821114af706d82dbd41b</id>
            <title>AI探索站 08月27日</title>
            <link>https://m.okjike.com/originalPosts/68ae821114af706d82dbd41b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ae821114af706d82dbd41b</guid>
            <pubDate></pubDate>
            <updated>Wed, 27 Aug 2025 03:57:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🧙‍♀️我无数次表达过 GPT image 是真正的魔法。但难以置信的是，仅仅半年时间Gemini 2.5 flash image 就将这种魔法上升到了全新的层次：<br /><br />- 10倍的生成速度<br />- 惊人的品质和一致性<br />- 几乎完全免费<br /><br />值得再次强调是，获取这种魔法的关键就是亲自尝试——「对话」的能动性成为了唯一的门槛。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</id>
            <title>AI探索站 08月12日</title>
            <link>https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Aug 2025 09:23:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    遇到了一个有趣的问题，正好落在 AI 模型的能力边界处：试证明不可能把平面分成无穷个圆的无交并。<br /><br />在我尝试的所有模型里，只有 GPT 5 thinking model 成功做了出来（虽然花了点时间）。<br /><br />有趣的不是这个结论，而是观察它们的思路。所有失败的模型都有个共同点：它们的思考基本上是从文字到文字的。它们会调用自己脑海中各种已有的定理和知识，然后漫无目的地试图拼凑出一个证明，但所有这些定理，不管是拓扑的还是几何的还是测度的，对它们来说都是纯粹字面意义上的陈述。Qwen 的思考过程最典型：它滔滔不绝想了很久，但很显然从头到尾它都并不真的理解它在说什么。圆也罢，开集闭集也罢，Baire 纲定理也罢，对它来说都是纯粹的概念，给人的感觉是它甚至并不真的知道「圆是圆的」。<br /><br />微妙之处在于，这种「没有几何直觉的几何思考」在某些时候其实未必是一种劣势。现代数学早已挣脱了对三维现实想象的依赖，大部份数学思考本来也确实是在纯粹的概念思辨空间中进行（特别是当问题进入代数乃至范畴论的领域的时候，这时从概念到概念的思考就变成了一种必然）。有的时候，几何直觉甚至反而会成为一种束缚，特别是当思考高维空间的时候，基于低维现实的直观常常是有误导性的。在这些问题上，AI 的「盲目」反而带来了自由，使得它不必受困于视觉直觉。——当然，人类的视觉直觉可能会渗透进人类的文本语料里，在某种程度上「污染」AI，但这是另一个问题。<br /><br />然而对原问题来说，因为这是一个低维问题，直觉在这里不但有用，而且能大大缩短思考搜索的难度。在这一点上，一个把圆只作为抽象概念来理解的 AI 就会有巨大的劣势，因为它无法享受到几何直觉带来的跳步。这种直觉使得人可以一眼「看出」关键的构造，而这种构造在文本层面被搜索出来是困难的。<br /><br />考虑到 AI 的应用毕竟大多数情况下还是为了解决世界现实问题而不是思考高维几何，有几何直觉的 AI 会在大多数问题上显得聪明得多。于是一个现实问题是，这种直觉是只有依赖多模态的训练才能获取，还是可以通过精巧的文本训练就能实现？这有点像是 AI 领域的玛丽房间问题。这是一个经典的知识论思想实验：一个从出生就生活在黑白房间里、精通颜色物理与神经机制的科学家玛丽，当她第一次走出房间看到红色时，她是否获得了新的知识？<br /><br />今天大多数 AI 领域的困难都可以归结于此。人类是自己感官的奴隶，我们听到、看到、闻到，我们体会身体激素的涨落，我们想象、困惑、愤怒，然后试图把这一切投射在文字空间里。AI 则正好相反，它们在文字里理解这一切，但最终需要努力地——有时候是徒劳地——明白，一个圆在什么意义上是圆的。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>