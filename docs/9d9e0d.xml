<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ef23fe26b22c70b79d1e3a</id>
            <title>AI探索站 10月15日</title>
            <link>https://m.okjike.com/originalPosts/68ef23fe26b22c70b79d1e3a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ef23fe26b22c70b79d1e3a</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Oct 2025 04:33:02 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    为什么影视飓风的内容总能爆火？<br /><br />当罗永浩问Tim，持续进步的原因是什么时，Tim的回答并非技术、设备或者创意。<br /><br />他说：“其实我觉得自媒体最大的修炼的点是大众情绪感知。你必须能感知大众的情绪，你才可以获得增长。”<br /><br />这句话，揭示了顶级内容玩家与普通创作者之间的根本分野。<br />大部分人依赖灵感和直觉，而Tim已经将“感知情绪”这件事，变成了一套可以执行的系统。<br /><br />他把这套方法论总结为“四象限矩阵”和“短视频合集”理论。<br /><br />很多创作者都有一个拧巴的状态：用心做的内容没人看，随便拍的反而火了。这背后是创作的巨大不确定性，以及一种常见的陷阱——“自我感动”。<br /><br />Tim在访谈里提到了一个尖锐的理论：“做蠢事赢蠢奖（do stupid things win stupid prizes）”。<br /><br />“你不用指望把头伸进马桶去探索马桶的抽水速度，能够获得诺贝尔奖，只会闷死在里面…很多人会花很大的心思去做一个自我感动的东西，只有8000的播放。”<br /><br />这种“自嗨式”创作，本质上是对观众情绪的误判或漠视。<br /><br />Tim很早就意识到了这个问题。他的转折点来自于父亲的一个建议：“你得从一开始就记录你账号的粉丝量是怎么增长的，每个月写一个报告。”<br /><br />这个建议，让Tim从一个纯粹的创作者，开始转变为一个用数据来理解大众的内容产品经理。而他感知大众情绪的系统，也由此建立起来。<br /><br />我将影视飓风的内容增长飞轮，拆解为三个核心策略：<br /><br />策略一：用“四象限矩阵”实现用户全覆盖<br /><br />单一账号的内容定位，天花板是可见的。为了打破这个瓶颈，影视飓风建立了一个精巧的内容矩阵。<br /><br />Tim这样分解他的布局：“长视频、短视频是一个X轴，然后专业和大众是Y轴，每个地方都有一个对应的账号。我的目的就是把四个象限全部都吃透。”<br /><br />这个矩阵是这样构成的：<br /><br />专业 x 长视频：这是影视飓风主号。内容精良、信息密度高，负责建立行业标杆和品牌深度，吸引核心粉丝。<br /><br />大众 x 长视频：这是**“模型师老原儿”**等账号（早期叫“亿点点”）。选题极其抓人眼球，比如《我熬夜48小时，大脑会发生什么？》、《我把同事送去割痔疮》，负责破圈，获取海量泛用户的关注。Tim透露，这类账号的播放量“比影视飓风还要高很多”。<br /><br />专业 x 短视频：这是他们的短片账号。专门制作冲击奥斯卡等国际奖项的艺术短片，负责拔高品牌调性，探索内容的上限。<br /><br />大众 x 短视频：这是一些体验类账号。内容更轻快、更碎片化，负责跟上短视频平台的节奏，保持高频互动和用户粘性。<br /><br />这个矩阵的厉害之处在于，不同的账号承担不同的战略目的，有的负责“名声”，有的负责“流量”，有的负责“未来”，形成了一个能覆盖不同用户圈层、互相补充、抗风险能力极强的生态。<br /><br />策略二：用“全球化信息源”制造认知差<br /><br />好的选题从哪里来？大部分人刷抖音、看热榜，而Tim的“情报网络”是全球化的。<br /><br />“我有非常特殊的信息输入渠道…全球各个地方的Reddit论坛，那些各种地方很多奇怪的论坛，不可能有人看到，我会去看，我会吸收他们在讨论什么，然后把它转化并且变成更有意思的内容。”<br /><br />这解释了为什么影视飓风的很多选题都具有开创性。当你的信息源比别人更广、更深、更前沿时，你就天然拥有了“认知差”优势。你可以把一个在海外小众极客圈里刚兴起的话题，用大众化的方式呈现给国内观众，这就是降维打击。<br /><br />策略三：用“短视频合集”理论重构长视频<br /><br />这是Tim内容方法论中最具颠覆性的一点。<br /><br />他认为，比短视频更厉害的，是“把短视频拼成长视频的长视频合集”。<br /><br />“车祸视频有很多人喜欢看，但是车祸集锦视频看的人更多。因为它不需要有滑动的这个操作，人是越来越懒的。”<br /><br />这个洞察完全是反直觉的。它揭示了MrBeast这类顶级内容能够维持超高完播率的秘密。<br /><br />Tim解释道：“以前长视频是花很长时间讲一件事，现在是长视频不断的转场给你讲八件事…（这个长视频）切成8段的话，每一段也都是成立的，都是一个短视频，然后拼起来的。”<br /><br />这种创作方式，是把一个长视频，当作一个由数个“小爆款”组成的“爆款包”。每一个环节都经过精心设计，有独立的钩子、冲突和爽点，全程无尿点，用户的注意力被持续锁定。<br /><br />这也是为什么影视飓风的《我把卫星送上天》这类视频能成功的底层逻辑。它不是一个平铺直叙的纪录片，而是一个包含了“悬念（能不能成功）”、“奇观（火箭发射）”、“知识（卫星原理）”等多个高刺激度环节的“体验合集”。<br /><br />这套方法论的背后，是对平台推荐算法的深刻理解。<br /><br />所有算法的核心，无非是几个关键指标：CTR（点击率） 和 AVD（平均观看时长）。<br /><br />Tim的“四象限矩阵”和“全球化信息源”是为了保证选题足够吸引人，从而提高CTR。而“短视频合集”理论，则是为了在用户点击进来之后，最大限度地留住他们，拉高AVD。<br /><br />当你的内容在这两个维度上都做到极致，平台就会把海量的流量灌给你。<br /><br />当然，这套打法对团队的要求是极高的。<br /><br />它需要工业化的制作能力、数据驱动的选题策划能力，以及对全球文化趋势的敏锐嗅觉。这已经远远超出了传统内容作坊的范畴，更像是一个拥有强大中台支持的“内容产品公司”。<br /><br />但Tim的思考方式，给所有创作者提供了一个重要的启示：<br /><br />不要做蠢事去赢一个蠢奖。<br /><br />与其沉醉在自我感动中，抱怨观众不懂你，不如去真正理解观众的情绪，理解平台的语言。<br /><br />你必须理解大众，但又不完全迎合大众，这才是顶级内容的平衡艺术。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ef16c726b22c70b79c03a0</id>
            <title>AI探索站 10月15日</title>
            <link>https://m.okjike.com/originalPosts/68ef16c726b22c70b79c03a0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ef16c726b22c70b79c03a0</guid>
            <pubDate></pubDate>
            <updated>Wed, 15 Oct 2025 03:36:39 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    https://editor.huasheng.ai/<br /><br />花两天时间，用Claude Code做了个可能是迄今为止最好用的Markdown内容至公众号排版器了，突出体现在省事，以及美观。<br /><br />几个特点：<br />1、支持直接复制飞书、notion，或者任意html、markdown文件的内容到编辑器完成排版；<br />2、内置了10多种从科技媒体、纸媒借鉴的样式，不用再自己思考半天怎么排版了；<br />3、所见即所得，选择完排版风格，复制到公众号后，100%都和在网页看见的一样，图片也不需要重新上传。<br /><br />要说缺点，也有两个：<br />一是这只是个排版器，不是个编辑器，不适合在里面写作，还是更适合复制你在Notion等渠道写完的内容；<br />二是不支持自定义，灵活度没那么高，但为了突出省事的特点，做了妥协。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ee40908ac6b034c0db0e06</id>
            <title>AI探索站 10月14日</title>
            <link>https://m.okjike.com/originalPosts/68ee40908ac6b034c0db0e06</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ee40908ac6b034c0db0e06</guid>
            <pubDate></pubDate>
            <updated>Tue, 14 Oct 2025 12:22:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近尝试用即梦AI数字人模型1.5 来还原课文中的《口技》，发现数字人角色已经不再只是站桩对口型了，还可以进行大幅度运动，还可以运镜！<br /><br />然后，玩着玩着就玩飞了……<br /><br />▶ 创意制作：@Simon阿文 &amp; me
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ed1d5b8122541cd3e88294</id>
            <title>AI探索站 10月13日</title>
            <link>https://m.okjike.com/originalPosts/68ed1d5b8122541cd3e88294</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ed1d5b8122541cd3e88294</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Oct 2025 15:40:11 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    牛皮！Andrej Karpathy 发布了一个从零构建 LLM 训练和推理的项目：nanochat<br /><br />基本上跟着学就可以了解 LLM 训练的所有步骤了<br /><br />只需要 100 美元的算力成本就可以训练出可以对话的模型，而且会带有一个 UI 界面，只有 8000 行代码<br /><br />项目覆盖从分词、预训练、对齐到推理与 WebUI 的完整闭环，会是他 LLM 课程的一部分。<br /><br />在云端 8×H100 节点上运行单脚本，约 4 小时 / ~100 美元即可得到能对话、写诗故事、答简单问题的模型；<br /><br />12 小时在 CORE 指标上超过 GPT‑2；~$1000 / ~41.6 小时进一步提升到能做基础数学/代码与多选题。<br /><br />具体训练管线包括：<br /><br />分词器：全新 Rust 实现训练分词器。<br />预训练：用 FineWeb 语料，评估 CORE 及多项指标。<br />中期训练：用 SmolTalk 的用户‑助手对话、多选题、工具使用数据。<br />SFT：评测覆盖常识与世界知识（ARC‑E/C、MMLU）、数学（GSM8K）、代码（HumanEval）。<br />强化学习：可选在 GSM8K 上用 GRPO 做 RL。<br />推理引擎：支持 KV cache、prefill/decode、工具调用（轻量沙箱内 Python 解释器），CLI 与 ChatGPT 风格 WebUI 交互。<br />自动生成报告卡：自动生成单一 Markdown 报告，汇总与“游戏化”指标。<br /><br />详情：https://github.com/karpathy/nanochat
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ec72f9f3bb27610d86d6c1</id>
            <title>AI探索站 10月13日</title>
            <link>https://m.okjike.com/originalPosts/68ec72f9f3bb27610d86d6c1</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ec72f9f3bb27610d86d6c1</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Oct 2025 03:33:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    即梦 4 用来做视频封面真是一绝！<br /><br />用我昨天探索的动漫杂志风格提示词改了一个视频封面，点击率非常高，这里说一下制作步骤<br /><br />步骤 1：<br />先用即梦 3.1 和这个提示词生成你喜欢的图片：将照片角色转换成动漫美女，美学风格非常现代且充满活力，像动态的杂志版面或波普艺术。将高对比度的人物剪影与半色调图案以及大量动感排版相结合，没有文字<br /><br />步骤 2：<br />上传你选好的图片，输入提示词为它增加文字，这个时候模型要换成即梦 4：在图片在上方增加留白和优秀的艺术文字排版，替换原有的文字：“Sora2制作高质量动漫片头”“藏师傅教你”，文字跟图片融合的很好<br /><br />步骤3：<br />上传你的真人照片和步骤 2 的结果图，替换原来的动漫角色，这时候是动漫风格的：图片的人物替代图 1 的动漫角色，为人物加上白色描边<br /><br />步骤 4：<br />如果需要真人风格，上传步骤 2 结果图和你的真人照片，使用提示词：图片的人物替代图 1 的动漫角色，保证人物的写实风格，同时在人物后方增加一些网点和波普艺术排版元素，为人物加上白色描边<br /><br />步骤 5：<br />如果需要更多比例的封面图片的话，重复步骤 4 切换生成图片的比例就行
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ec568a2acd422e2dfa972c</id>
            <title>AI探索站 10月13日</title>
            <link>https://m.okjike.com/originalPosts/68ec568a2acd422e2dfa972c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ec568a2acd422e2dfa972c</guid>
            <pubDate></pubDate>
            <updated>Mon, 13 Oct 2025 01:31:54 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    国庆做了两个分身，很愉快。之前一直看@余一.Dev 搞 AI as me，很想试。国庆花了点时间，将 flomo 里的 5 年 2000 条日记，和有道里的 4 年 1200 条日记，做成了几个 md 文档（处理有道文件时，全靠 manus 帮我整理），导入 GPT 做了一个 GPTs，导入 Gemini 做了一个 Gem。<br /><br />相当于他们各自拥有了我 9 年的记忆。<br /><br />在两个模型里各自创建了两个分身，一个是“石山-我的首席记忆官”，意思是我的镜像。目的是完全复制我的记忆，帮我回忆一些事，说话谨慎保守不多话。另一个是“姬十四-我的首席战略官”，意思是姬十三+1， 了解我，但比我更理性，更贝叶斯，在一些重要问题上帮我做决策。提示词里写明遇到什么事参考哪个文档，优先顺序等。<br /><br />目前大概是这样，已经感觉很爽了。<br /><br />跟即友交流一下：<br />大家都是怎么玩的，还有什么玩法，可以怎么改进？<br />最大的数据源其实是微信聊天记录吧，这个怎么导入？<br />记忆需要定期更新，有什么好用的操作？
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68ea47481ed9b53c78bffaee</id>
            <title>AI探索站 10月11日</title>
            <link>https://m.okjike.com/originalPosts/68ea47481ed9b53c78bffaee</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68ea47481ed9b53c78bffaee</guid>
            <pubDate></pubDate>
            <updated>Sat, 11 Oct 2025 12:02:16 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    很多需求真的是无法空想出来的。比如当我交替使用 GPT 和 Gemini 的时候，最终决定我使用体验的完全不是两者的智能或者风格区别，而是一个纯粹的 feature 差异：后者不支持通过修改对话历史从而实现对话的分岔。<br /><br />对话的分岔显然是一个 GPT 出现之前没有人会预料到的功能。现实中不存在这个东西。当然有时候你会想哎呀我昨天和那谁的对话要是编辑一下重开一个平行宇宙就好了，但反正你知道这不可能，也不会认真对待这个想法。然而 GPT 一旦提供这个功能，你就立刻发现它不可或缺。无数次——或者说几乎每一次——我能从一段对话中学到些什么的体验，都来自于我对之前对话记录的反复 refinement。通过不断比较它们导致的对话走向，我才真正理解我们其实是在说什么。<br /><br />非常奇妙。你意识到对话的本质不是线性的，而是由一连串 what-if 构成的。好的对话不是一条河流，而是一棵树。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68e507b756725ea8ff52fbe0</id>
            <title>AI探索站 10月07日</title>
            <link>https://m.okjike.com/originalPosts/68e507b756725ea8ff52fbe0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68e507b756725ea8ff52fbe0</guid>
            <pubDate></pubDate>
            <updated>Tue, 07 Oct 2025 12:29:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Sutton 最近跟 Dwarkesh 有个访谈，老爷子认为 LLM 并不是通向 AGI 的正确道路。搞笑的是：LLM 支持者 Dwarkesh 认为 LLM 是符合 “The Bitter Lesson” （通用计算方法加大规模数据终将战胜人工设计的策略）的，却被 Sutton 无情打脸。我看完访谈的最大感受是 Sutton 的观点有点抽象，后来我读了《智能简史》这本书，才完全理解了 Sutton 的观点。<br /><br />Sutton 在访谈里面提到：大模型只是在模仿人类，而不是真的理解了世界。大模型智能预测人类会说什么，而不能预测会发生什么。这个观点说实话很抽象，但我从《智能简史》的一个例子中理解了他的意思。<br /><br />大脑有一种神奇的能力，它可以想象未来会发生什么，《智能简史》用老鼠迷宫实验非常形象的介绍了这种能力。<br /><br />实验过程大致如下：研究人员将一只老鼠放进一个T型迷宫，迷宫的右臂尽头有食物。经过几次尝试，老鼠学会了右转去获取食物。但接下来，实验者将迷宫旋转了180度，入口和岔路口的位置都变了，但食物仍然在房间的同一个绝对位置。此时，如果老鼠只是学会了“右转”这个动作，那它应该还会右转，但这样它就会走向错误的方向。然而，实验中的老鼠在路口停下来左右摇头思考了一下，最终选择了左转，并成功找到了食物。<br /><br />这个实验说明，老鼠并不是死记硬背了向右转的动作，而是在大脑中建立了一个关于迷宫和食物位置的空间地图，一个“世界模型”。当迷宫被旋转后，老鼠能够利用这个内在的地图，在大脑中想象食物的位置，以达到获取食物的目的。它理解了目标（食物）在空间中的位置，而不是机械地重复之前被奖励的行为。后来的研究者通过监测老鼠的大脑神经活动，证明了它确实在脑中分别演练了两种选择的结果。<br /><br />相比之下，鱼就没有这么聪明了。取一条鱼放入水箱，箱中设有透明隔板。在隔板一角开个小孔，使鱼能从一侧游至另一侧。让鱼自由探索水箱，找到小孔并花些时间来回游动。数日后进行新操作：将鱼置于水箱一侧，在透明隔板的另一侧放置食物。结果发现鱼花了跟第一次一样的时间才找到小孔位置，也就是说鱼并没有建立世界模型。<br /><br />这些实验可以用来解释Sutton的观点。Sutton认为，真正的智能，需要像老鼠一样，能够在内在建立一个世界模型，并利用这个模型去灵活地适应和解决问题，而不仅仅是在已有的数据中寻找最优的“下一个词”。现在的大语言模型，本质上是在一个极其庞大的“语言迷宫”里，通过海量的数据训练，学会了在某个“路口”（当前上下文），选择最有可能的下一个“方向”（下一个词）。它能够预测人类会说什么，因为它已经“看”过了无数人类在相似情境下的选择。<br /><br />然而，一旦我们稍微改变“迷宫”的结构，提出一个它从未见过的、需要真正理解世界才能回答的问题，或者要求它根据现实世界的变化做出预测，它可能就会像那只鱼一样，暴露出其死记硬背的本质。比如有研究者发现，当使用 LLM 作为评判工具时，只需要加一个“解”，甚至只是空格、冒号等符号，就能让毫无意义的回答骗得高分。<br /><br />在 Sutton 看来，仅仅通过扩大数据和计算量来训练大模型，只是在让模型更擅长模仿人类的语言模式，而无法真正地理解世界，因此 LLM 不是通向AGI的正确道路。<br /><br />虽然我赞成 Sutton 的说法，LLM 相比大脑确实不够“智能”，但是从实用主义的角度看，即使 LLM 只会模仿人类，如果它确实能完成人类的工作，那么这算不算实现了 AGI？俗话说得好：“当一个东西走路像鸭子、叫声像鸭子，那它就是鸭子。”我自己是不纠结技术路线的，我只关心 AI 是不是真的能解决我的问题，而且我认为 LLM 可以帮助我们更快破解大脑智能之谜。<br /><br />最后也推荐大家可以读一下《智能简史》这本书，作者是搞 AI 出身的，为了研究 AI 学习了很多神经科学的知识，他将神经科学的研究成果跟机器学习的知识串联起来。所以我读的非常爽：就像飞机是从鸟类的飞行得到启发一样，AI 的很多突破都源于我们对大脑的研究。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68dc0eefe1724775b4369bba</id>
            <title>AI探索站 09月30日</title>
            <link>https://m.okjike.com/originalPosts/68dc0eefe1724775b4369bba</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68dc0eefe1724775b4369bba</guid>
            <pubDate></pubDate>
            <updated>Tue, 30 Sep 2025 17:10:07 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Sora 2  &amp; Sora App 来了～
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68cfce51dbff5eb45065eb28</id>
            <title>AI探索站 09月21日</title>
            <link>https://m.okjike.com/originalPosts/68cfce51dbff5eb45065eb28</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68cfce51dbff5eb45065eb28</guid>
            <pubDate></pubDate>
            <updated>Sun, 21 Sep 2025 10:07:13 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近听的最有价值的播客，是 Claude Code 使用量全球榜一大哥，刘小排在koji的十字路口的播客。<br />听完的一些收获：<br />1. 刘小排发现，人们都说 AI 不赚钱，其实是榜单头部的 AI 产品基本都不赚钱。但这跟他的体感完全不同。只要你不乱花钱投放，降低营销和人力成本，从第一天就开始赚钱。<br />2. 别被 Claude Code 的 Code 这个单词所迷惑，它是一个通用 Agent 工具，从调研到写代码都可以做。<br />3. 只要在虚拟世界中，任何有标准操作程序（SOP）的事情都可以通过 Claude Code 实现自动化。<br />4. Claude Code 的价值在于其可控性，允许用户根据需要为其提供工具，从而实现无限级的扩展，这与 Manas 等内置工具受限的 Agent 不同。<br />5. 用 Claude Code 之前可以先读官方文档，很多功能比如7x24地跑都是官方宣传的功能，根本不是黑科技<br />6. 使用 Claude Code 如何避免屎山代码？你先在飞书里把需求文档写清楚，最好配上图，然后再和AI讨论一下需求的细节，需求不清楚的结果就是屎山代码。<br />7. 猎豹移动的产品方法论，核心在于 “简单”，即专注于一个功能并做到极致，而不是做加法<br />8. 他从猎豹移动学到的产品三段论是：预测、单点击穿、All-in，即预测市场趋势，找到一个点站稳脚跟，然后投入所有资源。<br />9. 在微软亚洲研究院实习时发现 “科技” 是两个词，即 “科学” 和 “技术”，并意识到自己做的是工程而非科学，这一认知影响了他日后的创业方向。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>