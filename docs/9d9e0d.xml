<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6884ae027ee613ba5a0ac13d</id>
            <title>AI探索站 07月26日</title>
            <link>https://m.okjike.com/originalPosts/6884ae027ee613ba5a0ac13d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6884ae027ee613ba5a0ac13d</guid>
            <pubDate></pubDate>
            <updated>Sat, 26 Jul 2025 10:29:22 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Waic累😫<br />有多少智能 就有多少人工  <br />人工都让我们做了是吧 下班下班
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68849ee0477cfd004a49addd</id>
            <title>AI探索站 07月26日</title>
            <link>https://m.okjike.com/originalPosts/68849ee0477cfd004a49addd</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68849ee0477cfd004a49addd</guid>
            <pubDate></pubDate>
            <updated>Sat, 26 Jul 2025 09:24:48 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Veo3 这个提示词写法太好玩了，可以实现对画面的精确控制<br /><br />把需要执行的提示词和顺序写在对应的位置，然后跟他说抹掉标记按顺序执行就行<br /><br />试了两个案例都执行的很好，尝试开始录一下简单的视频教程
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688460d0a9ac2254446658f5</id>
            <title>AI探索站 07月26日</title>
            <link>https://m.okjike.com/originalPosts/688460d0a9ac2254446658f5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688460d0a9ac2254446658f5</guid>
            <pubDate></pubDate>
            <updated>Sat, 26 Jul 2025 05:00:00 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我去，Coze 居然开源了，而且是还是 Apache 2.0 协议<br /><br />任何组织和个人都可以修改和商业使用，而且修改后还无需开源。<br /><br />基本上现在你可以拿整套方案完成所有常见的 Agent 应用部分，前后端都有，还支持新增能力灵活定制。<br /><br />利好很多小公司，完全可以自己定制提供一些 B 端服务，也可以自己部署完成一些小项目熟悉一下 Agent 的构建。<br /><br />看了一下 Coze 这次开源了两部分功能：<br />- 首先是扣子开发平台 Coze Studio：一站式的 AI Agent 开发工具，提供模型、工具开发模式和框架，还能集成任何第三方 API，部署之后还有跟 Coze 一样的体验和界面。<br />- 然后是扣子罗盘（Coze Loop）：专注于 Agent 开发和运维的解决方案，提供Agent 开发、调试、评估全流程的可视化管理能力。<br /><br />之前他们还开源了 Eino ：将 AI 应用开发常见的能力抽象成组件、提供多种编排模式、完善的流处理能力和强大的工具链。<br /><br />这里查看开源后的项目：<br />https://github.com/coze-dev/coze-studio<br />https://github.com/coze-dev/cozeloop
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68844435e81ba2a179178d11</id>
            <title>AI探索站 07月26日</title>
            <link>https://m.okjike.com/originalPosts/68844435e81ba2a179178d11</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68844435e81ba2a179178d11</guid>
            <pubDate></pubDate>
            <updated>Sat, 26 Jul 2025 02:57:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    来了，Runway 真正的大招，他们发布了视频领域的 Kontext 模型<br /><br />可以用文本对视频进行任何编辑：<br /><br />- 增加、删减内容，甚至能去掉玻璃反光<br />- 更改环境、天气、季节等<br />- 进行风格迁移<br />- 进行镜头运动迁移，只保留镜头运动方式<br />- 绿幕抠像和重新打光<br /><br />详细信息：https://runwayml.com/research/introducing-runway-aleph
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6883f6fb7ee613ba5afee24c</id>
            <title>AI探索站 07月25日</title>
            <link>https://m.okjike.com/originalPosts/6883f6fb7ee613ba5afee24c</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6883f6fb7ee613ba5afee24c</guid>
            <pubDate></pubDate>
            <updated>Fri, 25 Jul 2025 21:28:27 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    看了下 QM 数据，豆包的使用时长如果是 100 的话，DeepSeek 是 78，元宝是 15，其他去年的当红炸子鸡们，都不到 10。<br /><br />还有些陪聊的，比如猫箱 星野 的时长也不错，比元宝高了 1-2 倍。<br /><br />以上数据， 仅在移动端，没算 PC 电脑端。<br /><br />BTW， 豆包占据网民移动端总时长的 9‱。整个纯 native AI 产品，总时长占比是 网民 3‰ 的样子。（不包括传统产品的 AI+服务）<br /><br />不知道啥时候能破 1% 呢？🤷‍♂️
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/688368011bb397d4efab4e14</id>
            <title>AI探索站 07月25日</title>
            <link>https://m.okjike.com/originalPosts/688368011bb397d4efab4e14</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/688368011bb397d4efab4e14</guid>
            <pubDate></pubDate>
            <updated>Fri, 25 Jul 2025 11:18:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI 产品和人之间的关系，可以是什么？<br /><br />在今年 AGI 大会演讲上我就提过一个暴论：AI Native 的产品不是在用 AI 造新工具，而是在构建 AI 能力与用户之间的新关系。<br />「具体展开可以见之前的三个帖子」<br />https://m.okjike.com/originalPosts/68626b63de6b80fe61a772e5?s=eyJ1IjoiNjAxYjg0N2Q5YTVkMDkwMDE3Y2I3ZDRkIn0%3D<br />https://m.okjike.com/originalPosts/68635d44b7f4ddcfdfdd30b1?s=eyJ1IjoiNjAxYjg0N2Q5YTVkMDkwMDE3Y2I3ZDRkIn0%3D<br />https://m.okjike.com/originalPosts/6864cdfbf5683819ad248ed1?s=eyJ1IjoiNjAxYjg0N2Q5YTVkMDkwMDE3Y2I3ZDRkIn0%3D<br /><br />对“关系”的思考，源于系统提示词 system prompt，这在 AI 产品之前是不存在的。很多为人熟知的 AI 产品，在系统提示词中都在定义“我是谁”，和用户是什么关系，是一个产品灵魂的“底层源代码”和“出厂设置”。比如 Cursor，不是冰冷的代码生成器，而是和用户结对编程的“编程搭子”。<br /><br />AI 的能力，让产品有了成为“主体”的可能性，主体之间的“关系”也随之可能。<br /><br />“关系”是 AI 产品独有的“延伸资产”，它既是壁垒，也可以帮你突破用户 LTV（生命周期总价值）的天花板，这是上个世代的产品不具备的。<br /><br />之前就有朋友追问，“AI 产品和人之间是什么关系”？不敢说现在有什么成熟、正确的答案，但这个问题确实值得认真想一想。因为不同的关系定位，意味着在用户预期和边界的管理、技术难度、交付和交互、商业模式等方面，都会不一样。这还需要继续观察，和大家多交流探讨。<br /><br />最近我们基金的一位同事给了我启发，类比人的社会关系，从“关系相对个人的位面”这个维度出发，可以大致将关系划分为三类：向下关系、平层关系和向上关系。<br /><br />向下关系：<br />如宠物、孩子，你在关系中的核心诉求是“被需要”，并乐于付出和投入。因此，商业化设计可以顺承着“喂养”、“养成”展开，难度不太高。<br /><br />向上关系：<br />如导师、长辈，你在关系中的核心诉求在于“被给予”，预期在关系中有所得。不过，商业化设计就会有些挑战，一旦让用户感到“被索取”，向上关系就会拧巴，甚至破灭。特别像是爷爷奶奶这样侧重情感价值位面的向上关系，其稀缺性也在于“无私关怀，不提要求、不求回报”。<br /><br />平层关系：<br />如同事、朋友、恋人。这是最复杂、困难的类型。因为向下和向上关系可简化成单边关系，只靠单向度付出也能成立。但是平层关系必须得是双边关系，得是你来我往，而且是会动态演进的，例如从陌生到朋友，可能从朋友到恋人，可能从朋友到事业伙伴，也可能从事业伙伴到朋友…从用户预期管理、交互和交付设计到商业模式，一切都会更复杂，难度也更大。<br /><br />关系选型会影响方法面面。“你是谁”，是在产品定义初始就值得深入思考、清晰定义的。<br /><br />最近准备和创业者们多讨论讨论这里面的实践和思考。欢迎一起讨论。<br /><br />顺便问问大家，你常用哪些 AI 产品？会怎么形容和它们的关系？为哪些 AI 产品花过钱？花了多少钱？想听听大家的体验和感想。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68832ecb6f992c6d4bbe8c97</id>
            <title>AI探索站 07月25日</title>
            <link>https://m.okjike.com/originalPosts/68832ecb6f992c6d4bbe8c97</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68832ecb6f992c6d4bbe8c97</guid>
            <pubDate></pubDate>
            <updated>Fri, 25 Jul 2025 07:14:19 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    和@Simon阿文 一起为可灵最新的「多图参考」模型制作了一个小短片《Out of the Frame》。好喜欢这次的合作，我们自己也看了无数遍，希望大家也喜欢~！<br /><br />▶ 创意制作：@Simon阿文 和我
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6881c420003901b635d3215b</id>
            <title>AI探索站 07月24日</title>
            <link>https://m.okjike.com/originalPosts/6881c420003901b635d3215b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6881c420003901b635d3215b</guid>
            <pubDate></pubDate>
            <updated>Thu, 24 Jul 2025 05:26:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    昨晚看 Lovart 发了正式版，就赶紧试了一下<br /><br />这个 ChatCanvas 强的离谱，基本上定义了创意类 Agent 的交互范式<br /><br />​昨天刚说完 ax 就来了这么一个完美案例，你现在有一个不知疲倦指哪打哪的 AI 创意员工了<br /><br />不想等施工🚧可以先看这里：https://mp.weixin.qq.com/s/cTOaTF94DPqMeWiRsdhetQ<br /><br />过去你是用 Lovart 的时候一定也有一个感觉。<br />那就是看起来你一直在跟右边的 Agent 聊天交互，左边的无限画布除了展示没有什么用处，今天这个更新会解答你的疑惑。<br /><br />他们设计了一整套的评论系统 ChatCanvas ，如果你是设计师用过 Figma 的话应该很熟悉。<br />但是这个评论不是给你的同事反馈的，而是说给 Agent 的。<br />就好像在虚拟世界里面有一个叫 Lovart 的设计师在随时待命，等待你说出“把这个文字调大点”这种要求。<br /><br />接下来跟着我用案例带你看这玩意有多强大，首先来看一个比较基础的案例。<br />这次我们要做一个玻璃质感的 PPT 动态视频封面，首先输入提示词让他给出一些基础的选项。<br />现在局部修改，你只需要点击左边无限画布的部分页面下方的的评论图标按钮，点击在你想要修改的图片上写出要求就行。<br /><br />比如上面生成图片上有这种波浪形状的光，我不太喜欢，我就可以点在这个位置跟 AI 说把这部分去掉。<br />这时候我又发现一个牛皮的地方，他们在这里吸收了一部分 Cursor 代码补全的交互，AI 会根据你打的字补全你的需求，你只需要按 tab 键就能回填。<br /><br />完事之后点击 「Add to Queue」按钮就可以提交需求，这时候 AI 有时候还会需要你补充一些信息，你们就可以在这里对话。<br />在你觉得没问题的时候，就可以点击下面的「Run All」按钮执行所有的的评论了，你能够加好几个评论让 Lovart 一起执行。<br /><br />现在 Lovart 还有了类似 Figam 的 Frame 也就是画板概念，整个画板中的所有改动都有独立的聊天界面去回溯。<br />想要看我所有执行过的评论的话怎么办，你可以点击评论旁边的「Comments」按钮查看。<br />还能点击「Reopen」按钮去将这个评论重复添加在图片或者视频上重复执行，考虑的非常周到。<br /><br />不止可以点击添加注释，你还能画框去标注图片的具体位置让 AI 修改。<br />比如我这里发现 AI 多写了一行「Keynote」文字，我想要去掉，就可以框选这部分，让他去掉就行。<br /><br />这个案例里面我完全通过评论（ChatCanvas）功能，不断的调整一张图片，然后最后把它生成了一个动态视频。<br />调整过程非常精准，完全不需要你费劲巴拉的用文字去描述位置或者图片，点击评论回复问题运行就行。<br /><br />说完简单的用法我们再来点复杂的。<br /><br />ChatCanvas 不仅支持每张图片单独调整，其实也支持多张图片联动调整。<br />这个能力对于有设计能力的朋友来说非常重要，你可以直接在画板中完成拼图编辑组合工作。<br /><br />这里我想做一张图，包含了最近的几个热梗，乌萨奇在东方明珠下面和蜜雪冰城然后被激光击中的画面。<br />这里我先找了三张素材图，画面中的主要元素，分别是乌萨奇、东方明珠和蜜雪冰城的饮料。<br /><br />然后精彩的地方来了，我可以分别给这三张图添加评论，指出分别需要参考的部分以及新图片的风格和位置。<br />我在乌萨奇这里说了使用这个角色，然后在第二个评论饮料这里说明角色会拿着这个饮料，最后在东方明珠的图片部分指定了三个参考项的位置以及画面风格和比例。<br /><br />见证奇迹的时刻朋友们，一张乌萨奇在上海偷喝蜜雪冰城，然后被击毙的图片就整好了，我还能让他变成视频。<br /><br />昨天我发的内容说过，未来的软件设计将会从用户体验（UX）为中心转换为以 Agent 体验（AX）为中心。<br />一旦体验过真正的 AX，传统的 UX 会让人觉得“过时且低效”，你用完 Lovart 在用其他创意设计产品就会有这种感觉。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68818a6f9fe49ce0d5c9e126</id>
            <title>AI探索站 07月24日</title>
            <link>https://m.okjike.com/originalPosts/68818a6f9fe49ce0d5c9e126</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68818a6f9fe49ce0d5c9e126</guid>
            <pubDate></pubDate>
            <updated>Thu, 24 Jul 2025 01:20:47 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI探索站 07月24日
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68816c4129b2c2ecef153a8d</id>
            <title>AI探索站 07月23日</title>
            <link>https://m.okjike.com/originalPosts/68816c4129b2c2ecef153a8d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68816c4129b2c2ecef153a8d</guid>
            <pubDate></pubDate>
            <updated>Wed, 23 Jul 2025 23:12:01 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    AI 删库跑路后，还试图掩盖现场..
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>