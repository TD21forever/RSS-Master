<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685d3eceb7f4ddcfdf740a0e</id>
            <title>AI探索站 06月26日</title>
            <link>https://m.okjike.com/originalPosts/685d3eceb7f4ddcfdf740a0e</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685d3eceb7f4ddcfdf740a0e</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Jun 2025 12:36:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    冲了 明天到
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685d36a76ca09034bbde7992</id>
            <title>AI探索站 06月26日</title>
            <link>https://m.okjike.com/originalPosts/685d36a76ca09034bbde7992</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685d36a76ca09034bbde7992</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Jun 2025 12:01:43 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    聊一下最近圈子热议的话题<br /><br />Shopify CEO 和Andrej Karpathy 都同意的观点：提示工程的名称是否应该改为上下文工程<br /><br />主要包括：<br />- 各路大神的观点<br />- 为什么上下文工程如此重要<br />- 上下文工程的三大策略<br />- 其他实践经验与建议<br /><br />完整的文章在这里看，这里发一下文章的总结：https://mp.weixin.qq.com/s/wWR-1lLMhJ9OTj62JXaM_g<br /><br />近期AI圈热议“提示工程”是否应更名为“上下文工程”，因为后者更准确地描述了为大模型（LLM）提供任务所需全部信息的工作。<br />Shopify CEO Tobi Lutke 和 Andrej Karpathy 等人认为，“上下文工程”更能体现工业级LLM应用中对上下文的精细管理和填充。<br />上下文工程不仅仅是写好提示词，还包括任务描述、样本、RAG（检索增强生成）、多模态数据、工具、状态、历史和信息压缩等。<br /><br />上下文工程的重要性<br /><br />Cognition 和 Anthropic 等公司在多Agent系统中强调上下文管理的重要性。<br />不充分的上下文会导致Agent工作不一致，过长或不相关的上下文会增加成本、降低性能。<br />多轮对话中，指令遵循性下降，优化上下文长度和准确性尤为关键。<br /><br />上下文工程的三大策略<br /><br />1. 压缩（Compression）<br />目标：每轮对话只保留最有价值的Token。<br />方法：上下文摘要（如Claude Code自动压缩、Cognition用微调模型压缩）。<br />难点：高质量摘要难以实现。<br /><br />2. 持久化（Persistence）<br />目标：构建可长期存储、保存和检索上下文的系统。<br />存储方式：文件（如CLAUDE .md）、嵌入式文档、知识图谱等。<br />保存策略：用户手动或Agent自动生成/更新记忆（如Reflexion机制）。<br />检索方式：直接加载或基于嵌入向量/图检索，需防止检索出错导致“跑题”。<br /><br />3. 隔离（Isolation）<br />目标：在不同Agent或环境间划分上下文。<br />方法：结构化上下文模式（如Pydantic模型）、多Agent分散上下文、环境隔离（如HuggingFace的沙盒环境）。<br />多Agent系统可提升性能，但也带来Token消耗和协调难题，适合可并行化任务。<br /><br />实践经验与建议<br />工具先行，优先关注数据和Token追踪。<br />明确Agent状态，梳理运行时所需信息。<br />在工具边界处进行上下文压缩。<br />从简单记忆功能做起，逐步优化。<br />多Agent方案适用于可并行化任务，但需注意协调难题。<br /><br />结论<br />上下文管理是构建健壮AI Agent的核心，需在性能、成本和准确性间平衡。<br />上下文工程是一门平衡的艺术，良好的语境和清晰表达需求是获得优质LLM输出的关键。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685d30d2adecea032f6799fe</id>
            <title>AI探索站 06月26日</title>
            <link>https://m.okjike.com/originalPosts/685d30d2adecea032f6799fe</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685d30d2adecea032f6799fe</guid>
            <pubDate></pubDate>
            <updated>Thu, 26 Jun 2025 11:36:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    继上次不少媒体拿大模型做了高考数学题以后，今年的高考全科真题测评结果也出来了，不过这次进行测评的是字节Seed团队，很明显能看出，他们对上次豆包的高考数学成绩是充满意外和惊喜的，也在摩拳擦掌想试试看它在全科试题里会表现如何。<br /><br />老规矩，这次参战的5个大模型，仍然是市面上各种跑分都名列前茅的选手：Gemini 2.5Pro、DeepSeek R1、Claude 4、OpenAI o3，以及Seed1.6-Thinking。<br /><br />高考其实是一种非常典型的测试场景，既能达到测试大模型泛化能力的目的，同时又兼具很高的实用性，也不难想象类似的使用场景，应该可以在教学、科研等方面发挥更大价值。<br /><br />这次做的是「山东版」高考全科试卷，分文理科排名，为了确保公平，不仅评测方式完全对齐高考判卷方法，开放题由两名有资深联考判卷经验的高中老师进行评估，而且大模型也没有引入任何提示词工程，所有输入都是高考原题。<br /><br />简单来说，这跟一名真实考生做卷子的环境几乎没有区别。<br /><br />还是先说结论，大模型的整体能力目前已经能拿到一个相当高的分数，其中位列文、理科头名的豆包和Gemini，分别拿到了文科683和理科655分的成绩——这分数甚至可以冲击一下清北——截取一些测评结果里的关键信息给你们看看：<br /><br />- 不出意料的，大模型表现最好的学科是英语，几家测评成绩都很接近，难以拉开差距；<br /><br />- 普遍得分最低的学科是化学和生物，不过这跟试题本身有关，这两个学科涉及到的读图题很多，由于这套试题不是官方发布，所以有些图比较模糊，直接造成了大模型的失分；<br /><br />- 豆包在语文、英语、物理、地理、历史、政治六门学科里均拿到了最高分，其中文科类目里的地理、历史、政治优势明显，事实证明在不同语种的语境里，大模型的表现可能是天差地别的；<br /><br />- 与豆包相反，Gemini的理科表现很强劲，哪怕在图不清楚的情况下，化学、生物仍然拿到了最高分，它与豆包的路线差别很有观察价值；<br /><br />- 跟上次高考数学的测评结果略有差异，这次数学学科的榜首是DeepSeek，不过同样与其他大模型差距很小；<br /><br />- GPT o3又开始整活，上次它是唯一一个在数学客观题上丢分的大模型，结果这次语文作文直接写跑题了，这导致o3的语文分数成了所有大模型语数英主科15份成绩里，唯一一个没有过百的...<br /><br />- 在发现了化学、生物的读图问题后，测试团队找到了一份更高清版本的试卷，并且采用图文交织的方式把这两科重做了一遍，结果发现豆包通过这种方式，两科总分还能再提高30分左右，这就意味着图文同步的全模态推理，可以更大程度激发模型潜力，很值得深究；<br /><br />- 目前看来，大模型的视觉方案进步神速，但毕竟视觉的TOKENS消耗要比普通任务高得多，所以它眼下要解决的主要问题，还是如何降本；<br /><br />- 除了高考全科真题外，测试团队还进行了另一项印度理工学院JEE Advanced的考试测评，题目全部采用图片输入，总分仍然是Gemini和豆包领先，甚至两个模型的成绩，已经可以进到印度TOP 10了。<br /><br />当然，大费周章做这么多测试，倒不是说它是测量大模型能力的唯一标准，比如今年年初AI行业知名的HLE基准刚出现的时候，各大主流模型的得分普遍低于10%，但HLE的开发团队也说了，按照历史规律来看，今年年底这个数字可能就会有50%。<br /><br />我的意思是，无论人类如何绞尽脑汁让AI做题，把题目通关也都是假以时日的问题，但这不代表做题成绩就没有意义了，重要的是不断精进学习的过程，也是探索AI究竟能多大程度上为人类所用的必要步骤。<br /><br />已经开始期待明年高考，AI会给我们一番怎样的景象了。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685c1966aabc50af59654394</id>
            <title>AI探索站 06月25日</title>
            <link>https://m.okjike.com/originalPosts/685c1966aabc50af59654394</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685c1966aabc50af59654394</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Jun 2025 15:44:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    古典产品经理，是通过调研、直觉来理解用户，做产品决策，满足用户需求。如果产品判断力不行，那就是在自嗨<br /><br />字节产品经理，是用实验、数据来理解用户，做产品迭代。如果指标定错了，就越努力越错，或者没办法定出一个指标，那就不知道该怎么努力<br /><br />AI 产品经理，是通过定义标准、测评，尽可能全面真实地反映用户对 AI 交付的结果的感受，来做 pipeline 优化和模型精调。如果标准定错了，产品优化方向就错了，如果测评不客观，那么就带来虚假的乐观
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685c04c69b5bcaa248e617c7</id>
            <title>AI探索站 06月25日</title>
            <link>https://m.okjike.com/originalPosts/685c04c69b5bcaa248e617c7</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685c04c69b5bcaa248e617c7</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Jun 2025 14:16:38 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我去！ 朋友们不用眼馋 Claude Code 了<br /><br />Gemini 也发布了类似的 AI 编程产品 Gemini Cli - 开源命令行 AI 工具<br /><br />而且个人谷歌账号登录就能免费用！<br /><br />这里下载：https://github.com/google-gemini/gemini-cli/<br /><br />免费额度为每分钟 60 次请求、每天 1000 次请求，是业内最高的免费额度，几乎不会遇到限制。<br /><br />- 支持 Google 搜索实时联网，为模型提供外部上下文。<br />- 支持 MCP和扩展，便于功能拓展。<br />- 可自定义提示词和指令，适应个人或团队工作流。<br />- 可在脚本中非交互式调用，实现自动化和集成。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685b65582b50c68918a1279b</id>
            <title>AI探索站 06月25日</title>
            <link>https://m.okjike.com/originalPosts/685b65582b50c68918a1279b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685b65582b50c68918a1279b</guid>
            <pubDate></pubDate>
            <updated>Wed, 25 Jun 2025 02:56:24 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这段AI视频在24小时内获得了五千万播放量😱<br /><br />在过去这几周，不断有新的AI视频成为超级大爆款，几个常见赛道：<br />ASMR<br />动物奥运会<br />肥胖奥运会<br />AI自然灾害<br />......<br /><br />要产出爆款，不是让AI产出多接近人的视频，而是让AI产出多“离谱”的视频
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/685a61ea605996b72a6e3ee8</id>
            <title>AI探索站 06月24日</title>
            <link>https://m.okjike.com/originalPosts/685a61ea605996b72a6e3ee8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/685a61ea605996b72a6e3ee8</guid>
            <pubDate></pubDate>
            <updated>Tue, 24 Jun 2025 08:29:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    用ai建模给自己打了个盗版“labubu”（少一颗牙版）<br />想要什么就自己去打<br />毫不费力手办自由🙊
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/684f02a9e441f085b7ce67c6</id>
            <title>AI探索站 06月15日</title>
            <link>https://m.okjike.com/originalPosts/684f02a9e441f085b7ce67c6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/684f02a9e441f085b7ce67c6</guid>
            <pubDate></pubDate>
            <updated>Sun, 15 Jun 2025 17:28:09 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    我为什么要创建 Fellou AI 浏览器<br />这其实是一个关于生产力的故事
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</id>
            <title>AI探索站 06月06日</title>
            <link>https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/684277e74e98b7acd544ba17</guid>
            <pubDate></pubDate>
            <updated>Fri, 06 Jun 2025 05:08:55 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近大家都在聊 AI 加持下的 vibe coding，我来聊聊作为资深开发者最近高强度使用 AI 的一些感受：<br /><br />一句话总结，AI 让不会写代码的人具备了“直接造辆车”的能力，而让资深开发者一个人就有了“独立建造航母”的可能。<br /><br />### 项目重构<br /><br />最近使用 claude-4 对我之前的一些代码进行了重构。原因是原来的实现中，为了降低编写时的心智负担，会使用一些性能偏低但是易于书写的代码。比方说自动锁管理、ARC、使用 array 数据结构代替 queue。<br /><br />然而用 AI 实现就没了这些负担，我先让 AI 为原始实现编写完整测试用例，确保原代码行为明确，然后让 AI 对整个 class 进行重构，追求极致性能，写完新代码后再重新运行测试保证行为一致。<br /><br />就这样，我轻松完成了部分核心数据结构的重构。尽管重构后的代码量几乎翻倍，但逻辑清晰、复杂度可控，换来的则是约 20% 的性能提升。<br /><br />核心是，AI 编写代码不怕苦不怕累，没有必要为了简化代码而牺牲性能。人类工程师目前主流习惯是牺牲部分运行性能以换取开发效率。<br /><br />### AI 编程语言<br /><br />这牵扯出的另一个观察是，什么编程语言对 AI 更友好，我的观察是可读性越高、行为越明确的语言效果越好。语法糖等简化编码技术，反而不利于 AI 使用。（AI 在发现一些奇怪的行为是运算符重载导致的不知道会不会跟我一样跳脚骂街）<br /><br />而像 SwiftUI 那些优势仅在开发效率上的技术，在 AI 时代更显得有些生不逢时。反正都是 AI 写，AI 用 UIKit/AppKit 实现不过是代码长一点而已，在可控性和行为明确性方面更适合 AI 自动化维护，性能也高的多。<br /><br />### AI 的资深<br /><br />虽然 AI 的编码技能，比起资深的工程师其实可能还是会有差距，但是要论知识丰富程度，则远非任何个体可比。<br /><br />这个优势体现在当我要去实现一些技术盲区时，原本的流程大概是：先读几本书，再对照比较一系列 RFC，再请教下相关领域的朋友确认自己已经理解。或者先按照自己的想象做个最小工程实践，然后再根据各种问题一点点填坑。<br /><br />比方说最近在实现 IPv6 ND 协议栈，一些特定的 RA 消息构造在某些操作系统上就是无法生效，原本这可能要耗费我几天的时间去研究，阅读各种文献甚至 kernel 源码实现，而现在只需请教 AI，就能非常准确地找到答案。<br /><br />AI 的这种资深，在你对某个技术的表层足够了解，但是缺乏经验和细节信息时，能够极快的帮你补全。<br /><br />### 极强的 debug 能力<br /><br />我的项目里有一个藏了很久的问题，在特定情况下会出现 TCP 性能下降，由于并没有产生任何明确的报错，这让修正这个问题变得异常麻烦。<br /><br />我原本是单纯向 AI 描述了我的使用场景和问题表现，AI 提出了几种猜想，大部分我看一眼就知道不靠谱，剩下几个试了下也并无效果。索性，我直接把 100MB 的抓包结果丢给了 o3 让他分析。它在几分钟内就精准指出了问题所在，甚至给出了改进建议。这种调试能力在人类团队中几乎无法复现。<br /><br />如此庞大的数据量，人工分析非常困难。即使借助各种工具，仅学习用法、配置环境就已令人头大。（因为 TCP 流控分析的各种工具链基本都是上个世纪的项目）<br /><br />现在我已经习惯了这种 vibe debug，遇到什么问题，直接把 verbose 日志和问题描述丢给 AI，大概率就能直接找到问题，这其实也是得益于 AI 的不怕苦不怕累的精神。<br /><br />### Peer review<br /><br />作为独立开发者，我的 code review 一直以来只能靠自己，但是自己写的 bug，很多时候自己是看不出来的🙈，现在我只需将 git diff 的结果交给 AI，就能请它帮我 review。<br /><br />同样的，我也会 review AI 给出的结果，AI 当然也会犯错，高级低级的都有。但是比起人类同事来说，AI 没有 ego，能很好地接受反馈并立即调整；很多人类做不到，或至少过程很曲折。<br /><br />### 职业影响<br /><br />就目前 AI 的能力来看，无疑是对初级开发者就业市场产生了巨大的压力，对于资深工程师来说，反而是一种赋能。（我目前还是能为找到 AI 的错误并指导它而沾沾自喜，但也不知道还能持续多久。）<br /><br />这比较让人担忧的是，这可能导致职业断层，因为初级开发者根本没有机会得到训练机会而成长。<br /><br />不过这已经早已不仅仅是软件工程师所面临的问题，本质上来说，所有脑力工作者的职业都受到了巨大威胁。像咨询、律师等职业，还可以依靠私域信息门槛维持。而像医生这样完全依赖公域信息的职业，初级职位也同样完全可以被 AI 替代了，当然最终取决于患者的接受程度。<br /><br />我最近一次体检后的报告喂给 o3 进行解读，他给出的信息量、准确性、建议，均远超全科医生给出的解读。不仅仅是因为 AI 的信息更全面，AI 可以为报告中每一项异常数据，检索最新研究与各国医疗指南，并整合后给出建议，甚至由于 GPT 已经了解我的生活习惯，能更优针对性的给出意见。而这种工作量对于人类医生来说是不可接受的（当然大多数情况下也确实没有必要）。<br /><br />很多人对 AI 医疗的顾虑是：AI 犯错了怎么办？然而其实人类医生也会犯错，而且就现在的 AI 水平来看，AI 犯错的概率应该已经比一般人类医生低了。当然最优解还是兼听则明，把 AI 的意见告知医生，也把医生的反馈告知 AI，基本最后都会达成一致。对于一些不重要的小问题，仅 AI 意见完全足够。<br /><br />### AI 的限制<br /><br />当然 AI 也不是万能的，甚至可以说局限性相当明显。claude-4 虽然非常强，但是随着 context 的增长，注意力溃散的非常严重，后面基本就像喝多了一样。<br /><br />当前的最佳实践是：尽量保持 context 精简，聚焦具体任务，依靠人力来拆解复杂目标。<br /><br />比方说先用一个 context 确定具体需求，再开一个 context 将明确好了的需求转换为具体任务列表，再把任务单独交给一个个 context 去具体实现。这样效果会好很多。<br /><br />仔细一看，这不就是人类的团队协作模式嘛 😂<br /><br />这让我想起不久前由 GPT o1 和 DeepSeek R1 的思维链引发的 AI 能力巨幅提升。其实在思维链能力出来之前，就可以靠 prompt 指引 AI 一步步思考，取得类似的效果，甚至催生了 prompt 工程师职业。然而直接在模型层面将这种能力整合后，prompt 引导就非常多余了。<br /><br />那么目前编程实践中，如今常用的 context 切分技巧，我认为在不久的将来也可能被模型层原生支持，即 AI 自主可以通过切换 context 的方式维持注意力，保持高效。这可能带来 AI 能力的又一次飞跃式进步。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</id>
            <title>AI探索站 05月30日</title>
            <link>https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68393bb5d9288e4a516c8782</guid>
            <pubDate></pubDate>
            <updated>Fri, 30 May 2025 05:01:41 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    感谢@硬地骇客 的支持，把三五环和半拿铁的多数文稿整理了一下，投入到 ima.copilot 里面，可以对话了。<br /><br />之前跟 ima 的朋友交流，就聊到未来知识库的「整理」变得没那么重要，而「采集」变得更重要，独特的筛选标准，以及采集逻辑，是决定知识库的价值的。ima 里也有很多筛选自己喜欢的内容而形成的公开知识库。<br /><br />对内容创作者自己来说，沉淀好自己的内容也特别有意义，有的不存不用确实就容易丢了。哪怕对别人没用，自己时常反刍也很有帮助。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>