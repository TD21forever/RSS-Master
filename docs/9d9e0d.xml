<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68240c57ab551d3d315f688b</id>
            <title>AI探索站 05月14日</title>
            <link>https://m.okjike.com/originalPosts/68240c57ab551d3d315f688b</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68240c57ab551d3d315f688b</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 May 2025 03:21:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    假装coser
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6824055e51bd007517aa165d</id>
            <title>AI探索站 05月14日</title>
            <link>https://m.okjike.com/originalPosts/6824055e51bd007517aa165d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6824055e51bd007517aa165d</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 May 2025 02:52:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    OpenMemory MCP 这个工具好啊<br /><br />将你需要的 AI 记录的内容都存在本地，然后共享给所有支持 MCP 的客户端<br /><br />这样你的 Cluade、Cursor、Windsurf 都可以读取相关信息了<br /><br />只需要维护一份记忆内容就行<br /><br />详细信息：https://mem0.ai/openmemory-mcp
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6823fc8bab551d3d315e4ea8</id>
            <title>AI探索站 05月14日</title>
            <link>https://m.okjike.com/originalPosts/6823fc8bab551d3d315e4ea8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6823fc8bab551d3d315e4ea8</guid>
            <pubDate></pubDate>
            <updated>Wed, 14 May 2025 02:14:35 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    过去几个月，我们一直在打造全新的 Devv。今天，Devv 2.0 正式开启 Private Beta 🎉<br /><br />👉🏻 https://v2.devv.ai<br /><br />2023 年发布 Devv 的时候，它是一个面向开发者的 AI 搜索引擎，两年间，AI Coding 的范式发生巨变，与其「搜索答案」，不如直接「生成并部署」。<br /><br />为了真正解决「想法落地」这一核心痛点，Devv 2.0 彻底转型为 AI App Builder：帮你把创意一步到位变成可用的 Web App。<br /><br />Devv 2.0 Beta 阶段的目标用户是「产品经理/编程初学者/设计师」等没有太多开发经验的用户，无论你是否会写代码，Devv 都能帮助你将想法变成产品。<br /><br />3 步完成一个可上线的 App：<br /><br />1. 描述需求<br />2. Devv 生成初始版本<br />3. 迭代 &amp; 发布<br /><br />在过去的几个月中，我们团队和一些早期用户已经把 Devv 2.0 大量融入到工作的 Workflow 中，例如这次发布的所有系统（包括 Landing Page 和邀请码管理系统）均是由 Devv 2.0 构建，极大提升了效率。<br /><br />我们仍是一个小团队，资金有限，所以 Private Beta 阶段会通过邀请的方式来让大家体验，所有 Beta 阶段的用户均可完全免费使用（由我们来 cover Claude 3.7/GPT o3 等模型的费用）。<br /><br />我们每周会邀请大概 100-200 名用户进行体验，并深度跟踪 &amp; 回访。<br /><br />🎫 获取邀请码的方法<br />1. 评论区<br />2. 如果你愿意分享具体使用场景，请私信，我们会优先邀请最匹配的用户
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822dbc2be924b3ca40cb3be</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822dbc2be924b3ca40cb3be</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822dbc2be924b3ca40cb3be</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 05:42:26 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天试了一组非常好看的双重曝光制图，适合游戏/影视/动画的概念实现，你们感受一下。<br /><br />提示词比较复杂，填充部分的内容需要自己手搓，我提供阿拉贡那张的示例：<br /><br />Double exposure, Midjourney style, merging, blending, overlay double exposure image, Double Exposure style,An exceptional masterpiece by Yukisakura revealing a fantastic double exposure composition of Aragorn son of Arathorn's silhouette harmoniously intertwined with the visually striking, Rugged landscape of the Middle-earth in The Lord of the Rings. Ash-choked skies loom over the jagged black spires of Mordor, where the air hangs thick with smoke and dread. Rivers of molten rock carve glowing veins through the barren wasteland, casting flickering light on the broken earth. At the heart of it all, Barad-dûr rises like a wound in the world, its lidless Eye burning with watchful malice. Every twisted shadow and gust of wind seems to whisper doom, as if the land itself resists the light. Beautiful tension builds as the stark monochrome background maintains razor-sharp contrast, drawing all focus to the richly layered double exposure. Characterized by its vibrant full-color scheme within Arogorn’s silhouette and crisp, deliberate lines that trace every contour with emotional precision. (Detailed:1.45). (Detailed background:1.4).<br /><br />简单来说，头尾部分大体是不变的，中间涉及到场景描述方面自己来写，要是词汇量不足的话，就抄一段范例然后ChatGPT来帮忙写，比如：<br /><br />下面是一段描写游戏《荒野大镖客2》的场景：Snow-covered pine forests, frosty mountain peaks, and a lone horse cutting through the trail echo outward through the fabric of his figure, adding layers of narrative and solitude. <br /><br />请以此作为参考，写一段描写电影《指环王》的场景文本，重点在于中土世界和魔眼的呈现。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822d761dc6b6d4853c1bc0f</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822d761dc6b6d4853c1bc0f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822d761dc6b6d4853c1bc0f</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 05:23:45 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    Prompt 放评论了
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</id>
            <title>AI探索站 05月13日</title>
            <link>https://m.okjike.com/originalPosts/6822c473e03d82181c847000</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6822c473e03d82181c847000</guid>
            <pubDate></pubDate>
            <updated>Tue, 13 May 2025 04:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    真正的领导者探索未知，而非发号施令<br /><br />在AI first团队中，真正的leader不会满足于开通付费工具、督促他人适应，而是亲自穿越未知的崎岖小径、发现独特风景，并将这些宝贵的发现和感悟无保留地分享给团队。<br /><br />在剧变的时代，领导力的精髓不只是指挥，而在于示范；不在于命令，而在于树立榜样。<br /><br />好的Leader以好奇心和同理心绘制「探索路书」，团队才会真正激发出10X的创造力。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/682220b4e900708e252f5e4a</id>
            <title>AI探索站 05月12日</title>
            <link>https://m.okjike.com/originalPosts/682220b4e900708e252f5e4a</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/682220b4e900708e252f5e4a</guid>
            <pubDate></pubDate>
            <updated>Mon, 12 May 2025 16:24:20 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一些个人认为适合非技术背景同学入门RL的材料不完全整理：<br /><br />1️⃣青铜级<br />（都是播客）<br />《一堂「强化学习」大师课》——42章经<br />《与马毅聊智能史:“DNA 是最早的大模型”，智能的本质是减熵》——晚点聊LateTalk<br />《我是这样用 RL + LLM 做 Agent 的｜对谈 Pokee AI 创始人朱哲清 Bill》——42章经<br />《走向强化学习：Agent 还是应用公司的机会吗？对话 Pokee.ai 创始人》——硅基觉醒<br />《Agent 开发的上半场：环境、Tools 和 Context 如何决定 Agent》——42章经<br />《强化学习的前世今生》——科技慢半拍<br />（以下是一些发布时间较早，但是我认为仍有价值所以保留推荐的⬇️）<br />《AGI 范式大转移：和广密预言草莓、OpenAI o1 和 self-play RL》——张小珺Jùn｜商业访谈录<br />《逐句讲解 DeepSeek-R1、Kimi K1.5、OpenAI o1 技术报告 ——“最优美的算法最干净”》——张小珺Jùn｜商业访谈录<br />《对话 Google Deepmind 研究员：OpenAI o1 及LLM+RL 新范式》——OnBoard! <br /><br />2️⃣白银<br />Andrej Karpathy《Deep Dive into LLMs like ChatGPT》（视频）（不是专门讲RL的，但是建议先看，系统了解）<br />Sam Lehman《The World's RL Gym》<br />Sutton与Deepmind《Welcome to the Era of Experience》<br />《Richard Sutton on Pursuing AGI Through Reinforcement Learning》（视频）<br /><br />3️⃣黄金<br />OpenAI o1 技术报告《Learning to reason with LLMs》<br />Deepseek官方论文《DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning》<br />Sebastian Raschka《The State of Reinforcement Learning for LLM Reasoning》<br /><br />4️⃣翡翠<br />《Transformer原作、斯坦福、清华交大三篇论文共识：基座模型边界锁死RL能力上限》（一篇公众号的概述，建议阅读原文）<br />《OpenAI's o3: Over-optimization is back and weirder than ever》<br /><br />5️⃣钻石<br />Sutton and Barto《Reinforcement Learning: An Introduction》<br />（坦白说还没学到这个层次，欢迎大佬们补充...）<br /><br />其实还有很多优质的资料，但我还没读的就不冒昧推荐了，欢迎在评论区安利🥹<br /><br />🎊扩展阅读<br />《A biref history of intelligence》
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/681adcd9efb7d4a44fd11dc8</id>
            <title>AI探索站 05月07日</title>
            <link>https://m.okjike.com/originalPosts/681adcd9efb7d4a44fd11dc8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/681adcd9efb7d4a44fd11dc8</guid>
            <pubDate></pubDate>
            <updated>Wed, 07 May 2025 04:08:57 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    基于OpenRouter的公开数据做了一个产品和模型的榜单，可以看到基于token使用量的产品排名和每个产品所使用的模型情况。如果你在选择模型或者研究对应产品，这个免费小工具应该会有帮助，网址是： https://yperf.com
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6819f51cdc6b6d48532c54a8</id>
            <title>AI探索站 05月06日</title>
            <link>https://m.okjike.com/originalPosts/6819f51cdc6b6d48532c54a8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6819f51cdc6b6d48532c54a8</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 May 2025 11:40:12 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    启师傅AI客厅-良渚demo day第5期报名啦！<br /><br />这次邀请了@少楠Plidezus @玉伯 、赵君三位嘉宾带来他们对AI产品的思考，还有@图拉鼎   Longyi Neko @henu王凯 @志鹏hustlzp @SUKIII 等优秀的开发者，来分享他们的最新产品！<br /><br />🎫报名链接：<br />https://mp.weixin.qq.com/s/YTeKjqc9X5J300HdP6AO_A<br /><br />📅 时间：2025年5月10日（周六）13:30 - 17:30<br />📍 地点：良渚文化村<br />🎧 主办：播客《启师傅AI客厅》<br /><br />🎙️ 主题分享<br />💡 《YouMind 产品思考》<br />讲者：玉伯 @玉伯 <br />语雀创始人，前飞书产品副总裁，现 YouMind 创始人<br /><br />🔧 《从需求到成本：AI落地产品的务实之路》<br />讲者：少楠 @少楠Plidezus <br />flomo、小报童联合创始人<br /><br />💰 《个人开发者怎么“捡”钱》<br />讲者：赵君<br />SimilarTube &amp; NanoInfluencer 开发者，产品经理<br /><br />🚀 产品分享<br />🎨 《Seede AI：人人都能用的 AI 设计工具》<br />讲者：Longyi <br />Seede.ai 创始人 &amp; CEO，前 Dora AI 团队成员，前美团架构师<br /><br />📺 《AIRI：如何从零实现外网爆火的AI主播》<br />讲者：奶扣 Neko<br />Literally Full-stack Developer，覆盖 AI Infra、模型开发、数据处理等全栈开源爱好者<br /><br />📊 《AI在交易中的实际运用 &amp; AGI视角的选择》<br />讲者：王凯 @henu王凯 <br />AI 连续创业者，FastFacts 等 AI 应用、松鼠快看创始人<br /><br />🗣️ 《Monspeak 的 What / Why / How》<br />讲者：Suki &amp; 志鹏 hustlzp<br />SUKI：设计师&amp;产品经理，正在边上班边做Monspeak @SUKIII <br />志鹏：iOS 独立开发者，《我的番茄》《LEMO FM》《西窗烛》等产品作者@志鹏hustlzp <br /><br />🌍 《PopTranslate：为 macOS 打造的 AI 原生翻译工具》<br />讲者：图拉鼎 @图拉鼎 <br />生活在良渚的开发者，专注 Apple 生态效率工具，正在打造新出海产品
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6819dcf6070109da49ad7802</id>
            <title>AI探索站 05月06日</title>
            <link>https://m.okjike.com/originalPosts/6819dcf6070109da49ad7802</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6819dcf6070109da49ad7802</guid>
            <pubDate></pubDate>
            <updated>Tue, 06 May 2025 09:57:10 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    对于想要大概了解 Flow Matching 的童鞋，推荐 MIT 的这门小课 https://diffusion.csail.mit.edu/，对于核心概念讲解清晰且符合物理直觉。flow matching 的原理我感觉比 diffusion 更易理解（而且还SOTA :D）。讲一下我从小白视角的理解：<br />文生图（无 condition）的过程，我们可以理解成是从一个纯随机的正态分布采样一个点，逐渐把它变成很“真”的一张图片。diffusion 是逐渐把采样到的这个“白噪音”点不断“去噪”，变成一张图片。而 flow matching，是让一个“磁场”去推着这个点不断移动，最终“移动”变成一张图片（想象图片 vector 各个维度的数值有加有减不断变化）。<br />稍微展开来说，flow matching 本质上是在学习一个 vector field/向量场（一个vector field定义一个ODE），可以把它想象成一个磁场。一开始我们只有一个符合正态分布的“沙堆”，我们的目标是逐渐”推移“这个沙堆，让它最终的分布符合我们要的分布（真实世界的图片）。对于每粒沙子在每个时间点、每个位置，磁场力的方向（往哪个方向推）就是我们要 neural network 学习的东西。一粒沙子从初始位置到目标位置”被磁场推着“经过的路，就是一个 flow（ODE 的一个解），不同沙子走出了多条 flow 形成多个训练数据不断调教 NN 去学习磁场里的方向，大量平均下来就是我们想要的磁场/模型。<br />细心的童鞋可能会问，那 NN 咋知道往哪推啊？给定了一张图片，对于”想要成为它的沙子“，在一个时间点和一个位置，我们磁场力的方向是提前设计好的（conditional vector field），这样 NN 对于一个样本往哪推是知道的。我们不知道的是大量这样的数据，最终让 NN 平均下来会学成个啥样，即 marginal vector field（就是我们想要的）。<br />最后附几张作业截图证明我不是瞎吹牛（btw 作业很简单）
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>