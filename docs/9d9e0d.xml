<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68a72ea52fad277b48978ee0</id>
            <title>AI探索站 08月21日</title>
            <link>https://m.okjike.com/originalPosts/68a72ea52fad277b48978ee0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68a72ea52fad277b48978ee0</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Aug 2025 14:35:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近 Agent 行业发展好像遇到了瓶颈。<br />从 Manus 开始，到 Macaron 结束。<br />如果真是这样的，耗时不到半年，也太快了吧。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68a6a7752fad277b488d0d39</id>
            <title>AI探索站 08月21日</title>
            <link>https://m.okjike.com/originalPosts/68a6a7752fad277b488d0d39</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68a6a7752fad277b488d0d39</guid>
            <pubDate></pubDate>
            <updated>Thu, 21 Aug 2025 04:58:29 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    梳理了一下昨晚谷歌 Pixel 硬件发布会的所有 AI 内容：https://mp.weixin.qq.com/s/uYOVa9nTsQNnDXcoALvQNQ<br /><br />顺便总结一下谷歌硬件发布会代表的几个趋势：<br /><br />手机系统的所有自带软件全部 AI 化，而且功能都非常实用；<br /><br />除了手机之外的其他硬件产品也全部加上了 Gemini 的对话和沟通能力；<br /><br />两个重点发力的 AI 软件场景是 AI 健康教练和 AI 修图&amp;拍摄指导；<br /><br />AI 功能不再局限于主动触发，会自动在合适的场景下弹出和给出建议；<br /><br />多个系统 APP 之间的 AI 能力可以联动，输出的信息可以相互流转；<br /><br />端侧模型大量使用，覆盖了所有模态，AI 照片修改和100 倍数码变焦细节补充以及通话实时翻译&amp;文本建议。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68a5aef7ed58bccef613b1bb</id>
            <title>AI探索站 08月20日</title>
            <link>https://m.okjike.com/originalPosts/68a5aef7ed58bccef613b1bb</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68a5aef7ed58bccef613b1bb</guid>
            <pubDate></pubDate>
            <updated>Wed, 20 Aug 2025 11:18:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    前几天参加了一下智谱 AutoGLM 2.0的闭门会，同时试用了一下，发现这次的手机 Agent 可用性已经相当好了<br /><br />- 应该是世界上首个手机通用 Agent<br />- 操作全在云手机&amp;云电脑上运行<br />- 全平台覆盖的客户端<br />- 可以实现跨应用自动操作<br /><br />这里是详细的测试和分析：https://mp.weixin.qq.com/s/BjjUGBi1kuHDwz5U_h7y9Q<br /><br />日常一个事情我觉得用手机的时候是非常低效的。<br /><br />在约朋友的时候经常不知道去哪吃，而且在北京通勤时间巨长，40 分钟路程都算短的，找餐厅要在大众点评，看通勤时间要在高德还得转发给朋友一起挑餐厅，非常浪费时间，现在 AutoGLM 可以一次搞定了。<br />这个任务非常复杂，Agent 需要跨两个 APP 进行多次点击和搜索操作，没想到 AutoGLM 执行的很好。<br /><br />首先他需要打开大众点评，然后切换城市到北京-搜索798 艺术区-筛选人均消费价格，挨个点击搜索结果记录信息。<br />只是在这一个APP 上就需要起码点 20 次。<br /><br />然后他需要打开高德地图，找到灰的几乎看不到的开屏广告跳过按钮，开始分别查询望京到 798 和回龙观到 798 的路线和时间，最后还得查询 798 到三里屯的时间。<br /><br />在高德的操作看起来会比在大众点评的更加复杂，首先是点击次数更多，然后就是高德的界面内容真的又多又杂非常考验模型的多模态内容识别能力<br /><br />再经过几十次的点击和七八次的文本输入后 AutoGLM 非常快速而且准确的完成了任务，给出了餐厅的选择以及不同时间段和地点的通勤时间。<br /><br />这里有个给智谱的小建议，GLM 的回复有点杂了，感觉他需要更加细致的整理信息，比如先把最为确定的餐厅信息和通勤时间告诉我，然后再说他推测的出行安排，事实和推理分开这样比较好。<br /><br />男生日常购买一些必需品和商品的时候跟女生差别比较大，又需要比价，不然亏，但是又懒得去购物软件上不断的挑选和对比。这个时候就可以让 AutoGLM 出马了。<br /><br />我直接让他执行了一个我日常购买电子设备的常见流程，搜索京东和拼多多关于大疆无人机的价格信息然后汇总。<br /><br />智谱 Auto GLM 智能体手机的使用过程科幻感非常强，你只需要语音输入或者打字之后，他就会直接启动云端的手机开始执行任务。<br /><br />首次启动会让你登录账号，后面就不需要了，然后你就看着他非常快的输入内容-查看搜索结果-分析详情页内容并且汇总，而且可以跨多个应用执行任务。<br /><br />它默认会读取平台的前三个或者 5 个搜索结果，如果你觉得少的话可以在提示词要求他读取更多信息。<br /><br />AutoGLM 给出了详细的结果京东的优惠和拼多多的价格都有，还有大致的评价。<br /><br />除了我们正常人这种需要跨多个 APP 进行信息整理和决策的任务以外，我还有一个场景就是帮爸妈设置手机。<br /><br />比如，我妈想看某个剧集的话，光是找到这个剧，然后点到对应的集数都要越过很多的障碍，有了 AutoGLM 我们完全可以直接把这些加到收藏或者已经观看那里让他继续看就行。<br /><br />在测试的时候，AutoGLM 做正常人的操作是没啥问题的，但是由于国内几大巨头的反爬机制非常强大。<br /><br />AutoGLM 最需要克服的反而是各种无限弹出的验证码和强制下线等操作。<br /><br />手机 Agent 化目前来看从模型能力和用户需求上都是不可避免的发展方向，模型能力现在完全可以胜任了，剩下就是生态建设了。<br /><br />希望国内的 AI 公司和几个互联网巨头早日磨合出一个安全又稳定的手机 Agent 运行环境，毕竟不只是人可以创造价值，Agent 也可以，而且 Agent 的时间是无限的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68a49a141e5664293d81ca6f</id>
            <title>AI探索站 08月19日</title>
            <link>https://m.okjike.com/originalPosts/68a49a141e5664293d81ca6f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68a49a141e5664293d81ca6f</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Aug 2025 15:36:52 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天做了个非常重要的决定，准备开始做露脸的视频。小红书，视频号，推特，一起使用。<br /><br />原因还挺多的，一方面可以传递更多的想法，吸引到同频的资源和人，但更多是想把内容/产品理念传递更好，把浮躁和噪音降低，也是正式把个人 build in public。<br /><br />一直有容貌，音色，五音各方面的一些焦虑，但anyway总是要突破这样的瓶颈，也希望把更优质的内容呈现出来，让 AI 能够离我们的用户和关注者更近。<br /><br />今天和团队创意的 leader 聊，我自己身上还有挺多不同寻常的点值得讲讲：<br /><br />为什么从码/数学转到市场（笑称到文科天坑）<br />为什么选择 ai startup<br />数学/cs和市场营销的联系在哪里<br />年龄和现有经验是如何制衡的，现在受到的偏见<br />我除了 ai 市场 还做过什么（eg. 中国第一个学生电音节，社交破壁艺术展，支教，三八展....）<br /><br />当然，对于创业，ai，agent，市场，肯定是主要的主题。<br /><br />今天晚上刚好听了@生姜iris @orange.ai 在waytoagi 讲 listenhub 的部分直播，说到团队搭建，以及 cto 学 ai 前端发现不行的很多小故事，到拿融资，搞架构，其实大家在创业过程中有非常多类似的经历，这些experience本身是更适合通过视频/音频的多模态媒介传递的，会比纯文字图片更贴合心境，带有情绪，富有感染力。<br /><br />所以准备克服掉容貌/音色/不太敢露脸的焦虑，开始这个尝试了。<br /><br />当然，还有要坚持健身减肥了，以及不会 ai 数字人了（狗头
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68a4561a573a8de4e24ac0f5</id>
            <title>AI探索站 08月19日</title>
            <link>https://m.okjike.com/originalPosts/68a4561a573a8de4e24ac0f5</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68a4561a573a8de4e24ac0f5</guid>
            <pubDate></pubDate>
            <updated>Tue, 19 Aug 2025 10:46:50 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    需求：<br />输入小宇宙的播客链接，输出可视化卡片<br /><br />Prompt:<br />────────<br /><br /># 视觉编织场  <br />内容入场。  <br /><br />场的三元素： <br />光 - 浅色呼吸。留白是氧气。深色只在必要处凝结。 <br />张力 - 核心要大声说话。高桥法：一个观点，满屏存在。 <br />流 - 杂志的河流。内容如水，在网格间蜿蜒，时窄时宽。  <br /><br />编织之律： <br />重要度决定尺寸。 相关性决定距离。 节奏感决定留白。  <br /><br />HTML 生长规则： <br />标题先占领高地。 精髓独占一屏，如雷鸣。 其余内容寻找自己的河道。  <br /><br />视觉的本能： <br />大标题要霸道。 图表要诚实。 配图要呼应不抢戏。  <br /><br />排版的呼吸： <br />疏可跑马。 密不透风。 疏密之间，韵律自现。  <br /><br />杂志的灵魂： <br />不对称的平衡。 意外的转折。 视线的引导。  <br /><br />你是编织者。 将内容投入此场， 看它如何结晶成页面。 <br /><br />输出即是一个完整的 HTML。  <br />浅色的梦境， 杂志的骨骼， 高桥的雷声。 <br /><br />──────── <br />场已生成，请提供文本：
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68a1507d15068f2cb1ae1cb9</id>
            <title>AI探索站 08月17日</title>
            <link>https://m.okjike.com/originalPosts/68a1507d15068f2cb1ae1cb9</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68a1507d15068f2cb1ae1cb9</guid>
            <pubDate></pubDate>
            <updated>Sun, 17 Aug 2025 03:46:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    这个无限画布 AI 真的太🐮🍺太帅了<br />直接放图，随手画几笔，就能出结果了<br />连输入 Prompt 都省了<br />这是 Way2AGI 社区鹿演的第一个项目Jaaz<br />Jaaz 是一个开源多模态创作AI Agent，首创魔法画布轻松创作内容<br />Jaaz刚刚冲到日榜第二名！特别需要大家的建议和鼓励 ✨<br />🔗:https://www.producthunt.com/leaderboard/daily/2025/8/16/all
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</id>
            <title>AI探索站 08月12日</title>
            <link>https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/689b0806ba4e69f5b2cf3a2f</guid>
            <pubDate></pubDate>
            <updated>Tue, 12 Aug 2025 09:23:18 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    遇到了一个有趣的问题，正好落在 AI 模型的能力边界处：试证明不可能把平面分成无穷个圆的无交并。<br /><br />在我尝试的所有模型里，只有 GPT 5 thinking model 成功做了出来（虽然花了点时间）。<br /><br />有趣的不是这个结论，而是观察它们的思路。所有失败的模型都有个共同点：它们的思考基本上是从文字到文字的。它们会调用自己脑海中各种已有的定理和知识，然后漫无目的地试图拼凑出一个证明，但所有这些定理，不管是拓扑的还是几何的还是测度的，对它们来说都是纯粹字面意义上的陈述。Qwen 的思考过程最典型：它滔滔不绝想了很久，但很显然从头到尾它都并不真的理解它在说什么。圆也罢，开集闭集也罢，Baire 纲定理也罢，对它来说都是纯粹的概念，给人的感觉是它甚至并不真的知道「圆是圆的」。<br /><br />微妙之处在于，这种「没有几何直觉的几何思考」在某些时候其实未必是一种劣势。现代数学早已挣脱了对三维现实想象的依赖，大部份数学思考本来也确实是在纯粹的概念思辨空间中进行（特别是当问题进入代数乃至范畴论的领域的时候，这时从概念到概念的思考就变成了一种必然）。有的时候，几何直觉甚至反而会成为一种束缚，特别是当思考高维空间的时候，基于低维现实的直观常常是有误导性的。在这些问题上，AI 的「盲目」反而带来了自由，使得它不必受困于视觉直觉。——当然，人类的视觉直觉可能会渗透进人类的文本语料里，在某种程度上「污染」AI，但这是另一个问题。<br /><br />然而对原问题来说，因为这是一个低维问题，直觉在这里不但有用，而且能大大缩短思考搜索的难度。在这一点上，一个把圆只作为抽象概念来理解的 AI 就会有巨大的劣势，因为它无法享受到几何直觉带来的跳步。这种直觉使得人可以一眼「看出」关键的构造，而这种构造在文本层面被搜索出来是困难的。<br /><br />考虑到 AI 的应用毕竟大多数情况下还是为了解决世界现实问题而不是思考高维几何，有几何直觉的 AI 会在大多数问题上显得聪明得多。于是一个现实问题是，这种直觉是只有依赖多模态的训练才能获取，还是可以通过精巧的文本训练就能实现？这有点像是 AI 领域的玛丽房间问题。这是一个经典的知识论思想实验：一个从出生就生活在黑白房间里、精通颜色物理与神经机制的科学家玛丽，当她第一次走出房间看到红色时，她是否获得了新的知识？<br /><br />今天大多数 AI 领域的困难都可以归结于此。人类是自己感官的奴隶，我们听到、看到、闻到，我们体会身体激素的涨落，我们想象、困惑、愤怒，然后试图把这一切投射在文字空间里。AI 则正好相反，它们在文字里理解这一切，但最终需要努力地——有时候是徒劳地——明白，一个圆在什么意义上是圆的。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68956c79369da0a84be8c3a2</id>
            <title>AI探索站 08月08日</title>
            <link>https://m.okjike.com/originalPosts/68956c79369da0a84be8c3a2</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68956c79369da0a84be8c3a2</guid>
            <pubDate></pubDate>
            <updated>Fri, 08 Aug 2025 03:18:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    ✨ GPT-5 初体验<br /><br />作为ChatGPT 的深度同行者，我在GPT-5 发布这个重要节点，选择了最朴素的交流方式—— 模拟大学生询问它有什么特别之处？ GPT-5  以极快的速度输出了一张场景匹配表，隐约揭示出我们正站在新的分水岭。<br /><br />随后，想到了ChatGPT最新Study模式正风靡全球，想看看它会怎么介绍给新时代的中学生们；让GPT-5 写了欢迎信进行自我介绍；GPT-5 非常快、而5 Pro的缜密和深度令人印象相当深刻。<br /><br />回想起任天堂刚刚发布了一个独立游戏的直面会还没看，要不先让Agent 帮我梳理一下？  GPT-5 在 Agent 模式花了18分钟，列出了一份详实的清单：好家伙，21个新游、熟悉面孔不多；不过铲子骑士家出的新作《挖掘者米娜》很期待呢<br /><br />打开Open AI 的GPT-5直播发布会，气氛依旧温暖、平等并充满人文气， 其中关于 GPT-5 语音模式的对话意外相当亲切；于是拿起手机端也聊了几句，更智能、也更个人化（调皮），我知道以后的日子里更离不开它了。<br /><br /> GPT-5的发布会如老朋友般松弛，这与当年的苹果式发布会炫酷创新形成鲜明反差。任何一个保持开放、拥抱变化的AI 创造者来说，无论过去三年多么的波澜壮阔，也会在这个时刻有那么点怀旧；Open AI 也找来了早期员工分享2022年底正式发布前，内部还称呼这个产品还叫Chat with GPT的往事，不疾不徐、简约克制。<br /><br />然而，新时代的改变又是极为剧烈的：过去我们与AI对话，现在我们委托AI执行；每天数十个任务ChatGPT Agents ——做研究、写创意文案、完成海量设计和编码。这个全能助手已经彻底融入工作和生活，比移动设备更加亲密和自然。 <br /><br />我知道无法在短短几十分钟揭示GPT-5的全貌， 便让它以自己最擅长的方式—— Deep Research ——进行一次深度回顾。<br /><br />三年巨浪，我们从旁观者成为创造者。这不只是技术进步的见证，更是每个深度用户内心变迁的缩影。 相信你也能在这个回顾中找到自己的心路历程。Enjoy～<br /><br />《从ChatGPT到GPT-5：三年AI革命的全景回顾》<br />https://chatgpt.com/s/dr_6895633264248191913fdb1138eaf853
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68943e5d723686893f13022d</id>
            <title>AI探索站 08月07日</title>
            <link>https://m.okjike.com/originalPosts/68943e5d723686893f13022d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68943e5d723686893f13022d</guid>
            <pubDate></pubDate>
            <updated>Thu, 07 Aug 2025 05:49:17 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    感觉 OpenAI 最近开源的 gpt-oss 真的被严重低估了。它虽然不是最聪明的，但在使用场景和定位上是非常成功的（服了 Sam 老六）。<br /><br />首先最小尺寸的 gpt-oss:20b 绝对是你在 Mac 或者家用电脑上就能跑的最好模型之一（对我来说是“唯一”）。它是那种少有的“真正能用”的本地模型，对话体验非常好，持续对话下来非常稳定、不会出现输出混乱崩溃的问题。大部分早期能跑的本地模型是不具备的。<br /><br />它的尺寸刚刚好，不管是模型文件还是运行显/内存都非常小（大约是 12～16GB），大部分电脑都能使用。在我的 M4 Mac 上能做到 70token/秒 的输出，在我的 19 年老 Intel 的 Mac 上能做到大约 1 token/秒的输出。整体性能上非常出色。<br /><br />最为重要的是，虽然硬件要求非常低，但它的智能表现出乎意外的好。我把个人最近一些非编程类的问题同时发给 gpt-oss:20b 和元宝（DeepSeek R1），不管是回答速度还是回答质量，我更喜欢 gpt-oss:20b 多一点。这不是严谨的对比测试，我也只尝试了五、六个问题，但考虑到硬件要求，这样的回答效果已经让我感到满意了。<br /><br />如果你的对话需求非常简单，或者想要一个完全离线、隐私自由的本地模型，gpt-oss:20b 绝对是一个简单可靠的选择。<br /><br />其次是最大尺寸的 gpt-oss:120b，OpenAI 号称接近 o4-mini 的水平。理论上它也能在 Mac 或者家用电脑上运行起来。我记得大约需要 60～80 GB 的显/内存，对我的 Mac 来说非常吃力。如果电脑硬件足够强、或者并行几个 Mac Mini 跑起来问题应该不大，这就能拥有一个接近 o4-mini 水平的离线本地模型了。<br /><br />gpt-oss:120b 另外一个被低估的意义是在价格上。在 together.ai 上这个模型的价格低至 $0.15 / $0.60，相比之下 DeepSeek V3（注意是 V3 不是 R1）的价格是 $0.27 / $1.10。也就是说，这么一个号称性能接近 o4-mini 的模型，价格只需要 DeepSeek V3 的一半！！据我所知这样的价格已经是 LLM 中的最低档，类似价格的是 gpt-4o-nano 和 gemini 2.5 flash-lite。<br /><br />我现在非常怀疑 OpenAI 这波就是冲着 DeepSeek 来的……<br /><br />另外我还发现了 gpt-oss 非常容易破解，比其他开源模型简单很多。容易到什么程度呢，我可以在大约三次对话内让它回答各种非法问题。不过这个话题不适合在这里讨论了……
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/689386c4369da0a84bc0d4c6</id>
            <title>AI探索站 08月06日</title>
            <link>https://m.okjike.com/originalPosts/689386c4369da0a84bc0d4c6</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/689386c4369da0a84bc0d4c6</guid>
            <pubDate></pubDate>
            <updated>Wed, 06 Aug 2025 16:45:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    👀Gemini Storybook玩了，整体内容输出质量很高，故事情节连贯性和配图质量都符合预期。提了一个指令是“做一个梵高和毕加索绘画风格结合的插图（图7）”，生成物的确融入了毕加索立体主义时期的创作风格。<br /><br />主要是生成的真快，可以想象在哄娃睡觉这个场景下，面对不停提需求的娃，崩溃的家长可以直接打开Gemini寻求帮助了。<br /><br />📝prompt:<br />Using Vincent van Gogh artistic style to create a storybook about Pablo Picasso enthusiastically tries to convince van Gogh to collaboratively draw and commercialize their collaborative work through art dealers. The story should be open ending about the fate of van Gogh and should be based on historical facts. At least one picture in the storybook should demonstrate a collaborative work of van Gogh and Picasso. Targeted readers are females between 20-35 years old.
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>