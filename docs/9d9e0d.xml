<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>AI探索站 - 即刻圈子</title>
        <link>https://m.okjike.com/topics/63579abb6724cc583b9bba9a</link>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6902b073130051d46bc69917</id>
            <title>AI探索站 10月30日</title>
            <link>https://m.okjike.com/originalPosts/6902b073130051d46bc69917</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6902b073130051d46bc69917</guid>
            <pubDate></pubDate>
            <updated>Thu, 30 Oct 2025 00:25:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    最近的美国裁员潮，背后是两个完全不同的故事<br />亚马逊、Meta、微软这些科技巨头在裁员，但收入在涨，股价在涨。<br />他们裁人是为了腾出预算买GPU。<br />这不是经济下行时的削减成本，而是把工资预算强行转移到数据中心。<br />算法很简单：裁掉1%的人，就能多买一批H100。<br /><br />另一边，UPS、雀巢、福特、Target也在裁员，但原因完全相反。<br />他们已经用上了真正有效的AI工具：客服自动化、供应链优化、生成式设计系统。生产力提升是真实的，而且在加速。<br />这些公司不需要买大规模GPU集群，他们从云服务商那里租推理算力就够了，裁人是因为账算得过来了。<br /><br />两边都在喂养同一头野兽。<br />科技公司在买铲子，其他公司在买铲子挖出来的金子。<br />半导体公司坐在中间，从整个价值链收租。<br />台积电、英伟达、ASML在印钞，两端的就业都在崩塌。<br /><br />时间点很关键。现在企业AI采用率是10%，正在往50%走。<br />历史经验是这个阶段跑得最快，创造的财富最多。<br />但这些财富在往算力集中，不是劳动力。<br />市值增长和工资增长之间的差距，从来没有这么大过。<br />这不是经济衰退，是一次重新平衡。<br />大多数打工人在错误的那一边。<br /><br />本文翻译自图2，不代表个人观点。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6901ce18d9abb9785d02257d</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/6901ce18d9abb9785d02257d</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6901ce18d9abb9785d02257d</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 08:19:36 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    谷歌昨晚发布了新的 AI 设计产品，想法挺屌的<br /><br />只需要只需要把你的官网链接给他，他就会提取品牌设计相关的所有元素，帮你生成营销海报<br /><br />下面是使用教程和具体的产品分析👇<br /><br />目前这个产品在美国、加拿大、澳大利亚和新西兰推出，需要尝试的注意 IP。<br /><br />长文链接在这里：https://mp.weixin.qq.com/s/TQRl_TX7iXUIzcYCBr5LYg<br /><br />我试了一下之后发现，如果优化一下这个思路未必不能再造一个 AI 版 Canvas，操作成本低，自定义程度高。<br /><br />在你进到产品里之后只有一个非常简洁的网址输入框，直接输入你的官网地址点击 Continue 就行。<br /><br />我们先输入我们的老朋友 Lovart 的官网，因为他们的设计比较一致，同时官网信息给的也比较丰富。<br /><br />Pomelli 会开始分析官网中涉及品牌的各种信息比如配色、字体、产品能力等。<br /><br />稍微等待一会之后，他就会根据从网站爬取的信息，帮你创建一个关于这个产品的品牌 DNA 卡片。<br /><br />如果你做品牌设计的话肯定很熟悉，包括产品 Logo、品牌字体、主要配色、各种主页上的图片素材，还有产品能力以及商业上的定位关键词等，非常详细。<br /><br />当你觉得上面的信息没问题的时候你就可以点那个「looks good」然后进入到生成页面了，他会在下方根据你的品牌 DNA 生成几个用于预览的设计稿。<br /><br />你也可以在输入框输入你需要的营销活动内容，他就会自动优化文案，帮你规划排版生成营销图片了。<br /><br />可以看到点击 「Generate ideas」 之后就会开始生成他会给你三个广告内容的创意，你需要先选择这部分。<br /><br />可以看到第三个的文案内容是比较符合这次营销的主题的，我们选择这个。<br /><br />在你选择文案主题之后，他就会开始生成对应的图片了，会给你四个选项。<br /><br />可以看到他给了四种完全不同的排版风格，比如第一种是比较专业的背景，第二种有点科技感，第三张偏人文，最后一张就是纯文字排版，比较醒目。<br /><br />如果你喜欢某一张图片的话，就可以点进去进行微调，这里我觉得第三张还行。<br /><br />微调的主要有四部分：背景图片、标题、内容、号召按钮。<br /><br />图片都是他从网站上爬取的图片素材，如果实在没有素材他也会调用 Nano Banana 生成背景图片。<br /><br />标题和内容这里主要调整的就是文案的内容以及文案样式，可以帮你生成新的文案。<br /><br />字体这里内置了一些，如果你改了之后就会重新生成。<br /><br />号召按钮 这里默认他是不生成的，如果你这张图是投放内容，需要有号召按钮需要点击的话，可以点击右边的生成按钮让他帮你生成。<br /><br />可以看到他生成的按钮颜色就是 Lovart 网站按钮的颜色，整个的一致性就会很高。<br /><br />可能你会看到海报下面有个「Fix Layout」的按钮，这个主要是为了修复在修改文案后，由于文字宽度和长度的不同导致的没有对齐的问题，如果他生成的海报有这个问题，可以点这个按钮。<br /><br />最后如果没问题的话点击下载按钮下载生成的海报和营销物料就行，下面这三张就是我在测试中生成还行的。<br /><br />好了这就是谷歌新的 AI 设计工具 Pomelli 的体验了。<br /><br />总得来说整个交互和产品点子是非常好的，如果是临时救急和批量生产广告内容也不错，总比代理商瞎搞强。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6901c89e4268c406fc41a671</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/6901c89e4268c406fc41a671</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6901c89e4268c406fc41a671</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 07:56:14 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    苹果美区账号注册最稳方法<br />无需信用卡，无需美国手机号，100%成功率。<br /><br />1、访问美区 Apple ID 注册页面<br />浏览器打开 appleid.apple.com，点击右上角「创建您的 Apple ID」。使用未注册过的邮箱（Gmail、 Outlook 等国际邮箱最佳）。<br /><br />2、填写注册信息<br />国家/地区务必选择「美国」。生日选择满18 岁以上日期。其他信息如实填写，手机号填写国内号码即（+86）。<br /><br />3、验证邮箱和手机号<br />查收邮箱和短信中的验证码，依次输入完成验证。通常1分钟内即可收到，若未收到检查垃圾邮件文件夹。<br /><br />4、登录并前往 App Store（重点）<br />在iPhone/iPad 的 App Store 中登录新账号（不要在iCloud 登录）。首次登录会弹出「检查账户信息」提示，点击「检查」。<br /><br />5、同意条款并填写付款信息<br />勾选同意条款，付款方式选择「无」。账单地址填写免税州地址（推荐俄勒冈州、特拉华州）。<br /><br />6、生成美国地址<br />访问meiguodizhi.com，点击「俄勒冈州地址」或「特拉华州地址」生成免税州地址，复制以下信息：<br />姓名、街道、城市、州、邮编、电话<br /><br />7、填写地址信息并完成<br />将生成的美国地址信息粘贴到对应字段，点击「下一页」完成设置。现在可以自由下载美区应用啦。<br /><br />🌟温馨小Tip<br />建议保持美区账号仅用于 App Store，日常iCloud 使用国区账号。需要付费购买 App时，可使用礼品卡充值（淘宝、美亚购买）。避免频繁切换地区，可能导致订阅服务中断。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6901af303ea7571a78f7baf4</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/6901af303ea7571a78f7baf4</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6901af303ea7571a78f7baf4</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 06:07:44 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    一个提示词秘籍，立马提升AI能力：<br />每个提示词结尾，都加上一句<br />“如果你有任何不清楚的地方，请向我提问”
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/69018d5b477e33c6e006d2c7</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/69018d5b477e33c6e006d2c7</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/69018d5b477e33c6e006d2c7</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 03:43:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    让我们直接一点。<br /><br />如果你不是投资人和研究员，这些媒体热议的话题，跟你关系不大：<br /><br />- AGI 到底是什么，何时实现？ 会不会抢掉大家的饭碗？<br />- AI 硬件投资是否过剩？ 寒冬还是泡沫？<br />- Agent 到底有没有通用性，是新的基础设施还是过度炒作？<br />- Reinforcement Learning  走到了死胡同？ Scaling Law 还在扩展吗？<br />- 某某公司又融了多少钱， ARR突破了多少？<br /><br />真正决定你的未来，是这些问题：<br /><br />- 你日常使用哪几个模型？ 它们是最好的吗？你如何更新认知？<br />- GPT-5 到底有多少种模式？ Thinking 模式为什么重要？<br />- 推理模型在哪些应用场景，实实在在改变了我的工作和生活？ <br />- 重大突破的新产品（例如 Deep Research、Notebook LM、Sora、Claude Code等），你持续探索其边界吗？<br />- 除了日常Copliot， 每周这个尺度上，AI 工作流有哪些新进展和新发现？<br />- 原型驱动是什么？为什么软件和创作领域专业人士认为，它在重塑创造范式？<br />- 对任何一个模型或一个新产品，下定论之前，我们深度探索过 10 次以上吗？那些使用 1000小时以上的人是如何看待的？<br /><br />好奇心与充满野心应用 AI 并不冲突；难的是突破认知偏见、对抗噪声。<br /><br />如费曼先生所言，「凡是我不能创造的，就意味着我还不理解。」    少围观， 多创造。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/690174d92c7c9e2ff1ef07f0</id>
            <title>AI探索站 10月29日</title>
            <link>https://m.okjike.com/originalPosts/690174d92c7c9e2ff1ef07f0</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/690174d92c7c9e2ff1ef07f0</guid>
            <pubDate></pubDate>
            <updated>Wed, 29 Oct 2025 01:58:49 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    🚀 YouMind 0.5 正式发布<br /><br />YouMind 是一个专门为内容创作者、内容学习者打造的一站式 AI 工作室。<br /><br />你是否记得，收集的一堆资料，再也没去看了。你是否记得，很想开始创作，但始终卡在第一篇。<br /><br />有了 YouMind，这一切挑战，依旧还是挑战。然而一个好的工具，可以塑造一个良好的环境。拥有 YouMind，你想创作的任何起心动念，就拥有了开始行动的翅膀。<br /><br />欢迎使用：https://youmind.com<br />大胆创作，不止于学
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6900d005336613c9e0fca901</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 14:15:33 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    在此推出 FlowithOS，全球首个为 Agent 原生打造的操作系统，可能是你的最后一个浏览器。<br /><br />FlowithOS 让 AI 可以 100% 像人一样与整个数字世界交互。<br /><br />- browser-use 浏览器使用: 让它可以自主点击网页、上传/下载文件、甚至可以操纵第一视角游戏，与其它玩家对战。<br />- terminal-use 终端使用: 让它可以通过命令行、访问和操作你的整个计算机，帮你整理文件、或者直接批量创造。<br />- script-use 脚本使用: 让它可以自主根据你的需求和网页状态、实时生成脚本，以 100 倍效率批量获取信息。<br /><br />除了这些超能力外，FlowithOS Agent 还搭配了 online-RL 和自我进化和学习的能力，配合经验和记忆系统，你的 OS Agent 可以随着时间变得越来越聪明、越来越懂你。<br /><br />在 Online-Mind2Web 全球评测中，FlowithOS 以压倒性接近满分成绩超过 OpenAI Atlas、Gemini 2.5 Pro CU 等顶尖浏览器 Agent，成为现地表最强浏览器智能体。<br /><br />现在，FlowithOS 公测版已全量上线，支持 Windows、Mac 所有平台，在 flowith.com 即可开始
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</id>
            <title>AI探索站 10月28日</title>
            <link>https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/6900cb4be74e87a1be648181</guid>
            <pubDate></pubDate>
            <updated>Tue, 28 Oct 2025 13:55:23 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    无意间发现 GPT 画这种信息图的还原度挺高啊<br /><br />搞成 SVG 以后还能扔进 Figma 里面改字体，改完就更像了<br /><br />让 GPT 总结了一套提示词👇<br /><br />用途：我发一张信息图或海报截图，你把它高保真还原为可编辑 SVG，整体排版尽量一致，但文字改成 {中文}（或保持原语言）。<br /> 提示词：<br />指令<br />请把我发送的图片转成可编辑 SVG：<br /><br />保持版式与层级结构（标题、分区、图标、箭头、图表等）尽量一致；<br />所有文字保留为  可编辑（不要转路径）；<br /><br />所有图形用向量元素（////），不要嵌入位图；<br /><br />颜色与风格尽量接近原图；<br /><br />分组与命名清晰：01_Header、02_Section_*、Icon_*、Chart_*；<br /><br />画布尺寸按原图推断；坐标/描边尽量用整数；<br /><br />生成文件到 /mnt/data/infographic.svg 并给出下载链接。<br />若图片中有不清晰的内容，请做合理假设并在结果底部列出“假设项”。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</id>
            <title>AI探索站 10月21日</title>
            <link>https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f6d424d9abb9785d23234f</guid>
            <pubDate></pubDate>
            <updated>Tue, 21 Oct 2025 00:30:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    DeepSeek的论文每篇都是精品，R1养活了一批研究强化学习的人，OCR这篇意味CV研究员的春天到来了。用图片替代文本输入，确实是很有开创性的想法。DeepSeek真是开源菩萨，换做CloseAI估计要藏一辈子。<br /><br />大模型在处理长文章时，消耗的计算量会爆炸性增长。<br /><br />但如果把文字“画成图片”，模型只需要很少的“视觉 token”就能理解同样内容。<br /><br />就像人看书一样，我们也是靠视觉来阅读文字，如果这个方向靠谱，那么我们就相当于用OCR技术给大模型装上了眼睛。
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</id>
            <title>AI探索站 10月18日</title>
            <link>https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</link>
            <guid isPermaLink="false">https://m.okjike.com/originalPosts/68f36542cc3970b79da16cc8</guid>
            <pubDate></pubDate>
            <updated>Sat, 18 Oct 2025 10:00:34 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    今天读到了一个非常有趣的 idea。<br /><br />背景是 Dwarkesh Patel 和 Andrej Karpathy 的一个对谈，里面提到了一个智能领域的常见问题：不管是人还是 AI，如果局限于自己的经验，用经验指导自己的行为， 又在这个行为的基础上累计经验，如此循环下去，最终总会崩溃（这里的「崩溃」不是心理意义上的，是智能层面上的）。一个健康的心智需要不断通过从不在自己经验范围内的世界（比如同他人的交谈，和与自己行为模式不符的人合作，etc.）获得外部熵来阻止这种崩溃。小孩还没有对生活过拟合，所以不太容易崩溃，而成年人崩溃的风险则越来越大。<br /><br />以上是背景。下面是那个有趣的 idea，来自2021年的一篇 paper "The overfitted brain: Dreams evolved to assist generalization"。它的主旨是说：人类做梦是防止这种过度拟合和崩溃的一种方式。做梦之所以具有进化适应性，是因为它会让你置身于与你日常现实截然不同的奇特情境中，从而防止这种过度拟合。<br /><br />这里有个鸡生蛋蛋生鸡的问题：既然过拟合体现为大脑无法学到分布外的规律，大脑是如何构建出这些分布外的梦境的？Hoel 的解释是梦的构建有一个非智能的 noise injection 步骤，这些随机噪声在白天建立的神经连接中渗透，产生奇异的、扭曲的、不连贯的 corrupted sensory inputs，从而把大脑从过拟合的陷阱中拯救出来。<br /><br />虽然这只是一个假说（而且是一个非常新的理论），但我越想越觉得它非常精妙。按照这种视角，梦的价值不在于它的逼真，而恰恰在于它的不逼真——梦境与清醒时的经历（训练集）如此不同（但又不是纯粹意义上的噪声），所以才能迫使大脑学习到更具泛化性的表征而不是仅仅记忆真实经历本身。<br /><br />梦通过不可能存在的反事实体验迫使我们更好地理解世界的本质。
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>