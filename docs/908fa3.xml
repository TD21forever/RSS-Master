<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/3355376004204291</id>
            <title>阿里版GPT-4o登场，一句话精准P图，免费可用</title>
            <link>https://www.36kr.com/p/3355376004204291</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3355376004204291</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Jun 2025 09:30:30 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 多模态模型,Qwen VLo,图像生成,开放指令  
<br>  
<br>  
总结: 阿里推出多模态统一理解与生成模型Qwen VLo，具备三大亮点：理解和生成更准确、支持开放指令编辑图片、多语言指令支持。该模型通过渐进式生成方式优化图像质量，支持风格迁移、物体修改等复杂操作。Qwen VLo能解析多任务指令，完成检测、分割等视觉任务，并支持多图输入和动态长宽比生成。目前处于预览阶段，未来将增强图像辅助交流功能。 </div>
                        <hr>
                    
                    <p>6月27日深夜，阿里推出<strong>多模态统一理解与生成模型Qwen VLo</strong>。该模型不仅能够“看懂”世界，更能基于理解进行高质量的再创造，具有三大亮点：<strong>理解和生成更准确，支持开放指令编辑修改图片，多语言指令支持</strong>。&nbsp;</p>
  <p>用户即日起可以<strong>通过Qwen Chat访问</strong>该模型（预览版），比如直接发送类似“生成一张可爱猫咪的图片”的提示来生成图像，或者上传一张猫咪的图片并要求“给猫咪头上加顶帽子”来修改图像。&nbsp;</p>
  <p>Qwen VLo以一种<strong>渐进式生成方式</strong>生成图片。在生成过程中，模型会对预测的内容不断调整和优化，从而确保最终结果更加和谐一致，在提升视觉效果同时带来更灵活和可控的创作体验。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_954e6dd67a484e7eb30542913cd717ce@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>理解和生成更准确，支持开放指令修改图片</strong>&nbsp;</h2>
  <p>从最初的QwenVL到Qwen2.5 VL ，阿里本次推出的Qwen VLo在原始多模态理解与生成能力上进行了全面升级。&nbsp;</p>
  <p>以下是Qwen VLo的核心亮点：&nbsp;</p>
  <p><strong>1、更精准的内容理解与再创造</strong>&nbsp;</p>
  <p>以往的多模态模型在生成过程中容易出现语义不一致的问题，例如将汽车误生成其他类型的物体，或者无法保留原图的关键结构特征。而Qwen VLo通过更强大的细节捕捉能力，能够在生成过程中保持高度的语义一致性。&nbsp;</p>
  <p><strong>2、支持开放指令编辑修改生成</strong>&nbsp;</p>
  <p>用户可以通过自然语言提出各种创意性指令，如“将这张画风改为梵高风格”、“让这张照片看起来像19世纪的老照片”或“给这张图片添加一个晴朗的天空”。Qwen VLo能够灵活响应这些开放性指令，并生成符合用户预期的结果。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_9bb2e6d19e1842c488f464933453687d@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>无论是艺术风格迁移、场景重构还是细节修饰，模型都能应对。甚至一些传统的视觉感知人物如预测深度图、分割图、检测图以及边缘信息等也可以通过编辑指令轻松完成。&nbsp;</p>
  <p>更进一步，像很多更复杂的指令，比如一条指令中同时包含修改物体、修改文字、更换背景，模型也能完成。&nbsp;</p>
  <p><strong>3、多语言指令支持</strong>&nbsp;</p>
  <p>Qwen VLo支持包括中文、英文在内的多种语言指令，打破了语言壁垒，为全球用户提供了统一且便捷的交互体验。&nbsp;</p>
  <h2><strong>像人类画师一样精细创作，一句话“指哪改哪”</strong>&nbsp;</h2>
  <p>Qwen VLo更像一个人类画师, 根据自己的理解再进行创作，下面是一些具体的例子。&nbsp;</p>
  <p>1、该模型能够直接生成图像，并对其进行修改，例如替换背景、添加主体、进行风格迁移，甚至可以完成基于开放指令的大幅修改，包括检测和分割等视觉感知任务。&nbsp;</p>
  <p>用户：生成一个可爱的柴犬&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e9e67d0d3722481e8baf7badf0aaa989@000000_oswg74284oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：背景改成草原&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_00a666ddecc148f4bcddf49eecedc8e6@000000_oswg111414oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：给它带上红色帽子和黑色透明墨镜,帽子上写着“QwenVLo”&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_23cd0697216646e2848aeb053122d084@000000_oswg99366oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：变成吉卜力风格&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_3bb99c960350428797545599167c577f@000000_oswg114212oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：变成3d Q版风格&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_7c3cc2ab158b4d29915f4f01f8164a3a@000000_oswg89456oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：把它放到水晶球里&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e40f9d707abd481fbaabb8140cf52dfa@000000_oswg97762oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：桌面上摆着这个水晶球，生成以一个人的第一视角在公园的圆形咖啡桌上在笔记本上画画&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e9852453f86e49e290b0bdb90eb50b2f@000000_oswg112565oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：用蓝色的蒙版检测框框出图中的笔&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_5aa5fd10417348e682e9e8855a166002@000000_oswg104170oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：用粉色的mask分割出图中的狗狗边缘&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_be041501d77a4f9f80cba8a2944fbf82@000000_oswg99550oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>2、Qwen VLo会根据自己的理解进行重新创作，这意味着在风格转换和迁移方面拥有更大的发挥空间，比如将卡通变为写实、将形象变成气球等有趣的生成效果。&nbsp;</p>
  <p>用户：变成真实照片&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_5def44d0417841f88614844bae0dc9e9@000000_oswg32742oswg320oswg320_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_7035ce872ed14fa68729ae801ef612b4@000000_oswg81888oswg1024oswg1040_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：背景换成埃菲尔铁塔&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_65f06fc35d7a41a8a2c31365baaa88e2@000000_oswg124284oswg1008oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：变成气球飘到空中&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_4dcbc49803564fdd80ba1673f0ded6f8@000000_oswg118827oswg1024oswg1040_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：把西瓜换成榴莲&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_f8ccffc86e604eadafac44d49af6a365@000000_oswg117898oswg1008oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>3、Qwen VLo在图像与指令理解上的优势使其能够更好地解析复杂指令，一条指令中可以包含多个操作和修改，从而一次性完成多重任务，例如生成海报、组合物体等。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_05dc7662a12a483e8291c814a6a152c5@000000_oswg208807oswg1080oswg618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_c2322a891b2c4e95b7bd8a6453b948b2@000000_oswg127992oswg768oswg1360_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>4、Qwen VLo除了能对图像的编辑和再创作，还可以完成一些对已有信息的标注，比如检测、分割、边缘检测等。&nbsp;</p>
  <p>用户：生成摆满水果的桌面&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_b421beff63ad4892a9fe413e7c0f1ef8@000000_oswg108647oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：预测边缘检测图&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_4907838dd7bd4d9e8c07401c4ecb6c01@000000_oswg165813oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：用红色mask分割图中香蕉的边缘&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_0c079859bf30470b95a1ffb97802ded2@000000_oswg108647oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_c76fe91f0e034080b63d46f56d7efa09@000000_oswg101871oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>5、Qwen VLo可以支持多张图像的输入理解和生成。（多图输入的功能还没有正式上线）&nbsp;</p>
  <p>用户：把这些洗浴用品，放到这个红色的篮子里面&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_a256b865062f42d9a7251df6ba9cfca3@000000_oswg160828oswg600oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_8830db75b8a84b46b85f0d0535ef2f1d@000000_oswg860825oswg800oswg800_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_a8b05aae59894fe6bae2d98f8c7cf74c@000000_oswg25336oswg225oswg225_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_aa1089023f304718b8541052dd82fd41@000000_oswg227623oswg1080oswg1080_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_26bd300b8f4243a9a6d88b0a3ce01371@000000_oswg210256oswg512oswg485_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e76d47f9cf284870afe246267da8ae45@000000_oswg648496oswg928oswg880_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>6、除了图文同时输入的情况，Qwen VLo也支持文本到图像的直接生成，包括通用图像和中英文海报等。&nbsp;</p>
  <p>用户：Epic anime artwork of a wizard atop a mountain at night casting a cosmic spell into the dark sky that says “Qwen VLo!” made out of colorful energy&nbsp;</p>
  <p>（一幅史诗级的动漫艺术作品：夜晚，一位巫师立于山顶，向黑暗的天空施展宇宙咒语，由彩色能量构成的“Qwen VLo!”字样在夜空中显现。）&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_41e3a6377e894923ac456d636bf62729@000000_oswg100509oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>7、Qwen VLo支持动态长宽比的图像生成，对于长宽比高达4:1，1:3等细长类型图像也能轻松掌握。（极端长宽比图像生成功能还没有正式上线。）&nbsp;</p>
  <p>用户：动漫插画；水彩手绘；前景是草坡，草坡上有个人在奔跑，动态感，然后是厚重的白云；蓝色背景；颜色层次多渐变；过渡自然和谐&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e21f865882254ae9b2f15e075a005a8a@000000_oswg1324472oswg640oswg1920_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>8、作为统一的理解与生成模型，Qwen VLo还可以对生成的内容进行再分析和理解，例如识别生成图片中的狗和猫的品种。&nbsp;</p>
  <p>用户：Generate a puppy and a kitten.&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_0f59124810384af9bbbe029fca1b7349@000000_oswg118394oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>用户：What breed of cat and dog is this?&nbsp;</p>
  <p>Qwen VLo：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_775c7a85bf66486a872ba751c9da7f4c@000000_oswg216685oswg1080oswg760_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>结语：统一理解与生成，看图说话再升级</strong>&nbsp;</h2>
  <p>Qwen VLo还创新性地引入了一种全新的渐进式生成机制，这一机制不仅提升了生成效率，还适用于需要精细控制的长段落文字生成任务。&nbsp;</p>
  <p>同时，Qwen VLo还属于预览阶段，在生成的过程可能存在不符合事实、不完全和原图一致、指令不遵循、在识别生图和理解的意图不够稳定的问题。&nbsp;</p>
  <p>未来，模型不仅可以用文本回答问题，还可以用图像来传递想法和含义。例如，生成示意图、添加辅助线、标注关键区域等功能，都将为用户提供更多元化的交流手段。&nbsp;</p>
  <p>与此同时，具备输出能力的多模态模型也为研发者提供了新的监督方式。通过生成任务，他们们可以更好地帮助模型理解世界。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652785055&amp;idx=1&amp;sn=56c770c6033e246c2277b802c5b81774&amp;chksm=859a9fd841f3f58730cf2a9618a8cc339d76e20e87d39530505d2e8c2596e9db831d531e97fe&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：李水青，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3355674845104132</id>
            <title>拯救P图废柴，阿里上新多模态模型Qwen-VLo！人人免费可玩</title>
            <link>https://www.36kr.com/p/3355674845104132</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3355674845104132</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Jun 2025 06:18:40 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 多模态模型,Qwen-VLo,图像编辑,细节捕捉  
<br>  
<br>  
总结: 阿里推出全新多模态模型Qwen-VLo，具备增强的细节捕捉能力和高度语义一致性。该模型支持通过单一指令实现图像风格替换、素材增删等编辑功能，并兼容任意分辨率和长宽比。Qwen-VLo不仅能生成图像，还能识别图像内容并添加注释，如分割物体边缘。其渐进式生成方式优化了视觉效果和效率，适用于广告设计等精细控制任务。模型支持中英等多语言，目前免费开放使用。网友实测展示了包括一键上色、梗图制作等多样化应用场景。 </div>
                        <hr>
                    
                    <p>一上手就令网友直呼「生图能力」比GPT-4o更强？！</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_473067f9454d4448a46adfa9d8df439c@000000_oswg403562oswg1080oswg1068_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>就在昨夜，阿里带着全新<strong>多模态模型Qwen-VLo</strong>开启炸场模式。</p>
  <p>据介绍，Qwen-VLo在阿里原有的多模态理解和生成能力上进行了全面升级，具备三大亮点：</p>
  <p>具有增强的<strong>细节捕捉能力</strong>，能在整个生成过程中保持高度语义一致性；</p>
  <p>一个指令即可实现图像编辑，包括风格替换、素材增删、添加文字等等；</p>
  <p>支持中英等多语言，全球用户使用更方便。</p>
  <p>而且无论是输入端还是输出端，Qwen-VLo都<strong>支持任意分辨率和长宽比，不受固定格式的限制</strong>。</p>
  <p>同时在官方释出的demo中，除了那些GPT-4o已经有的玩法（如连续生成、吉卜力风格、添加文字），它还支持一些脑洞大开的idea。</p>
  <p>前者无需多言，它现在也能像“连续剧”一样生成各种精准符合指令的图片：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_c976309fb72048e9b01b04445386e086@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>至于后者，比如我们像在超市选购日用品一样，让Qwen-VLo生成一张<strong>“洗浴用品都在购物篮里”</strong>的图片。</p>
  <p>结果啪的一下，还真立马完成装货了(⊙ˍ⊙)：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_c9afba6e0556423e9fba0506f11755d4@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不是没有一些小瑕疵，但有一说一，其<strong>“理解”能力</strong>确实比之前更强。</p>
  <p>官方介绍，这种理解能力不止体现在图像生成上，还包括对图像的识别解释。</p>
  <p>比如完成生图任务后，再让它介绍一下图中小猫小狗的品种（正确识别为虎斑猫和比格）：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_1cc5cfa67e95499d9a6e57d68475317e@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而且和以往模型稍显不同的是，Qwen-VLo还可以对现有信息进行注释（如检测、分割等）。</p>
  <p>下图中，它成功用红色Mask分割出了香蕉的边缘。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e1fe0baa0a3b4d7898d0110cebb635fe@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>……</p>
  <p>目前模型人人免费可玩（当前为预览版），具体请认准Qwen3-235B-A22B，直接在首页输入框提需求就行。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_fbe756ef0dd44065a51884982060a134@000000_oswg51853oswg1080oswg441_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>话不多说，我们先一起来上手实测一波走起。</p>
  <h2><strong>Qwen-VLo，你到底有多能编辑？</strong></h2>
  <p>根据Qwen介绍的亮点，即“强细节捕捉”和“一句话编辑图像”，我们着重在测试中考查了Qwen-VLo的<strong>各种编辑能力</strong>。</p>
  <p>毕竟这点真的很吸引人啊！</p>
  <p>一方面几乎所有的模型生图都需要抽卡，但前一次的生成效果并非让人完全不满意，所以二次/多次编辑能力非常重要。</p>
  <p>另一方面，强编辑能力，真的给P图废材省不少事儿……</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_1660ba475f604ab3b807ab2e6b3c162f@000000_oswg37335oswg174oswg177_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>开胃小菜先走起！</p>
  <p>第一测，让它先生成一张北极熊喝可乐的照片。</p>
  <p>这一回合主打的是非现实风格。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_287e4aa90083443c8bf52b1e693512ec@000000_oswg228529oswg1080oswg557_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在此基础上，继续通过对话<strong>将可乐换成牛奶</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_0f4908674ff944b3a7b81c929c79ed6d@000000_oswg199540oswg1080oswg518_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>一次成功，Qwen-VLo确实完成了替换。</p>
  <p>且背景、北极熊本熊都几乎没被乱改。</p>
  <p>但非要挑挑毛病的话，还是能观察出来，前后两张图中北极熊的眉眼部分和毛发质感稍微有那么一丁点不一样。</p>
  <p>第二测，先让它帮忙生成一张小鸟的照片。</p>
  <p>这一回合主打的是现实摄影风格。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_38d2dd89a73142b58d5d0742622f87d5@000000_oswg226156oswg1080oswg538_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然后不用读霍格沃茨，只需一句“把图中的这只鸟换成鸽子”，你就能施展魔法：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_8a82e41998594c4b9ddf37d6cc7b0796@000000_oswg228241oswg1080oswg612_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>但我们尝试玩儿个“蒜鸟”的梗，Qwen-VLo就没get到。</p>
  <p>（注：“蒜鸟”一词是近期爆梗。短视频画外音中的武汉方言“算了算了，都不容易”，被网友谐音称“算鸟”，后来演变成“蒜鸟”）</p>
  <p>不过，虽然没get到梗，Qwen-VLo还是努力想完成编辑任务。</p>
  <p>看下图成果，在不改变其它元素的基础上，Qwen-VLo给咱们把图中的鸽子换成了别的鸟。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_8a221aed8eb34d7e92d15175cfe4c591@000000_oswg232011oswg1080oswg580_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>也算是一种换鸟了？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_8e797d54ae694bffbad096ce7d96e6e7@000000_oswg40562oswg236oswg232_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>第三测，来个多步骤任务，全方位测试Qwen-VLo“描绘”世界的同时，重点考察下它在图像上的文本编辑能力。</p>
  <p>过程是「让Qwen-VLo生成草图——上色——加字——编辑汉字」。</p>
  <p>来，怕动图滑太快，咱们连看过程中顺次截取的四张图，感受它每一步带来的改变：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_c1c91d31ba3842ff9efb4171532e718c@000000_oswg315080oswg1080oswg599_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_babc1103a4ed42af9e60bc9302d2d5c6@000000_oswg339209oswg1080oswg598_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_3a790fade56541cbbd1085ede27987ba@000000_oswg274433oswg1080oswg575_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_f38fa9e230c145e8b0aabedec838f7e1@000000_oswg270440oswg1080oswg625_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>虽然图里小帅同学的五官在变，但人物主体稳定，背景没变，一整套下来，编辑汉字的任务算是搞得不错，</p>
  <p>最后来个附加题，编辑英文——</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_510df90552f1486aa3ad20d2820a7a3e@000000_oswg259951oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>字编辑对了，多人物主体位置没变，背景依旧，总体没错。</p>
  <p>但如你所见，小帅同学也长得比较美漫风了（手动笑死）。</p>
  <h2><strong>同样是逐步展示，但Qwen-VLo这背后真有活</strong></h2>
  <p>这里我们展开补充一点，大家上手玩儿的时候应该都能注意到。</p>
  <p>那就是Qwen-VLo生成图像的过程，是酱婶儿的——</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_73c8f5db64854aafac399332ea154097@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>是不是有点熟悉的味道？</p>
  <p>没错，GPT-4o也是从上到下逐块生成图像的：先显示模糊轮廓，再逐步填充细节。</p>
  <p>不过当时港中文研究逆向工程研究发现，用户看到的逐行渲染效果只是OpenAI的障眼法，不是真的由上至下逐像素生成。</p>
  <p>这样做的目的，既满足用户对“实时生成”的心理预期，又避免了真正逐行渲染的技术负担。</p>
  <p><strong>但Qwen这么做就不是上演OpenAI的戏码了</strong>。</p>
  <p>敲敲黑板——</p>
  <p>首先，Qwen官方表示Qwen-VLo的这种渐进式生成方式，不仅是从上到下，还是从左至右逐步清晰地构建整幅图片。</p>
  <p>我们多次实测，暂时没有肉眼观察到“从左至右”的前端效果。</p>
  <p>但从上到下逐渐构成照片的前端效果是保准会有的：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_e2c77818e9d143f9b5b0ba32f1a6693f@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>其次，Qwen引入这个形式，它是真·有用啊：</p>
  <blockquote>
   <p>在生成过程中，模型会对预测的内容不断调整和优化，从而确保最终结果更加和谐一致。</p>
   <p>这种生成机制不仅提升了视觉效果，生成效率，还特别适用于需要精细控制的长段落文字生成任务。</p>
  </blockquote>
  <p>例如，在生成带有大量文本的广告设计或漫画分镜时，Qwen-VLo会逐步生成，慢慢修改。</p>
  <p>这个生成过程，其实有点思维链“一步一步慢慢想”具像化的意思了！</p>
  <h2><strong>网友实测脑洞开很大，来吧展示</strong></h2>
  <p>除了以上量子位实测，诸多网友也火速贡献了一波有趣玩法…</p>
  <p>随手一张动漫角色草图， Qwen-VLo便能帮忙一键上色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_d90b737ab6ca4f0fb313167653104846@000000_oswg674788oswg1080oswg815_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>让小猫担任宣传员，还能直接生成带有“Qwen Chat”字样的看板。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_a6a677a5ed12407e977141ccbb810484@000000_oswg511518oswg1080oswg1126_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>或者也可以借鉴下面网友的做法，以后用来制作一些梗图（doge）。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_9d3c22c098224e9dbfa4998ef47346f9@000000_oswg269848oswg1080oswg797_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>顺便一提，连Qwen团队成员之一Binyuan Hui也出来给大家打样，分享了吉卜力风格的某近日顶流。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20250628/v2_6782fc39564b45e28cda5ffcb9d337bb@000000_oswg953753oswg1080oswg2444_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>好了，更多例子就不一一展示了，只说一句：</p>
  <p>目前模型免费开放，评论区可带图，记得回来分享一波～</p>
  <p>在线体验：https://chat.qwen.ai/博客：https://qwenlm.github.io/blog/Qwen-VLoo/</p>
  <p>参考链接：[1]https://x.com/Alibaba_Qwen/status/1938604105909600466[2]https://x.com/szkane/status/1938614382369575048[3]https://x.com/huybery/status/1938639781988286957</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;mid=2247806174&amp;idx=2&amp;sn=62cadf58aa538d3091ccb0c08e8bdf07&amp;chksm=e98213bdea6fbac6b42738afa1a373682b1f7cb9bb3e12409f3d130d2503ad7ddcdf1a1357d8&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“量子位”（ID：QbitAI）</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3354967454177417</id>
            <title>海致科技赴港IPO：百度创业元老大谈“AI除幻”，赎回负债压顶</title>
            <link>https://www.36kr.com/p/3354967454177417</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3354967454177417</guid>
            <pubDate></pubDate>
            <updated>Sat, 28 Jun 2025 06:00:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                        <div> 关键词: 大模型幻觉,AI除幻,知识图谱,海致科技  

总结:  
1. 大模型工具存在生成偏差和事实性错误，形成谎言迭代的恶性循环，影响医疗、金融等落地场景。  
2. 马斯克宣布xAI通过重写知识库解决该问题，行业将"AI除幻"列为重要发展方向。  
3. 海致科技以知识图谱技术减少大模型幻觉，自称中国首家该领域企业，正申请港股上市。  
4. 公司创始人系百度元老，获多轮融资但尚未盈利，2024年营收5.03亿元，亏损9459万元。  
5. 核心业务Atlas图谱解决方案占营收超80%，"AI除幻"新业务2024年贡献17.2%收入。  
6. 行业竞争激烈，百度、明略科技等企业也在布局类似技术，海致研发投入逐年下降。  
7. 公司面临17亿元赎回负债压力，上市是解除该风险的唯一途径。  
8. 招股书显示若上市失败，资金风险将持续存在。 </div>
                        <hr>
                    
                    <p>在使用大模型工具时，你是否也遇到过会“说谎”的AI？</p>
  <p>随着AI不断深入渗透人类的日常生活，不少用户发现大模型在生产文本时会出现生成偏差或事实性错误。这些错误信息看似逻辑严密，实则是毫无根据的结论，且错误信息后续可能被模型当作真实信息学习，由此形成谎言迭代的恶性循环。</p>
  <p>而这一现象逐渐影响AI落地场景，例如AI医生误诊病情、金融风控系统放过诈骗交易、智能制造系统错误调整参数等等。</p>
  <p>针对这一问题，近日马斯克宣布xAI旗下大语言模型Grok 3.5重写人类知识库，添加缺失信息，删除错误内容，基于这个纯净版知识库，重新训练模型。最终目的是根除数据训练中未经校正的垃圾信息。</p>
  <p>AI技术正以前所未有的速度发展，“AI除幻”成为行业十分重要的发展工作之一。</p>
  <p>近期，北京海致科技集团（简称“海致科技）正式向港交所主板递交上市申请，冲击“AI除幻第一股”，招银国际、中银国际及申万宏源香港担任联席保荐。</p>
  <p>根据海致科技招股书来看，公司已然将“AI除幻”作为未来重点发展方向，并在开头处强调为——中国首家通过知识图谱有效减少大模型幻觉的AI企业。</p>
  <h2><strong>背靠百度创业元老，科技底色有多深？</strong></h2>
  <p>除“AI除幻”叙事外，管理层履历或是海致科技的最大看点。</p>
  <p>创始人任旭阳为百度前副总裁，2001年便加入百度，称得上元老级人物，其还曾牵头创立爱奇艺、联合创立一点资讯，现担任真知创投董事长兼管理合伙人。</p>
  <p>百度元老创业，自然吸引无数资本跟投。</p>
  <p>截至招股书披露日，海致科技累计完成13轮融资活动，投资方不乏亿方资本、IDG、高瓴、君联资本等知名机构，以及中国互联网投资基金、北京人工智能基金、上海人工智能基金等国资平台。</p>
  <p>以最后一笔融资项目来看，发生于IPO前夕。2025年6月初，海致科技完成规模为3.5亿元的E-2系列融资，公司估值由2023年末E-1系列融资时的29.08亿元增至33亿元。</p>
  <p>截至招股书披露日，创始人任旭阳直间接持有海致科技13.06%股份；CEO杨再飞直间接持有海致科技16.40%股份，双方为一致行动人，共同持股占比最高。</p>
  <p>君联资本为外部第一大机构股东持股13.62%，此外BAI持股6.5%、IDG持股4.86%、产业升级基金持股4.55%、中国互联网投资基金持股3.94%、高瓴持股2.55%等。</p>
  <p>抛开资本赋予的光环外，作为一家科技创新型企业，海致科技虽经历多轮融资，但目前估值水平并不算太高。</p>
  <p>根据港交所主板上市（三选一）规则来看，需满足“近1年盈利≥3500万港元，前两年累计≥4500万港元，预计上市市值≥5亿港元”；或满足“最近一年收入≥5亿港元、前三年累计经营性现金流净额≥1亿港元，市值≥20亿港元”；亦或是“营业收入≥5亿港元，市值≥40亿港元”。</p>
  <p>从海致科技基本财务信息来看，2022年至2024年，海致科技分别实现营业收入3.13亿元、3.76亿元、5.03亿元，2024年营收规模勉强过线。</p>
  <p>但海致科技目前尚未实现盈利，2022年至2024年公司净利润分别为-1.75亿元、-2.65亿元、-9459.4万元。且公司经营性现金流净额连续3年为负值，分别为-1.62亿元、-1.40亿元、-3854.9万元。</p>
  <p>显然，海致科技仅剩下最后一种上市标准，而根据E-2轮融资后33亿元（约36亿港元）估值来看，目前略低于预计上市市值40亿港元标准。</p>
  <p>值得一提的是，在港交所“科企专线”刚落地1个月之际，身处当下热门AI赛道的海致科技却并未趁机以18C规则申请上市，而依旧选择冲击主板。</p>
  <p>这是否也可以从侧面反映，海致科技的“硬科技”属性并不高？</p>
  <h2><strong>规模仅2亿元，行业第一？</strong></h2>
  <p>看看海致科技的基本面。</p>
  <p>据海致科技介绍，公司核心能力在于通过创新的“图模融合技术”开发产业级智能体并提供相应解决方案。其中，Atlas图谱解决方案业务构成公司的基本盘，营收贡献超8成。</p>
  <p>招股书显示，海致科技Atlas图谱解决方案所属行业为产业级AI解决方案领域。据弗若斯特沙利文报告，2024年中国产业级AI服务市场的规模453亿元，由此计算，海致科技市占率仅1%左右，虽可排在行业第4，但市场整体集中度低，可能随时被赶超。</p>
  <p>于是，海致科技将目光转向垂直细分行业，力争做到小而美，AI除幻龙头企业便是海致科技给自己的新标签。</p>
  <p>据了解，海致科技于2023年正是切入“AI除幻”领域。2023年9月，海致科技首次推出Atlas智能体，该方案提升了大语言模型在特定行业场景中的精准推理能力，提升大模型的决策效率和预测准确性，同时降低大模型的幻觉现象。</p>
  <p>按2024年收入计算，海致科技在中国产业级AI智能体提供商中位列第五，在以图为核心的AI智能体提供商中位列第一。</p>
  <p>然而，从海致科技营收结构来看，“AI除幻”所在的Atlas智能体板块对公司总营收贡献尚不足两成。</p>
  <p>2022年至2024年，海致科技“AI除幻”业务所在的Atlas智能体板块分别实现营业收入0万元、890.3万元、8655.3万元，占总营收比重由0%增至17.2%。</p>
  <p>板块规模不足1个亿，行业第一的名头是如何得来的？主要还是中国“AI除幻”赛道尚处发展初期，整体市场较小。</p>
  <p>按2024年收入计算，中国产业级AI智能体市场规模仅31亿元。其中，海致科技深耕的以图为核心的AI智能体市场规模则更小，仅2亿元左右。</p>
  <p>但出于可观的前景，已有不少玩家相继布局该领域。</p>
  <p>2024年11月，李彦宏曾分享百度大模型的除幻技术，主要用的就是检索增强技术。无独有偶，近期同样赴港IPO的明略科技，也在通过使用知识图谱技术及超图谱检索增强生成技术，降低通用大模型在特定场景下的幻觉问题。</p>
  <p>需要关注的是，身处各行业龙头齐聚的AI赛道，海致科技虽在招股中有不少类似“技术优势”、“强大研发能力”等自述，但掩盖不了公司在研发工作中逐渐懈怠的事实。</p>
  <p>2022年至2024年，海致科技研发费用由8694.2万元降至6068.10万元，期间研发费用率由27.8%降至12.1%，已是“腰斩”。其中，研发及技术员工作为企业核心资源，员工福利却在逐年锐减，2022年至2024年由6629.5万元降至5225.2万元，以556名技术员工计算，2024年人均福利费用9.40万元。</p>
  <p>另一头，海致科技的销售及营销费用金额常年高于研发费用，2022年至2024年分别为1.15亿元、8629.2万元、6779.6万元。其中，2024年销售员工福利费用达4879.6万元，以103名销售员工计算，人均福利费用高达47.37万元。</p>
  <p>身处依靠研发技术创新驱动发展的AI行业，海致科技这种福利失衡又是否有失公允？</p>
  <p>对比同样涉及图谱技术解决幻觉问题的明略科技，近三年研发费用累计近16亿元，2024年研发费用率达25.56%，高出海致科技一倍。</p>
  <h2><strong>赎回负债压顶，上市成唯一解药？</strong></h2>
  <p>如此看下来，在百度创业元老、AI除幻光环外衣之下，海致科技的科技属色并不算太扎实。之所以急于赴港上市，矛头指向资产负债表中的巨额“赎回负债”。</p>
  <p>2022年至2024年，海致科技资产负债率由87.52%增至313.22%，期间流动负债由3.17亿元增至19.74亿元。</p>
  <p>据了解，在海致科技此前13轮外部融资中，虽吸引诸多知名资本加持，但同时海致科技也为这些投资者赋予一系列特殊权利，其中最核心的便是“赎回权”。</p>
  <p>2022年至2024年及2025年前4个月，海致科技赎回负债分别为0元、14.59亿元、16.72亿元、17.14亿元，主要是由于赎回负债账面值发生变动。</p>
  <p>海致科技在招股书中坦言，投资者有权力要求公司按投资者各自支付的本金加上预定年化回报率，赎回该等投资者所持有的普通股，这将大大影响公司的现金流健康。</p>
  <p>除此之外，赎回负债账面值变动产生的亏损同样影响公司利润水平。</p>
  <p>2022年至2024年，海致科技赎回账面金额变动金额分别为0元、-4896.9万元、-7609.2万元。同时，海致科技在融资过程中，为投资者附带优先股股份造成公司公允价值变动损益，分别为0元、-1981.6万元、-2143.3万元。若剔除这两项损益，海致科技经调整后净利润于2024年实现扭亏，达1693.2万元。</p>
  <p>连年亏损叠加巨额赎回压力，海致科技资金状况已经发出危险信号，2024年海致科技现金及现金等价物同比减少11.11%至1.76亿元。</p>
  <p>而IPO，正是拆解这颗“金融炸弹”的唯一方式。</p>
  <p>海致科技招股书中明确指出，所有授予首次公开发售前投资者的特别权利（包括赎回权）将于公司向联交所提交上市申请时终止。也就是说，一旦成功上市，这笔17亿的赎回负债将转换为权益，同时公司的优先股也会转化为普通股，资金风险将自然消失。</p>
  <p>但公司一旦撤回上市申请或IPO失败，该部分风险将会延续。</p>
  <p>敬告读者：本文基于公开资料信息或受访者提供的相关内容撰写，全球财说及文章作者不保证相关信息资料的完整性和准确性。无论何种情况下，本文内容均不构成投资建议。市场有风险，投资需谨慎！未经许可不得转载、抄袭！</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>