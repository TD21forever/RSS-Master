<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/3677400007500419</id>
            <title>尝试两年半后，抖音决定不搞内容付费了</title>
            <link>https://www.36kr.com/p/3677400007500419</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3677400007500419</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Feb 2026 13:29:53 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>在试水两年半之后，抖音的内容付费似乎要告一段落了。日前有爆料显示，抖音平台将对内容变现模式进行重大调整，自2026年2月5日起正式停止付费合集的相关功能与服务，原“合集付费配置”功能全面下线，所有已创建的付费合集将统一转为免费合集，用户无需购买即可正常观看。</p>
  <p>具体来说，就是抖音或将彻底关闭付费合集的变现经营能力，已购买相关付费合集的用户，可通过抖音客户端下载保存对应内容，创作者也可通过合集管理功能对已转为免费的合集进行删除等操作。针对因功能调整导致的用户退款需求，据称抖音方面明确相关退款将由平台全额承担，以保障付费用户的权益不受损失。</p>
  <p>在关闭付费合集的同时，抖音也为创作者提供了替代选项。据悉，抖音将同步推出合集升级计划，以投稿数量、内容质量、播放效果等多维度数据为核心评估指标，定向为优质创作者提供创作激励，来替代原有的付费分成模式，引导创作者转向基于内容流量与平台补贴的变现路径。</p>
  <p>简而言之，兜兜转转一圈后，抖音创作者的内容变现路径又回到了单一的流量模式。那么问题就来了，抖音探索付费短视频为何短短两年半时间就终止了呢？其实要想回答这个问题，先得来看看抖音当初开放短视频付费的缘由。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_0ab48d079b3149e181ee60edd5e90c47@000000_oswg14196oswg600oswg262_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>此前在2023年11月中旬，#抖音测试付费短视频# 这个话题曾冲上热搜，说的就是用户在观看创作者的内容时，部分需要付费解锁才能全部观看，涉及的品类不止短剧，还包括日常、知识、娱乐等UGC内容。而创作者则需要满足近90天内无账号违规封禁记录、粉丝数不少于10万、完成抖音实名认证这三个要求，才能开通付费服务。</p>
  <p>其实这已经不是抖音第一次尝试让用户直接为优质短视频内容付费，早在2021年他们就曾推出“赞赏”功能，旨在为抖音短视频创作者提供内容变现的途径。但由于彼时抖音的UGC属性过于突出，用户的付费心智也并不成熟，所以当时抖音在内容付费上的小试牛刀没有激起太大的水花。</p>
  <p>但短剧的异军突起，让抖音坚定了尝试内容付费的决心。此前艾媒咨询发布的中国网络微短剧市场规模的研究报告显示，2021年这个市场的规模还只有3.68亿，可到了2023年，短短两年间其市场规模就达到373.9亿、增长了10倍。短剧快速壮大的市场规模以及用户惊人的付费能力犹如强心剂，让一众短视频平台看到了内容付费的潜力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_88592ba22c1c42d69a7d20b5aa4a57ac@000000_oswg37025oswg533oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>然而彼时短剧的付费模式是围绕微信小程序展开，付费路径通常是用户刷短视频时不经意看到感兴趣的投流素材，点击即可一键跳转至微信小程序，之后再付费观看完整版。而开通付费功能后，短剧的曝光、付费、观看就都能在抖音内部完成，不再需要跳转至微信小程序。</p>
  <p>为了短剧这碟“醋”，抖音相当于包了全品类内容付费这个“饺子”。然而在过去的两年里短剧赛道风云突变，付费订阅被免费+广告的组合打得找不着北。</p>
  <p>此前，以庸俗、低俗、媚俗为核心的1.0版本短剧面向的是下沉市场的“五环外人群”，这类用户的特点是对价格敏感。当他们逐渐发现按集付费解锁模式的其实很贵时，立刻就选择了捂紧荷包。</p>
  <p>在2024年春节后，短剧行业模仿长视频平台搞起了会员订阅，用户需要充值VIP才能解锁付费剧集。从按集付费到按天付费，会员订阅就降低了用户观看短剧的成本，可短剧制片方却不干了。事实上，短剧行业玩的就是高举高打，会员订阅模式很难让片方维持盈亏平衡。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_648602c891064133a491646b077f9168@000000_oswg32859oswg600oswg370_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>这时候，高举免费大旗的红果短剧，就提供了一个有别于传统的商业模式。对短剧的核心受众群体、也就是“五环外人群”，免费才是硬道理。并且在用户拉新上，红果短剧还采取了网赚引流模式，刷短剧赚红包也让海量用户迁移到了红果。</p>
  <p>而针对片方，红果短剧提出了应用内广告（IAA）模式，也就是用户需要观看广告才能解锁下一集。不仅如此，与付费模式靠单点悬念来驱动付费不同，免费短剧以“无广告免费看”“看剧赚金币”为核心卖点，盈利更依赖用户观看时长、播放量与拉新率带来的平台分账，就倒逼短剧内容创作的精品化，以构建高密度的“钩子矩阵”与强逻辑的情节递进体系。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_0bfcd28c2aa846a4be17f0aa724ce626@000000_oswg51527oswg600oswg452_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>既免费又质量在线，就使得免费模式很快就主导了短剧行业。然而皮之不存毛将焉附，当短剧走向全面免费，短视频的内容付费就迅速沦为鸡肋。在绝大多数用户的认知里，抖音是一个娱乐属性爆棚的平台，打发碎片时间就是他们刷抖音的核心原因，而抖音本身的推送机制一直以来也在为这样的调性服务。</p>
  <p>其实用户不是不愿意为泛娱乐内容付费，而是不想为质量飘忽不定的UGC内容付费，并且单独购买、而非付费订阅就意味着平台不保证付费内容的质量。由于无法提供获得感、或者说价值感，用户的付费意愿已经不是不高，而是低得可怜。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_1f1b6b1c8fcf4c19979b7fe078a87de9@000000_oswg22565oswg492oswg600_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而隔壁B站的充电与其说是用户付费购买内容，不如说是粉丝对欣赏的偶像进行打赏。所以在2026年这个时间点，继续保留付费内容对抖音有害无益。况且对于创作者而言，让受众直接用现金为内容买单，反而不如基于流量与平台补贴的这一变现路径。</p>
  <p>当真正有价值的短剧走向广告变现后，抖音的内容付费也就完成了历史使命。</p>
  <p>【本文图片来自网络】</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTk2NTk5Nw==&amp;mid=2649904892&amp;idx=3&amp;sn=74ac8e6a20cb49a4f8e119a33780f46f&amp;chksm=862b55507ea4ae9e7a678535691229a7e668103ca1da7071f3a4f783944cca7890135320eae0&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“三易生活”（ID：IT-3eLife）</a>，作者：三易菌，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3677396936811142</id>
            <title>腾讯心动谷歌齐下阵，新一轮AI抢人大战开启</title>
            <link>https://www.36kr.com/p/3677396936811142</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3677396936811142</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Feb 2026 13:02:59 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>春节还没来，AI这边就已经开始过年了。</strong></p>
  <p>这几天，大伙可能都在群里收到元宝发的“红包”，很多人（包括我）的第一反应都是：我去，被盗号了？</p>
  <p>这种反应实在普遍，以至于元宝的这波活动还引来了大量用户反馈与投诉。2月4日，微信官方账号“微信派”发布《关于第三方诱导分享行为的打击公告》，“微信屏蔽元宝红包链接”这一话题也随即冲上热搜。</p>
  <p>藤子这一波“狠起来连自己人都打”的操作还真是让人看不懂。</p>
  <p>不止是元宝，最近游戏圈也上演了一出“我杀我自己”的大戏，Genie3刚一面世，就在游戏股中杀了个“七进七出”，导致&nbsp;Take Two股价暴跌10%、Unity&nbsp;股价重挫27%、Roblox也大跌13%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_0b26710152d64cb2a7b19c6ab694f184@000000_oswg386710oswg1080oswg819_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>将军：“游戏，一定要可以玩”</strong></h2>
  <p>为什么这事能引起这么大范围的关注和讨论？现在但凡谈到AI在游戏里的应用，常见的论调无非是：它目前还只是辅助，还有很多不足；但又“莫欺少年穷”，它发展太快了，我们应该对此保持期待；又或者，AI会不会彻底颠覆这个行业，引发一波新的焦虑。老实说，这些观点翻来覆去讲了太多遍，如果今天还只是重复这些，确实没什么意思。</p>
  <p>唯一的可能性是：资本是不是反应过度了？</p>
  <p>《原神》制作人蔡浩宇曾对AI发表过这样一种看法：未来的游戏开发只会有两类人，前0.0001%的天才带领精英团队创造出前所未有的东西，以及99%的业余爱好者开发满足自己想法的游戏。</p>
  <p>如果你是那前0.0001%的天才，很遗憾，当下的&nbsp;Genie3&nbsp;还远未达到“解放生产力”的程度。它生成的内容只能维持在一分钟左右，互动性也仅局限在前后左右以及移动视角上面，而且还无法导出为可复用的3D资产，简单来说，还只是一种“可交互视频”。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_0d57b0e858f2414e90803ff5cd4741c1@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>亲戚家的孩子说不定能玩一整天</strong></h2>
  <p>但如果你是那99%的“纯路人”，Genie3所带来的那种“手搓GTA”的即兴创作乐趣，确实值得一试。自其发布以来，网上已涌现出形形色色脑洞大开的作品。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_00d927e9b8564a58bf4b38dd046dde98@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>比如它最基础的功能是图像生成三维场景，只需上传一张图片，AI就能自动构建出完整的3D环境。你大可以尝试下将自家的“爱宠”做成游戏，然后操控它满屋子乱逛，出来的光影效果以及猫猫的动作连贯性，已经比很多3A大作还要好了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_88223f66f1044b86b74118b5d43ac74b@000000_oswg619710oswg1079oswg599_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_f6b0a86a8b10438789f84b6dadbfd037@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>那要是直接把3A大作的截图放进去会怎样呢？已经有网友试过了，别说，还真像那么一回事儿。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_21f25e13a1474a5c82de85e56949955d@000000_oswg2076449oswg1080oswg1441_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_0940dd9a3d4e4d46b80b0dbc8cf51e17@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_4801cd97a32843b1b4d414894c720a02@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>或者还可以将电影中的截图变成游戏，像下面这个“环太平洋VS哥斯拉”就很有想象力。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_8735c45634fd4f1d82d11aafd5af31e0@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>玩家能在里面走动、跳跃、看看风景，但复杂的任务、剧情或者深度的交互就别指望了。你说它的可玩性高吗？这很难用传统游戏的标准去衡量。</p>
  <p>而之所以说它能让玩家体验到那种“开发游戏过程中”所带来的“造物”乐趣，是因为用户还能够通过提示词进行更改，做到“所想即所见”。</p>
  <p>比如，原本中规中矩的街道，在用户的几句提示词下，就能在建筑物上变出一扇任意门，穿过后就来到了一片沙漠，转头一看任意门还在原地。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_48d83fbc6ac1447cba13b539c77d765d@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>随手一拍的城市鸟瞰图确实没啥意思，那要是做成“霍格沃茨”或者“皇牌空战”呢？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_e70a164120ea4b96b8c456644483900a@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_30f16911b76a4e3a994b565201bb7677@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>好了，该我玩了</strong></h2>
  <p>如果肯花时间微调，像下面这个就有非常高的可信度，若不是有水印，第一眼还真看不出是AI生成的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_d6eed34c8a784d0680050ca109045058@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>由于Genie3&nbsp;现阶段并没有向全民开放，需要250美元/月门槛价，因此在网上我还看到有不少网友跃跃欲试，请求有资格的用户把动漫里的名场面做成游戏。还有不少网友说，要是把小说直接放进去，“头号玩家”不就成了？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_be214f07b00f451da347512d7be5bf9e@000000_oswg831114oswg973oswg650_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>现在我们或许能够想象到资本为什么恐慌了，哪怕只是用来验证设计师的部分想法，那也是有一定的颠覆性。比如，一个策划如果有了某个版本、玩法的初步想法，传统流程中可能需要协调程序、美术等员工花好几天才能做出一个可试玩的&nbsp;demo。而现在，借助这类工具，策划1小时就能快速生成数十个可交互的雏形，尽管粗糙，却足以直观地展示想法、进行内部讨论。这种流程上的简化，对于节约早期沟通与试错成本是有实际意义的。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_4d84a2f36c25470dbd2d1b00f5bac00c@000000_oswg46882oswg831oswg447_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>事实上，国内业界也在进行类似的探索。几乎就在&nbsp;Genie3&nbsp;引发讨论的同时，心动公司发布了&nbsp;Taptap Maker，一个能通过自然语言对话让&nbsp;AI&nbsp;辅助创作游戏的原型产品，目标是让创作者无需离开聊天窗口就能完成从零到上线的全过程，真正降低游戏创作的门槛；蚂蚁集团则推出了灵波，思路与&nbsp;Genie3&nbsp;类似，同样聚焦在生成可交互的场景上；腾讯旗下的混元3D世界模型，其优势则在于能导出点云文件进行二次编辑……大厂云集，开启了AI生游戏的新一轮“抢人”大战。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_56b901794bcc404ab00af01cba0cd72c@000000_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">灵波生成的效果图</p>
  <p>话说回来，做一个能运行的demo从来都不是最困难的部分。真正的挑战始终在于，如何把demo变成一款完整、稳定、能被市场接受的成熟产品。这就像谁都可以在家炒个菜，但要把菜炒到能开餐厅卖钱的程度，那就是另一回事了。</p>
  <h2><strong>路很长，还很远</strong></h2>
  <p>刚刚提到的这些AI生成游戏的思路各有不同，有的是让AI敲代码做渲染，有的则是跳过代码建模步骤直接生成互动式场景。</p>
  <p>但其实都涉及一个更底层的概念：“世界模型”。简单来说，它指的是&nbsp;AI&nbsp;能够对虚拟环境的状态、变化与互动进行某种程度的推演和生成。</p>
  <p>近些年，业界对“世界模型”的探索大致分为两个方向：一种是追求高度还原真实世界的物理规律，力求像素级精准预测；另一种则像研究者杨立昆曾提出的，只需把握关键信息进行推理，不必完全还原每一个细节。</p>
  <p>前一种方向虽然理想，但实现起来极为困难，因为真实世界下一秒会发生什么，本身就充满不确定性。</p>
  <p>而后一种思路，实际上更接近游戏开发的逻辑——游戏并不需要完全复刻现实，它只需要构建出一个符合自身规则、能让玩家信服并沉浸其中的世界就行了。</p>
  <p>从这个角度看，Genie3&nbsp;这类工具之所以引人注目，正是因为它们在“世界模型”的实践上往前迈了一步：它能够通过学习大量的游戏实况、视频，自动“领悟”部分物理规则，并产生交互式预测。</p>
  <p>这也是为什么，虽然前年&nbsp;Sora&nbsp;出现时已经有人用它生成过《我的世界》风格的视频并引发过一波讨论，但Genie3&nbsp;带来的反响似乎更具体。Sora&nbsp;生成的视频固然震撼，但它终究是预先渲染好的、不可交互的影像。而&nbsp;Genie3&nbsp;则允许用户实时走进那个生成的世界，并且通过提示词去修改它。</p>
  <p>尽管它离一个真正的游戏开发工具还有距离，但它确实让人看到，AI&nbsp;不仅能在内容生成上辅助人类，未来或许也能在构建可互动虚拟世界这件事上，扮演更核心的角色。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_7cef76b61b224182936191e6e954b547@000000_oswg61817oswg1080oswg568_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>所以，围绕&nbsp;Genie3&nbsp;及其同类产品的讨论，表面上看是在评价一个&nbsp;AI&nbsp;产品能做什么、不能做什么，但更深层反映的，其实是整个行业对创作方式变迁的一种敏感。资本的反应未必全是过度，更多可能是一种对趋势的试探与布局。而普通爱好者的热情，则揭示了工具民主化所带来的新可能，即便这“可能”距离成熟的产品生态还有很长的路要走。</p>
  <p>说到底，技术始终在向前走，但它的价值最终还是要落到具体的人、具体的需求上。无论是那&nbsp;0.0001%&nbsp;追求极致创新的团队，还是那&nbsp;99%只想创造点小乐趣的普通用户，工具的意义，终究是让人多一点选择的自由，多一点实现想法的可能。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkzOTYwMjE2NA==&amp;mid=2247548560&amp;idx=1&amp;sn=4833316073ef3a04937a0830b2646a32&amp;chksm=c3d5ffb0b6d1080d94aa751e4abbd0cc13b5cf93a2fecfa6cbf65f7aa283662e2e71770898f0&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“游戏矩阵 GameMatrix”（ID：gamematrix2013）</a>，作者：Pheies，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3677481316409991</id>
            <title>被马斯克点赞，陈炜鹏希望做“可以玩的抖音”</title>
            <link>https://www.36kr.com/p/3677481316409991</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3677481316409991</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Feb 2026 12:49:08 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>文｜周鑫雨</strong></p>
  <p><strong>编辑｜苏建勋</strong></p>
  <p><strong>如果没有亲自上手，真的很难形容Loopit的产品定位。</strong></p>
  <p><strong>它像是内容“活过来”的抖音。</strong>通过Feed流喂给用户的内容，不只是视频、图片、音乐，而是可以<strong>通过点击、划动、自拍、语音、摇一摇等玩法，进行互动的内容。</strong></p>
  <p>由于产品交互太新，在和<strong>Loopit创始人陈炜鹏</strong>交流之前，他极力嘱咐我们：<strong>“不能只看demo，一定要亲自体验！”</strong></p>
  <p>此前，陈炜鹏是搜狗和百川智能的技术负责人。2025年6月，他创立了AI应用公司“涌跃智能”，产品方向为AI内容社区。<strong>《智能涌现》独家获悉，涌跃智能过去30天内完成了两轮融资。据测算，最新估值较1个月前提升了6倍。</strong></p>
  <p><strong>2026年2月10日，旗下产品Loopit正式上线，</strong>一名海外用户将使用视频，发布到了X，随即得到了埃隆·马斯克的评论转发。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_560727eefa314239b65ba7fe863b57fe@5783683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△马斯克转发Loopit。图源：马斯克X账号</p>
  <p>的确，在一众工具型、服务垂直场景的AI产品中，这款名为Loopit的平台型AI社区应用，形态和玩法，都令人眼前一亮。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_cf4e7119a0ba465781982c949e45edd2@5783683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△打开Loopit，就能看到单列Feed流中，有用户发布的各种互动内容，比如用手指滑动掉落的柚子，让它们在卡皮巴拉头上保持平衡。图源：作者试用</p>
  <p>在内容生产的另一端，与UGC平台类似，用户可以通过Loopit，制作并发表互动内容。</p>
  <p>但Loopit的不同之处在于，创作的门槛，被AI压得很低。用户只需要用文字输入大致的想法，Loopit会主动提供点子，并且生成支持图像、语音、视频、3D等全模态的可交互H5，并发布在社区中。</p>
  <p>比如生成一款“Y2K风格的答案之书”，我们只经历了两轮对话。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_b9d196a7d4384372895638f7ba48b41a@5783683_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△用文字在制作界面输入想法，Loopit就能生成点子，并且制作出互动内容。图源：作者试用</p>
  <p>产品上线初期，不少人将其定义为“AI游戏”。陈炜鹏不以为然：“我们不希望把产品定义得这么狭窄，用户在探索产品的过程中自己会拓宽边界。”</p>
  <p>2025年12月，Loopit在海外开启了小范围测试。陈炜鹏发现，一些用户会制作变身特效、设计整蛊游戏、搭建理想中的城市、投掷赛博臭鸡蛋，“本质上，<strong>这些互动内容，都是用户表达自我的一种新形式。”</strong></p>
  <p>十多年的职业生涯中，陈炜鹏最为人所知的身份，一是<strong>前搜狗搜索研发总经理、9年晋升超过10级的NLP（自然语言处理）大牛</strong>，二是<strong>百川智能联创、大模型负责人。</strong></p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_e4cde7d3b76645c3bc0a37b0f592daaf@5783683_oswg34004oswg1080oswg795_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△陈炜鹏。图源：互联网</p>
  <p>然而，在和我们的交流中，他主动提及最多的经历，是Soul。2021年，搜狗被腾讯收购后，陈炜鹏加入Soul，出任技术VP，负责AIGC技术和内容社区业务。</p>
  <p>这段经历，弥补了他在内容社区产品管理经验上的空缺。他发现，Soul内部，<strong>“我们不关心竞争对手，也不认为有人会是我们的竞争对手。</strong>我们在意的只有怎么给用户创造价值，这点给我带来很大的震撼”。</p>
  <p>某种意义上，Soul的产品方法论，也被用于如今的创业。陈炜鹏告诉我们，他不担心 Loopit 未来潜在的竞争对手，“如果我们能够用持续的创新拓宽行业对 AI 应用的想象力，一定就会获得用户的激励。”</p>
  <p>但鲜为人知的是，Loopit上线前，经历了7个多月的漫长探索。陈炜鹏记得，几乎每隔一两周，团队就要推翻产品demo，从头开始。</p>
  <p>彼时和他们在一栋写字楼创业的焦可（前百川智能联合创始人），偶遇陈炜鹏后也疑惑道：这么久了，你们的产品怎么还没发？</p>
  <p>产品形态的动摇，源自陈炜鹏对一条新路线的押注：<strong>把模型的Coding能力，和多模态能力结合在一起。</strong></p>
  <p>在他看来，多模态是最贴近C端应用的一种能力，能够拓宽用户与产品交互的边界。而Coding能力则更贴近底层架构，“所有的产品，都是靠Coding驱动的”，而AI，则帮普通人把Coding的门槛降低了。</p>
  <p>创业第一天，他就提出了一个大胆的构想：<strong>AI Coding不只是程序员的工具，AI Coding驱动多模态生成构成的互动引擎，会产生内容互动上的创新。</strong></p>
  <p>然而，走这条路并不容易。</p>
  <p>一是技术难，用Coding驱动多模态的可控生成，是一条鲜有人尝试过的路——团队用了整整7个月，才做出了能落地的架构。</p>
  <p>另一面，则是对产品形态的纠结。团队曾经想过做工具型产品，确定性强，第一天就能收费。但陈炜鹏判断，<strong>AI工具既没有想象力，也很难形成网络效应。</strong>他形容自己做了个“任性的决定”：“即便做社交平台更复杂、更艰难，但我很兴奋。”</p>
  <p>在更宏观的创投环境中，早期，陈炜鹏也并不是第一梯队的明星创业者。最早的融资过程，陈炜鹏被贴了很多标签：技术人不擅长做产品；年纪不够轻；之前在搜狗、百川等公司做过高管，冲劲可能不足。</p>
  <p>“我一直不是最开始就被看好的那个人，但10多年来，我也做了很多很棒的事。”他告诉我们，<strong>“如果先验我没有优势，那我就创造后验。”</strong></p>
  <p>以下是《智能涌现》与前百川智能联合创始人、涌跃智能创始人兼CEO陈炜鹏的交流，内容经编辑整理：</p>
  <h2><strong>我说服小川，做了几个重要决策</strong></h2>
  <p><strong>智能涌现：</strong>离开搜狗后，你去了Soul，看上去跨度挺大的。</p>
  <p><strong>陈炜鹏：</strong>这段经历其实很宝贵。搜狗是一个由算法驱动的公司，我在里面获得的认知是怎么用算法驱动产品发展。</p>
  <p>但技术导向的公司就比较容易“拿着锤子找钉子”。所以当时我比较好奇，更加产品导向的公司，是怎么运作的。</p>
  <p>我去Soul的时候，发现这家公司很特别，<strong>内部从来没有人讨论Soul的竞品是什么。</strong>他们更关心要创造的用户价值是什么，怎么开创新体验。</p>
  <p>他们在2021年就意识到，AIGC会在未来扮演非常重要的角色。所以Soul当时就开始布局对话系统、文生声音，还做AI虚拟角色交互产品，比MiniMax的Glow（发布于2022年10月）还要早。</p>
  <p>这个产品思路的转变，对我现在的创业影响很大。<strong>AI时代会奖励能够开拓人类想象力的公司。</strong></p>
  <p><strong>智能涌现：</strong>怎么理解“开拓人类想象力”？</p>
  <p><strong>陈炜鹏：</strong>刚出来创业的时候，我就很坚定，<strong>我们一定要做通用产品。</strong></p>
  <p>这算是一个很大的非共识。大家都说，创业要做垂直领域，确定性更强。</p>
  <p>但所谓的AGI，最核心的特点就是通用。我从上学，到工作，一直做NLP（自然语言处理）。一直以来我们遇到的最大问题，就是技术不够通用，所以很难构建可规模化的商业模式，所有的市场是被切割的。</p>
  <p><strong>既然我们终于在ChatGPT上看到了AGI的可能性，为什么还要回头做一个垂直产品呢？</strong></p>
  <p><strong>智能涌现：</strong>做通用的创业公司，需要有怎样的能力？</p>
  <p><strong>陈炜鹏：</strong>大模型公司相信能力涌现，<strong>AI应用公司要追求的东西，叫做组合能力，</strong>就是如何把AI背后的所有能力，比如代码、模型、语言、视频、图像、推理，甚至未来的世界模型，都组合起来。</p>
  <p>组合其实也能带来用户体验的“涌现”，用户会认为你的产品是可以探索的，能持续创造惊喜感。所以我觉得<strong>通用才是AI时代最大的确定性</strong>，这是我们做产品或者技术的principle。</p>
  <p><strong>智能涌现：</strong>2022年底ChatGPT发布，如果没有小川组局，你当时会自己创业吗？</p>
  <p><strong>陈炜鹏：</strong>会。我已经决定从Soul离职了。</p>
  <p>当时我下了很大的决心。因为还有3个月，我就能拿到Soul两年的期权。但我觉得大模型的机会很难再有了。</p>
  <p>我们做NLP的人一直讲，自然语言是智能皇冠上的明珠。所以我看到ChatGPT是非常震惊的，因为过去我想做的事一直没有突破，突然OpenAI给你做了示范。</p>
  <p>我就反思，过去自己还是认知不足，没有非常坚定地Scale up模型。所以我放弃了Soul两年的期权，寻找做大模型的机会。刚好那时小川也找了我。</p>
  <p><strong>智能涌现：</strong>自己从0开始训基座是百川内部第一天的共识吗？</p>
  <p><strong>陈炜鹏：</strong>是，我们非常坚定要自己训。即使可能存在很大的复杂性和风险，但是从发展的眼光来看，如果我们能够持续推动行业的发展，就一定能够得到行业的激励。</p>
  <p><strong>智能涌现：</strong>你能想到模型层的竞争这么快变激烈吗？</p>
  <p><strong>陈炜鹏：</strong>我有预料到。如果我们做的事足够重要，竞争一定会变得激烈。</p>
  <p>但一些事也比我想象的困难。当时很多人下场之后，早期大家对百川能不能做好大模型，是有疑问的。</p>
  <p>2023年5月的时候，我们的压力已经蛮大了。当时融资，我经常要回答非常多有关模型训练的细节。为什么大家会问这么多细节问题？核心原因是不相信我们能做到。</p>
  <p><strong>智能涌现：</strong>你怎么消化这些压力？</p>
  <p><strong>陈炜鹏：</strong>说实话我个人没什么困扰。因为在我个人的职业发展中，我从来不是最开始就被看到的那个人，但我总有信心能够创造条件。</p>
  <p><strong>我们当时做了几个重要的决策：</strong></p>
  <p><strong>第一，百川要走开源，</strong>开源是最容易建立Reputation的方式；</p>
  <p><strong>第二，我们只能从零开始训模型，掌握预训练的能力。</strong>很多公司基于风险和确定性的考虑，都想基于别人的模型做contiue pretrain，但是并不本质，比如你不知道别人的数据配比，团队的经验不可积累。看似低风险，长期是高风险。</p>
  <p><strong>第三，如果要短期出成果，我们在模型结构上要尽量保守。</strong>我的经验是，早期模型结构对智能的影响，没有数据大，模型结构也不是一个短时间内可以做激进创新的事。</p>
  <p><strong>第四，要建立模型评测的完整体系，</strong>这对提升团队的迭代效率非常重要。</p>
  <p>我记得很清楚，2023年5月8日我正式从Soul离职，上午坐上从上海到北京的高铁，下午到公司，把团队拉起来。</p>
  <p>当时我们决定未来3个月发布3个模型，后来也做到了。6月17日，百川发了第一个开源模型，<strong>就用了大概40天。</strong>后面我们的融资就非常顺利了，没有人再怀疑。</p>
  <p><strong>智能涌现：</strong>现在看来，这些决策也大多是正确的。</p>
  <p><strong>陈炜鹏：</strong>是的。所以做Baichuan 1-4的一整年时间，我都很快乐。</p>
  <p><strong>智能涌现：</strong>Baichuan 4之后你在做什么？</p>
  <p><strong>陈炜鹏：</strong>我转去和<strong>施政（前百川智能医疗业务负责人，涌跃智能联合创始人）</strong>一起做医疗大模型。当时我有些迷茫，不是对技术，而是运营的优先级。</p>
  <p><strong>智能涌现：</strong>什么样的基模创业公司，能跑出来？</p>
  <p><strong>陈炜鹏：组织能力强的公司。</strong>我经历过搜狗和Soul，知道一家技术导向的公司，如果要做出一个成熟的应用型产品，复杂性在哪里。</p>
  <p>你需要把产品思维和技术思维放在一个脑子里，没几家公司可以做到。</p>
  <p><strong>智能涌现：</strong>这两种思维可以通过招人弥补吗？</p>
  <p><strong>陈炜鹏：</strong>很难。我学到的一点是，一家公司的成败，很多时候都和创始团队有很大的关系。</p>
  <p><strong>智能涌现：</strong>你决定离职创业的契机是什么？</p>
  <p><strong>陈炜鹏：</strong>OpenAI o1的发布，是一个非常重要的时间点。这代表大模型的范式发生了很大变化。</p>
  <p>我当时的第一个判断就是，<strong>未来大模型公司和应用公司的界限，会越来越模糊。</strong>o1的技术是强化学习，这个技术更贴近应用场景。</p>
  <p>我就想，为什么不自己去做应用，创造一个全新的事？</p>
  <p><strong>智能涌现：</strong>百川对o1的态度是什么？你有考虑在内部做探索吗？</p>
  <p><strong>陈炜鹏：</strong>小川对强化学习很关注，场景聚焦在医疗。</p>
  <p>但我有自己专注想做的事情，所以选择从百川离开。</p>
  <h2><strong>做拓宽用户想象力的产品：Coding+多模态</strong></h2>
  <p><strong>智能涌现：</strong>o1发布后，你有想好自己的创业方向吗？</p>
  <p><strong>陈炜鹏：</strong>当时我就想做跟AI Coding相关的事。</p>
  <p>在整个技术范式中，Coding是一个自验证任务，所以进化的速度很快。我们很容易能预测到<strong>AI Coding是未来AI最大的变量。</strong></p>
  <p>抽象来看，整个移动互联网其实都是基于Coding去构造的。所以最早思考Coding这件事，我并没有把它当作类似Cursor的程序员工具。当时我最喜欢的产品是Lovable，因为它让每个人都可以创造一个网页、游戏或者应用。</p>
  <p>另外一个我看到的方向，是多模态。所以创业第一天我就思考，<strong>怎么把Coding和多模态结合起来，做一个有意思的通用产品。</strong></p>
  <p><strong>智能涌现：</strong>为什么看好多模态？</p>
  <p><strong>陈炜鹏：</strong>因为<strong>多模态是离C端最近的技术能力。</strong>很多时候我们对逻辑或理性的评价是确定的，但对美的评价是相对模糊的。这种包容性，对目前AI技术架构的能力不足更友好。</p>
  <p>所以我觉得多模态在应用场景里会有很大的价值。<strong>多模态的每一个改变，都在延展我们的想象力。</strong></p>
  <p><strong>智能涌现：</strong>你是怎么找到结合Coding和多模态能力的产品形态的？</p>
  <p><strong>陈炜鹏：</strong>产品不是第一天就ready的，我们用了很长时间探索。平均一到两个月，我们就会做一个不同的demo，去判断用户会不会觉得有意思。</p>
  <p>最早的时候，我们内部定义了一个系统，叫做互动内容引擎，也就是用Coding去操作多模态。</p>
  <p>早期我们想把这个引擎包装成一个工具，比如用Coding去做可以互动的PPT，或者用Coding去剪辑视频。</p>
  <p><strong>智能涌现：</strong>后来为什么推翻？</p>
  <p><strong>陈炜鹏：</strong>因为AI的Coding和多模态能力在不断提升，尤其到了Nano Banana和Sora 2，我们觉得产品可以不只是一个面向专业人士的工具，而是能变成更ToC的、低门槛的产品。</p>
  <p>当时我们思考做一个互动式的短剧，但过程中发现，这个场景不通用。短剧虽然“短”，但它相对文章、图片来说是长内容。<strong>长内容对技术的要求、对创作者的要求是很高的，所以一开始很难是个UGC产品。</strong></p>
  <p>最后我们放弃了长内容和故事性，转做一个短交互的产品和社区，也就是现在的Loopit。</p>
  <p><strong>智能涌现：</strong>Coding结合多模态，在技术层面困难吗？</p>
  <p><strong>陈炜鹏：</strong>很难。从2025年6月出来创业开始，我们可能每隔几个礼拜，就觉得之前的架构是一堆垃圾，又重新推翻。</p>
  <p>其中的难点在于，通用的AI Coding，或者是通用的多模态 Agent，本身就有很大的复杂性。</p>
  <p>在我们的场景里面，AI还需要根据用户的需求，Coding一个物理引擎，在这个引擎里面去驱动多模态的生成。本质上，<strong>Coding和多模态的生成都是受到一定的约束，比单纯做生成要难得多。</strong></p>
  <p>直到三个月前（2025年12月），我们才看到可能性。我们创新了一条结合Coding和多模态能力的好路径。</p>
  <p>这个过程我们要克服两点，一是技术的挑战性，二是怎么把他包装成一个<strong>让用户觉得“Aha”的产品。</strong>这两件事都有很大的不确定性。</p>
  <p><strong>智能涌现：</strong>你找到的让用户“Aha”的点是什么？</p>
  <p><strong>陈炜鹏：</strong>在Soul的经历，让我观察到<strong>今天的用户其实并不满足于观看，而是希望参与到内容中。</strong></p>
  <p>我们用空间打一个比方。抖音像舞台，大多数人在看，少数人在演；小红书更像广场，每个人都可以摆个小摊，说自己的故事；</p>
  <p>Soul的群聊房是更开放的房间，大家围绕同一个话题即时互动。包括我们看到直播平台内容的变化，用户的参与逐渐在成为内容本身。</p>
  <p>我慢慢意识到，内容的形态在发生一个很清晰的进化 ——<strong>人和内容的距离越来越近。从观看，到交流，再到参与。</strong></p>
  <p>所以我就希望我们能做一个可以和内容互动的平台。</p>
  <p><strong>智能涌现：</strong>Loopit现在的产品设计，比如单列Feed流，和抖音挺像的。为什么这么设计产品？</p>
  <p><strong>陈炜鹏：互动内容最重要的价值，是让用户第一时间感受到内容可以互动。</strong>所以产品的分发方式一定要内容优先。</p>
  <p>过去有两种内容分发的方式，一种是单列，一种是双列。<strong>为什么我们依然在过去的产品范式中思考？因为用户消费内容的渠道没有改变，</strong>仍然在手机上。</p>
  <p>我们认为，其中单列Feed流，是突出内容的一种更好的方式。现在光互动内容，就占了屏幕的80%。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_9259a5bf8d754b26a74af917d4f9fcde@5783683_oswg1535127oswg1080oswg2341_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">△Loopit首页的单列Feed流。图源：Loopit</p>
  <p><strong>智能涌现：</strong>但短视频传递信息的效率很高，互动内容把信息传递的门槛提得很高。用户愿意跨过门槛去体验吗？</p>
  <p><strong>陈炜鹏：</strong>我们之前也找过一些朋友，尤其是年轻人去体验，他们对这种形态的接受度蛮高的。另一方面，我们的产品设计也在刻意追求一件事，就是<strong>做符合用户直觉的交互，</strong>来降低交互的门槛。</p>
  <p>用户本质上评判的是互动的ROI，也就是我输入的注意力，能获得多少爽感。</p>
  <p>我认为<strong>互动内容提供的爽感密度，一定会大于视频。</strong>即便现在没有，但未来一定会发生。</p>
  <p><strong>智能涌现：</strong>这是共识还是非共识？</p>
  <p><strong>陈炜鹏：</strong>我不太确定，但我愿意相信。</p>
  <h2><strong>AI应用大多没有网络效应，工具没法成为新的平台</strong></h2>
  <p><strong>智能涌现：</strong>你理想的产品用户画像是什么？</p>
  <p><strong>陈炜鹏：</strong>早期肯定是年轻人，而且有想法、有创意。</p>
  <p>但未来很难描述清晰，比如小红书早期在几百万DAU的时候，是很难预测未来会成为一个什么样的平台。所以很多时候，我们只能讨论自己不想做什么。</p>
  <p><strong>智能涌现：</strong>你们不想做什么？</p>
  <p><strong>陈炜鹏：</strong>比如我们不想做成一个游戏平台。我不想给这么死的定位，还是希望用户自己去探索边界，我们提供的是能力和机制。</p>
  <p><strong>智能涌现：</strong>有人把你们的产品定义为“可以玩的抖音”。你认同吗？</p>
  <p><strong>陈炜鹏：</strong>挺好的。<strong>一个新物种，让人们认识的最好办法就是类比过去的事物。</strong></p>
  <p>就像最早，马云把淘宝定义为“商品搜索”，因为当时没有电商的概念，用户只知道搜索引擎。</p>
  <p>概念不重要，最重要的是让用户先用起来。</p>
  <p><strong>智能涌现：</strong>在冷启动阶段，用户和内容交互的动力是什么？</p>
  <p><strong>陈炜鹏：</strong>很多内容平台最后切中的是痒点，而不是痛点。当好的内容不断涌现，用户每刷一次都有惊喜的时候，交互动力的问题就不存在了。</p>
  <p>这就是我们下一步要构建的事，人会愿意把互动式内容当作一种新的表达方式。</p>
  <p><strong>智能涌现：</strong>这个结论是怎么得出的？</p>
  <p><strong>陈炜鹏：</strong>表达和展示自己是非常底层、非常人性的欲望，因为我们都希望获得认可。</p>
  <p><strong>如果表达是人的本能，那我们只需要思考，怎么样的表达是更高效的，或者是更fancy的。</strong></p>
  <p>整个AI技术的发展其实解决的都是人和世界交互的问题。从图片到视频，我们看到交互增加了时间，时间包含了逻辑；等到世界模型，又增加了时空的维度，让你的input都能得到回应。</p>
  <p>所以<strong>互动本身，我不理解为是人类的需求，而是一种能力。这</strong>个世界本来就应该是可以互动的。</p>
  <p><strong>智能涌现：</strong>早期你们怎么做增长？</p>
  <p><strong>陈炜鹏：</strong>在海外，我们先定向邀请了几百个专业创作者，在平台里创作高质量的互动内容。就像早期的抖音一样，我们先用优质内容建立创作生态。</p>
  <p><strong>智能涌现：</strong>你之前提到，未来大模型公司和应用公司的界限，会越来越模糊，你怎么做一个不会被模型吃掉的产品？</p>
  <p><strong>陈炜鹏：</strong>还是那个逻辑，应用公司更要注重组合能力，因为组合能力能带来新的价值。</p>
  <p>模型公司关心的是智能的涌现，<strong>应用公司关注的是怎么把智力通过组合，去提供全新的体验。</strong></p>
  <p>现在的AI应用已经不再是个模型了，很多时候是一个系统，里面包括了模型本身、模型使用的工具、使用的上下文，甚至包括模型运行的整个环境。至少目前，应用不再只由模型决定一切。</p>
  <p>我还想提一点，有个现象比较少被讨论，<strong>AI应用大多是没有网络效应的。</strong></p>
  <p><strong>智能涌现：</strong>为什么多数AI应用没有网络效应？</p>
  <p><strong>陈炜鹏：大多数 AI 应用是工具，不具备网络效应，</strong>就像剪映很难发展成为抖音。</p>
  <p>Sora2 虽然是一个很大的技术创新，但是没有产生新的交互维度，<strong>它很容易变成抖音的一个工具，因为现在视频最大的分发渠道就是抖音。</strong>对用户来说，用Sora 2制作视频之后，ROI最高的方式就是在抖音分发。</p>
  <p><strong>智能涌现：</strong>Loopit能产生网络效应吗？</p>
  <p><strong>陈炜鹏：</strong>我认为能。我们做的是互联网时代完全没有的形态，没有一个平台能够支持互动内容。</p>
  <p><strong>智能涌现：</strong>平台型产品必然涉及内容的分发。你会做推荐引擎吗？</p>
  <p><strong>陈炜鹏：</strong>我们会做，我和另一个联创，之前就是做推荐出身的。</p>
  <p>但AI时代的推荐和上一个时代一定会不一样。我们一直在探索，怎么把推荐和生成式AI结合起来，这样内容的创作，会直接更贴近用户的消费。</p>
  <p>这形成的闭环是：<strong>内容分发会影响创作工具，创作工具也会影响内容分发。</strong></p>
  <p><strong>智能涌现：</strong>你在互联网时代经历过平台型产品竞争激烈的年代。Loopit未来也会面临这样的竞争？</p>
  <p><strong>陈炜鹏：</strong>现在这个问题不重要。过去每一个产品出来，如果创造的价值足够大，那一定会面临激烈的竞争。但我们依然能看到，每个时代都有新公司、新产品出来。</p>
  <p>所以，竞争是个伪命题。Soul的经历让我得出一个结论，与其考虑竞争本身，不如考虑怎么持续创造价值。</p>
  <p><strong>智能涌现：</strong>现在AI应用打品牌、做增长都很卷。你打算怎么做？</p>
  <p><strong>陈炜鹏：</strong>我不太受外部影响。我们有自己完整的思考和计划，但我们不太方便对外说，因为我不是一个习惯把信念和可能性，说成确定性的人。</p>
  <p><strong>智能涌现：</strong>产品的商业模式呢？</p>
  <p><strong>陈炜鹏：</strong>这太早了。在我的视角里，<strong>过早讨论一个社区型产品的商业化，是不专业的、不懂社区的行为。</strong></p>
  <p>只有当社区具有较大的用户规模，你才能够真正说清楚用户是谁，才能围绕这批人做商业化。</p>
  <p>我并不担心商业模式。过去内容平台的商业化有两个变化，一个是<strong>分发效率提升</strong>，带来商业效率的提升；另一个是<strong>广告内容化</strong>。</p>
  <p>互动天然可以获得更多的注意力，互动广告和内容的边界也更模糊，用户的体验更平滑。</p>
  <p>但我现在不想给出答案，因为大概率会有更好的商业模式出现。</p>
  <h2><strong>如果先验没有优势，就创造后验优势</strong></h2>
  <p><strong>智能涌现：</strong>从创业到上线产品，差不多花了7个月的时间。这段时间你焦虑吗？</p>
  <p><strong>陈炜鹏：</strong>焦虑肯定是有的。</p>
  <p>因为我们很早就看到了这个方向，但真正难的是把想象力变成产品。</p>
  <p>创业的前几个月，其实每天都在和时间赛跑——怎么更快验证、迭代。</p>
  <p><strong>智能涌现：</strong>你会担心自己比别人慢吗？</p>
  <p><strong>陈炜鹏：</strong>我认同要快速迭代、快速收集反馈。但对我们来说，更重要的是方向对不对。</p>
  <p>如果一件事从一开始就是错的，再快也没有意义。</p>
  <p>我们节奏并不慢，几乎每隔几周就会做一个 demo，只是很多都被我们自己推翻了——因为还不够好。我们要确保的是，我们的每次迭代都是在我们相信的方向上持续的探索，让团队的努力有积累。</p>
  <p><strong>智能涌现：</strong>这期间你有踩过坑吗？</p>
  <p><strong>陈炜鹏：</strong>肯定有。</p>
  <p>我最大的体会是，<strong>要尽快做出选择，不选择本身也是一种选择。</strong></p>
  <p>当时我们面临一个很现实的分岔：做工具，更确定、更容易变现；做社区，更难、更复杂，但天花板更高。</p>
  <p>最后我们选择了后者。因为我们想做的不是一个效率工具，而是一个新的内容形态。如果只是做工具，我们自己都不会那么兴奋。</p>
  <p><strong>智能涌现：</strong>早期融资顺利吗？</p>
  <p><strong>陈炜鹏：</strong>当时产品还在 0-1 阶段，基本没有数据和模型可以证明自己。</p>
  <p>所以第一轮融资，本质上不是投产品，而是投人——投团队对这个方向的判断力，以及把事情做出来的能力。</p>
  <p><strong>智能涌现：</strong>当时投资人对你创业是什么态度？</p>
  <p><strong>陈炜鹏：</strong>确实有人担心，我们会不会做得太保守。</p>
  <p>因为市场上有一种刻板印象：年轻才有想象力，有经验反而会变稳。</p>
  <p>但我不太相信标签。<strong>创业本质上是创造，而不是符合画像。</strong>如果意识到经验可能是我的负担，那经验就是我的优势。</p>
  <p>所以我现在对贴标签释然了，<strong>如果先验我没有优势，那我就创造后验。</strong>一个算法人的工作模式，就是提出假设，然后证明它。我接受大家不同的假设。</p>
  <p><strong>智能涌现：</strong>“年轻人”，对AI行业来说到底意味着什么？</p>
  <p><strong>陈炜鹏：</strong>对攻坚大模型这样一个全新的技术，我觉得年轻人肯定有优势。</p>
  <p>但如果探讨一个工程问题，反倒有工作经验的人更有优势，因为工程问题需要的是架构思维。至于产品经理，年轻人有一定的优势，但不是压倒性的。</p>
  <p>那么创业这个事，我不认为年轻人有极大的优势。我不讨论判断，就讨论结果，<strong>今天大模型应用领域比较成功的创业公司，国内有哪一个是非常年轻的人做的？</strong></p>
  <p><strong>智能涌现：</strong>产品上线后，投资人的态度有变化吗？</p>
  <p><strong>陈炜鹏：</strong>有，疑虑都打消了<strong>。产品上线后，我们一个月里融了两轮。</strong></p>
  <p><strong>智能涌现：</strong>你是NLP出身的，转向多模态有门槛吗？</p>
  <p><strong>陈炜鹏：</strong>我不认为这是门槛。就像我之前从搜狗到Soul，一个更技术导向，一个更产品导向。这种差异对我来说不是阻力，反而是认知升级。</p>
  <p>我们在组建团队时，也刻意追求这种差异带来的互补。所以我们在组建团队时，反而刻意做了跨模态组合：我偏语言模型背景，合伙人是文生视频方向。这不是偶然，而是设计出来的。</p>
  <p><strong>智能涌现：</strong>你是怎么组团队的？</p>
  <p><strong>陈炜鹏：</strong>我们找团队的思路很明确，要找有互补性的人。我希望每一个成员的加入，都对团队有增益。</p>
  <p>但同时大家又有一定的信任，一旦团队形成共识，大家能坚定地推动。</p>
  <p>我认为这个时代团队最重要的事，就是有<strong>技术想象力</strong>。AI时代做产品和过去不太一样。过去是先确定用户需求，技术大概率都能做到。</p>
  <p>现在技术是动态发展的，<strong>只有想象力，很多时候只是对技术的幻想；只有技术，可能只是做一个平庸的产品。</strong>只有把技术和产品放在一起思考，才可能做出提升想象力的产品。所以我现在既负责技术，也负责产品。</p>
  <p><strong>智能涌现：</strong>为什么选择在临近春节的时间在国内上线产品？大家的注意力都被几家公司的模型发布吸引了。</p>
  <p><strong>陈炜鹏：</strong>这件事我思考了很久，也有很多人提醒我春节发布的风险。</p>
  <p>不久前一天，我突然想明白，在这么多热点面前，如果我们能够给市场提供一个新的想象力，会不会反而有超额的回报？</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_873d2e16da0f432e8c86a0ecf4d234a0@5783683_oswg649725oswg1389oswg517_img_png?x-oss-process=image/quality,q_90/format,jpg/interlace,1" /></p>
  <p class="img-desc">欢迎交流！</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3677337027158660</id>
            <title>字节发完阿里发，Qwen-Image 2.0火线出击</title>
            <link>https://www.36kr.com/p/3677337027158660</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3677337027158660</guid>
            <pubDate></pubDate>
            <updated>Tue, 10 Feb 2026 12:48:04 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_2a5b33a05a6e4ad08073f0e53e4e6d19@000000_oswg574580oswg900oswg383_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>字节的图像生成模型刚发不到半天，阿里的新模型也来了！&nbsp;</p>
  <p>智东西2月10日报道，今天，阿里巴巴发布了<strong>新一代图像生成基础模型Qwen-Image 2.0</strong>，这一模型支持长达一千个token的超长指令、2k分辨率，并采用了更轻量的模型架构，模型尺寸远小于Qwen-Image 2.0的20B，带来更快的推理速度。&nbsp;</p>
  <p>智东西第一时间对<strong>阿里Qwen-Image 2.0、字节Seedream 5.0 Preview以及谷歌Nano Banana Pro</strong>三款模型进行了横向体验比较，发现Qwen-Image 2.0在长指令遵循、长文本渲染方面确实具有优势，但在图像生成的真实感上仍稍逊于Nano Banana Pro。&nbsp;</p>
  <p>Qwen-Image 2.0的升级重点是<strong>文字渲染</strong>。在下方关于AB测试的官方案例中，文字的字体、排版、格式等都是由一则<strong>888个token（包含近千个中英文字词）</strong>的超长提示词精确定义的，而Qwen-Image 2.0可以做到不错的还原。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_2352aba1ac1149c1969b7169733bbcca@000000_oswg867750oswg1000oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen-Image 2.0还能用毛笔字渲染《兰亭集序》的全文，并且确保文字和画面的相对协调，文字没有遮挡画面的山水景色和人物。细看文字部分，虽然仍然可以找到一些渲染失败的文字，但是占比已经很低了。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_29ebb43f642747bcb9f6e51decbff0a3@000000_oswg640386oswg1000oswg459_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen-Image 2.0还支持<strong>一次性渲染属数十个子图</strong>，并保持其中主体的一致性。比如，下图就是Qwen-Image 2.0一次性生成的漫画，一共有24个画面，其中的人物、画风都较为连贯。&nbsp;</p>
  <p>针对AI生图常见的<strong>“油腻感”</strong>问题，Qwen-Image 2.0也做了优化。与前一代模型相比，Qwen-Image 2.0的色彩不会过于饱和，观感更像实拍，AI味淡了一些。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_c995ca0da12d46db87a83193cf74adef@000000_oswg757052oswg1080oswg470_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲从左到右：原图、Qwen-Image-2512、Qwen-Image 2.0</p>
  <p>阿里在AI盲测平台AI Arena上对Qwen-Image 2.0进行了测试，数据显示，Qwen-Image 2.0在文生图和图生图基准中分别排名第三和第二，不过距离谷歌的Nano Banana Pro（图中为Gemini-3-Pro-Image-Preview）还有一定差距。此外，这一模型暂时还没有和刚发布的Seedream 5.0 Preview进行对比。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_8a044acb4ce5476583c3d1efee2e7fe5@000000_oswg121655oswg1080oswg1618_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>千问视觉生成负责人吴晨飞在采访中谈道，Qwen-Image项目2025年5月份项目才立项，去年8月份发布首款模型，此后主要围绕生图和编辑两个支线迭代模型，而Qwen-Image 2.0则把生图和编辑两个能力整合到了一个模型中。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_4fd0c4402cbb4de8bfef7a5bd2d21873@000000_oswg719478oswg1000oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>目前，Qwen-Image 2.0已在阿里云百炼上已开通API邀测，用户也可通过Qwen Chat（chat.qwen.ai）免费体验新模型。千问App产品经理刘巍透露，这一模型后续将在千问App里上线。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_6e0c0222009d4cd4a20c0883af0f2438@000000_oswg234298oswg1000oswg574_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>会后，我们还与吴晨飞和千问大模型高级解决方案架构师熊瀚天进行了沟通。&nbsp;</p>
  <p>当我们问及Qwen-Image系列模型的未来规划时，吴晨飞称，如果用一个词作为Qwen-Image 2.0升级的核心，那就是<strong>“信息图”</strong>，而在未来一年，Qwen-Image团队会继续研究如PPT、多图海报、漫画等复杂“父图”的生成，进一步减少幻觉和错误。&nbsp;</p>
  <p>此外，该团队还计划在此前发布的分层模型基础上，进一步强化模型的<strong>分层编辑能力</strong>，目标是让生成模型真正成为生产力工具。通过AI分图层，设计师可以灵活结合AI生成（如千问编辑特定层）与传统手段，或融合不同模型的专长，实现“分而治之”的复杂编辑流程。&nbsp;</p>
  <h2><strong>01.阿里、字节、谷歌三款模型对决，Qwen-Image 2.0文字渲染能力突出</strong></h2>
  <p>在超长提示词任务上，我们对Qwen-Image 2.0的官方超长提示词进行了微调，调整了部分元素的位置，看看Qwen-Image 2.0能否交付同样质量的生成结果。&nbsp;</p>
  <p>提示词内容：&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_1d6ef3c5c7774a2f93180d9a2ed1962e@000000_oswg121140oswg1000oswg772_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Qwen-Image 2.0的生成结果如下。可以看到模型还原了我们对图片布局、字体颜色的要求，内容也得到准确呈现，基本没有遗漏。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_27d4619e4db34e1ebd935f2e5fceb567@000000_oswg804375oswg1000oswg571_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而Nano Banana Pro的生成结果明显有更多的图像和图标，设计风格和我们要求的一样，大部分文字也都成功渲染。美中不足的是，可以看到部分文字出现了模糊的问题，已经难以辨别。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_80fdd59ca3c44e039273c1091ef0278e@000000_oswg102951oswg1000oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Seedream 5.0 Preview的生成结果较我们的提示词出现了一些偏差，并没有准确还原文字内容，这在PPT等场景可能是较为严重的问题。但是抛开这一问题之外，完成度还是不错的。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_6afd4dbba3a046b2bc384686b613e34b@000000_oswg116869oswg1000oswg558_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>而在多子图生成任务上，我们让上述三款模型生成一副具有20个分镜的漫画，提示词依旧较长。&nbsp;</p>
  <p>在经过三次尝试后，Qwen-Image 2.0未能完全按照我们的要求生成这张图像。我们也对提示词本身进行了优化，标注了更为清晰的序号，但是没能让模型生成更准确的结果。&nbsp;</p>
  <p>此外，画面中也有一些不符合常理的现象，比如外卖员的手机竟然安在电动车车头上，手机屏幕面向外侧，。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_218e7b6981874c0bb24a113b517b5000@000000_oswg317437oswg1000oswg1725_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲Qwen-Image 2.0的三个生成结果</p>
  <p>在这一任务中，Nano Banana Pro（左）和Seedream 5.0 Preview（右）拿到提示词后都陷入了长时间的推理过程，最终未能成功生成。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_653a704e50c14df59e2cf4361c7f459d@000000_oswg177848oswg1000oswg429_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>文字渲染之外，我们也考察了这两款模型在图像生成方面的表现。发布会中提到，超现实场景其实对图像生成模型来说是一大挑战，如何在满足提示词要求的情况下保证真实感，很考验模型的功力。&nbsp;</p>
  <p>我们向模型发送了如下提示词：&nbsp;</p>
  <blockquote>
   <p>无边无际的海面上漂浮着一座倒置的城市，城市建筑如水晶般透明，内部流动着星空与光点。天空呈现撕裂般的云层结构，巨大的月亮贴近海平面，月光化为实体的光带缠绕在城市周围。一名渺小的人站在水面之上，脚下泛起涟漪，现实与梦境在此交汇，画面安静而震撼。&nbsp;</p>
  </blockquote>
  <p>Qwen-Image 2.0生成的画面其实与提示词有一些差距，图中的城市与其说是倒置，不如说是镜像。同时，左右两侧云层的形状是完全对称的，在美感上较有视觉冲击力，在真实性上稍显欠缺。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_39b9ed5e99ef4752aaa0a1bf9bb3eeec@000000_oswg1004496oswg1080oswg617_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Nano Banana Pro的生成结果则更符合我们的提示词，还原了城市的“倒置”、云层的“撕裂感”等关键描述。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_b5929cd82fac47d09ba49e321a0a13c7@000000_oswg1095737oswg1000oswg545_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>Seedream5.0 Preview提供了四个版本，可以看到它并没有遵循我们提示词中“像水晶般透明”的要求，不过其余内容基本得到了还原。其画风更为科幻感一些。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_0fb046d796c04666a1eda2f07e18b68a@000000_oswg694055oswg1000oswg542_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>02.生成、编辑融合效果1+1&gt;2，新模型尺寸远小于1.0版本</strong></h2>
  <p>发布会结束后，千问视觉生成负责人吴晨飞、千问大模型高级解决方案架构师熊瀚天与智东西等媒体进行了沟通。&nbsp;</p>
  <p>当谈及1.0版本与2.0版本相比，最大的提升在哪些领域，吴晨飞称Qwen-Image 2.0主要实现了<strong>“多”和“真”</strong>两个特性的融合。&nbsp;</p>
  <p>“多”指的是其更强的文字渲染能力。Qwen-Image 2.0能在一个画面中稳定生成大量、复杂的文字（如完整的PPT、信息图），错误率极低，基本达到“可用”状态，而之前的模型生成结果依然是不可用的。&nbsp;</p>
  <p>“真”指图像的真实感。1.0主要聚焦文字准确性，2.0在保证文字精准的同时，提升了图像（如材质、光影）的真实感。尤其当文字与图像结合时，生成结果更具真实感和代入感，减少了以往AI生图在文字区域的模糊和虚假感。&nbsp;</p>
  <p>谈及融合图像生成与编辑的选择时，吴晨飞透露，经过探索，他们发现<strong>二合一模型能实现能力相互促进，达到1+1&gt;2的效果</strong>，而非功能妥协。&nbsp;</p>
  <p>文生图中训练出的能力（如文字生成、图像质感）可以迁移到编辑任务上。例如，上传照片“题诗”的功能，就是文生图能力在编辑任务上的体现。&nbsp;</p>
  <p>编辑任务训练能迫使基础模型更好地理解语义变化和遵循指令，从而反哺文生图，使其对提示词更敏感、遵循更精确。这也是实现“理解-生成”一体化统一范式的重要一步。&nbsp;</p>
  <p>此外，<strong>Qwen-Image 2.0的模型尺寸比1.0（约200亿参数）显著减小</strong>，但能力更强，且生成速度更快。&nbsp;</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20260210/v2_7bb01c8969434dfc9a7a2dad8a2bf51b@000000_oswg383793oswg1000oswg560_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">▲千问视觉生成负责人吴晨飞</p>
  <p>当被问及如何解决文字生成崩溃的难点时，吴晨飞回应道，目前大部分生图模型都需要用到VAE（变分自编码器）负责图像压缩，小文字信息密集，压缩难度大，因此容易出现文字崩坏。其团队提升了VAE的重构能力，为清晰小字生成奠定基础。&nbsp;</p>
  <p>Qwen-Image 2.0对密集、细小文字的建模和生成能力也得到了增强。两者结合，使得小文字也能清晰渲染、准确显示。&nbsp;</p>
  <p>熊瀚天则分享了与模型落地场景相关的话题。他认为，模型能力的提升（尤其是可控性、稳定性）使其能真正渗透到各行各业。&nbsp;</p>
  <p>在电商领域，图像生成模型可用于海量商品的主图、详情图、广告素材图生成。例如，服装行业的模特换装、商品属性修改、多图融合，以及利用“信息图”能力生成商品详情长图。&nbsp;</p>
  <p>在医疗等专业领域，图像生成模型可以将复杂的流程（如就诊流程、诊断报告）通过信息图、流程图等形式可视化，便于理解。&nbsp;</p>
  <p>他认为，中国AIGC市场在应用落地和产业迭代速度上具有优势。国内有强大的应用土壤和快速落地的能力。当技术追平后，丰富的应用场景能催生出新的产业链（如短剧），并快速反哺模型迭代。&nbsp;</p>
  <p>Qwen-Image系列将与WPS等国民级应用进行合作，获取真实用户反馈和需求，并融入下一代模型开发，形成从应用到技术的闭环迭代。&nbsp;</p>
  <h2><strong>03.结语：从玩具到生产力，图像生成模型探索真实场景落地</strong></h2>
  <p>从近期的发布情况来看，图像生成领域的多家头部厂商已达成共识。如今，图像生成模型不仅仅追求生成逼真的画面，更要满足现实场景中对提示词精准遵循、文字准确渲染等关键因素的需求，这些才是真正决定模型生产力的核心要素。&nbsp;</p>
  <p>随着模型的不断优化与迭代，图像生成或许有潜力成为企业和个人在信息处理、创作表达及决策支持等方面的强大助手。&nbsp;</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzA4MTQ4NjQzMw==&amp;mid=2652796833&amp;idx=1&amp;sn=ab27426eff8777e679d9811c3af7839c&amp;chksm=8520a1d06431e24fb408b133f6821cabf7fa2d37ef41eb7a9b6fe142e4d017ab16dd45f9d850&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“智东西”（ID：zhidxcom）</a>，作者：陈骏达，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>