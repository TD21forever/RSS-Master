<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <channel>
        <title>36氪 - 最新资讯频道</title>
        <link>https://www.36kr.com/information/web_news</link>
        
        <item>
            <id>https://www.36kr.com/p/3572671380871559</id>
            <title>Gemini立功了，谷歌AI再次伟大，百度阿里们可以抄作业了？</title>
            <link>https://www.36kr.com/p/3572671380871559</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3572671380871559</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Nov 2025 12:00:32 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果仅看过去这一个月，很难想象这是那个在 2023 年因为 Bard「翻车」而被全球科技圈集体嘲笑的 Google。</p>
  <p>上周（11 月 18 日），Google 发布了新一代大模型 Gemini 3，用恐怖的实力碾压了更大模型，基于 Gemini 3 Pro 的 Nano Banana Pro 更是延续了 Google 在 AI 生成图像上的「王座」，也让 OpenAI 更加「焦虑」。</p>
  <p>不单如此，Gemini 3 也彻底了扭转「Google 掉队论」，自研 TPU 也被视为英伟达算力霸权的最大变量，Meta 都被传出正评估大规模采购 TPU，直接让英伟达股价下跌近 7%，随后英伟达官方也在 X（原 Twitter）上发文称：</p>
  <blockquote>
   <p>「我们为谷歌取得的成功感到高兴——他们在 AI 领域取得了重大进展，而我们也将继续向谷歌（云）提供产品。」</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_8adf9da29c67428c9096dc000b3174a5@1547419282_oswg160799oswg1188oswg684_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：X</p>
  <p>与此同时，Anthropic（Claude）在上月也刚宣布了最新一批百万级的 Google TPU 订单 ，包括 OpenAI 联合创始人、前首席科学家 Ilya Sutskever 新创立的 SSI 也在年初选择了 Google TPU 作为算力来源。</p>
  <p><strong>坦白讲，这一切也不仅仅因为从 Gemini 2.5 到 Gemini 3 「模型的胜利」，也因为 Google 身上的另一种叙事——体系的胜利。</strong>Gemini、TPU、Google Cloud、Android、Google Search 这套长期被认为「太慢」「太重」的策略，突然显得有了压迫力。</p>
  <p>行业的态度的变化尤为明显。</p>
  <p>今年以前流行的论调是：Google 老了、官僚化了。如今却几乎是反向的情绪：Google 的节奏稳了、产品线统一了、技术底座终于显露了威力。甚至有分析师将&nbsp; Google 称为「醒来的巨人」，暗示这家公司可能正在重新定义整个产业的技术路线。</p>
  <p><strong>不过，真正让人感到戏剧性的并不是今天的掌声，而是它与过去的落差。</strong>两年前，Google 还在为 Bard 的「翻车」公开道歉，被当作大模型时代最典型的失败案例之一。而如今，同一家公司却成了最受追捧的那一个。</p>
  <p>从被群嘲到被追捧，Google 到底是怎么做到的？</p>
  <h2><strong>被 ChatGPT 打醒了，但路线从未改变</strong></h2>
  <p>2022 年底的 ChatGPT 是一声惊雷，被这声雷劈醒最彻底的，恰恰是设计开发了 Transformer 架构、当时如日中天的 Google。</p>
  <p>基于 Transformer 架构和 Scaling Law（扩展法则），GPT-3.5 的横空出世让全球第一次意识到通用大模型的潜力。而 Google 内部的反应远比外界猜测得更激烈，搜索团队紧急成立「Code Red」应急小组，DeepMind 与 Google Brain 在内部反复讨论路线，管理层数周连续加班开会，甚至内部邮件里都弥漫着一种压力和窘境：</p>
  <blockquote>
   <p>「如果再慢，我们会被历史淘汰。」</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_ae22f03f659a4e618c366e7eedf8dca6@1547419282_oswg15838oswg430oswg430_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p>在这种背景下，Bard 仓促上线，问题百出，甚至因为一条错误回答导致市值狂跌千亿美元，社交媒体和科技圈都在质疑 Google「尚能饭否」？至少在当时，更关键的还不是产品本身，而是背后很多人的行业判断：</p>
  <p><strong>Google 失去了节奏感，躺在功劳簿上，被 OpenAI 打得措手不及。</strong></p>
  <p>这就是「Google 掉队论」的起点。但真正反转的是，Google 在最被看衰的那段时间，并没有换路线。2016 年起，Google 就宣布「AI-first」（AI 优先），并在那之后持续投入了一条业内最重、最系统的「全栈式 AI」路线：</p>
  <blockquote>
   <p>不仅作为全球第三大云计算厂商运营遍布全球的数据中心，自研 AI 芯片（TPU），还自主训练大模型，甚至开发 AI 应用（如 Nano Banana、NotebookLM）。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_8048dc2f600a48e4a1a9dd65eb812c05@1547419282_oswg512138oswg1300oswg731_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p>更不用说，Google 还有全球规模最大的搜索场景、Google Photos、YouTube 上海量的多模态训练素材。这些看起来「不性感」「非爆发式」的长期工程，在 ChatGPT 的巨大冲击下并没有被抛弃。</p>
  <p><strong>掉队不是方向错，而是路线太长。既然路线正确，那就不能换，而是要加码。</strong>所以 Google 在经历 ChatGPT 的冲击和 Bard 的失败后，也经历了最猛烈的调整期。</p>
  <h2><strong>「Google 式全栈」：十年投入，一朝兑现</strong></h2>
  <p>首先是当年被认为「不可能」的事情发生了，2023 年 4 月，Google Brain 与 DeepMind 合并为一个统一团队，两支全球最强的研究力量被强行揉成一支，路线和节奏由曾经主导开发 AlphaGo 的 DeepMind 创始人 Demis Hassabis（杰米斯·哈萨比）统一指挥。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_5431cc25729a4a199f953fe638970898@1547419282_oswg98658oswg1280oswg720_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p>对外的说法是「统一资源」，但业内都知道，这背后真正清理掉的是 Google 内部长期存在、几乎无法调和的路线分歧和组织壁垒。AI-first 战略喊了很多年，但直到这次重组，它才第一次真正「力出一孔」。</p>
  <p><strong>与此同时，Google 过去十年一点点打下的底座开始显露出价值。</strong>TPU 本来就是为谷歌自身服务的芯片，先是给搜索和广告做推理加速，然后逐步支撑内部模型的训练。当大模型时代到来，这种优势恰好成为了一个行业变量，也是 Google 与其他所有大模型厂商最核心的差异之一。</p>
  <p>尤其是在 ChatGPT 之后，TPU v5、v6、v7（Ironwood）的节奏明显加快、加大。从 Anthropic 开始，Google 也开始把自家芯片拿出去做外部大规模商用，从本地训练、云部署，到现在的专线算力、TPU@Premises 等方案，一步一步抬升自家云的含金量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_11f1eeeacbc7454eb591dbd5d50dcf19@1547419282_oswg1598502oswg1300oswg731_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p><strong>而从 Bard 到 Gemini，本质上还伴随着一次「架构统一工程」：</strong>从跑在 Pixel 和 Chrome 上的 Gemini Nano，到侧重吞吐和延迟的 Gemini Flash，再到最强的 Gemini Pro，背后都共享同一套架构、训练方法和评测体系。</p>
  <p>这套统一后的体系，让 Gemini 2.5 能在推理和多模态上重返第一梯队，也让 Gemini 3 能在视觉、语音、文本和代码理解上全面进化。Google 过去被嘲笑的「慢」，恰恰来自于它在为这条统一路线铺底，而不是没有方向。</p>
  <p>体系的成形，最终还是要落地到产品上才能证明价值。在 Bard 的失败后，Google 可能也意识到模型的核心价值，以及盲目生成式 AI 化的问题，选择了一条不同优先级的路线。</p>
  <p>最激进的突破是搜索，不仅支持了 AI 预览，还在早些时候下定决心，正式上线了 AI Mode。Pixel 手机也是 Google AI 化改造的另一个主力，云端和设备端不同尺寸、不同设计目的的 Gemini 模型，也在影像、翻译、信息处理以及语音助手体验上带来质的改变，Magic Cue 智能信息提示更是手机 AI 化的关键方向之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_fa0d733e5d674d14b99840e5d725525c@1547419282_oswg30570oswg686oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p><strong>不同于已有产品和服务的 AI 化改造，NotebookLM 和 Nano Banana 作为今天原生 AI 应用的代表，则是代表了 Google 探索 AI 时代的另一种路径，</strong>一个重构了学习与知识管理，一个把视觉生成推向了更轻、更快、更自由的方向。</p>
  <p>可以说，过去差不多十年 Google 把芯片、模型、云基础设施、搜索规模、移动端生态、视频和图像数据全部捏成了一套体系。这看上去笨重、缓慢，但当模型能力、算力底座和产品矩阵在同一条路径上汇合时，也突然具备了别人难以复刻的整体性。</p>
  <h2><strong>阿里、百度能否实现 Google 式「反转」？</strong></h2>
  <p>如果把国内这两年的大模型竞争放到同一个坐标系里，豆包的领先已经不是「更快一点」，而是彻底甩开了身后的所有追赶者。</p>
  <p>QuestMobile 的数据显示，今年第三季度豆包 App 的月活已经冲到 1.59 亿，超越了 DeepSeek，并且遥遥领先其他 AI 应用。同时，火山引擎的公有云大模型调用量份额更是逼近一半，日均 token 调用量突破三十万亿。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_7b704064f40d4dfeaff1c3575e09bed9@1547419282_oswg83979oswg1024oswg892_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：QuestMobile</p>
  <p>这种规模带来的滚雪球效应，让豆包在用户侧、应用生态和模型调用上都形成了「越用越强」的正循环。</p>
  <p><strong>但如果把视角稍微拉高一点，又会发现豆包的领先并不意味着这场竞争已经盖棺定论。</strong>因为在 Google 身上我们已经看到，真正决定胜负的从来不是一两次爆发，而是体系。阿里这两年在模型、算力、开源和应用层的连招，正在让它成为最有可能走出「Google 式反转」的国内玩家。</p>
  <p>千问 App 的爆发只是最外层的信号。<strong>真正支撑它的，是阿里过去两年在全球开源社区建立起来的 Qwen 模型号召力，以及大规模基础设施投入带来的底层优势。</strong></p>
  <p>Qwen2.5 到 Qwen3-Max 这条路线，把模型的推理、多模态和代码能力推到国际一线；Qwen 在 Hugging Face、GitHub 的累计下载量已经摆在全球前列，甚至多次登上全球开源榜前几的位置。</p>
  <p>而阿里今年明确以千问取代通义，也是在把这些底层能力重新压缩成一个 C 端入口，让自身的技术体系第一次具备了向大众规模化输出的可能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_6602c8a465a3411b96778e23b55df633@1547419282_oswg673867oswg1200oswg673_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：阿里</p>
  <p>某种意义上，千问现在的状态很像 Google 之前的阶段——模型够强，生态够深，入口刚刚成型，<strong>真正的大考才刚开始。</strong></p>
  <p>而百度虽然在产品，尤其是在 C 端产品的节奏上慢半拍，但仍然有着极强的技术底座。文心 5.0 原生全模态架构、万亿参数规模、与昆仑芯的深度绑定，让百度在技术完整性上保持着独特的位置。它的 AI 云、城市级业务、自动驾驶体系，也让它在 To B / To G 领域拥有别人难以复制的纵深。</p>
  <p><strong>只是，这种体系化的投入并不会自然转化成 C 端用户规模，中间还有很多路要走。</strong></p>
  <p>把国内这三家放在一起看，更能理解 Google 的启示意义。豆包证明了「规模」本身就是能力的一部分，是最现实、最直接的飞轮；阿里证明了开源、全栈和大生态的深耕可以在关键时刻形成反转势能；百度则证明了底座的完整性永远不会过时，只是在等待一个足够大的应用窗口把体系推向前台。</p>
  <p>国内的竞争还远没结束，而真正决定未来的，很可能不是谁跑得最快，而是谁能把模型、算力和应用最终捏成一条完整的路径。</p>
  <p>本文来自微信公众号<a href="https://mp.weixin.qq.com/s/VsB_KOEhO5ujFGthuRJhqg" rel="noopener noreferrer nofollow" target="_blank">“雷科技”</a>，作者：雷科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3572648798239616</id>
            <title>Gemini立功，谷歌AI再次伟大，百度阿里们可以抄作业了？</title>
            <link>https://www.36kr.com/p/3572648798239616</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3572648798239616</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Nov 2025 11:58:25 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>如果仅看过去这一个月，很难想象这是那个在 2023 年因为 Bard「翻车」而被全球科技圈集体嘲笑的 Google。</p>
  <p>上周（11 月 18 日），Google 发布了新一代大模型 Gemini 3，用恐怖的实力碾压了更大模型，基于 Gemini 3 Pro 的 Nano Banana Pro 更是延续了 Google 在 AI 生成图像上的「王座」，也让 OpenAI 更加「焦虑」。</p>
  <p>不单如此，Gemini 3 也彻底了扭转「Google 掉队论」，自研 TPU 也被视为英伟达算力霸权的最大变量，Meta 都被传出正评估大规模采购 TPU，直接让英伟达股价下跌近 7%，随后英伟达官方也在 X（原 Twitter）上发文称：</p>
  <blockquote>
   <p>「我们为谷歌取得的成功感到高兴——他们在 AI 领域取得了重大进展，而我们也将继续向谷歌（云）提供产品。」</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_0101f405b2ad4bdbbefa068c69fc4f3b@5888275_oswg228148oswg1080oswg622_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：X</p>
  <p>与此同时，Anthropic（Claude）在上月也刚宣布了最新一批百万级的 Google TPU 订单 ，包括 OpenAI 联合创始人、前首席科学家 Ilya Sutskever 新创立的 SSI 也在年初选择了 Google TPU 作为算力来源。</p>
  <p><strong>坦白讲，这一切也不仅仅因为从 Gemini 2.5 到 Gemini 3 「模型的胜利」，也因为 Google 身上的另一种叙事——体系的胜利。</strong>Gemini、TPU、Google Cloud、Android、Google Search 这套长期被认为「太慢」「太重」的策略，突然显得有了压迫力。</p>
  <p>行业的态度的变化尤为明显。</p>
  <p>今年以前流行的论调是：Google 老了、官僚化了。如今却几乎是反向的情绪：Google 的节奏稳了、产品线统一了、技术底座终于显露了威力。甚至有分析师将Google 称为「醒来的巨人」，暗示这家公司可能正在重新定义整个产业的技术路线。</p>
  <p><strong>不过，真正让人感到戏剧性的并不是今天的掌声，而是它与过去的落差。</strong>两年前，Google 还在为 Bard 的「翻车」公开道歉，被当作大模型时代最典型的失败案例之一。而如今，同一家公司却成了最受追捧的那一个。</p>
  <p>从被群嘲到被追捧，Google 到底是怎么做到的？</p>
  <h2><strong>被 ChatGPT 打醒了，但路线从未改变</strong></h2>
  <p>2022 年底的 ChatGPT 是一声惊雷，被这声雷劈醒最彻底的，恰恰是设计开发了 Transformer 架构、当时如日中天的 Google。</p>
  <p>基于 Transformer 架构和 Scaling Law（扩展法则），GPT-3.5 的横空出世让全球第一次意识到通用大模型的潜力。而 Google 内部的反应远比外界猜测得更激烈，搜索团队紧急成立「Code Red」应急小组，DeepMind 与 Google Brain 在内部反复讨论路线，管理层数周连续加班开会，甚至内部邮件里都弥漫着一种压力和窘境：</p>
  <blockquote>
   <p>「如果再慢，我们会被历史淘汰。」</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_33bd2c636f0e47bb9f71e5d63a4e3fcf@5888275_oswg30730oswg936oswg628_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p>在这种背景下，Bard 仓促上线，问题百出，甚至因为一条错误回答导致市值狂跌千亿美元，社交媒体和科技圈都在质疑 Google「尚能饭否」？至少在当时，更关键的还不是产品本身，而是背后很多人的行业判断：</p>
  <p><strong>Google 失去了节奏感，躺在功劳簿上，被 OpenAI 打得措手不及。</strong></p>
  <p>这就是「Google 掉队论」的起点。但真正反转的是，Google 在最被看衰的那段时间，并没有换路线。2016 年起，Google 就宣布「AI-first」（AI 优先），并在那之后持续投入了一条业内最重、最系统的「全栈式 AI」路线：</p>
  <blockquote>
   <p>不仅作为全球第三大云计算厂商运营遍布全球的数据中心，自研 AI 芯片（TPU），还自主训练大模型，甚至开发 AI 应用（如 Nano Banana、NotebookLM）。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_4ca7e720ce5e41b08367cc394e12a031@5888275_oswg359627oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p>更不用说，Google 还有全球规模最大的搜索场景、Google Photos、YouTube 上海量的多模态训练素材。这些看起来「不性感」「非爆发式」的长期工程，在 ChatGPT 的巨大冲击下并没有被抛弃。</p>
  <p><strong>掉队不是方向错，而是路线太长。既然路线正确，那就不能换，而是要加码。</strong>所以 Google 在经历 ChatGPT 的冲击和 Bard 的失败后，也经历了最猛烈的调整期。</p>
  <h2><strong>「Google 式全栈」：十年投入，一朝兑现</strong></h2>
  <p>首先是当年被认为「不可能」的事情发生了，2023 年 4 月，Google Brain 与 DeepMind 合并为一个统一团队，两支全球最强的研究力量被强行揉成一支，路线和节奏由曾经主导开发 AlphaGo 的 DeepMind 创始人 Demis Hassabis（杰米斯·哈萨比）统一指挥。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_31412a185ef142d0b124832f9d91daf5@5888275_oswg66946oswg1080oswg608_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p>对外的说法是「统一资源」，但业内都知道，这背后真正清理掉的是 Google 内部长期存在、几乎无法调和的路线分歧和组织壁垒。AI-first 战略喊了很多年，但直到这次重组，它才第一次真正「力出一孔」。</p>
  <p><strong>与此同时，Google 过去十年一点点打下的底座开始显露出价值。</strong>TPU 本来就是为谷歌自身服务的芯片，先是给搜索和广告做推理加速，然后逐步支撑内部模型的训练。当大模型时代到来，这种优势恰好成为了一个行业变量，也是 Google 与其他所有大模型厂商最核心的差异之一。</p>
  <p>尤其是在 ChatGPT 之后，TPU v5、v6、v7（Ironwood）的节奏明显加快、加大。从 Anthropic 开始，Google 也开始把自家芯片拿出去做外部大规模商用，从本地训练、云部署，到现在的专线算力、TPU@Premises 等方案，一步一步抬升自家云的含金量。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_7f6b6eaa57f24985813beab47df2066f@5888275_oswg1083798oswg1080oswg607_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p><strong>而从 Bard 到 Gemini，本质上还伴随着一次「架构统一工程」：</strong>从跑在 Pixel 和 Chrome 上的 Gemini Nano，到侧重吞吐和延迟的 Gemini Flash，再到最强的 Gemini Pro，背后都共享同一套架构、训练方法和评测体系。</p>
  <p>这套统一后的体系，让 Gemini 2.5 能在推理和多模态上重返第一梯队，也让 Gemini 3 能在视觉、语音、文本和代码理解上全面进化。Google 过去被嘲笑的「慢」，恰恰来自于它在为这条统一路线铺底，而不是没有方向。</p>
  <p>体系的成形，最终还是要落地到产品上才能证明价值。在 Bard 的失败后，Google 可能也意识到模型的核心价值，以及盲目生成式 AI 化的问题，选择了一条不同优先级的路线。</p>
  <p>最激进的突破是搜索，不仅支持了 AI 预览，还在早些时候下定决心，正式上线了 AI Mode。Pixel 手机也是 Google AI 化改造的另一个主力，云端和设备端不同尺寸、不同设计目的的 Gemini 模型，也在影像、翻译、信息处理以及语音助手体验上带来质的改变，Magic Cue 智能信息提示更是手机 AI 化的关键方向之一。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_d757c0c884c64f3da5a864f8fd079a2d@5888275_oswg26386oswg686oswg386_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：Google</p>
  <p><strong>不同于已有产品和服务的 AI 化改造，NotebookLM 和 Nano Banana 作为今天原生 AI 应用的代表，则是代表了 Google 探索 AI 时代的另一种路径，</strong>一个重构了学习与知识管理，一个把视觉生成推向了更轻、更快、更自由的方向。</p>
  <p>可以说，过去差不多十年 Google 把芯片、模型、云基础设施、搜索规模、移动端生态、视频和图像数据全部捏成了一套体系。这看上去笨重、缓慢，但当模型能力、算力底座和产品矩阵在同一条路径上汇合时，也突然具备了别人难以复刻的整体性。</p>
  <h2><strong>阿里、百度能否实现 Google 式「反转」？</strong></h2>
  <p>如果把国内这两年的大模型竞争放到同一个坐标系里，豆包的领先已经不是「更快一点」，而是彻底甩开了身后的所有追赶者。</p>
  <p>QuestMobile 的数据显示，今年第三季度豆包 App 的月活已经冲到 1.59 亿，超越了 DeepSeek，并且遥遥领先其他 AI 应用。同时，火山引擎的公有云大模型调用量份额更是逼近一半，日均 token 调用量突破三十万亿。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_20a5088689304cd0882bcac4fae6f645@5888275_oswg67368oswg1024oswg892_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：QuestMobile</p>
  <p>这种规模带来的滚雪球效应，让豆包在用户侧、应用生态和模型调用上都形成了「越用越强」的正循环。</p>
  <p><strong>但如果把视角稍微拉高一点，又会发现豆包的领先并不意味着这场竞争已经盖棺定论。</strong>因为在 Google 身上我们已经看到，真正决定胜负的从来不是一两次爆发，而是体系。阿里这两年在模型、算力、开源和应用层的连招，正在让它成为最有可能走出「Google 式反转」的国内玩家。</p>
  <p>千问 App 的爆发只是最外层的信号。<strong>真正支撑它的，是阿里过去两年在全球开源社区建立起来的 Qwen 模型号召力，以及大规模基础设施投入带来的底层优势。</strong></p>
  <p>Qwen2.5 到 Qwen3-Max 这条路线，把模型的推理、多模态和代码能力推到国际一线；Qwen 在 Hugging Face、GitHub 的累计下载量已经摆在全球前列，甚至多次登上全球开源榜前几的位置。</p>
  <p>而阿里今年明确以千问取代通义，也是在把这些底层能力重新压缩成一个 C 端入口，让自身的技术体系第一次具备了向大众规模化输出的可能。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_9aee689300d14cf194e87c05a7acd714@5888275_oswg516098oswg1080oswg606_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图片来源：阿里</p>
  <p>某种意义上，千问现在的状态很像 Google 之前的阶段——模型够强，生态够深，入口刚刚成型，<strong>真正的大考才刚开始。</strong></p>
  <p>而百度虽然在产品，尤其是在 C 端产品的节奏上慢半拍，但仍然有着极强的技术底座。文心 5.0 原生全模态架构、万亿参数规模、与昆仑芯的深度绑定，让百度在技术完整性上保持着独特的位置。它的 AI 云、城市级业务、自动驾驶体系，也让它在 To B / To G 领域拥有别人难以复制的纵深。</p>
  <p><strong>只是，这种体系化的投入并不会自然转化成 C 端用户规模，中间还有很多路要走。</strong></p>
  <p>把国内这三家放在一起看，更能理解 Google 的启示意义。豆包证明了「规模」本身就是能力的一部分，是最现实、最直接的飞轮；阿里证明了开源、全栈和大生态的深耕可以在关键时刻形成反转势能；百度则证明了底座的完整性永远不会过时，只是在等待一个足够大的应用窗口把体系推向前台。</p>
  <p>国内的竞争还远没结束，而真正决定未来的，很可能不是谁跑得最快，而是谁能把模型、算力和应用最终捏成一条完整的路径。</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/83EFqENJMCT6BhQgHJLX7g" rel="noopener noreferrer nofollow" target="_blank">“智能Pro”</a>，作者：冬日果酱，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3572630922492803</id>
            <title>腾讯站台的Soul赴港IPO，Z世代的“情绪绿洲”值多少钱？</title>
            <link>https://www.36kr.com/p/3572630922492803</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3572630922492803</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Nov 2025 11:58:05 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p><strong>虚拟社交平台Soul试图用AI编织一张温暖的情绪网络，但现实的资本市场只会用审判眼光审视这张网的牢固程度和捕捞收获能力。</strong></p>
  <p>据港交所披露，国内最早一批布局AI+沉浸式社交的平台Soulgate Inc.（以下简称“Soul”）于近日正式向港交所递交招股说明书，拟主板挂牌上市，中信证券担任独家保荐人。</p>
  <p>从其招股书数据来看，Soul已经建立起以Z世代为核心的用户生态，并实现了连续两年的稳定盈利。</p>
  <p>不过，Soul的上市尝试并非首次，2021年曾寻求美股上市，后调整资本路径转向港股；而此次IPO时机选择却很微妙，正值全球AI应用从工具型向陪伴型转型的关键节点。</p>
  <p><strong>据IDC最新报告，2025年全球AI社交市场规模预计580亿美元，而中国作为全球最大的数字社交市场，正成为AI情感计算落地的前沿阵地。</strong></p>
  <p>因此不管最终能否成功上市，Soul此番赴港都是进一步细致观察AI社交商业化可行性的巧妙窗口之一。</p>
  <h2><strong>年入16.8亿，Soul撬动Z世代情绪经济的闭环</strong></h2>
  <p><strong>据公开资料介绍，Soul上线于2016年，早期凭借非颜值虚拟社交、灵魂匹配、兴趣图谱等创新性产品特征，此后围绕核心用户群，Soul不断深耕并优化用户体验，逐渐走出了一条独特的路。</strong></p>
  <p>区别于传统社交平台的流量逻辑，该平台用了近十年的摸索与打磨，转向情感连接的价值逻辑。</p>
  <p>截至2025年8月31日，Soul已累计拥有约3.9亿名注册用户，这一数字在中国垂类AI社交领域堪称第一梯队。</p>
  <p>该平台还是年轻群体情感表达的重要载体。截至同日，平台日均活跃用户数达到1100万，其中Z世代用户占比高达78.7%，构成了Soul最核心的用户群体。</p>
  <p>在用户粘性方面，Soul也展示出强劲的吸引力：前8个月，日均使用时长超50分钟，月均三个月留存率80%，人均日私信量约75条。这些数据综合表明，Soul已形成大规模、高活跃度且能持续吸引年轻用户的数字社交生态。</p>
  <p>生态成型后，Soul的业绩基本面也已步入稳健增长轨道。招股书显示，2022年至2024年，Soul的营收从16.67亿元增长至22.11亿元，复合年增长率超过15%。</p>
  <p><strong>2025年前8个月，Soul的营收同比增长17.8%至16.83亿元，维持了双位数的增长势头。</strong></p>
  <p>盈利能力方面，Soul自2023年起录得稳定盈利，2024年的经调整净利润为3.37亿元。2025年前8个月继续大幅增长73%至2.86亿元，显示出其盈利高增长的强持续性。</p>
  <p>就核心驱动力来说，Soul的商业化模式主要围绕“情绪价值服务”展开。前8个月，AI驱动的情绪价值服务（包括虚拟物品及会员特权）占平台总收入比例超过九成，付费率为6.5%，每名付费用户的月均收入达到104.4元，反映用户对平台提供的情绪价值服务具有较强的付费意愿。</p>
  <p>腾讯研究院高级研究员白惠天在《AI社交的热潮与沉思》中指出：“AI陪伴正在完成从‘工具’到‘伙伴’的跃迁。”此时用户不仅在消费内容，更在主动构建社交关系。而Soul的用户行为数据和财务数据，无疑为市场探讨这一趋势的商业可行性提供了一个真实窗口。</p>
  <p>Soul的高毛利率相信也是资本市场青睐的类型。2022年至2024年，公司的毛利率均保持在80%以上，2025年前8个月为81.5%，这一水平即便在社交平台中表现也很突出。</p>
  <p>Soul将其成功归因于其独特的“用户-AI-平台”飞轮体系。平台通过自研的原生情绪价值大模型Soul X，不断提升用户体验与社区活跃度，而用户的高参与度又反过来推动模型和算法的持续优化，形成良性循环。</p>
  <p><strong>这种技术驱动模式符合AI社交的演进逻辑。</strong>如行业分析指出：“记忆是AI社交的灵魂，多模态赋予在场感。”Soul通过Avatar虚拟身份、兴趣图谱和AI辅助交互，创造沉浸式社交场景，规避了传统社交平台以颜值导向的浅层互动弊端。</p>
  <h2><strong>AI社交的现实论：有需求却难成功</strong></h2>
  <p><strong>然而，正如白惠天分析所言，“AI社交需求是真实存在的，但成功远比想象中艰难”。</strong></p>
  <p>这句话，用最简单的表述道出了这一赛道参与者的共同困境。</p>
  <p><strong>根据QuestMobile报告，至2025年春，AI社交互动已超越短视频和游戏，成为移动互联网中人均使用频率最高的赛道，单月人均使用次数达到167.9次。</strong></p>
  <p>然而，市场的热度掩盖不了残酷的筛选机制。数据显示，仅10%的应用贡献了行业近89%的收入，全球累计收入超100万美元的产品仅33款。</p>
  <p>过去两年，业内已有多款知名项目相继陨落，包括阶跃星辰的“冒泡鸭”、Soul旗下“异世界回响”等平台停止运营或暂停新用户注册，行业洗牌加剧。</p>
  <p>用户留存问题成为行业普遍痛点。一项调查显示，尽管超过半数的青少年每月都会使用AI陪伴应用，但其动机主要为短期尝鲜，而非长期付费。更为直观的是市场数据：头部产品用户月均使用仅5天，部分平台如“星野”的月活环比下滑超过三成。</p>
  <p>Soul在招股书中引用的弗若斯特沙利文报告显示，截至2025年前8个月，Soul在新安装用户的30日留存率达到23%，在中国AI+沉浸式社交平台中排名第一。可这一数据虽然领先行业，但仍反映出维持用户长期黏性的挑战。</p>
  <p>技术能力的一致性也是AI社交平台面临的共同难题。尤其是当市面上的模型能力越来越同质化，AI社交产品存在明显的“角色语言重复、记忆能力弱、剧情推动力不足”等通病；此外，UGC内容质量参差，大量角色陷入模板化困境。</p>
  <p>这些问题最终汇聚到整个行业的商业模式困境中。相关研报显示，海外头部产品Character.AI的2.33亿月活，仅对应1670万美元年收入，用户付费率低至0.72美元/年，甚至无法覆盖人力成本。</p>
  <blockquote>
   <p>相比之下，Soul的ARPPU达104.4元（约14.3美元），显示其付费转化效率领先，但能否持续维持高增长仍需市场检验。毕竟目前业内外相对统一的共识是，“AI社交似乎难以成为爆款大众赛道”，多数用户仍处于尝鲜阶段。</p>
  </blockquote>
  <p>面对这些挑战，Soul在招股书中表示，IPO募集所得资金净额将主要用于进一步研发AI能力、GPU能力和资料分析能力，以及在全球范围内拓展平台，接触更广泛的用户群体。</p>
  <p>这一战略方向与行业发展趋势相符。白惠天在研究报告中指出，“记忆和多模态交互为AI陪伴赋予了在场感”，未来的竞争将集中在技术深度和用户体验上。</p>
  <h2><strong>AI社交的隐形合规红线一直在</strong></h2>
  <p><strong>更大的外部困难则在于监管与伦理边界的摸索。不久前，腾讯阅文旗下“筑梦岛”因低俗内容被约谈再度引发行业对AI社交边界的反思。</strong></p>
  <p>一方面，AI社交陪伴深入情感世界，其价值与风险并存。另一方面，过度依赖虚拟关系可能加剧现实孤独感，未成年人保护更成监管重点。</p>
  <p>作为年轻群体的聚集地，Soul在招股书中明确将投入研发安全机制，这与行业趋势相符。其全虚拟身份设计虽规避颜值歧视，但也面临内容治理挑战。</p>
  <p><strong>随着全球监管收紧，AI社交平台需在创新与合规间寻找平衡。Soul的上市结果，部分还将取决于其治理能力能否获得监管认可。</strong></p>
  <p>更重要的，资本市场有多大的意愿却接受纯“AI社交”的资本故事。至少目前，历经过去多次，投资人对AI社交态度已趋谨慎。当前项目估值普遍下降，ROI压力凸显。</p>
  <p>Soul虽获腾讯（持股49.9%，有28.5%的投票权）、米哈游、元生资本等机构投资，但上市后，平台仍需用增长、盈利、监管之间的立体平衡，向市场证明AI社交可构建健康商业生态。</p>
  <p>本文来自微信公众号 <a href="https://mp.weixin.qq.com/s?__biz=MzkzMTczMjQwMw==&amp;mid=2247574498&amp;idx=4&amp;sn=79079fa68d132b7b317d878fa07dd0fc&amp;chksm=c344192632254c1871470b4163a041cbbbb1f5bd9b1fa0b7cb11c478f443b450230beb0f6da9&amp;scene=0&amp;xtrack=1#rd" rel="noopener noreferrer nofollow" target="_blank">“港股研究社”（ID：ganggushe）</a>，作者：港股研究社，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3572629001206664</id>
            <title>“18个月火速弃用Office”，7年前立的Flag翻车，这家巨头至今未能完全摆脱微软，现任高管：当初预估得太乐观</title>
            <link>https://www.36kr.com/p/3572629001206664</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3572629001206664</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Nov 2025 11:31:28 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>作为 PC 行业的软件巨头，微软的 Windows 和 Office 已成各行各业绕不开的基础软件。然而，一些公司曾出于成本、协作方式、使用习惯等原因，一度萌生过“弃用”的念头。但事实证明，基础软件的迁移往往远比想象中复杂得多。</p>
  <p>2018 年，欧洲一家民航巨头空客（Airbus）就信心满满地宣布，要摆脱微软的束缚，其计划将 130,000 名员工从 Microsoft Office 办公软件转向 Google Workspace（彼时还叫做 G Suite），并预计使用 18 个月就能完成迁移。</p>
  <p>然而，时至今日，据外媒 The Register 报道，Airbus&nbsp;的“去微软化”之路仍然遥遥无期。理论上，这是一家世界 500 强企业，资金雄厚、人才顶尖，为什么迁移如此困难？这个问题也引发了外界的广泛关注。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_2f2db5bc5f0f40c9a93e114e44c195e4@5888275_oswg954563oswg1024oswg1024_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p class="img-desc">图源 Nano Banana</p>
  <h2><strong>迁移计划：淘汰本地部署的 Office，迈向云端数字化</strong></h2>
  <p>7 年前，Airbus&nbsp;时任 CEO Tom Enders 在一份内部备忘录中表示，这一决定将塑造公司的未来，也是企业数字化转型的新阶段。</p>
  <p>为此，他们计划把全部员工迁移到 Google 的云端办公与协作工具上，同时淘汰本地部署的 Microsoft Office 软件。</p>
  <p>Tom Enders 强调：“我们需要能够积极支持新工作方式的技术，需要现代化的数字工具，使我们能够真正协作，跨团队、跨国界、跨时区工作——真正实现一体化。”</p>
  <p>他还表示，选择 G Suite 是一个战略性决定，既是与过去彻底割裂，也确保业务连续性。他还承诺员工将获得充分支持和培训，使得这些操作更加方便实用，同时也能借助 Google 搜索打破信息孤岛。</p>
  <blockquote>
   <p>简单来看，G Suite 是在谷歌提供的订阅服务基础上提供的一套云计算生产力和协作软件工具和软件，最初于 2006 年以 Google Apps for Your Domain 名义推出，2020 年更名为 Google Workspace。</p>
  </blockquote>
  <p>Enders 曾预计，覆盖所有 130,000 名员工的工具迁移工作最多需要 18 个月的时间就能完成。</p>
  <p>值得一提的是，当时 Airbus 并非只有谷歌一个选择——理论上，他们完全可以迁移到 Office 365，但不知为何，其最终并未选择微软的云端服务。</p>
  <h2><strong>Google Workspace 为什么无法完全替代 Office？</strong></h2>
  <p>回顾当初的计划，Airbus&nbsp;数字化部门执行副总裁 Catherine Jestin 在接受外媒采访时直言，18 个月的预估真的过于乐观了。</p>
  <p>这一决定，如今也让这家公司似乎陷入了两难的局面。</p>
  <p>基于过去几年的发展，Airbus 的员工数量已经从 13 万人增长到了 15 万，外媒 The Register 称，虽然这家公司内部超过三分之二的员工已经完全切换到谷歌工具，但仍有相当一部分团队在并行使用微软软件。</p>
  <p>为什么“去不掉”微软？原因有很多：</p>
  <p><strong>其一，Excel 在处理大型文件时仍具有不可替代的优势。</strong></p>
  <p>以&nbsp;Airbus&nbsp;财务团队为例，他们的一些电子表格单个文件就包含 2000 万个单元格，远超 Google Sheets 在云端的处理能力。对于需要处理大规模数据、复杂计算和报表的财务系统而言，这是一个难以逾越的技术瓶颈。</p>
  <p>换句话说，这不是功能不够，而是数据量过大让云表格力不从心，因此这家公司的财务部门至今仍依赖本地 Excel。</p>
  <p><strong>其二，一些团队需要高级文档管理功能。</strong></p>
  <p>一些譬如商业、采购和法律团队在合同管理、审批流程中，需要严谨、可审计的“变更追踪”功能。据 The Register 报道，当前 Google Workspace 在这类高级文档／合同追踪功能上的表现尚未达到理想状态。</p>
  <p><strong>其三，法规与数据安全的限制。</strong></p>
  <p>这一点其实也非常好理解，企业内部的部分机密或保密文档不能存储在云端，这意味着许多工作仍需在本地完成。尽管 Google Workspace 协作体验不错，但在合规性和数据主权方面存在局限，导致迁移无法全面覆盖。</p>
  <p>基于以上种种，Airbus 虽然努力地迁移了七年，当前只能维持 “部分使用 Google，部分用 Microsoft” 的混合状态。这不仅导致成本居高不下，而且还带来了各种兼容性问题。</p>
  <p>一个本地办公软件、一个云端工具，又所属不同的科技巨头，所以很多员工抱怨称，「文档格式不一致、功能差异、协作冲突，影响了工作效率和协同流程。」</p>
  <p>对此，身为高管的&nbsp;Catherine Jestin 也坦言，“当部分工作在 Google Workspace 中进行，而另一部分在微软工具中进行时，就会出现兼容性问题。谷歌正在解决这一点，明年我们应该能看到一个 100% 完全兼容的版本。”</p>
  <h2><strong>迁移难题引发的热议</strong></h2>
  <p>对于大型企业来说，迁移不仅是技术问题，更是一项系统工程，毕竟它牵扯的不单纯是工具更换，也会包含流程重塑、职责调整，甚至是组织文化的重建。</p>
  <p>从当初扬言 18 个月内完全弃用 Office，到如今两种工具并行使用，这一过程引发了网友热议。</p>
  <p>有人惊讶于电子表格的庞大数据：“2000 万个单元格，真的有这么夸张吗？”也有人表示：“作为过来人，我可以确认，企业确实会有这么多单元格。”</p>
  <p>也有人指出，不少员工使用 Excel，已经形成了自己的舒适区和现有惯性，这也是很多公司不愿脱离微软生态的重要原因。</p>
  <p>还有网友还辣评道：</p>
  <p>“很难理解为什么有人认为用另一个美国巨头来替换现有供应商是个好主意。不过当时重点可能只是节省 Office 许可成本，而非现代化问题。成本考虑确实合理，但如果本地方案已能处理大数据，为何还要迁移到云端？LibreOffice 虽非完美，但从 Office 切换到 LibreOffice 的文化冲击远小于从本地迁移到云端。</p>
  <p>我怀疑是有人给财务人员演示了同一个 Google Sheet 在两台屏幕上同时显示，在一台上修改后发现另一台自动同步，于是就认为这才是真正的解决方案。我自己也曾在客户演示中这么做过，而那些因长期 Excel 版本控制混乱而心生阴影的老用户们的反应，真是令人印象深刻。”</p>
  <p>总的来看，一些基础软件即便切换到云端，很多问题并不会自动消失，因为云表格在功能、性能、稳定性和合规性上，远未必能达到传统本地软件的标准。对此，你怎么看？</p>
  <p>参考：https://www.theregister.com/2025/11/26/microsoft_airbus_migration</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/6cquMdiUZ2BdccR3YTiNxA" rel="noopener noreferrer nofollow" target="_blank">“CSDN”</a>，整理：苏宓，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3572628833139843</id>
            <title>苹果AI论文太坑了，用GPT写的GT，导致北京程序员通宵加班</title>
            <link>https://www.36kr.com/p/3572628833139843</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3572628833139843</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Nov 2025 11:30:15 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>大无语事件天天有，今天特别多——</p>
  <p><strong>AI大模型公司阶跃星辰的研究员，自曝被苹果挂在arXiv上的论文，狠狠坑了一把。</strong></p>
  <p>自己去反馈问题，对方简单回了两句就把issue关了；直到自己留下公开评论，对方才撤稿下架代码了。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_9fc85bd7a99c485282b58dc0d6a75df6@5888275_oswg57380oswg1080oswg236_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>别着急，我们先来梗概一下故事线：</p>
  <p>这个月月初，阶跃研究员Lei Yang被同事安利了一篇arXiv上苹果出品的论文（该论文也在投ICLR 2026），论文中提出的benchmark和Lei Yang最近做的研究非常契合。</p>
  <p>他超级开心，马上停下手头的工作，开始适配这个benchmark。</p>
  <p>结果这个声称“小模型全面超越GPT-5、数据经人工精心把控”的视觉benchmark，<strong>实际上却存在荒谬的官方代码bug和高达约30%的GT（Ground Truth）错误率</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_f9b0c7b3f15e41f88beada707750ac67@5888275_oswg42021oswg234oswg240_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>看到这儿，你是不是已经觉得够离谱了？</p>
  <p>不好意思了朋友们，<strong>这还不是最离谱的</strong>……后续的故事看得人脑子上一个问号接一个问号冒出来。</p>
  <p>这场闹剧的荒诞程度，一步步升级，直到最终Lei Yang“公开把它喷撤稿了”。</p>
  <p>总之看得围观的Reddit吃瓜网友连连摇头：</p>
  <blockquote>
   <p>我们曾拥有BatchNorm、ResNet、Dropout、Transformer这些革命性成果。但到了大模型时代看起来真的是一团糟。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_cf9d940dd71745d5baef4f5bd517a295@5888275_oswg66202oswg1080oswg301_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>好了，咱们一起来详细看看这个大无语事件到底是怎么回事。</p>
  <h2><strong>什么，GT的错误率可能高达30%？</strong></h2>
  <p>这个荒诞故事涉及的论文名为《Where Did the Reasoning Go Wrong? A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection》。</p>
  <p>它提出了一个基于谜题的视觉推理任务的诊断benmark。</p>
  <p>巧的是，论文中提出的这个新benchmark，和Lei Yang近期的研究方向挺契合。</p>
  <p>所以Lei Yang读完论文后，停下手头其他工作，开始着手适配。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_f6de9ad8454e434f9c31867173b4a909@5888275_oswg306131oswg636oswg502_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>没想到的是，熬了一个周末的通宵完成适配后，<strong>模型跑出来的点数极其之低</strong>，远低于预期。</p>
  <p>“我非常沮丧。”Lei Yang又开始做各种检查和尝试。</p>
  <p>这个阶段就开始出现不对劲了。<strong>Lei Yang发现了官方代码的bug</strong>：</p>
  <blockquote>
   <p>请求VLM的时候只用了图片路径的字符串，而不包含图片本身。</p>
  </blockquote>
  <p>行，有bug咱们就修bug呗！</p>
  <p>好家伙，<strong>修复这个bug后，模型的点数更低了</strong>……</p>
  <p>这结果给Lei Yang干懵了。他在多个平台公开的小作文中写道：“由于结果过于离谱，我不得不做更多的验证工作，最终结论仍然是修了bug后点会更低。”</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_ca769042262e4f4685607b816b76ae70@5888275_oswg67475oswg234oswg230_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>不得已，Lei Yang决定一条一条地分析错题，看看自家的模型是怎么做错的。</p>
  <p>他抽查了前20道阶跃模型答错的题，结果令人大吃一惊：</p>
  <p>里面有6道题明确属于GT错误。</p>
  <p>从GT错误风格来看，很可能是模型自动生成的GT加上质检严重不足，导致GT包含大量幻觉。</p>
  <p>这意味着，写进论文里、作者精心挑选用于展示的内容存在大问题。</p>
  <p>他初步估算了一下，<strong>GT错误率可能高达30%</strong>。</p>
  <h2><strong>“我公开把它喷撤稿了”</strong></h2>
  <p>于是，Lei Yang选择在GitHub上向作者反馈，指出其中的错误。</p>
  <p>6天过后，<strong>论文作者简单回复了一下，然后直接关闭了issue</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_9c04cd8ba4074ec09fc4eba8d06f7113@5888275_oswg148009oswg1080oswg259_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>给Lei Yang气的呀，组织语言一通回击。</p>
  <p>然而这件荒谬事件没有最离谱，只有更离谱——</p>
  <p>ICLR review公布后，Lei Yang看了看该论文的<strong>5条reviews，居然没有任何一个审稿人发现GT质量问题，也没人发现论文中的例子存在幻觉和错误</strong>。</p>
  <p>（这里中插一下Openreview的直通车：https://openreview.net/forum?id=pS9jc2zxQz）</p>
  <p>愤怒之下，他撰写了一份详尽的Public Comment。</p>
  <p>内容大概是列举GT问题的实例，提醒ICLR审稿人和社区这个数据集质量堪忧、极易误导研究方向。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_c082106a5017497ab4db1c1e955df34d@5888275_oswg219914oswg1080oswg452_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>在这条评论最后，Lei Yang留了句话</p>
  <blockquote>
   <p>我在这里评论是为了<strong>防止有兴趣的研究人员重复我经历的相同循环</strong>——看到第一个错误检测任务时的兴奋，运行它后的震惊和失望，以及追踪底层GT问题后的沮丧——<strong>从而节省每个人的时间和精力</strong>。</p>
  </blockquote>
  <p>Fine，看似是输出愤怒，实则是真没招了，顺便警醒一下后来人不要再被坑。</p>
  <p>不少网友为Lei Yang的这个行为超棒的：</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_9ed24535b87846ec9f2fdbdd70efcca4@5888275_oswg107034oswg1080oswg363_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>最后，在<strong>这条公开评论发表的第二天，论文作者就宣布撤稿，并删除了GitHub上的repo</strong>。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_0f7e696e9fab4580ae4a0c32f55cd41f@5888275_oswg115075oswg1080oswg226_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <h2><strong>原论文作者公开回应</strong></h2>
  <p>这两天Lei Yang在多个平台分享自己的惨痛踩坑经历，希望通过分享这一遭遇，让更多研究者警觉起来，尤其不要盲目信任表面包装，哪怕是来自大公司。</p>
  <p>今天上午，论文作者在小地瓜（没错就是那个平台）上现身回应了。</p>
  <p>他首先<strong>声明自己这边已经和Lei Yang详细交流</strong>，也感谢和尊重推动学术社区进展的每个人。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_718cb8b85d5e473793972956e534e192@5888275_oswg81576oswg230oswg220_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>我们梳理了一下论文作者的回应。</p>
  <p><strong>首先关于数据质量，作者承认审核不周</strong>。</p>
  <p>虽然当初对injected error（人为注入错误）的样本做了人工检查，但没有认真审核更关键的部分。</p>
  <p>所以也就没有留意到GT解答思路由GPT自动转换成分步骤CoT时出现了幻觉，导致step label出现了问题。</p>
  <p>这部分实质上承认了此次荒谬事件中最核心的问题，即自动构建数据时的质检严重不足。</p>
  <p><strong>其次说了说关于论文中example inference的事儿。</strong></p>
  <p>他解释称项目中的example inference代码是一个dummy示例，不是正式的演示代码。</p>
  <p>在o3的输出例子中，是可以看到模型确实看到了图片的。</p>
  <p>然后，他表示<strong>当时接收到Lei Yang的提醒后，修改了dummy代码</strong>，并且回复了Lei Yang。</p>
  <p>最后他对自己当时直接关闭了issue感到非常抱歉。</p>
  <p>“当时reopen并且回复了新提出的问题，下次也会一直开着直到问题全部解决。”</p>
  <p>回应贴的最后一点是这么写的：</p>
  <blockquote>
   <p>我们的目标包括这个benchmark的目的都是推进各个研究方向，在做数据时有不应出现的疏忽，但我们各自都是出于对这个方向的兴趣，利用业余时间在做这个项目，也在其中花费了大量时间精力为了推进这个小方向的发展。我们<strong>会认真总结这次的经验教训</strong>，再接再厉。</p>
  </blockquote>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_1480e271bbe34d2c90250778452e4d0c@5888275_oswg358240oswg1080oswg635_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>参考链接：</p>
  <p>[1]https://x.com/diyerxx/status/1994042370376032701</p>
  <p>[2]https://www.reddit.com/r/MachineLearning/comments/1p82cto/d_got_burned_by_an_apple_iclr_paper_it_was/</p>
  <p>[3]https://www.xiaohongshu.com/explore/6928aaf8000000001b022d64?app_platform=ios&amp;app_version=9.10&amp;share_from_user_hidden=true&amp;xsec_source=app_share&amp;type=normal&amp;xsec_token=CBLEH7cvuVDNN78gtS-RUB8YQp0_GXstBHlQAk14v6t8I=&amp;author_share=1&amp;xhsshare=WeixinSession&amp;shareRedId=NzxHOEQ6OTw6Pjw3Sj81SD1HQUk5R0lK&amp;apptime=1764289526&amp;share_id=c73caa18d27a408898ea99622f8e0360</p>
  <p>[4]https://openreview.net/forum?id=pS9jc2zxQz</p>
  <p>[5]https://openreview.net/pdf/e5917f72a8373c7f56b3cb9c0ac881d991294ee2.pdf</p>
  <p class="editor-note">本文来自微信公众号<a href="https://mp.weixin.qq.com/s/0mCnTF-qYW08a2LpPdsXxA" rel="noopener noreferrer nofollow" target="_blank">“量子位”</a>，作者：关注前沿科技，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
        <item>
            <id>https://www.36kr.com/p/3572585284615046</id>
            <title>苹果北京直营店加入国补阵营，最高可享2000元优惠</title>
            <link>https://www.36kr.com/p/3572585284615046</link>
            <guid isPermaLink="false">https://www.36kr.com/p/3572585284615046</guid>
            <pubDate></pubDate>
            <updated>Fri, 28 Nov 2025 11:00:56 GMT</updated>
                
                
            <content:encoded>
                <![CDATA[
                    
                    <p>11月28日，界面新闻从苹果官网获悉，最新信息显示，北京地区的苹果Apple Store直营店正式加入国家补贴行列，消费者在购买指定产品时可享受最高2000元的优惠。以苹果最新版本的iPhone 17 256GB为例，其原价5999元，直接触发500元满额补贴，仅需5499元就可购买，成为本轮政策中性价比最高的旗舰机型。</p>
  <p>据界面新闻致电苹果官方电话，相关工作人员表示，这一次的补贴仅限苹果北京线下直营门店，线上下单购买的消费者需要到线下门店咨询工作人员相关具体流程。据其透露，此前，今年8、9月份，苹果北京、上海地区的线下直营门店都加入了国家补贴行列。但此后不久，北京地区停止了补贴活动，但上海地区一直参与补贴。</p>
  <p>目前，全国范围内，仅限于北京和上海的苹果线下直营门店参加国补。</p>
  <p class="image-wrapper"><img src="https://img.36krcdn.com/hsossms/20251128/v2_b0751509c59d4c4691147f25f586ceb1@5888275_oswg84494oswg1175oswg1079_img_000?x-oss-process=image/format,jpg/interlace,1" /></p>
  <p>官网信息显示，此次国补政策覆盖范围广泛，不仅限于手机产品，还涵盖iPad、Apple Watch、Mac等苹果全系数码设备。符合资格的消费者购买参与活动的&nbsp;iPhone、iPad、Apple Watch&nbsp;时，可享商品到手价基础上再立减&nbsp;15%&nbsp;的国家补贴，每件补贴不超过500元，仅限到手价不超过6000元的单件商品；购买参与活动的Mac时，可享商品到手价基础上再立减&nbsp;20%&nbsp;的国家补贴，每件补贴不超过2000元。政策还提醒消费者，参与国家补贴活动的产品范围可能因政策要求等原因进行调整。实际补贴金额以商品购买页面展示为准。</p>
  <p>值得注意的是，除苹果Mac外，iPhone、iPad、Apple Watch等单价超过6000元的单件商品不参与此次补贴。</p>
  <p>此外，参与国家补贴的订单不支持与&nbsp;iPhone&nbsp;年年焕新计划、Apple Trade In&nbsp;换购计划或&nbsp;AppleCare+&nbsp;服务计划同时下单购买。参与国家补贴的订单不支持部分退款，不支持换货，不支持保价退差。</p>
  <p>政策还要求，在北京和上海地区&nbsp;Apple Store&nbsp;零售店参与活动的消费者必须出示身份证件，提供姓名，用以按要求开具个人实名信息的发票。此外，在北京地区&nbsp;Apple Store&nbsp;零售店参与活动的消费者必须输入身份证号、手机号码等个人信息，用以核实消费者和补贴资格领用者为同一人并绑定补贴资格，该等信息由银联商务支付股份有限公司北京分公司收集和处理。</p>
  <p>需要提醒的是，参与国家补贴的Apple Store&nbsp;零售店订单，消费者购买后需在门店配合工作人员完成现场拆封、激活及拍照存档等国家补贴政策所要求的操作。如不能在购买当场完成激活或配合拍照存档等操作，则无法享受国家补贴。</p>
  <p>苹果今年最新推出的iPhone 17系列很畅销。市场研究机构CounterPoint Research的数据显示，iPhone 17系列上市首月，苹果在部分市场的手机销量增长高达22%，而同期全球智能手机市场整体却下滑了2.7%。在中国市场，10月份iPhone的销量占据了当月手机总销量的四分之一，其中80%的销量来自新款iPhone 17系列。</p>
  <p>本文来自“<a href="https://www.jiemian.com/article/13695621.html" rel="noopener noreferrer nofollow" target="_blank">界面新闻</a>”，记者：彭朋，36氪经授权发布。</p>
                ]]>
            </content:encoded>
        </item>
        
    </channel>
</rss>